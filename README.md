# American-sign-language-classifiction-
extracting landmarks via Mediapipe library and build model using Tensorflow and Kerass 
Using the Mediapipe library, I developed a model in Keras and TensorFlow for sign language classification. The model utilizes a combination of GRU and dense layers to classify signs into 174 different classes. To extract key features for classification, such as face, left hand, and right hand landmarks, I employed the Mediapipe library. This allowed the model to learn the intricate patterns of sign language gestures. The GRU layers in the model help capture the sequential nature of sign language, while the dense layers aid in the final classification. Overall, the project aimed to provide an accurate and efficient model for sign language classification, leveraging both the power of deep learning and the precision of landmark extraction.
