{
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "LKlPaPDD4vhO",
        "2GgYLT5FNQ_s",
        "VmwW_-aw-S3D",
        "xz52iA7bJj4s",
        "7zWeLRkZNe4z",
        "nUSMtzeZJwjA",
        "dDJy4FTKKHOI",
        "iL2Wlnu4KQF6",
        "k_hkkI68KvQW"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Drive & Clone & Unrar"
      ],
      "metadata": {
        "id": "Fcf5CZmlU4Eh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to Drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "id": "c-E8wyi0Pftu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a4c72b3-ec95-4f85-c9ee-c7d3297a9846"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install mediapipe library"
      ],
      "metadata": {
        "id": "LKlPaPDD4vhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe"
      ],
      "metadata": {
        "id": "1o8ifBk2LuhN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdce771b-3db8-4e8f-9ea9-066ea1a64ef7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.8/34.8 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.5.26)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.23)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.25.2)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.8.0.76)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.20.3)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.11.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Installing collected packages: sounddevice, mediapipe\n",
            "Successfully installed mediapipe-0.10.10 sounddevice-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Librarys"
      ],
      "metadata": {
        "id": "2GgYLT5FNQ_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import PIL\n",
        "import shutil\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.python.client import device_lib\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam,RMSprop,Adadelta\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import InceptionV3, ResNet50, MobileNetV2,VGG16,EfficientNetB0\n",
        "from tensorflow.keras.layers import Input,GRU, Conv2D, MaxPooling2D, Concatenate, Flatten, Dense, Dropout,GlobalAveragePooling2D\n",
        "\n"
      ],
      "metadata": {
        "id": "zt8Yvepr5Dmw",
        "execution": {
          "iopub.status.busy": "2023-06-23T16:06:46.816264Z",
          "iopub.execute_input": "2023-06-23T16:06:46.816764Z",
          "iopub.status.idle": "2023-06-23T16:06:57.052669Z",
          "shell.execute_reply.started": "2023-06-23T16:06:46.816726Z",
          "shell.execute_reply": "2023-06-23T16:06:57.050796Z"
        },
        "jupyter": {
          "source_hidden": true
        },
        "trusted": true
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Default Variables\n",
        "batch_size = 32\n",
        "img_height = 64 # 64\n",
        "img_width = 64  # 64\n",
        "\n",
        "# LR and Dropout\n",
        "lr = 0.009\n",
        "dropout_rate = 0.2\n",
        "\n",
        "input_shape = (img_height, img_width, 3)\n",
        "\n",
        "class_names = [name for name in os.listdir('/content/gdrive/MyDrive/asl_client_dataset')]\n",
        "print(f\"Total Classes {len(class_names)}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ELVRnJixk2Sl",
        "execution": {
          "iopub.status.busy": "2023-06-23T16:07:55.080418Z",
          "iopub.execute_input": "2023-06-23T16:07:55.081470Z",
          "iopub.status.idle": "2023-06-23T16:07:55.405194Z",
          "shell.execute_reply.started": "2023-06-23T16:07:55.081418Z",
          "shell.execute_reply": "2023-06-23T16:07:55.404132Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2691ba2-94da-4ba4-f179-bad665df6640"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Classes 174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to Plot Train History"
      ],
      "metadata": {
        "id": "VmwW_-aw-S3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_history(history,epochs=500):\n",
        "  acc = history.history['accuracy']\n",
        "  val_acc = history.history['val_accuracy']\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "  epochs_range = range(epochs)\n",
        "  plt.figure(figsize=(15, 5))\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "  plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "  plt.legend(loc='lower right')\n",
        "  plt.title('Training and Validation Accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.plot(epochs_range, loss, label='Training Loss')\n",
        "  plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "  plt.legend(loc='upper right')\n",
        "  plt.title('Training and Validation Loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "gLFWJ73ChW-Y",
        "execution": {
          "iopub.status.busy": "2023-06-23T16:08:05.495362Z",
          "iopub.execute_input": "2023-06-23T16:08:05.495854Z",
          "iopub.status.idle": "2023-06-23T16:08:05.506320Z",
          "shell.execute_reply.started": "2023-06-23T16:08:05.495817Z",
          "shell.execute_reply": "2023-06-23T16:08:05.504990Z"
        },
        "trusted": true
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Copy first 50  images from each class"
      ],
      "metadata": {
        "id": "xz52iA7bJj4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counter=0\n",
        "# Path to the dataset folder\n",
        "dataset_path = '/content/gdrive/MyDrive/asl_client_dataset'\n",
        "\n",
        "# Path to the folder where you want to copy the images\n",
        "output_path = '/content/d'\n",
        "os.mkdir('d')\n",
        "# Loop through each folder in the dataset folder\n",
        "for folder_name in os.listdir(dataset_path):\n",
        "    folder_path = os.path.join(dataset_path, folder_name)\n",
        "    subfolder_path=os.path.join(output_path,folder_name)\n",
        "\n",
        "    os.mkdir(subfolder_path)\n",
        "    print(counter )\n",
        "    counter+=1\n",
        "    # Check if the path is a directory\n",
        "    if os.path.isdir(folder_path):\n",
        "        # Get the list of images in the folder\n",
        "        images = os.listdir(folder_path)\n",
        "        # Copy the first 50 images to the output folder\n",
        "        for i in range(50):\n",
        "          image_path = os.path.join(folder_path, images[i])\n",
        "          shutil.copy(image_path, subfolder_path)\n"
      ],
      "metadata": {
        "id": "EgPe-Y5O6faY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# show some images"
      ],
      "metadata": {
        "id": "7zWeLRkZNe4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Path to the folder containing the images\n",
        "folder_path = '/content/gdrive/MyDrive/asl_client_dataset'\n",
        "\n",
        "# Get the list of subfolders (classes)\n",
        "classes = sorted(os.listdir(folder_path))\n",
        "\n",
        "# Plot the first image in the first 10 classes\n",
        "plt.figure(figsize=(20, 8))\n",
        "for i, class_name in enumerate(classes[:10]):\n",
        "    class_path = os.path.join(folder_path, class_name)\n",
        "    images = os.listdir(class_path)\n",
        "    img_path = os.path.join(class_path, images[0])\n",
        "    img = mpimg.imread(img_path)\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(class_name)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "id": "Ae6KIgxTNhn_",
        "outputId": "5805a873-9c8f-4d5e-8ba8-b3dec0012a68"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x800 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract th face ,(left,right) hands and Face landmarks from each image"
      ],
      "metadata": {
        "id": "nUSMtzeZJwjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Load the MediaPipe Holistic model\n",
        "mp_holistic = mp.solutions.holistic\n",
        "holistic = mp_holistic.Holistic(static_image_mode=True)\n",
        "\n",
        "# Path to your main folder containing subfolders\n",
        "main_folder_path = '/content/gdrive/MyDrive/asl_client_dataset'\n",
        "\n",
        "# List to store the extracted features\n",
        "features = []\n",
        "counter=0\n",
        "counter1=0\n",
        "# Iterate over the subfolders in the main folder\n",
        "for subfolder in os.listdir(main_folder_path):\n",
        "    print(counter)\n",
        "    counter+=1\n",
        "    subfolder_path = os.path.join(main_folder_path, subfolder)\n",
        "    if os.path.isdir(subfolder_path):\n",
        "        # Iterate over the images in the subfolder\n",
        "        for filename in os.listdir(subfolder_path):\n",
        "\n",
        "            if filename.endswith('.png'):\n",
        "                # Load the image\n",
        "                image_path = os.path.join(subfolder_path, filename)\n",
        "                image = cv2.imread(image_path)\n",
        "                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "                # Process the image with the MediaPipe Holistic model\n",
        "                results = holistic.process(image_rgb)\n",
        "\n",
        "                # Extract facial features, pose landmarks, and hand landmarks\n",
        "                if results.face_landmarks:\n",
        "                    face_landmarks = [landmark.x for landmark in results.face_landmarks.landmark]\n",
        "                else:\n",
        "                    face_landmarks = [0] * 468  # If no face landmarks detected, use zeros\n",
        "\n",
        "                if results.pose_landmarks:\n",
        "                    pose_landmarks = [landmark.x for landmark in results.pose_landmarks.landmark]\n",
        "                else:\n",
        "                    pose_landmarks = [0] * 33  # If no pose landmarks detected, use zeros\n",
        "\n",
        "                if results.left_hand_landmarks:\n",
        "                    left_hand_landmarks = [landmark.x for landmark in results.left_hand_landmarks.landmark]\n",
        "                else:\n",
        "                    left_hand_landmarks = [0] * 21  # If no left hand landmarks detected, use zeros\n",
        "\n",
        "                if results.right_hand_landmarks:\n",
        "                    right_hand_landmarks = [landmark.x for landmark in results.right_hand_landmarks.landmark]\n",
        "                else:\n",
        "                    right_hand_landmarks = [0] * 21  # If no right hand landmarks detected, use zeros\n",
        "\n",
        "                # Store the extracted features\n",
        "                features.append({\n",
        "                    'filename': filename,\n",
        "                    'subfolder': subfolder,\n",
        "                    'face_landmarks': face_landmarks,\n",
        "                    'pose_landmarks': pose_landmarks,\n",
        "                    'left_hand_landmarks': left_hand_landmarks,\n",
        "                    'right_hand_landmarks': right_hand_landmarks\n",
        "                })\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SN7NYHlrGqDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*italicized text*# Convert the features list to a DataFrame"
      ],
      "metadata": {
        "id": "dDJy4FTKKHOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(features)"
      ],
      "metadata": {
        "id": "auavNV4FKF4E"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save the DataFrame to a pickl file\n"
      ],
      "metadata": {
        "id": "iL2Wlnu4KQF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_pickle('asl_landmarks.pkl')"
      ],
      "metadata": {
        "id": "MH_A3vhwKMKa"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Release resources"
      ],
      "metadata": {
        "id": "k_hkkI68KvQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "holistic.close()"
      ],
      "metadata": {
        "id": "8gE3OVrwKNyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# read the data from pickl file"
      ],
      "metadata": {
        "id": "_R8Q7IFjLFTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_pickle('/content/gdrive/MyDrive/asl_landmarks.pkl')"
      ],
      "metadata": {
        "id": "qbOMweaW9QTM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "xwaJo1HT_ezB",
        "outputId": "3a5adb57-8797-46e7-d6d7-1aa7231868bd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  filename subfolder                                     face_landmarks  \\\n",
              "0   25.png      News  [0.5167853832244873, 0.5138649940490723, 0.515...   \n",
              "1   26.png      News  [0.5171927213668823, 0.5157039761543274, 0.516...   \n",
              "2   27.png      News  [0.5185508131980896, 0.5180432796478271, 0.518...   \n",
              "3   28.png      News  [0.5193772912025452, 0.5197213888168335, 0.519...   \n",
              "4   29.png      News  [0.5177680850028992, 0.5164494514465332, 0.517...   \n",
              "\n",
              "                                      pose_landmarks  \\\n",
              "0  [0.5257177352905273, 0.5443427562713623, 0.555...   \n",
              "1  [0.5269301533699036, 0.5445324778556824, 0.555...   \n",
              "2  [0.5265355110168457, 0.5442528128623962, 0.554...   \n",
              "3  [0.5244090557098389, 0.5427693128585815, 0.553...   \n",
              "4  [0.5238819718360901, 0.5427224636077881, 0.553...   \n",
              "\n",
              "                                 left_hand_landmarks  \\\n",
              "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "\n",
              "                                right_hand_landmarks  \n",
              "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2726bb4f-640a-4036-980b-553dcdb811d2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>subfolder</th>\n",
              "      <th>face_landmarks</th>\n",
              "      <th>pose_landmarks</th>\n",
              "      <th>left_hand_landmarks</th>\n",
              "      <th>right_hand_landmarks</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25.png</td>\n",
              "      <td>News</td>\n",
              "      <td>[0.5167853832244873, 0.5138649940490723, 0.515...</td>\n",
              "      <td>[0.5257177352905273, 0.5443427562713623, 0.555...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>26.png</td>\n",
              "      <td>News</td>\n",
              "      <td>[0.5171927213668823, 0.5157039761543274, 0.516...</td>\n",
              "      <td>[0.5269301533699036, 0.5445324778556824, 0.555...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>27.png</td>\n",
              "      <td>News</td>\n",
              "      <td>[0.5185508131980896, 0.5180432796478271, 0.518...</td>\n",
              "      <td>[0.5265355110168457, 0.5442528128623962, 0.554...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>28.png</td>\n",
              "      <td>News</td>\n",
              "      <td>[0.5193772912025452, 0.5197213888168335, 0.519...</td>\n",
              "      <td>[0.5244090557098389, 0.5427693128585815, 0.553...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>29.png</td>\n",
              "      <td>News</td>\n",
              "      <td>[0.5177680850028992, 0.5164494514465332, 0.517...</td>\n",
              "      <td>[0.5238819718360901, 0.5427224636077881, 0.553...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2726bb4f-640a-4036-980b-553dcdb811d2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2726bb4f-640a-4036-980b-553dcdb811d2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2726bb4f-640a-4036-980b-553dcdb811d2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-819c982f-c161-4578-93dd-0de94d19e864\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-819c982f-c161-4578-93dd-0de94d19e864')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-819c982f-c161-4578-93dd-0de94d19e864 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 15620,\n  \"fields\": [\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 226,\n        \"samples\": [\n          \"34.png\",\n          \"209.png\",\n          \"145.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subfolder\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 174,\n        \"samples\": [\n          \"Climbs\",\n          \"Chooses\",\n          \"Please\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"face_landmarks\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pose_landmarks\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"left_hand_landmarks\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"right_hand_landmarks\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# combine data"
      ],
      "metadata": {
        "id": "10GO9iFZqO-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['all_future']=df.face_landmarks+\tdf.pose_landmarks\t+df.left_hand_landmarks\t+df.right_hand_landmarks\n"
      ],
      "metadata": {
        "id": "bKw7V1smKetA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UNFin3eSvWY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# make it as numpy array"
      ],
      "metadata": {
        "id": "Tzc_VR-QvXCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X= np.asarray(df['all_future'])\n",
        "X = np.array(X.tolist())\n",
        "X = X.reshape((X.shape[0], 1, X.shape[1]))"
      ],
      "metadata": {
        "id": "R2UIcBhGFeTM"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split data set and convert label from categorical to numerical  data"
      ],
      "metadata": {
        "id": "c2FP9SDbgI7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, df['subfolder'], test_size=0.2, random_state=42)\n",
        "# Initialize the LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit and transform the target classes (y_train and y_test)\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)"
      ],
      "metadata": {
        "id": "yKNKxwlGzIV6"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make the model\n"
      ],
      "metadata": {
        "id": "rJd8jwCkvcgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Assuming you have 174 classes\n",
        "num_classes = 174\n",
        "\n",
        "model = Sequential()\n",
        "model.add(GRU(128, return_sequences=True, input_shape=(1, 543)))\n",
        "model.add(GRU(128, return_sequences=True))\n",
        "model.add(GRU(64, return_sequences=True))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgP_Uo6q_qWR",
        "outputId": "b6ab13c4-3913-419e-f75e-c4109a668df0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru (GRU)                   (None, 1, 128)            258432    \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 1, 128)            99072     \n",
            "                                                                 \n",
            " gru_2 (GRU)                 (None, 1, 64)             37248     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 32)                12416     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 174)               5742      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 412910 (1.58 MB)\n",
            "Trainable params: 412910 (1.58 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, df['subfolder'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model"
      ],
      "metadata": {
        "id": "GIvmvRruAguo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train model"
      ],
      "metadata": {
        "id": "JvNsNz02wQGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filepath       = \"/content/asl/Adam/cp-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint     = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "history = model.fit(X_train, y_train_encoded, validation_data=(X_test, y_test_encoded), epochs=700, batch_size=32,callbacks=callbacks_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EKPd-V8AgmV",
        "outputId": "77cd0cfd-582a-4cc3-e531-7fefa12fe8c9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 5.1158 - accuracy: 0.0068\n",
            "Epoch 1: val_accuracy improved from -inf to 0.00920, saving model to /content/asl/Adam/cp-01-0.01.hdf5\n",
            "218/218 [==============================] - 12s 15ms/step - loss: 5.1158 - accuracy: 0.0068 - val_loss: 4.9691 - val_accuracy: 0.0092\n",
            "Epoch 2/700\n",
            " 15/218 [=>............................] - ETA: 1s - loss: 4.9601 - accuracy: 0.0063    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "214/218 [============================>.] - ETA: 0s - loss: 4.9446 - accuracy: 0.0082\n",
            "Epoch 2: val_accuracy did not improve from 0.00920\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 4.9435 - accuracy: 0.0083 - val_loss: 4.8990 - val_accuracy: 0.0063\n",
            "Epoch 3/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 4.8671 - accuracy: 0.0137\n",
            "Epoch 3: val_accuracy improved from 0.00920 to 0.01667, saving model to /content/asl/Adam/cp-03-0.02.hdf5\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 4.8676 - accuracy: 0.0138 - val_loss: 4.8332 - val_accuracy: 0.0167\n",
            "Epoch 4/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 4.8025 - accuracy: 0.0171\n",
            "Epoch 4: val_accuracy improved from 0.01667 to 0.02069, saving model to /content/asl/Adam/cp-04-0.02.hdf5\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 4.8012 - accuracy: 0.0170 - val_loss: 4.7667 - val_accuracy: 0.0207\n",
            "Epoch 5/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 4.7466 - accuracy: 0.0176\n",
            "Epoch 5: val_accuracy did not improve from 0.02069\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 4.7475 - accuracy: 0.0177 - val_loss: 4.7465 - val_accuracy: 0.0207\n",
            "Epoch 6/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 4.6928 - accuracy: 0.0230\n",
            "Epoch 6: val_accuracy improved from 0.02069 to 0.02126, saving model to /content/asl/Adam/cp-06-0.02.hdf5\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 4.6935 - accuracy: 0.0228 - val_loss: 4.7181 - val_accuracy: 0.0213\n",
            "Epoch 7/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 4.6507 - accuracy: 0.0228\n",
            "Epoch 7: val_accuracy did not improve from 0.02126\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 4.6498 - accuracy: 0.0228 - val_loss: 4.6119 - val_accuracy: 0.0207\n",
            "Epoch 8/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 4.6042 - accuracy: 0.0276\n",
            "Epoch 8: val_accuracy improved from 0.02126 to 0.02586, saving model to /content/asl/Adam/cp-08-0.03.hdf5\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 4.6035 - accuracy: 0.0276 - val_loss: 4.5748 - val_accuracy: 0.0259\n",
            "Epoch 9/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 4.5696 - accuracy: 0.0292\n",
            "Epoch 9: val_accuracy did not improve from 0.02586\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 4.5714 - accuracy: 0.0293 - val_loss: 4.5571 - val_accuracy: 0.0253\n",
            "Epoch 10/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 4.5445 - accuracy: 0.0331\n",
            "Epoch 10: val_accuracy improved from 0.02586 to 0.03218, saving model to /content/asl/Adam/cp-10-0.03.hdf5\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 4.5439 - accuracy: 0.0329 - val_loss: 4.5212 - val_accuracy: 0.0322\n",
            "Epoch 11/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 4.5182 - accuracy: 0.0320\n",
            "Epoch 11: val_accuracy did not improve from 0.03218\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 4.5203 - accuracy: 0.0319 - val_loss: 4.5459 - val_accuracy: 0.0264\n",
            "Epoch 12/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 4.4968 - accuracy: 0.0350\n",
            "Epoch 12: val_accuracy did not improve from 0.03218\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 4.4949 - accuracy: 0.0353 - val_loss: 4.4887 - val_accuracy: 0.0287\n",
            "Epoch 13/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 4.4738 - accuracy: 0.0384\n",
            "Epoch 13: val_accuracy did not improve from 0.03218\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 4.4742 - accuracy: 0.0381 - val_loss: 4.6001 - val_accuracy: 0.0316\n",
            "Epoch 14/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 4.4577 - accuracy: 0.0384\n",
            "Epoch 14: val_accuracy improved from 0.03218 to 0.03793, saving model to /content/asl/Adam/cp-14-0.04.hdf5\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 4.4577 - accuracy: 0.0384 - val_loss: 4.4495 - val_accuracy: 0.0379\n",
            "Epoch 15/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 4.4532 - accuracy: 0.0392\n",
            "Epoch 15: val_accuracy improved from 0.03793 to 0.04310, saving model to /content/asl/Adam/cp-15-0.04.hdf5\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 4.4538 - accuracy: 0.0391 - val_loss: 4.4260 - val_accuracy: 0.0431\n",
            "Epoch 16/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 4.4348 - accuracy: 0.0401\n",
            "Epoch 16: val_accuracy did not improve from 0.04310\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 4.4340 - accuracy: 0.0397 - val_loss: 4.4193 - val_accuracy: 0.0379\n",
            "Epoch 17/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 4.4102 - accuracy: 0.0430\n",
            "Epoch 17: val_accuracy did not improve from 0.04310\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 4.4133 - accuracy: 0.0427 - val_loss: 4.4209 - val_accuracy: 0.0420\n",
            "Epoch 18/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 4.4034 - accuracy: 0.0464\n",
            "Epoch 18: val_accuracy improved from 0.04310 to 0.04483, saving model to /content/asl/Adam/cp-18-0.04.hdf5\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 4.4042 - accuracy: 0.0464 - val_loss: 4.4009 - val_accuracy: 0.0448\n",
            "Epoch 19/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 4.3857 - accuracy: 0.0505\n",
            "Epoch 19: val_accuracy did not improve from 0.04483\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 4.3852 - accuracy: 0.0503 - val_loss: 4.4179 - val_accuracy: 0.0385\n",
            "Epoch 20/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 4.3828 - accuracy: 0.0501\n",
            "Epoch 20: val_accuracy did not improve from 0.04483\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 4.3816 - accuracy: 0.0500 - val_loss: 4.3878 - val_accuracy: 0.0391\n",
            "Epoch 21/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 4.3618 - accuracy: 0.0529\n",
            "Epoch 21: val_accuracy improved from 0.04483 to 0.05460, saving model to /content/asl/Adam/cp-21-0.05.hdf5\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 4.3619 - accuracy: 0.0527 - val_loss: 4.3497 - val_accuracy: 0.0546\n",
            "Epoch 22/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 4.3714 - accuracy: 0.0505\n",
            "Epoch 22: val_accuracy did not improve from 0.05460\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 4.3711 - accuracy: 0.0506 - val_loss: 4.3671 - val_accuracy: 0.0477\n",
            "Epoch 23/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 4.3456 - accuracy: 0.0517\n",
            "Epoch 23: val_accuracy did not improve from 0.05460\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 4.3456 - accuracy: 0.0517 - val_loss: 4.3288 - val_accuracy: 0.0437\n",
            "Epoch 24/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 4.3401 - accuracy: 0.0559\n",
            "Epoch 24: val_accuracy did not improve from 0.05460\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 4.3392 - accuracy: 0.0562 - val_loss: 4.3215 - val_accuracy: 0.0483\n",
            "Epoch 25/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 4.3135 - accuracy: 0.0552\n",
            "Epoch 25: val_accuracy did not improve from 0.05460\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 4.3149 - accuracy: 0.0553 - val_loss: 4.3020 - val_accuracy: 0.0529\n",
            "Epoch 26/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 4.3213 - accuracy: 0.0534\n",
            "Epoch 26: val_accuracy did not improve from 0.05460\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 4.3213 - accuracy: 0.0534 - val_loss: 4.3141 - val_accuracy: 0.0546\n",
            "Epoch 27/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 4.3121 - accuracy: 0.0516\n",
            "Epoch 27: val_accuracy improved from 0.05460 to 0.06092, saving model to /content/asl/Adam/cp-27-0.06.hdf5\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 4.3115 - accuracy: 0.0516 - val_loss: 4.2908 - val_accuracy: 0.0609\n",
            "Epoch 28/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 4.2893 - accuracy: 0.0609\n",
            "Epoch 28: val_accuracy did not improve from 0.06092\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 4.2871 - accuracy: 0.0608 - val_loss: 4.2745 - val_accuracy: 0.0609\n",
            "Epoch 29/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 4.2813 - accuracy: 0.0637\n",
            "Epoch 29: val_accuracy improved from 0.06092 to 0.06552, saving model to /content/asl/Adam/cp-29-0.07.hdf5\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 4.2814 - accuracy: 0.0636 - val_loss: 4.2612 - val_accuracy: 0.0655\n",
            "Epoch 30/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 4.2737 - accuracy: 0.0597\n",
            "Epoch 30: val_accuracy did not improve from 0.06552\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 4.2748 - accuracy: 0.0589 - val_loss: 4.2630 - val_accuracy: 0.0615\n",
            "Epoch 31/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 4.2694 - accuracy: 0.0609\n",
            "Epoch 31: val_accuracy did not improve from 0.06552\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 4.2711 - accuracy: 0.0605 - val_loss: 4.3118 - val_accuracy: 0.0506\n",
            "Epoch 32/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 4.2561 - accuracy: 0.0666\n",
            "Epoch 32: val_accuracy did not improve from 0.06552\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 4.2553 - accuracy: 0.0661 - val_loss: 4.3602 - val_accuracy: 0.0494\n",
            "Epoch 33/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 4.2558 - accuracy: 0.0634\n",
            "Epoch 33: val_accuracy improved from 0.06552 to 0.06724, saving model to /content/asl/Adam/cp-33-0.07.hdf5\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 4.2558 - accuracy: 0.0632 - val_loss: 4.2480 - val_accuracy: 0.0672\n",
            "Epoch 34/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 4.2349 - accuracy: 0.0685\n",
            "Epoch 34: val_accuracy improved from 0.06724 to 0.06897, saving model to /content/asl/Adam/cp-34-0.07.hdf5\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 4.2338 - accuracy: 0.0685 - val_loss: 4.2459 - val_accuracy: 0.0690\n",
            "Epoch 35/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 4.2228 - accuracy: 0.0703\n",
            "Epoch 35: val_accuracy improved from 0.06897 to 0.07011, saving model to /content/asl/Adam/cp-35-0.07.hdf5\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 4.2228 - accuracy: 0.0703 - val_loss: 4.2192 - val_accuracy: 0.0701\n",
            "Epoch 36/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 4.2579 - accuracy: 0.0613\n",
            "Epoch 36: val_accuracy did not improve from 0.07011\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 4.2583 - accuracy: 0.0605 - val_loss: 4.2258 - val_accuracy: 0.0684\n",
            "Epoch 37/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 4.2333 - accuracy: 0.0624\n",
            "Epoch 37: val_accuracy did not improve from 0.07011\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 4.2348 - accuracy: 0.0628 - val_loss: 4.2385 - val_accuracy: 0.0701\n",
            "Epoch 38/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 4.2031 - accuracy: 0.0717\n",
            "Epoch 38: val_accuracy did not improve from 0.07011\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 4.2031 - accuracy: 0.0717 - val_loss: 4.2230 - val_accuracy: 0.0649\n",
            "Epoch 39/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 4.2063 - accuracy: 0.0726\n",
            "Epoch 39: val_accuracy did not improve from 0.07011\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 4.2075 - accuracy: 0.0718 - val_loss: 4.2158 - val_accuracy: 0.0644\n",
            "Epoch 40/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 4.1895 - accuracy: 0.0731\n",
            "Epoch 40: val_accuracy did not improve from 0.07011\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 4.1912 - accuracy: 0.0733 - val_loss: 4.2160 - val_accuracy: 0.0586\n",
            "Epoch 41/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 4.1905 - accuracy: 0.0724\n",
            "Epoch 41: val_accuracy did not improve from 0.07011\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 4.1908 - accuracy: 0.0723 - val_loss: 4.1915 - val_accuracy: 0.0701\n",
            "Epoch 42/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 4.1663 - accuracy: 0.0756\n",
            "Epoch 42: val_accuracy improved from 0.07011 to 0.07414, saving model to /content/asl/Adam/cp-42-0.07.hdf5\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 4.1685 - accuracy: 0.0753 - val_loss: 4.1624 - val_accuracy: 0.0741\n",
            "Epoch 43/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 4.1655 - accuracy: 0.0773\n",
            "Epoch 43: val_accuracy improved from 0.07414 to 0.07701, saving model to /content/asl/Adam/cp-43-0.08.hdf5\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 4.1638 - accuracy: 0.0770 - val_loss: 4.2019 - val_accuracy: 0.0770\n",
            "Epoch 44/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 4.1585 - accuracy: 0.0805\n",
            "Epoch 44: val_accuracy did not improve from 0.07701\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 4.1564 - accuracy: 0.0807 - val_loss: 4.2100 - val_accuracy: 0.0707\n",
            "Epoch 45/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 4.1401 - accuracy: 0.0794\n",
            "Epoch 45: val_accuracy did not improve from 0.07701\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 4.1420 - accuracy: 0.0796 - val_loss: 4.1740 - val_accuracy: 0.0690\n",
            "Epoch 46/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 4.1481 - accuracy: 0.0794\n",
            "Epoch 46: val_accuracy did not improve from 0.07701\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 4.1484 - accuracy: 0.0793 - val_loss: 4.1306 - val_accuracy: 0.0753\n",
            "Epoch 47/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 4.1382 - accuracy: 0.0796\n",
            "Epoch 47: val_accuracy improved from 0.07701 to 0.07931, saving model to /content/asl/Adam/cp-47-0.08.hdf5\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 4.1382 - accuracy: 0.0796 - val_loss: 4.1251 - val_accuracy: 0.0793\n",
            "Epoch 48/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 4.1262 - accuracy: 0.0849\n",
            "Epoch 48: val_accuracy improved from 0.07931 to 0.08793, saving model to /content/asl/Adam/cp-48-0.09.hdf5\n",
            "218/218 [==============================] - 3s 11ms/step - loss: 4.1265 - accuracy: 0.0849 - val_loss: 4.1191 - val_accuracy: 0.0879\n",
            "Epoch 49/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 4.1430 - accuracy: 0.0775\n",
            "Epoch 49: val_accuracy did not improve from 0.08793\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 4.1429 - accuracy: 0.0776 - val_loss: 4.1237 - val_accuracy: 0.0856\n",
            "Epoch 50/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 4.0993 - accuracy: 0.0886\n",
            "Epoch 50: val_accuracy did not improve from 0.08793\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 4.0981 - accuracy: 0.0886 - val_loss: 4.1340 - val_accuracy: 0.0770\n",
            "Epoch 51/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 4.0800 - accuracy: 0.0865\n",
            "Epoch 51: val_accuracy did not improve from 0.08793\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 4.0811 - accuracy: 0.0865 - val_loss: 4.0834 - val_accuracy: 0.0839\n",
            "Epoch 52/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 4.0427 - accuracy: 0.0860\n",
            "Epoch 52: val_accuracy improved from 0.08793 to 0.09080, saving model to /content/asl/Adam/cp-52-0.09.hdf5\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 4.0425 - accuracy: 0.0859 - val_loss: 4.0463 - val_accuracy: 0.0908\n",
            "Epoch 53/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 4.0179 - accuracy: 0.0896\n",
            "Epoch 53: val_accuracy improved from 0.09080 to 0.09483, saving model to /content/asl/Adam/cp-53-0.09.hdf5\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 4.0161 - accuracy: 0.0895 - val_loss: 3.9916 - val_accuracy: 0.0948\n",
            "Epoch 54/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 3.9710 - accuracy: 0.0936\n",
            "Epoch 54: val_accuracy improved from 0.09483 to 0.10460, saving model to /content/asl/Adam/cp-54-0.10.hdf5\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 3.9691 - accuracy: 0.0945 - val_loss: 3.9464 - val_accuracy: 0.1046\n",
            "Epoch 55/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 3.9169 - accuracy: 0.1049\n",
            "Epoch 55: val_accuracy did not improve from 0.10460\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 3.9185 - accuracy: 0.1049 - val_loss: 3.9156 - val_accuracy: 0.1034\n",
            "Epoch 56/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 3.8717 - accuracy: 0.1121\n",
            "Epoch 56: val_accuracy did not improve from 0.10460\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 3.8704 - accuracy: 0.1119 - val_loss: 3.9202 - val_accuracy: 0.0971\n",
            "Epoch 57/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 3.8724 - accuracy: 0.1056\n",
            "Epoch 57: val_accuracy did not improve from 0.10460\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 3.8738 - accuracy: 0.1055 - val_loss: 3.9255 - val_accuracy: 0.0994\n",
            "Epoch 58/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 3.8077 - accuracy: 0.1127\n",
            "Epoch 58: val_accuracy improved from 0.10460 to 0.12126, saving model to /content/asl/Adam/cp-58-0.12.hdf5\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 3.8074 - accuracy: 0.1129 - val_loss: 3.8095 - val_accuracy: 0.1213\n",
            "Epoch 59/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 3.7578 - accuracy: 0.1168\n",
            "Epoch 59: val_accuracy did not improve from 0.12126\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 3.7578 - accuracy: 0.1168 - val_loss: 3.8957 - val_accuracy: 0.0897\n",
            "Epoch 60/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 3.7611 - accuracy: 0.1138\n",
            "Epoch 60: val_accuracy did not improve from 0.12126\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 3.7632 - accuracy: 0.1135 - val_loss: 3.7284 - val_accuracy: 0.1172\n",
            "Epoch 61/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 3.7159 - accuracy: 0.1199\n",
            "Epoch 61: val_accuracy did not improve from 0.12126\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 3.7170 - accuracy: 0.1197 - val_loss: 3.8890 - val_accuracy: 0.0943\n",
            "Epoch 62/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 3.7037 - accuracy: 0.1217\n",
            "Epoch 62: val_accuracy did not improve from 0.12126\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 3.7032 - accuracy: 0.1216 - val_loss: 3.7014 - val_accuracy: 0.1213\n",
            "Epoch 63/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 3.6524 - accuracy: 0.1282\n",
            "Epoch 63: val_accuracy improved from 0.12126 to 0.13103, saving model to /content/asl/Adam/cp-63-0.13.hdf5\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 3.6509 - accuracy: 0.1292 - val_loss: 3.6489 - val_accuracy: 0.1310\n",
            "Epoch 64/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 3.6209 - accuracy: 0.1320\n",
            "Epoch 64: val_accuracy improved from 0.13103 to 0.14540, saving model to /content/asl/Adam/cp-64-0.15.hdf5\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 3.6200 - accuracy: 0.1320 - val_loss: 3.6340 - val_accuracy: 0.1454\n",
            "Epoch 65/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 3.6115 - accuracy: 0.1344\n",
            "Epoch 65: val_accuracy improved from 0.14540 to 0.14885, saving model to /content/asl/Adam/cp-65-0.15.hdf5\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 3.6123 - accuracy: 0.1348 - val_loss: 3.5985 - val_accuracy: 0.1489\n",
            "Epoch 66/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 3.5773 - accuracy: 0.1354\n",
            "Epoch 66: val_accuracy did not improve from 0.14885\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 3.5781 - accuracy: 0.1352 - val_loss: 3.6041 - val_accuracy: 0.1333\n",
            "Epoch 67/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 3.5682 - accuracy: 0.1379\n",
            "Epoch 67: val_accuracy did not improve from 0.14885\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 3.5676 - accuracy: 0.1376 - val_loss: 3.5920 - val_accuracy: 0.1253\n",
            "Epoch 68/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 3.4973 - accuracy: 0.1471\n",
            "Epoch 68: val_accuracy did not improve from 0.14885\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 3.4971 - accuracy: 0.1473 - val_loss: 3.5870 - val_accuracy: 0.1270\n",
            "Epoch 69/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 3.4632 - accuracy: 0.1515\n",
            "Epoch 69: val_accuracy did not improve from 0.14885\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 3.4624 - accuracy: 0.1509 - val_loss: 3.4815 - val_accuracy: 0.1471\n",
            "Epoch 70/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 3.4113 - accuracy: 0.1522\n",
            "Epoch 70: val_accuracy improved from 0.14885 to 0.15920, saving model to /content/asl/Adam/cp-70-0.16.hdf5\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 3.4110 - accuracy: 0.1524 - val_loss: 3.5239 - val_accuracy: 0.1592\n",
            "Epoch 71/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 3.4091 - accuracy: 0.1603\n",
            "Epoch 71: val_accuracy did not improve from 0.15920\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 3.4098 - accuracy: 0.1605 - val_loss: 3.4816 - val_accuracy: 0.1466\n",
            "Epoch 72/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 3.3891 - accuracy: 0.1603\n",
            "Epoch 72: val_accuracy did not improve from 0.15920\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 3.3884 - accuracy: 0.1603 - val_loss: 3.4205 - val_accuracy: 0.1523\n",
            "Epoch 73/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 3.3393 - accuracy: 0.1700\n",
            "Epoch 73: val_accuracy did not improve from 0.15920\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 3.3393 - accuracy: 0.1700 - val_loss: 3.4855 - val_accuracy: 0.1420\n",
            "Epoch 74/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 3.3599 - accuracy: 0.1628\n",
            "Epoch 74: val_accuracy improved from 0.15920 to 0.16552, saving model to /content/asl/Adam/cp-74-0.17.hdf5\n",
            "218/218 [==============================] - 3s 13ms/step - loss: 3.3581 - accuracy: 0.1636 - val_loss: 3.3723 - val_accuracy: 0.1655\n",
            "Epoch 75/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 3.2934 - accuracy: 0.1753\n",
            "Epoch 75: val_accuracy did not improve from 0.16552\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 3.2934 - accuracy: 0.1753 - val_loss: 3.4432 - val_accuracy: 0.1454\n",
            "Epoch 76/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 3.2796 - accuracy: 0.1753\n",
            "Epoch 76: val_accuracy improved from 0.16552 to 0.17759, saving model to /content/asl/Adam/cp-76-0.18.hdf5\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 3.2798 - accuracy: 0.1757 - val_loss: 3.3244 - val_accuracy: 0.1776\n",
            "Epoch 77/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 3.2354 - accuracy: 0.1860\n",
            "Epoch 77: val_accuracy improved from 0.17759 to 0.18621, saving model to /content/asl/Adam/cp-77-0.19.hdf5\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 3.2362 - accuracy: 0.1862 - val_loss: 3.2740 - val_accuracy: 0.1862\n",
            "Epoch 78/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 3.2184 - accuracy: 0.1852\n",
            "Epoch 78: val_accuracy improved from 0.18621 to 0.19368, saving model to /content/asl/Adam/cp-78-0.19.hdf5\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 3.2178 - accuracy: 0.1848 - val_loss: 3.2425 - val_accuracy: 0.1937\n",
            "Epoch 79/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 3.2084 - accuracy: 0.1842\n",
            "Epoch 79: val_accuracy did not improve from 0.19368\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 3.2094 - accuracy: 0.1841 - val_loss: 3.2472 - val_accuracy: 0.1874\n",
            "Epoch 80/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 3.1794 - accuracy: 0.1881\n",
            "Epoch 80: val_accuracy did not improve from 0.19368\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 3.1844 - accuracy: 0.1872 - val_loss: 3.3108 - val_accuracy: 0.1678\n",
            "Epoch 81/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 3.1656 - accuracy: 0.1907\n",
            "Epoch 81: val_accuracy did not improve from 0.19368\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 3.1656 - accuracy: 0.1907 - val_loss: 3.2372 - val_accuracy: 0.1862\n",
            "Epoch 82/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 3.1418 - accuracy: 0.1993\n",
            "Epoch 82: val_accuracy did not improve from 0.19368\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 3.1435 - accuracy: 0.1991 - val_loss: 3.4725 - val_accuracy: 0.1172\n",
            "Epoch 83/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 3.1583 - accuracy: 0.1852\n",
            "Epoch 83: val_accuracy did not improve from 0.19368\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 3.1637 - accuracy: 0.1846 - val_loss: 3.2577 - val_accuracy: 0.1701\n",
            "Epoch 84/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 3.0860 - accuracy: 0.2077\n",
            "Epoch 84: val_accuracy did not improve from 0.19368\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 3.0866 - accuracy: 0.2072 - val_loss: 3.2164 - val_accuracy: 0.1736\n",
            "Epoch 85/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 3.0793 - accuracy: 0.2059\n",
            "Epoch 85: val_accuracy improved from 0.19368 to 0.19885, saving model to /content/asl/Adam/cp-85-0.20.hdf5\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 3.0826 - accuracy: 0.2057 - val_loss: 3.1479 - val_accuracy: 0.1989\n",
            "Epoch 86/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 3.0455 - accuracy: 0.2135\n",
            "Epoch 86: val_accuracy did not improve from 0.19885\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 3.0451 - accuracy: 0.2132 - val_loss: 3.1699 - val_accuracy: 0.1902\n",
            "Epoch 87/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 3.0439 - accuracy: 0.2123\n",
            "Epoch 87: val_accuracy did not improve from 0.19885\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 3.0444 - accuracy: 0.2124 - val_loss: 3.3390 - val_accuracy: 0.1500\n",
            "Epoch 88/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 3.0405 - accuracy: 0.2104\n",
            "Epoch 88: val_accuracy did not improve from 0.19885\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 3.0413 - accuracy: 0.2106 - val_loss: 3.2915 - val_accuracy: 0.1649\n",
            "Epoch 89/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 3.0155 - accuracy: 0.2136\n",
            "Epoch 89: val_accuracy did not improve from 0.19885\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 3.0155 - accuracy: 0.2136 - val_loss: 3.1342 - val_accuracy: 0.1966\n",
            "Epoch 90/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 3.0190 - accuracy: 0.2110\n",
            "Epoch 90: val_accuracy did not improve from 0.19885\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 3.0209 - accuracy: 0.2105 - val_loss: 3.2888 - val_accuracy: 0.1603\n",
            "Epoch 91/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 2.9920 - accuracy: 0.2134\n",
            "Epoch 91: val_accuracy improved from 0.19885 to 0.21207, saving model to /content/asl/Adam/cp-91-0.21.hdf5\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 2.9882 - accuracy: 0.2147 - val_loss: 3.0855 - val_accuracy: 0.2121\n",
            "Epoch 92/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 3.0111 - accuracy: 0.2185\n",
            "Epoch 92: val_accuracy did not improve from 0.21207\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 3.0111 - accuracy: 0.2185 - val_loss: 3.2042 - val_accuracy: 0.1747\n",
            "Epoch 93/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 2.9484 - accuracy: 0.2282\n",
            "Epoch 93: val_accuracy improved from 0.21207 to 0.22011, saving model to /content/asl/Adam/cp-93-0.22.hdf5\n",
            "218/218 [==============================] - 3s 13ms/step - loss: 2.9490 - accuracy: 0.2276 - val_loss: 3.0099 - val_accuracy: 0.2201\n",
            "Epoch 94/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 2.9350 - accuracy: 0.2283\n",
            "Epoch 94: val_accuracy improved from 0.22011 to 0.22241, saving model to /content/asl/Adam/cp-94-0.22.hdf5\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.9355 - accuracy: 0.2280 - val_loss: 3.0498 - val_accuracy: 0.2224\n",
            "Epoch 95/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 2.9484 - accuracy: 0.2212\n",
            "Epoch 95: val_accuracy did not improve from 0.22241\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.9503 - accuracy: 0.2204 - val_loss: 3.0463 - val_accuracy: 0.2178\n",
            "Epoch 96/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 2.9382 - accuracy: 0.2253\n",
            "Epoch 96: val_accuracy improved from 0.22241 to 0.22644, saving model to /content/asl/Adam/cp-96-0.23.hdf5\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.9382 - accuracy: 0.2253 - val_loss: 2.9895 - val_accuracy: 0.2264\n",
            "Epoch 97/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 2.9051 - accuracy: 0.2256\n",
            "Epoch 97: val_accuracy did not improve from 0.22644\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.9051 - accuracy: 0.2256 - val_loss: 3.0463 - val_accuracy: 0.2086\n",
            "Epoch 98/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 2.9120 - accuracy: 0.2259\n",
            "Epoch 98: val_accuracy did not improve from 0.22644\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 2.9102 - accuracy: 0.2263 - val_loss: 3.0164 - val_accuracy: 0.2195\n",
            "Epoch 99/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 2.8741 - accuracy: 0.2360\n",
            "Epoch 99: val_accuracy did not improve from 0.22644\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 2.8742 - accuracy: 0.2356 - val_loss: 2.9766 - val_accuracy: 0.2241\n",
            "Epoch 100/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 2.9298 - accuracy: 0.2242\n",
            "Epoch 100: val_accuracy improved from 0.22644 to 0.22989, saving model to /content/asl/Adam/cp-100-0.23.hdf5\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 2.9289 - accuracy: 0.2239 - val_loss: 2.9706 - val_accuracy: 0.2299\n",
            "Epoch 101/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 2.8603 - accuracy: 0.2367\n",
            "Epoch 101: val_accuracy did not improve from 0.22989\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.8652 - accuracy: 0.2355 - val_loss: 3.1123 - val_accuracy: 0.1989\n",
            "Epoch 102/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 2.8204 - accuracy: 0.2457\n",
            "Epoch 102: val_accuracy improved from 0.22989 to 0.23678, saving model to /content/asl/Adam/cp-102-0.24.hdf5\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.8204 - accuracy: 0.2457 - val_loss: 2.9296 - val_accuracy: 0.2368\n",
            "Epoch 103/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 2.8092 - accuracy: 0.2518\n",
            "Epoch 103: val_accuracy did not improve from 0.23678\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.8094 - accuracy: 0.2517 - val_loss: 2.9948 - val_accuracy: 0.2109\n",
            "Epoch 104/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 2.8278 - accuracy: 0.2331\n",
            "Epoch 104: val_accuracy improved from 0.23678 to 0.25345, saving model to /content/asl/Adam/cp-104-0.25.hdf5\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.8278 - accuracy: 0.2333 - val_loss: 2.8818 - val_accuracy: 0.2534\n",
            "Epoch 105/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 2.8200 - accuracy: 0.2435\n",
            "Epoch 105: val_accuracy did not improve from 0.25345\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 2.8206 - accuracy: 0.2437 - val_loss: 2.9247 - val_accuracy: 0.2397\n",
            "Epoch 106/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 2.7917 - accuracy: 0.2474\n",
            "Epoch 106: val_accuracy did not improve from 0.25345\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 2.7910 - accuracy: 0.2473 - val_loss: 3.1095 - val_accuracy: 0.1948\n",
            "Epoch 107/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 2.8029 - accuracy: 0.2422\n",
            "Epoch 107: val_accuracy did not improve from 0.25345\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.8018 - accuracy: 0.2428 - val_loss: 2.8514 - val_accuracy: 0.2471\n",
            "Epoch 108/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 2.7657 - accuracy: 0.2503\n",
            "Epoch 108: val_accuracy did not improve from 0.25345\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.7657 - accuracy: 0.2503 - val_loss: 2.9322 - val_accuracy: 0.2374\n",
            "Epoch 109/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 2.7731 - accuracy: 0.2538\n",
            "Epoch 109: val_accuracy did not improve from 0.25345\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.7712 - accuracy: 0.2540 - val_loss: 2.8802 - val_accuracy: 0.2397\n",
            "Epoch 110/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 2.7651 - accuracy: 0.2510\n",
            "Epoch 110: val_accuracy did not improve from 0.25345\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.7651 - accuracy: 0.2510 - val_loss: 2.9253 - val_accuracy: 0.2218\n",
            "Epoch 111/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 2.7815 - accuracy: 0.2474\n",
            "Epoch 111: val_accuracy did not improve from 0.25345\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 2.7817 - accuracy: 0.2468 - val_loss: 2.8891 - val_accuracy: 0.2374\n",
            "Epoch 112/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 2.7454 - accuracy: 0.2599\n",
            "Epoch 112: val_accuracy improved from 0.25345 to 0.26609, saving model to /content/asl/Adam/cp-112-0.27.hdf5\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 2.7463 - accuracy: 0.2603 - val_loss: 2.8158 - val_accuracy: 0.2661\n",
            "Epoch 113/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 2.7218 - accuracy: 0.2631\n",
            "Epoch 113: val_accuracy did not improve from 0.26609\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.7234 - accuracy: 0.2622 - val_loss: 2.8867 - val_accuracy: 0.2299\n",
            "Epoch 114/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 2.7191 - accuracy: 0.2548\n",
            "Epoch 114: val_accuracy did not improve from 0.26609\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.7187 - accuracy: 0.2556 - val_loss: 2.8522 - val_accuracy: 0.2580\n",
            "Epoch 115/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 2.7046 - accuracy: 0.2624\n",
            "Epoch 115: val_accuracy did not improve from 0.26609\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.7077 - accuracy: 0.2621 - val_loss: 2.8397 - val_accuracy: 0.2529\n",
            "Epoch 116/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 2.7059 - accuracy: 0.2634\n",
            "Epoch 116: val_accuracy did not improve from 0.26609\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.7060 - accuracy: 0.2639 - val_loss: 2.7942 - val_accuracy: 0.2575\n",
            "Epoch 117/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 2.7053 - accuracy: 0.2687\n",
            "Epoch 117: val_accuracy improved from 0.26609 to 0.27184, saving model to /content/asl/Adam/cp-117-0.27.hdf5\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 2.7005 - accuracy: 0.2701 - val_loss: 2.7772 - val_accuracy: 0.2718\n",
            "Epoch 118/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 2.6686 - accuracy: 0.2797\n",
            "Epoch 118: val_accuracy did not improve from 0.27184\n",
            "218/218 [==============================] - 3s 13ms/step - loss: 2.6679 - accuracy: 0.2796 - val_loss: 2.8014 - val_accuracy: 0.2471\n",
            "Epoch 119/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 2.6959 - accuracy: 0.2631\n",
            "Epoch 119: val_accuracy did not improve from 0.27184\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 2.6959 - accuracy: 0.2631 - val_loss: 2.8572 - val_accuracy: 0.2305\n",
            "Epoch 120/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 2.6992 - accuracy: 0.2669\n",
            "Epoch 120: val_accuracy did not improve from 0.27184\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.6924 - accuracy: 0.2674 - val_loss: 2.9078 - val_accuracy: 0.2213\n",
            "Epoch 121/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 2.6286 - accuracy: 0.2829\n",
            "Epoch 121: val_accuracy did not improve from 0.27184\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.6286 - accuracy: 0.2829 - val_loss: 2.7666 - val_accuracy: 0.2661\n",
            "Epoch 122/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 2.6538 - accuracy: 0.2716\n",
            "Epoch 122: val_accuracy did not improve from 0.27184\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 2.6542 - accuracy: 0.2717 - val_loss: 2.9592 - val_accuracy: 0.2057\n",
            "Epoch 123/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 2.6602 - accuracy: 0.2753\n",
            "Epoch 123: val_accuracy did not improve from 0.27184\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.6597 - accuracy: 0.2754 - val_loss: 2.8066 - val_accuracy: 0.2443\n",
            "Epoch 124/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 2.6289 - accuracy: 0.2799\n",
            "Epoch 124: val_accuracy did not improve from 0.27184\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 2.6289 - accuracy: 0.2799 - val_loss: 2.9142 - val_accuracy: 0.2299\n",
            "Epoch 125/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 2.6479 - accuracy: 0.2773\n",
            "Epoch 125: val_accuracy did not improve from 0.27184\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 2.6523 - accuracy: 0.2767 - val_loss: 2.8208 - val_accuracy: 0.2563\n",
            "Epoch 126/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 2.6222 - accuracy: 0.2841\n",
            "Epoch 126: val_accuracy did not improve from 0.27184\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.6222 - accuracy: 0.2841 - val_loss: 2.7990 - val_accuracy: 0.2466\n",
            "Epoch 127/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 2.5913 - accuracy: 0.2897\n",
            "Epoch 127: val_accuracy did not improve from 0.27184\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.5865 - accuracy: 0.2909 - val_loss: 2.7790 - val_accuracy: 0.2586\n",
            "Epoch 128/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 2.5781 - accuracy: 0.2918\n",
            "Epoch 128: val_accuracy improved from 0.27184 to 0.29023, saving model to /content/asl/Adam/cp-128-0.29.hdf5\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 2.5799 - accuracy: 0.2920 - val_loss: 2.7024 - val_accuracy: 0.2902\n",
            "Epoch 129/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 2.6200 - accuracy: 0.2741\n",
            "Epoch 129: val_accuracy did not improve from 0.29023\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.6234 - accuracy: 0.2734 - val_loss: 2.8331 - val_accuracy: 0.2362\n",
            "Epoch 130/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 2.5933 - accuracy: 0.2843\n",
            "Epoch 130: val_accuracy did not improve from 0.29023\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 2.5933 - accuracy: 0.2843 - val_loss: 2.7464 - val_accuracy: 0.2655\n",
            "Epoch 131/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 2.5512 - accuracy: 0.2976\n",
            "Epoch 131: val_accuracy did not improve from 0.29023\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 2.5512 - accuracy: 0.2976 - val_loss: 2.6588 - val_accuracy: 0.2862\n",
            "Epoch 132/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 2.5516 - accuracy: 0.3001\n",
            "Epoch 132: val_accuracy did not improve from 0.29023\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 2.5536 - accuracy: 0.2994 - val_loss: 2.9211 - val_accuracy: 0.2190\n",
            "Epoch 133/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 2.5641 - accuracy: 0.2909\n",
            "Epoch 133: val_accuracy did not improve from 0.29023\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.5628 - accuracy: 0.2912 - val_loss: 2.7013 - val_accuracy: 0.2741\n",
            "Epoch 134/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 2.5392 - accuracy: 0.2972\n",
            "Epoch 134: val_accuracy did not improve from 0.29023\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.5408 - accuracy: 0.2963 - val_loss: 2.7625 - val_accuracy: 0.2672\n",
            "Epoch 135/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 2.5634 - accuracy: 0.2876\n",
            "Epoch 135: val_accuracy did not improve from 0.29023\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.5638 - accuracy: 0.2872 - val_loss: 2.7379 - val_accuracy: 0.2609\n",
            "Epoch 136/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 2.5789 - accuracy: 0.2839\n",
            "Epoch 136: val_accuracy improved from 0.29023 to 0.30000, saving model to /content/asl/Adam/cp-136-0.30.hdf5\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.5784 - accuracy: 0.2851 - val_loss: 2.6490 - val_accuracy: 0.3000\n",
            "Epoch 137/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 2.5233 - accuracy: 0.3010\n",
            "Epoch 137: val_accuracy did not improve from 0.30000\n",
            "218/218 [==============================] - 3s 11ms/step - loss: 2.5233 - accuracy: 0.3010 - val_loss: 2.9187 - val_accuracy: 0.2241\n",
            "Epoch 138/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 2.5327 - accuracy: 0.3012\n",
            "Epoch 138: val_accuracy improved from 0.30000 to 0.30172, saving model to /content/asl/Adam/cp-138-0.30.hdf5\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 2.5317 - accuracy: 0.3006 - val_loss: 2.6218 - val_accuracy: 0.3017\n",
            "Epoch 139/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 2.5233 - accuracy: 0.3022\n",
            "Epoch 139: val_accuracy did not improve from 0.30172\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.5255 - accuracy: 0.3009 - val_loss: 2.7020 - val_accuracy: 0.2724\n",
            "Epoch 140/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 2.5192 - accuracy: 0.3020\n",
            "Epoch 140: val_accuracy did not improve from 0.30172\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 2.5172 - accuracy: 0.3022 - val_loss: 2.6435 - val_accuracy: 0.2891\n",
            "Epoch 141/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 2.5003 - accuracy: 0.2994\n",
            "Epoch 141: val_accuracy did not improve from 0.30172\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 2.5011 - accuracy: 0.2993 - val_loss: 2.6380 - val_accuracy: 0.2805\n",
            "Epoch 142/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 2.5100 - accuracy: 0.3050\n",
            "Epoch 142: val_accuracy did not improve from 0.30172\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.5122 - accuracy: 0.3047 - val_loss: 2.6149 - val_accuracy: 0.2966\n",
            "Epoch 143/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 2.5246 - accuracy: 0.3035\n",
            "Epoch 143: val_accuracy improved from 0.30172 to 0.32069, saving model to /content/asl/Adam/cp-143-0.32.hdf5\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 2.5231 - accuracy: 0.3034 - val_loss: 2.6075 - val_accuracy: 0.3207\n",
            "Epoch 144/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 2.4434 - accuracy: 0.3205\n",
            "Epoch 144: val_accuracy did not improve from 0.32069\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 2.4443 - accuracy: 0.3200 - val_loss: 2.6128 - val_accuracy: 0.2862\n",
            "Epoch 145/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 2.5667 - accuracy: 0.2864\n",
            "Epoch 145: val_accuracy did not improve from 0.32069\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 2.5623 - accuracy: 0.2871 - val_loss: 2.6092 - val_accuracy: 0.2966\n",
            "Epoch 146/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 2.4239 - accuracy: 0.3221\n",
            "Epoch 146: val_accuracy did not improve from 0.32069\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.4246 - accuracy: 0.3217 - val_loss: 2.6579 - val_accuracy: 0.2747\n",
            "Epoch 147/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 2.4144 - accuracy: 0.3275\n",
            "Epoch 147: val_accuracy improved from 0.32069 to 0.32874, saving model to /content/asl/Adam/cp-147-0.33.hdf5\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 2.4143 - accuracy: 0.3277 - val_loss: 2.5630 - val_accuracy: 0.3287\n",
            "Epoch 148/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 2.4991 - accuracy: 0.3004\n",
            "Epoch 148: val_accuracy did not improve from 0.32874\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.4990 - accuracy: 0.3007 - val_loss: 2.6278 - val_accuracy: 0.2943\n",
            "Epoch 149/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 2.4528 - accuracy: 0.3138\n",
            "Epoch 149: val_accuracy did not improve from 0.32874\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 2.4530 - accuracy: 0.3141 - val_loss: 2.7179 - val_accuracy: 0.2638\n",
            "Epoch 150/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 2.5115 - accuracy: 0.3029\n",
            "Epoch 150: val_accuracy did not improve from 0.32874\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 2.5136 - accuracy: 0.3014 - val_loss: 2.7257 - val_accuracy: 0.2552\n",
            "Epoch 151/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 2.4346 - accuracy: 0.3200\n",
            "Epoch 151: val_accuracy did not improve from 0.32874\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 2.4349 - accuracy: 0.3198 - val_loss: 2.5932 - val_accuracy: 0.2914\n",
            "Epoch 152/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 2.4284 - accuracy: 0.3192\n",
            "Epoch 152: val_accuracy did not improve from 0.32874\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.4326 - accuracy: 0.3177 - val_loss: 2.7693 - val_accuracy: 0.2425\n",
            "Epoch 153/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 2.4148 - accuracy: 0.3211\n",
            "Epoch 153: val_accuracy did not improve from 0.32874\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.4133 - accuracy: 0.3223 - val_loss: 2.5562 - val_accuracy: 0.3161\n",
            "Epoch 154/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 2.3738 - accuracy: 0.3379\n",
            "Epoch 154: val_accuracy did not improve from 0.32874\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.3785 - accuracy: 0.3371 - val_loss: 2.6227 - val_accuracy: 0.2937\n",
            "Epoch 155/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 2.5127 - accuracy: 0.2943\n",
            "Epoch 155: val_accuracy did not improve from 0.32874\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.5127 - accuracy: 0.2943 - val_loss: 2.5336 - val_accuracy: 0.3207\n",
            "Epoch 156/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 2.4485 - accuracy: 0.3131\n",
            "Epoch 156: val_accuracy did not improve from 0.32874\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 2.4485 - accuracy: 0.3131 - val_loss: 2.6357 - val_accuracy: 0.2925\n",
            "Epoch 157/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 2.4210 - accuracy: 0.3159\n",
            "Epoch 157: val_accuracy did not improve from 0.32874\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 2.4207 - accuracy: 0.3167 - val_loss: 2.7071 - val_accuracy: 0.2644\n",
            "Epoch 158/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 2.4000 - accuracy: 0.3278\n",
            "Epoch 158: val_accuracy did not improve from 0.32874\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.4007 - accuracy: 0.3274 - val_loss: 2.5188 - val_accuracy: 0.3236\n",
            "Epoch 159/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 2.3610 - accuracy: 0.3398\n",
            "Epoch 159: val_accuracy improved from 0.32874 to 0.34540, saving model to /content/asl/Adam/cp-159-0.35.hdf5\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 2.3614 - accuracy: 0.3401 - val_loss: 2.4849 - val_accuracy: 0.3454\n",
            "Epoch 160/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 2.4017 - accuracy: 0.3195\n",
            "Epoch 160: val_accuracy did not improve from 0.34540\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.4006 - accuracy: 0.3198 - val_loss: 2.6170 - val_accuracy: 0.2874\n",
            "Epoch 161/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 2.4482 - accuracy: 0.3118\n",
            "Epoch 161: val_accuracy did not improve from 0.34540\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.4470 - accuracy: 0.3116 - val_loss: 2.6262 - val_accuracy: 0.2902\n",
            "Epoch 162/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 2.3777 - accuracy: 0.3259\n",
            "Epoch 162: val_accuracy did not improve from 0.34540\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 2.3772 - accuracy: 0.3261 - val_loss: 2.7303 - val_accuracy: 0.2557\n",
            "Epoch 163/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 2.3608 - accuracy: 0.3359\n",
            "Epoch 163: val_accuracy did not improve from 0.34540\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 2.3622 - accuracy: 0.3349 - val_loss: 2.6340 - val_accuracy: 0.2805\n",
            "Epoch 164/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 2.4337 - accuracy: 0.3154\n",
            "Epoch 164: val_accuracy improved from 0.34540 to 0.35172, saving model to /content/asl/Adam/cp-164-0.35.hdf5\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 2.4311 - accuracy: 0.3155 - val_loss: 2.4620 - val_accuracy: 0.3517\n",
            "Epoch 165/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 2.3571 - accuracy: 0.3379\n",
            "Epoch 165: val_accuracy did not improve from 0.35172\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.3555 - accuracy: 0.3384 - val_loss: 2.6431 - val_accuracy: 0.2787\n",
            "Epoch 166/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 2.3354 - accuracy: 0.3459\n",
            "Epoch 166: val_accuracy did not improve from 0.35172\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 2.3333 - accuracy: 0.3461 - val_loss: 2.4989 - val_accuracy: 0.3282\n",
            "Epoch 167/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 2.2962 - accuracy: 0.3579\n",
            "Epoch 167: val_accuracy did not improve from 0.35172\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.2959 - accuracy: 0.3573 - val_loss: 2.7671 - val_accuracy: 0.2615\n",
            "Epoch 168/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 2.3271 - accuracy: 0.3474\n",
            "Epoch 168: val_accuracy did not improve from 0.35172\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 2.3273 - accuracy: 0.3470 - val_loss: 2.4764 - val_accuracy: 0.3402\n",
            "Epoch 169/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 2.3120 - accuracy: 0.3478\n",
            "Epoch 169: val_accuracy did not improve from 0.35172\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 2.3123 - accuracy: 0.3481 - val_loss: 2.5212 - val_accuracy: 0.3224\n",
            "Epoch 170/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 2.2706 - accuracy: 0.3668\n",
            "Epoch 170: val_accuracy did not improve from 0.35172\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 2.2723 - accuracy: 0.3659 - val_loss: 2.4213 - val_accuracy: 0.3460\n",
            "Epoch 171/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 2.3899 - accuracy: 0.3238\n",
            "Epoch 171: val_accuracy did not improve from 0.35172\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.3911 - accuracy: 0.3243 - val_loss: 2.5303 - val_accuracy: 0.3178\n",
            "Epoch 172/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 2.3626 - accuracy: 0.3381\n",
            "Epoch 172: val_accuracy did not improve from 0.35172\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 2.3641 - accuracy: 0.3381 - val_loss: 2.6191 - val_accuracy: 0.2966\n",
            "Epoch 173/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 2.2851 - accuracy: 0.3600\n",
            "Epoch 173: val_accuracy did not improve from 0.35172\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 2.2878 - accuracy: 0.3588 - val_loss: 2.4807 - val_accuracy: 0.3293\n",
            "Epoch 174/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 2.3277 - accuracy: 0.3473\n",
            "Epoch 174: val_accuracy did not improve from 0.35172\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.3299 - accuracy: 0.3467 - val_loss: 2.4949 - val_accuracy: 0.3293\n",
            "Epoch 175/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 2.2545 - accuracy: 0.3737\n",
            "Epoch 175: val_accuracy did not improve from 0.35172\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 2.2545 - accuracy: 0.3737 - val_loss: 2.5127 - val_accuracy: 0.3241\n",
            "Epoch 176/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 2.2790 - accuracy: 0.3616\n",
            "Epoch 176: val_accuracy did not improve from 0.35172\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 2.2790 - accuracy: 0.3616 - val_loss: 2.4803 - val_accuracy: 0.3339\n",
            "Epoch 177/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 2.2727 - accuracy: 0.3638\n",
            "Epoch 177: val_accuracy did not improve from 0.35172\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.2703 - accuracy: 0.3652 - val_loss: 2.4927 - val_accuracy: 0.3218\n",
            "Epoch 178/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 2.2738 - accuracy: 0.3608\n",
            "Epoch 178: val_accuracy did not improve from 0.35172\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 2.2675 - accuracy: 0.3625 - val_loss: 2.4604 - val_accuracy: 0.3391\n",
            "Epoch 179/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 2.2332 - accuracy: 0.3734\n",
            "Epoch 179: val_accuracy did not improve from 0.35172\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.2332 - accuracy: 0.3734 - val_loss: 2.4859 - val_accuracy: 0.3213\n",
            "Epoch 180/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 2.2508 - accuracy: 0.3699\n",
            "Epoch 180: val_accuracy improved from 0.35172 to 0.36437, saving model to /content/asl/Adam/cp-180-0.36.hdf5\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.2513 - accuracy: 0.3703 - val_loss: 2.3829 - val_accuracy: 0.3644\n",
            "Epoch 181/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 2.2928 - accuracy: 0.3570\n",
            "Epoch 181: val_accuracy did not improve from 0.36437\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 2.2928 - accuracy: 0.3570 - val_loss: 2.6263 - val_accuracy: 0.2885\n",
            "Epoch 182/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 2.2530 - accuracy: 0.3629\n",
            "Epoch 182: val_accuracy did not improve from 0.36437\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 2.2546 - accuracy: 0.3622 - val_loss: 2.4591 - val_accuracy: 0.3333\n",
            "Epoch 183/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 2.2165 - accuracy: 0.3763\n",
            "Epoch 183: val_accuracy did not improve from 0.36437\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 2.2197 - accuracy: 0.3753 - val_loss: 2.3703 - val_accuracy: 0.3575\n",
            "Epoch 184/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 2.2480 - accuracy: 0.3645\n",
            "Epoch 184: val_accuracy did not improve from 0.36437\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.2511 - accuracy: 0.3632 - val_loss: 2.5838 - val_accuracy: 0.2920\n",
            "Epoch 185/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 2.2487 - accuracy: 0.3607\n",
            "Epoch 185: val_accuracy improved from 0.36437 to 0.36839, saving model to /content/asl/Adam/cp-185-0.37.hdf5\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 2.2479 - accuracy: 0.3611 - val_loss: 2.3597 - val_accuracy: 0.3684\n",
            "Epoch 186/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 2.2628 - accuracy: 0.3559\n",
            "Epoch 186: val_accuracy did not improve from 0.36839\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.2628 - accuracy: 0.3559 - val_loss: 2.3829 - val_accuracy: 0.3460\n",
            "Epoch 187/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 2.2448 - accuracy: 0.3605\n",
            "Epoch 187: val_accuracy did not improve from 0.36839\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 2.2448 - accuracy: 0.3605 - val_loss: 2.6616 - val_accuracy: 0.2770\n",
            "Epoch 188/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 2.1682 - accuracy: 0.3903\n",
            "Epoch 188: val_accuracy improved from 0.36839 to 0.36954, saving model to /content/asl/Adam/cp-188-0.37.hdf5\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 2.1695 - accuracy: 0.3895 - val_loss: 2.3471 - val_accuracy: 0.3695\n",
            "Epoch 189/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 2.1676 - accuracy: 0.3888\n",
            "Epoch 189: val_accuracy did not improve from 0.36954\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 2.1676 - accuracy: 0.3888 - val_loss: 2.5187 - val_accuracy: 0.3075\n",
            "Epoch 190/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 2.2692 - accuracy: 0.3670\n",
            "Epoch 190: val_accuracy did not improve from 0.36954\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.2681 - accuracy: 0.3672 - val_loss: 2.3638 - val_accuracy: 0.3672\n",
            "Epoch 191/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 2.2354 - accuracy: 0.3687\n",
            "Epoch 191: val_accuracy did not improve from 0.36954\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.2348 - accuracy: 0.3675 - val_loss: 2.4505 - val_accuracy: 0.3511\n",
            "Epoch 192/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 2.2065 - accuracy: 0.3753\n",
            "Epoch 192: val_accuracy did not improve from 0.36954\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.2088 - accuracy: 0.3749 - val_loss: 2.3723 - val_accuracy: 0.3534\n",
            "Epoch 193/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 2.2041 - accuracy: 0.3694\n",
            "Epoch 193: val_accuracy did not improve from 0.36954\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.2025 - accuracy: 0.3708 - val_loss: 2.4012 - val_accuracy: 0.3575\n",
            "Epoch 194/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 2.2133 - accuracy: 0.3713\n",
            "Epoch 194: val_accuracy did not improve from 0.36954\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 2.2118 - accuracy: 0.3716 - val_loss: 2.3281 - val_accuracy: 0.3684\n",
            "Epoch 195/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 2.1275 - accuracy: 0.4001\n",
            "Epoch 195: val_accuracy did not improve from 0.36954\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 2.1303 - accuracy: 0.3991 - val_loss: 2.5751 - val_accuracy: 0.3121\n",
            "Epoch 196/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 2.1746 - accuracy: 0.3866\n",
            "Epoch 196: val_accuracy did not improve from 0.36954\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 2.1745 - accuracy: 0.3864 - val_loss: 2.3686 - val_accuracy: 0.3632\n",
            "Epoch 197/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 2.1693 - accuracy: 0.3806\n",
            "Epoch 197: val_accuracy did not improve from 0.36954\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.1693 - accuracy: 0.3806 - val_loss: 2.3385 - val_accuracy: 0.3632\n",
            "Epoch 198/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 2.1662 - accuracy: 0.3813\n",
            "Epoch 198: val_accuracy did not improve from 0.36954\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.1662 - accuracy: 0.3813 - val_loss: 2.3261 - val_accuracy: 0.3638\n",
            "Epoch 199/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 2.1810 - accuracy: 0.3733\n",
            "Epoch 199: val_accuracy did not improve from 0.36954\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 2.1797 - accuracy: 0.3736 - val_loss: 2.3642 - val_accuracy: 0.3534\n",
            "Epoch 200/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 2.1161 - accuracy: 0.4003\n",
            "Epoch 200: val_accuracy did not improve from 0.36954\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 2.1162 - accuracy: 0.3999 - val_loss: 2.3976 - val_accuracy: 0.3385\n",
            "Epoch 201/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 2.1624 - accuracy: 0.3785\n",
            "Epoch 201: val_accuracy improved from 0.36954 to 0.38161, saving model to /content/asl/Adam/cp-201-0.38.hdf5\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 2.1632 - accuracy: 0.3787 - val_loss: 2.2758 - val_accuracy: 0.3816\n",
            "Epoch 202/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 2.1771 - accuracy: 0.3738\n",
            "Epoch 202: val_accuracy did not improve from 0.38161\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 2.1738 - accuracy: 0.3749 - val_loss: 2.2914 - val_accuracy: 0.3678\n",
            "Epoch 203/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 2.1436 - accuracy: 0.3879\n",
            "Epoch 203: val_accuracy did not improve from 0.38161\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.1476 - accuracy: 0.3868 - val_loss: 2.4191 - val_accuracy: 0.3402\n",
            "Epoch 204/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 2.1221 - accuracy: 0.3897\n",
            "Epoch 204: val_accuracy did not improve from 0.38161\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.1208 - accuracy: 0.3908 - val_loss: 2.3107 - val_accuracy: 0.3667\n",
            "Epoch 205/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 2.1062 - accuracy: 0.4008\n",
            "Epoch 205: val_accuracy did not improve from 0.38161\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.1064 - accuracy: 0.4004 - val_loss: 2.2488 - val_accuracy: 0.3793\n",
            "Epoch 206/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 2.1143 - accuracy: 0.3957\n",
            "Epoch 206: val_accuracy did not improve from 0.38161\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.1140 - accuracy: 0.3961 - val_loss: 2.3911 - val_accuracy: 0.3431\n",
            "Epoch 207/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 2.1116 - accuracy: 0.3963\n",
            "Epoch 207: val_accuracy did not improve from 0.38161\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 2.1111 - accuracy: 0.3967 - val_loss: 2.3146 - val_accuracy: 0.3603\n",
            "Epoch 208/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 2.1011 - accuracy: 0.4002\n",
            "Epoch 208: val_accuracy did not improve from 0.38161\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 2.1050 - accuracy: 0.3984 - val_loss: 2.5304 - val_accuracy: 0.2977\n",
            "Epoch 209/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 2.1019 - accuracy: 0.4001\n",
            "Epoch 209: val_accuracy improved from 0.38161 to 0.38391, saving model to /content/asl/Adam/cp-209-0.38.hdf5\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 2.0993 - accuracy: 0.4016 - val_loss: 2.2542 - val_accuracy: 0.3839\n",
            "Epoch 210/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 2.0775 - accuracy: 0.4054\n",
            "Epoch 210: val_accuracy did not improve from 0.38391\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.0769 - accuracy: 0.4065 - val_loss: 2.3208 - val_accuracy: 0.3598\n",
            "Epoch 211/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 2.0669 - accuracy: 0.4127\n",
            "Epoch 211: val_accuracy did not improve from 0.38391\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.0666 - accuracy: 0.4128 - val_loss: 2.4415 - val_accuracy: 0.3253\n",
            "Epoch 212/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 2.0769 - accuracy: 0.4054\n",
            "Epoch 212: val_accuracy did not improve from 0.38391\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.0750 - accuracy: 0.4060 - val_loss: 2.2344 - val_accuracy: 0.3810\n",
            "Epoch 213/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 2.0365 - accuracy: 0.4192\n",
            "Epoch 213: val_accuracy improved from 0.38391 to 0.39368, saving model to /content/asl/Adam/cp-213-0.39.hdf5\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 2.0382 - accuracy: 0.4184 - val_loss: 2.2589 - val_accuracy: 0.3937\n",
            "Epoch 214/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 2.0955 - accuracy: 0.3983\n",
            "Epoch 214: val_accuracy did not improve from 0.39368\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 2.0948 - accuracy: 0.3986 - val_loss: 2.2657 - val_accuracy: 0.3540\n",
            "Epoch 215/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 2.0773 - accuracy: 0.3992\n",
            "Epoch 215: val_accuracy did not improve from 0.39368\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.0772 - accuracy: 0.3994 - val_loss: 2.4419 - val_accuracy: 0.3115\n",
            "Epoch 216/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 2.0662 - accuracy: 0.4129\n",
            "Epoch 216: val_accuracy did not improve from 0.39368\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.0659 - accuracy: 0.4121 - val_loss: 2.3050 - val_accuracy: 0.3839\n",
            "Epoch 217/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 2.0816 - accuracy: 0.3978\n",
            "Epoch 217: val_accuracy did not improve from 0.39368\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.0818 - accuracy: 0.3974 - val_loss: 2.2252 - val_accuracy: 0.3908\n",
            "Epoch 218/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 2.0733 - accuracy: 0.4052\n",
            "Epoch 218: val_accuracy improved from 0.39368 to 0.40862, saving model to /content/asl/Adam/cp-218-0.41.hdf5\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.0725 - accuracy: 0.4065 - val_loss: 2.1719 - val_accuracy: 0.4086\n",
            "Epoch 219/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 2.0647 - accuracy: 0.4075\n",
            "Epoch 219: val_accuracy did not improve from 0.40862\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 2.0647 - accuracy: 0.4075 - val_loss: 2.3901 - val_accuracy: 0.3362\n",
            "Epoch 220/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 2.0451 - accuracy: 0.4192\n",
            "Epoch 220: val_accuracy did not improve from 0.40862\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 2.0449 - accuracy: 0.4193 - val_loss: 2.3567 - val_accuracy: 0.3517\n",
            "Epoch 221/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 2.1144 - accuracy: 0.3963\n",
            "Epoch 221: val_accuracy did not improve from 0.40862\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 2.1145 - accuracy: 0.3964 - val_loss: 2.3759 - val_accuracy: 0.3253\n",
            "Epoch 222/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 1.9946 - accuracy: 0.4316\n",
            "Epoch 222: val_accuracy did not improve from 0.40862\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.9973 - accuracy: 0.4307 - val_loss: 2.2411 - val_accuracy: 0.3747\n",
            "Epoch 223/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 2.0337 - accuracy: 0.4095\n",
            "Epoch 223: val_accuracy did not improve from 0.40862\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.0352 - accuracy: 0.4093 - val_loss: 2.5059 - val_accuracy: 0.3040\n",
            "Epoch 224/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 2.0600 - accuracy: 0.4112\n",
            "Epoch 224: val_accuracy did not improve from 0.40862\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.0590 - accuracy: 0.4125 - val_loss: 2.2031 - val_accuracy: 0.4063\n",
            "Epoch 225/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 2.0632 - accuracy: 0.4036\n",
            "Epoch 225: val_accuracy did not improve from 0.40862\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.0632 - accuracy: 0.4036 - val_loss: 2.4653 - val_accuracy: 0.3086\n",
            "Epoch 226/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.9726 - accuracy: 0.4315\n",
            "Epoch 226: val_accuracy did not improve from 0.40862\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.9729 - accuracy: 0.4313 - val_loss: 2.3418 - val_accuracy: 0.3437\n",
            "Epoch 227/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 2.0570 - accuracy: 0.4123\n",
            "Epoch 227: val_accuracy did not improve from 0.40862\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 2.0547 - accuracy: 0.4131 - val_loss: 2.2298 - val_accuracy: 0.4000\n",
            "Epoch 228/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 2.0160 - accuracy: 0.4203\n",
            "Epoch 228: val_accuracy did not improve from 0.40862\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 2.0160 - accuracy: 0.4203 - val_loss: 2.3695 - val_accuracy: 0.3420\n",
            "Epoch 229/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 2.0680 - accuracy: 0.4022\n",
            "Epoch 229: val_accuracy did not improve from 0.40862\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.0680 - accuracy: 0.4022 - val_loss: 2.1748 - val_accuracy: 0.3931\n",
            "Epoch 230/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.9772 - accuracy: 0.4325\n",
            "Epoch 230: val_accuracy did not improve from 0.40862\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.9772 - accuracy: 0.4325 - val_loss: 2.2030 - val_accuracy: 0.3989\n",
            "Epoch 231/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.9909 - accuracy: 0.4275\n",
            "Epoch 231: val_accuracy did not improve from 0.40862\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.9898 - accuracy: 0.4280 - val_loss: 2.2074 - val_accuracy: 0.3931\n",
            "Epoch 232/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 1.9867 - accuracy: 0.4214\n",
            "Epoch 232: val_accuracy improved from 0.40862 to 0.42126, saving model to /content/asl/Adam/cp-232-0.42.hdf5\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.9859 - accuracy: 0.4217 - val_loss: 2.1437 - val_accuracy: 0.4213\n",
            "Epoch 233/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 2.0100 - accuracy: 0.4213\n",
            "Epoch 233: val_accuracy did not improve from 0.42126\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 2.0089 - accuracy: 0.4216 - val_loss: 2.1916 - val_accuracy: 0.4046\n",
            "Epoch 234/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.9916 - accuracy: 0.4268\n",
            "Epoch 234: val_accuracy did not improve from 0.42126\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.9911 - accuracy: 0.4270 - val_loss: 2.3998 - val_accuracy: 0.3241\n",
            "Epoch 235/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.9521 - accuracy: 0.4430\n",
            "Epoch 235: val_accuracy did not improve from 0.42126\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.9514 - accuracy: 0.4438 - val_loss: 2.4226 - val_accuracy: 0.3138\n",
            "Epoch 236/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.9488 - accuracy: 0.4334\n",
            "Epoch 236: val_accuracy did not improve from 0.42126\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.9477 - accuracy: 0.4351 - val_loss: 2.2184 - val_accuracy: 0.3753\n",
            "Epoch 237/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.9651 - accuracy: 0.4347\n",
            "Epoch 237: val_accuracy did not improve from 0.42126\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.9626 - accuracy: 0.4349 - val_loss: 2.1836 - val_accuracy: 0.4023\n",
            "Epoch 238/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 2.0048 - accuracy: 0.4225\n",
            "Epoch 238: val_accuracy did not improve from 0.42126\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 2.0012 - accuracy: 0.4231 - val_loss: 2.1958 - val_accuracy: 0.3977\n",
            "Epoch 239/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.9516 - accuracy: 0.4310\n",
            "Epoch 239: val_accuracy did not improve from 0.42126\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.9513 - accuracy: 0.4312 - val_loss: 2.2533 - val_accuracy: 0.3833\n",
            "Epoch 240/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 2.0246 - accuracy: 0.4108\n",
            "Epoch 240: val_accuracy did not improve from 0.42126\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 2.0324 - accuracy: 0.4093 - val_loss: 2.2307 - val_accuracy: 0.3868\n",
            "Epoch 241/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 2.0735 - accuracy: 0.4042\n",
            "Epoch 241: val_accuracy did not improve from 0.42126\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 2.0752 - accuracy: 0.4032 - val_loss: 2.1770 - val_accuracy: 0.4155\n",
            "Epoch 242/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.9360 - accuracy: 0.4394\n",
            "Epoch 242: val_accuracy did not improve from 0.42126\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.9341 - accuracy: 0.4411 - val_loss: 2.2543 - val_accuracy: 0.3718\n",
            "Epoch 243/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.8847 - accuracy: 0.4505\n",
            "Epoch 243: val_accuracy did not improve from 0.42126\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.8838 - accuracy: 0.4504 - val_loss: 2.3105 - val_accuracy: 0.3615\n",
            "Epoch 244/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 1.9365 - accuracy: 0.4404\n",
            "Epoch 244: val_accuracy did not improve from 0.42126\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.9367 - accuracy: 0.4401 - val_loss: 2.2270 - val_accuracy: 0.3816\n",
            "Epoch 245/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.9227 - accuracy: 0.4385\n",
            "Epoch 245: val_accuracy did not improve from 0.42126\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.9234 - accuracy: 0.4382 - val_loss: 2.2871 - val_accuracy: 0.3678\n",
            "Epoch 246/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.9556 - accuracy: 0.4368\n",
            "Epoch 246: val_accuracy improved from 0.42126 to 0.45057, saving model to /content/asl/Adam/cp-246-0.45.hdf5\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.9564 - accuracy: 0.4356 - val_loss: 2.0584 - val_accuracy: 0.4506\n",
            "Epoch 247/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.9536 - accuracy: 0.4418\n",
            "Epoch 247: val_accuracy did not improve from 0.45057\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.9534 - accuracy: 0.4418 - val_loss: 2.0681 - val_accuracy: 0.4443\n",
            "Epoch 248/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 2.0082 - accuracy: 0.4168\n",
            "Epoch 248: val_accuracy did not improve from 0.45057\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 2.0027 - accuracy: 0.4181 - val_loss: 2.0923 - val_accuracy: 0.4356\n",
            "Epoch 249/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.9063 - accuracy: 0.4493\n",
            "Epoch 249: val_accuracy did not improve from 0.45057\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.9064 - accuracy: 0.4499 - val_loss: 2.0458 - val_accuracy: 0.4471\n",
            "Epoch 250/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.8940 - accuracy: 0.4507\n",
            "Epoch 250: val_accuracy did not improve from 0.45057\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.8951 - accuracy: 0.4506 - val_loss: 2.1671 - val_accuracy: 0.4023\n",
            "Epoch 251/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.8715 - accuracy: 0.4549\n",
            "Epoch 251: val_accuracy did not improve from 0.45057\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.8755 - accuracy: 0.4532 - val_loss: 2.1699 - val_accuracy: 0.3908\n",
            "Epoch 252/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.9708 - accuracy: 0.4279\n",
            "Epoch 252: val_accuracy did not improve from 0.45057\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.9676 - accuracy: 0.4290 - val_loss: 2.0732 - val_accuracy: 0.4385\n",
            "Epoch 253/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.9455 - accuracy: 0.4339\n",
            "Epoch 253: val_accuracy did not improve from 0.45057\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.9445 - accuracy: 0.4336 - val_loss: 2.1419 - val_accuracy: 0.4172\n",
            "Epoch 254/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.8803 - accuracy: 0.4540\n",
            "Epoch 254: val_accuracy did not improve from 0.45057\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.8803 - accuracy: 0.4540 - val_loss: 2.1149 - val_accuracy: 0.4247\n",
            "Epoch 255/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.8592 - accuracy: 0.4570\n",
            "Epoch 255: val_accuracy did not improve from 0.45057\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.8592 - accuracy: 0.4570 - val_loss: 2.0856 - val_accuracy: 0.4397\n",
            "Epoch 256/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.9224 - accuracy: 0.4426\n",
            "Epoch 256: val_accuracy did not improve from 0.45057\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.9179 - accuracy: 0.4432 - val_loss: 2.1087 - val_accuracy: 0.4213\n",
            "Epoch 257/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.9285 - accuracy: 0.4376\n",
            "Epoch 257: val_accuracy did not improve from 0.45057\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.9285 - accuracy: 0.4376 - val_loss: 2.0800 - val_accuracy: 0.4247\n",
            "Epoch 258/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 1.9414 - accuracy: 0.4368\n",
            "Epoch 258: val_accuracy did not improve from 0.45057\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.9363 - accuracy: 0.4381 - val_loss: 2.0850 - val_accuracy: 0.4276\n",
            "Epoch 259/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.8772 - accuracy: 0.4517\n",
            "Epoch 259: val_accuracy did not improve from 0.45057\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.8753 - accuracy: 0.4520 - val_loss: 2.3083 - val_accuracy: 0.3678\n",
            "Epoch 260/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.8858 - accuracy: 0.4533\n",
            "Epoch 260: val_accuracy did not improve from 0.45057\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.8858 - accuracy: 0.4533 - val_loss: 2.2940 - val_accuracy: 0.3598\n",
            "Epoch 261/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.8742 - accuracy: 0.4521\n",
            "Epoch 261: val_accuracy did not improve from 0.45057\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.8712 - accuracy: 0.4527 - val_loss: 2.0205 - val_accuracy: 0.4385\n",
            "Epoch 262/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.8837 - accuracy: 0.4520\n",
            "Epoch 262: val_accuracy did not improve from 0.45057\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.8817 - accuracy: 0.4527 - val_loss: 2.0889 - val_accuracy: 0.4270\n",
            "Epoch 263/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.8638 - accuracy: 0.4525\n",
            "Epoch 263: val_accuracy did not improve from 0.45057\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.8639 - accuracy: 0.4524 - val_loss: 2.1744 - val_accuracy: 0.3920\n",
            "Epoch 264/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.8479 - accuracy: 0.4613\n",
            "Epoch 264: val_accuracy did not improve from 0.45057\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.8474 - accuracy: 0.4618 - val_loss: 2.2038 - val_accuracy: 0.3828\n",
            "Epoch 265/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.9544 - accuracy: 0.4267\n",
            "Epoch 265: val_accuracy did not improve from 0.45057\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.9544 - accuracy: 0.4267 - val_loss: 2.4221 - val_accuracy: 0.3236\n",
            "Epoch 266/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.9273 - accuracy: 0.4407\n",
            "Epoch 266: val_accuracy did not improve from 0.45057\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.9273 - accuracy: 0.4407 - val_loss: 2.1264 - val_accuracy: 0.4178\n",
            "Epoch 267/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.8421 - accuracy: 0.4682\n",
            "Epoch 267: val_accuracy did not improve from 0.45057\n",
            "218/218 [==============================] - 3s 11ms/step - loss: 1.8412 - accuracy: 0.4682 - val_loss: 2.2880 - val_accuracy: 0.3626\n",
            "Epoch 268/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.8679 - accuracy: 0.4572\n",
            "Epoch 268: val_accuracy did not improve from 0.45057\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.8631 - accuracy: 0.4596 - val_loss: 2.0537 - val_accuracy: 0.4282\n",
            "Epoch 269/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 1.9042 - accuracy: 0.4462\n",
            "Epoch 269: val_accuracy did not improve from 0.45057\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.8986 - accuracy: 0.4477 - val_loss: 2.1004 - val_accuracy: 0.4115\n",
            "Epoch 270/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.8329 - accuracy: 0.4653\n",
            "Epoch 270: val_accuracy did not improve from 0.45057\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.8329 - accuracy: 0.4652 - val_loss: 2.0892 - val_accuracy: 0.4305\n",
            "Epoch 271/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.8023 - accuracy: 0.4819\n",
            "Epoch 271: val_accuracy did not improve from 0.45057\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.8028 - accuracy: 0.4816 - val_loss: 2.0970 - val_accuracy: 0.4218\n",
            "Epoch 272/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 1.8414 - accuracy: 0.4659\n",
            "Epoch 272: val_accuracy did not improve from 0.45057\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.8381 - accuracy: 0.4659 - val_loss: 2.0142 - val_accuracy: 0.4477\n",
            "Epoch 273/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.8996 - accuracy: 0.4432\n",
            "Epoch 273: val_accuracy did not improve from 0.45057\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.8978 - accuracy: 0.4438 - val_loss: 2.2516 - val_accuracy: 0.3707\n",
            "Epoch 274/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.8421 - accuracy: 0.4640\n",
            "Epoch 274: val_accuracy did not improve from 0.45057\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.8417 - accuracy: 0.4638 - val_loss: 2.3044 - val_accuracy: 0.3707\n",
            "Epoch 275/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.8247 - accuracy: 0.4672\n",
            "Epoch 275: val_accuracy improved from 0.45057 to 0.45287, saving model to /content/asl/Adam/cp-275-0.45.hdf5\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.8247 - accuracy: 0.4672 - val_loss: 2.0076 - val_accuracy: 0.4529\n",
            "Epoch 276/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 1.7803 - accuracy: 0.4795\n",
            "Epoch 276: val_accuracy did not improve from 0.45287\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.7850 - accuracy: 0.4783 - val_loss: 2.3232 - val_accuracy: 0.3557\n",
            "Epoch 277/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.7888 - accuracy: 0.4727\n",
            "Epoch 277: val_accuracy did not improve from 0.45287\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.7864 - accuracy: 0.4733 - val_loss: 2.1261 - val_accuracy: 0.4121\n",
            "Epoch 278/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.8224 - accuracy: 0.4654\n",
            "Epoch 278: val_accuracy did not improve from 0.45287\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.8219 - accuracy: 0.4657 - val_loss: 2.3218 - val_accuracy: 0.3678\n",
            "Epoch 279/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.7681 - accuracy: 0.4826\n",
            "Epoch 279: val_accuracy did not improve from 0.45287\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.7678 - accuracy: 0.4829 - val_loss: 2.0009 - val_accuracy: 0.4466\n",
            "Epoch 280/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.8082 - accuracy: 0.4718\n",
            "Epoch 280: val_accuracy improved from 0.45287 to 0.45920, saving model to /content/asl/Adam/cp-280-0.46.hdf5\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.8091 - accuracy: 0.4711 - val_loss: 1.9740 - val_accuracy: 0.4592\n",
            "Epoch 281/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.7918 - accuracy: 0.4802\n",
            "Epoch 281: val_accuracy did not improve from 0.45920\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.7912 - accuracy: 0.4807 - val_loss: 2.0599 - val_accuracy: 0.4241\n",
            "Epoch 282/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.8213 - accuracy: 0.4608\n",
            "Epoch 282: val_accuracy did not improve from 0.45920\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.8199 - accuracy: 0.4612 - val_loss: 2.0067 - val_accuracy: 0.4511\n",
            "Epoch 283/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.8401 - accuracy: 0.4647\n",
            "Epoch 283: val_accuracy did not improve from 0.45920\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.8433 - accuracy: 0.4634 - val_loss: 2.3357 - val_accuracy: 0.3425\n",
            "Epoch 284/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.8471 - accuracy: 0.4648\n",
            "Epoch 284: val_accuracy did not improve from 0.45920\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.8444 - accuracy: 0.4661 - val_loss: 1.9946 - val_accuracy: 0.4494\n",
            "Epoch 285/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.7856 - accuracy: 0.4710\n",
            "Epoch 285: val_accuracy improved from 0.45920 to 0.47529, saving model to /content/asl/Adam/cp-285-0.48.hdf5\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.7876 - accuracy: 0.4703 - val_loss: 1.9388 - val_accuracy: 0.4753\n",
            "Epoch 286/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.7714 - accuracy: 0.4805\n",
            "Epoch 286: val_accuracy did not improve from 0.47529\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.7696 - accuracy: 0.4806 - val_loss: 1.9459 - val_accuracy: 0.4701\n",
            "Epoch 287/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.7807 - accuracy: 0.4776\n",
            "Epoch 287: val_accuracy did not improve from 0.47529\n",
            "218/218 [==============================] - 3s 11ms/step - loss: 1.7813 - accuracy: 0.4779 - val_loss: 1.9965 - val_accuracy: 0.4506\n",
            "Epoch 288/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.7403 - accuracy: 0.4917\n",
            "Epoch 288: val_accuracy did not improve from 0.47529\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.7429 - accuracy: 0.4914 - val_loss: 1.9824 - val_accuracy: 0.4414\n",
            "Epoch 289/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.7304 - accuracy: 0.4894\n",
            "Epoch 289: val_accuracy improved from 0.47529 to 0.48563, saving model to /content/asl/Adam/cp-289-0.49.hdf5\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.7293 - accuracy: 0.4894 - val_loss: 1.9138 - val_accuracy: 0.4856\n",
            "Epoch 290/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.7847 - accuracy: 0.4779\n",
            "Epoch 290: val_accuracy did not improve from 0.48563\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.7854 - accuracy: 0.4780 - val_loss: 2.0685 - val_accuracy: 0.4201\n",
            "Epoch 291/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.8549 - accuracy: 0.4551\n",
            "Epoch 291: val_accuracy did not improve from 0.48563\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.8540 - accuracy: 0.4552 - val_loss: 1.9401 - val_accuracy: 0.4557\n",
            "Epoch 292/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.8395 - accuracy: 0.4572\n",
            "Epoch 292: val_accuracy did not improve from 0.48563\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.8385 - accuracy: 0.4575 - val_loss: 2.1562 - val_accuracy: 0.4000\n",
            "Epoch 293/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.8786 - accuracy: 0.4497\n",
            "Epoch 293: val_accuracy did not improve from 0.48563\n",
            "218/218 [==============================] - 3s 11ms/step - loss: 1.8786 - accuracy: 0.4497 - val_loss: 2.0701 - val_accuracy: 0.4167\n",
            "Epoch 294/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 1.7085 - accuracy: 0.4991\n",
            "Epoch 294: val_accuracy did not improve from 0.48563\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.7083 - accuracy: 0.4990 - val_loss: 1.9703 - val_accuracy: 0.4540\n",
            "Epoch 295/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.7401 - accuracy: 0.4903\n",
            "Epoch 295: val_accuracy did not improve from 0.48563\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.7404 - accuracy: 0.4897 - val_loss: 2.0262 - val_accuracy: 0.4253\n",
            "Epoch 296/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.7025 - accuracy: 0.4980\n",
            "Epoch 296: val_accuracy did not improve from 0.48563\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.7064 - accuracy: 0.4971 - val_loss: 1.9339 - val_accuracy: 0.4661\n",
            "Epoch 297/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.7420 - accuracy: 0.4905\n",
            "Epoch 297: val_accuracy did not improve from 0.48563\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.7420 - accuracy: 0.4905 - val_loss: 1.8819 - val_accuracy: 0.4822\n",
            "Epoch 298/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 1.7418 - accuracy: 0.4886\n",
            "Epoch 298: val_accuracy did not improve from 0.48563\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.7434 - accuracy: 0.4881 - val_loss: 2.2841 - val_accuracy: 0.3701\n",
            "Epoch 299/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.7475 - accuracy: 0.4814\n",
            "Epoch 299: val_accuracy did not improve from 0.48563\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.7461 - accuracy: 0.4815 - val_loss: 2.0077 - val_accuracy: 0.4293\n",
            "Epoch 300/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.7588 - accuracy: 0.4837\n",
            "Epoch 300: val_accuracy improved from 0.48563 to 0.48736, saving model to /content/asl/Adam/cp-300-0.49.hdf5\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.7605 - accuracy: 0.4835 - val_loss: 1.8870 - val_accuracy: 0.4874\n",
            "Epoch 301/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.7781 - accuracy: 0.4729\n",
            "Epoch 301: val_accuracy did not improve from 0.48736\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.7787 - accuracy: 0.4727 - val_loss: 1.8928 - val_accuracy: 0.4851\n",
            "Epoch 302/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.7738 - accuracy: 0.4782\n",
            "Epoch 302: val_accuracy did not improve from 0.48736\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.7753 - accuracy: 0.4774 - val_loss: 1.9487 - val_accuracy: 0.4741\n",
            "Epoch 303/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.6706 - accuracy: 0.5114\n",
            "Epoch 303: val_accuracy did not improve from 0.48736\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.6727 - accuracy: 0.5103 - val_loss: 1.9976 - val_accuracy: 0.4391\n",
            "Epoch 304/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 1.6838 - accuracy: 0.5018\n",
            "Epoch 304: val_accuracy did not improve from 0.48736\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.6865 - accuracy: 0.5010 - val_loss: 1.9823 - val_accuracy: 0.4425\n",
            "Epoch 305/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.7416 - accuracy: 0.4850\n",
            "Epoch 305: val_accuracy did not improve from 0.48736\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.7447 - accuracy: 0.4848 - val_loss: 1.9344 - val_accuracy: 0.4534\n",
            "Epoch 306/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.7802 - accuracy: 0.4751\n",
            "Epoch 306: val_accuracy did not improve from 0.48736\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.7807 - accuracy: 0.4747 - val_loss: 1.9172 - val_accuracy: 0.4661\n",
            "Epoch 307/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.7907 - accuracy: 0.4746\n",
            "Epoch 307: val_accuracy did not improve from 0.48736\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.7910 - accuracy: 0.4737 - val_loss: 1.9091 - val_accuracy: 0.4724\n",
            "Epoch 308/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.6936 - accuracy: 0.4936\n",
            "Epoch 308: val_accuracy did not improve from 0.48736\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.6946 - accuracy: 0.4940 - val_loss: 2.6691 - val_accuracy: 0.2908\n",
            "Epoch 309/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.7251 - accuracy: 0.4862\n",
            "Epoch 309: val_accuracy improved from 0.48736 to 0.49080, saving model to /content/asl/Adam/cp-309-0.49.hdf5\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.7251 - accuracy: 0.4862 - val_loss: 1.8708 - val_accuracy: 0.4908\n",
            "Epoch 310/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.6559 - accuracy: 0.5126\n",
            "Epoch 310: val_accuracy did not improve from 0.49080\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.6569 - accuracy: 0.5124 - val_loss: 1.8926 - val_accuracy: 0.4713\n",
            "Epoch 311/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.6549 - accuracy: 0.5112\n",
            "Epoch 311: val_accuracy did not improve from 0.49080\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.6549 - accuracy: 0.5112 - val_loss: 2.1739 - val_accuracy: 0.3914\n",
            "Epoch 312/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.7023 - accuracy: 0.4923\n",
            "Epoch 312: val_accuracy did not improve from 0.49080\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.7010 - accuracy: 0.4924 - val_loss: 1.9038 - val_accuracy: 0.4701\n",
            "Epoch 313/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.7289 - accuracy: 0.4880\n",
            "Epoch 313: val_accuracy did not improve from 0.49080\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.7304 - accuracy: 0.4876 - val_loss: 2.0812 - val_accuracy: 0.3966\n",
            "Epoch 314/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.7232 - accuracy: 0.4908\n",
            "Epoch 314: val_accuracy did not improve from 0.49080\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.7243 - accuracy: 0.4908 - val_loss: 1.9090 - val_accuracy: 0.4782\n",
            "Epoch 315/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.7002 - accuracy: 0.4961\n",
            "Epoch 315: val_accuracy did not improve from 0.49080\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.6989 - accuracy: 0.4963 - val_loss: 1.9451 - val_accuracy: 0.4638\n",
            "Epoch 316/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.6536 - accuracy: 0.5066\n",
            "Epoch 316: val_accuracy did not improve from 0.49080\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.6537 - accuracy: 0.5068 - val_loss: 1.9776 - val_accuracy: 0.4460\n",
            "Epoch 317/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.6415 - accuracy: 0.5114\n",
            "Epoch 317: val_accuracy improved from 0.49080 to 0.49828, saving model to /content/asl/Adam/cp-317-0.50.hdf5\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.6426 - accuracy: 0.5115 - val_loss: 1.8448 - val_accuracy: 0.4983\n",
            "Epoch 318/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.6638 - accuracy: 0.5075\n",
            "Epoch 318: val_accuracy did not improve from 0.49828\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.6672 - accuracy: 0.5069 - val_loss: 1.9436 - val_accuracy: 0.4529\n",
            "Epoch 319/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.7203 - accuracy: 0.4949\n",
            "Epoch 319: val_accuracy did not improve from 0.49828\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.7182 - accuracy: 0.4951 - val_loss: 2.0581 - val_accuracy: 0.4155\n",
            "Epoch 320/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.7010 - accuracy: 0.4955\n",
            "Epoch 320: val_accuracy did not improve from 0.49828\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.7010 - accuracy: 0.4955 - val_loss: 1.9745 - val_accuracy: 0.4299\n",
            "Epoch 321/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.7225 - accuracy: 0.4940\n",
            "Epoch 321: val_accuracy did not improve from 0.49828\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.7226 - accuracy: 0.4940 - val_loss: 1.9052 - val_accuracy: 0.4764\n",
            "Epoch 322/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.6459 - accuracy: 0.5088\n",
            "Epoch 322: val_accuracy did not improve from 0.49828\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.6469 - accuracy: 0.5083 - val_loss: 1.9317 - val_accuracy: 0.4517\n",
            "Epoch 323/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.6656 - accuracy: 0.5088\n",
            "Epoch 323: val_accuracy did not improve from 0.49828\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.6656 - accuracy: 0.5088 - val_loss: 1.9176 - val_accuracy: 0.4626\n",
            "Epoch 324/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.6860 - accuracy: 0.4970\n",
            "Epoch 324: val_accuracy did not improve from 0.49828\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.6857 - accuracy: 0.4974 - val_loss: 1.8640 - val_accuracy: 0.4920\n",
            "Epoch 325/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.6316 - accuracy: 0.5147\n",
            "Epoch 325: val_accuracy did not improve from 0.49828\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.6361 - accuracy: 0.5142 - val_loss: 1.9125 - val_accuracy: 0.4690\n",
            "Epoch 326/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.7284 - accuracy: 0.4880\n",
            "Epoch 326: val_accuracy did not improve from 0.49828\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.7275 - accuracy: 0.4884 - val_loss: 1.8862 - val_accuracy: 0.4690\n",
            "Epoch 327/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.6231 - accuracy: 0.5158\n",
            "Epoch 327: val_accuracy did not improve from 0.49828\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.6240 - accuracy: 0.5154 - val_loss: 1.8587 - val_accuracy: 0.4851\n",
            "Epoch 328/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.6633 - accuracy: 0.5080\n",
            "Epoch 328: val_accuracy did not improve from 0.49828\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.6638 - accuracy: 0.5075 - val_loss: 2.0390 - val_accuracy: 0.4299\n",
            "Epoch 329/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.6282 - accuracy: 0.5145\n",
            "Epoch 329: val_accuracy did not improve from 0.49828\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.6271 - accuracy: 0.5148 - val_loss: 1.8884 - val_accuracy: 0.4816\n",
            "Epoch 330/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.6623 - accuracy: 0.5064\n",
            "Epoch 330: val_accuracy did not improve from 0.49828\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.6579 - accuracy: 0.5079 - val_loss: 1.8349 - val_accuracy: 0.4862\n",
            "Epoch 331/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.5832 - accuracy: 0.5343\n",
            "Epoch 331: val_accuracy did not improve from 0.49828\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.5838 - accuracy: 0.5339 - val_loss: 2.1908 - val_accuracy: 0.4126\n",
            "Epoch 332/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.6574 - accuracy: 0.5098\n",
            "Epoch 332: val_accuracy did not improve from 0.49828\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.6581 - accuracy: 0.5093 - val_loss: 1.8647 - val_accuracy: 0.4851\n",
            "Epoch 333/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.6438 - accuracy: 0.5089\n",
            "Epoch 333: val_accuracy did not improve from 0.49828\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.6405 - accuracy: 0.5112 - val_loss: 1.8789 - val_accuracy: 0.4718\n",
            "Epoch 334/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.6709 - accuracy: 0.4964\n",
            "Epoch 334: val_accuracy did not improve from 0.49828\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.6709 - accuracy: 0.4964 - val_loss: 1.9985 - val_accuracy: 0.4414\n",
            "Epoch 335/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.6239 - accuracy: 0.5143\n",
            "Epoch 335: val_accuracy improved from 0.49828 to 0.50115, saving model to /content/asl/Adam/cp-335-0.50.hdf5\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.6282 - accuracy: 0.5135 - val_loss: 1.8380 - val_accuracy: 0.5011\n",
            "Epoch 336/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.6034 - accuracy: 0.5255\n",
            "Epoch 336: val_accuracy did not improve from 0.50115\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.6027 - accuracy: 0.5253 - val_loss: 1.8713 - val_accuracy: 0.4759\n",
            "Epoch 337/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.6174 - accuracy: 0.5154\n",
            "Epoch 337: val_accuracy did not improve from 0.50115\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.6173 - accuracy: 0.5154 - val_loss: 2.1783 - val_accuracy: 0.3966\n",
            "Epoch 338/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.5952 - accuracy: 0.5230\n",
            "Epoch 338: val_accuracy did not improve from 0.50115\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.5954 - accuracy: 0.5230 - val_loss: 1.9279 - val_accuracy: 0.4678\n",
            "Epoch 339/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.5628 - accuracy: 0.5365\n",
            "Epoch 339: val_accuracy improved from 0.50115 to 0.50230, saving model to /content/asl/Adam/cp-339-0.50.hdf5\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.5642 - accuracy: 0.5358 - val_loss: 1.7920 - val_accuracy: 0.5023\n",
            "Epoch 340/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.5977 - accuracy: 0.5250\n",
            "Epoch 340: val_accuracy did not improve from 0.50230\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.5984 - accuracy: 0.5253 - val_loss: 1.9083 - val_accuracy: 0.4506\n",
            "Epoch 341/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.6511 - accuracy: 0.5135\n",
            "Epoch 341: val_accuracy did not improve from 0.50230\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.6512 - accuracy: 0.5132 - val_loss: 1.9193 - val_accuracy: 0.4586\n",
            "Epoch 342/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.6208 - accuracy: 0.5216\n",
            "Epoch 342: val_accuracy did not improve from 0.50230\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.6172 - accuracy: 0.5224 - val_loss: 1.8553 - val_accuracy: 0.4839\n",
            "Epoch 343/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 1.5792 - accuracy: 0.5298\n",
            "Epoch 343: val_accuracy did not improve from 0.50230\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.5770 - accuracy: 0.5305 - val_loss: 1.7878 - val_accuracy: 0.5006\n",
            "Epoch 344/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.5875 - accuracy: 0.5292\n",
            "Epoch 344: val_accuracy did not improve from 0.50230\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.5874 - accuracy: 0.5292 - val_loss: 2.0701 - val_accuracy: 0.4167\n",
            "Epoch 345/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.7110 - accuracy: 0.4982\n",
            "Epoch 345: val_accuracy improved from 0.50230 to 0.50977, saving model to /content/asl/Adam/cp-345-0.51.hdf5\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.7114 - accuracy: 0.4980 - val_loss: 1.7830 - val_accuracy: 0.5098\n",
            "Epoch 346/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.5972 - accuracy: 0.5245\n",
            "Epoch 346: val_accuracy did not improve from 0.50977\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.5975 - accuracy: 0.5244 - val_loss: 1.9003 - val_accuracy: 0.4713\n",
            "Epoch 347/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.6553 - accuracy: 0.5089\n",
            "Epoch 347: val_accuracy did not improve from 0.50977\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.6555 - accuracy: 0.5088 - val_loss: 1.8811 - val_accuracy: 0.4770\n",
            "Epoch 348/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.6747 - accuracy: 0.5075\n",
            "Epoch 348: val_accuracy did not improve from 0.50977\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.6747 - accuracy: 0.5075 - val_loss: 1.8451 - val_accuracy: 0.4851\n",
            "Epoch 349/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.5650 - accuracy: 0.5327\n",
            "Epoch 349: val_accuracy improved from 0.50977 to 0.51092, saving model to /content/asl/Adam/cp-349-0.51.hdf5\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.5640 - accuracy: 0.5332 - val_loss: 1.7832 - val_accuracy: 0.5109\n",
            "Epoch 350/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.5496 - accuracy: 0.5365\n",
            "Epoch 350: val_accuracy did not improve from 0.51092\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.5496 - accuracy: 0.5365 - val_loss: 1.8525 - val_accuracy: 0.4828\n",
            "Epoch 351/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.6238 - accuracy: 0.5162\n",
            "Epoch 351: val_accuracy did not improve from 0.51092\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.6260 - accuracy: 0.5165 - val_loss: 2.0550 - val_accuracy: 0.4195\n",
            "Epoch 352/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.5928 - accuracy: 0.5259\n",
            "Epoch 352: val_accuracy did not improve from 0.51092\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.5891 - accuracy: 0.5272 - val_loss: 1.9422 - val_accuracy: 0.4609\n",
            "Epoch 353/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.5465 - accuracy: 0.5409\n",
            "Epoch 353: val_accuracy improved from 0.51092 to 0.51782, saving model to /content/asl/Adam/cp-353-0.52.hdf5\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.5463 - accuracy: 0.5409 - val_loss: 1.7794 - val_accuracy: 0.5178\n",
            "Epoch 354/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.5591 - accuracy: 0.5374\n",
            "Epoch 354: val_accuracy did not improve from 0.51782\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.5618 - accuracy: 0.5361 - val_loss: 2.0031 - val_accuracy: 0.4299\n",
            "Epoch 355/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.5848 - accuracy: 0.5223\n",
            "Epoch 355: val_accuracy did not improve from 0.51782\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.5857 - accuracy: 0.5223 - val_loss: 1.8811 - val_accuracy: 0.4770\n",
            "Epoch 356/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.6553 - accuracy: 0.5034\n",
            "Epoch 356: val_accuracy did not improve from 0.51782\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.6549 - accuracy: 0.5027 - val_loss: 2.0338 - val_accuracy: 0.4310\n",
            "Epoch 357/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 1.6082 - accuracy: 0.5209\n",
            "Epoch 357: val_accuracy did not improve from 0.51782\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.6044 - accuracy: 0.5216 - val_loss: 1.9186 - val_accuracy: 0.4580\n",
            "Epoch 358/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.5673 - accuracy: 0.5336\n",
            "Epoch 358: val_accuracy did not improve from 0.51782\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.5682 - accuracy: 0.5330 - val_loss: 2.0146 - val_accuracy: 0.4247\n",
            "Epoch 359/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.5262 - accuracy: 0.5419\n",
            "Epoch 359: val_accuracy did not improve from 0.51782\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.5229 - accuracy: 0.5430 - val_loss: 1.9748 - val_accuracy: 0.4339\n",
            "Epoch 360/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.5886 - accuracy: 0.5248\n",
            "Epoch 360: val_accuracy did not improve from 0.51782\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.5883 - accuracy: 0.5247 - val_loss: 1.9246 - val_accuracy: 0.4598\n",
            "Epoch 361/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.5860 - accuracy: 0.5260\n",
            "Epoch 361: val_accuracy did not improve from 0.51782\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.5961 - accuracy: 0.5239 - val_loss: 2.1836 - val_accuracy: 0.3724\n",
            "Epoch 362/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.6190 - accuracy: 0.5202\n",
            "Epoch 362: val_accuracy did not improve from 0.51782\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.6211 - accuracy: 0.5195 - val_loss: 1.8042 - val_accuracy: 0.5115\n",
            "Epoch 363/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.5144 - accuracy: 0.5415\n",
            "Epoch 363: val_accuracy did not improve from 0.51782\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.5133 - accuracy: 0.5417 - val_loss: 1.9068 - val_accuracy: 0.4523\n",
            "Epoch 364/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 1.6145 - accuracy: 0.5136\n",
            "Epoch 364: val_accuracy improved from 0.51782 to 0.52471, saving model to /content/asl/Adam/cp-364-0.52.hdf5\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.6079 - accuracy: 0.5151 - val_loss: 1.7470 - val_accuracy: 0.5247\n",
            "Epoch 365/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.5269 - accuracy: 0.5450\n",
            "Epoch 365: val_accuracy did not improve from 0.52471\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.5256 - accuracy: 0.5448 - val_loss: 2.0286 - val_accuracy: 0.4178\n",
            "Epoch 366/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.5147 - accuracy: 0.5502\n",
            "Epoch 366: val_accuracy did not improve from 0.52471\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.5134 - accuracy: 0.5510 - val_loss: 1.7739 - val_accuracy: 0.5109\n",
            "Epoch 367/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.6975 - accuracy: 0.4963\n",
            "Epoch 367: val_accuracy did not improve from 0.52471\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.6998 - accuracy: 0.4955 - val_loss: 2.0622 - val_accuracy: 0.4138\n",
            "Epoch 368/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.5772 - accuracy: 0.5286\n",
            "Epoch 368: val_accuracy did not improve from 0.52471\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.5761 - accuracy: 0.5289 - val_loss: 2.0155 - val_accuracy: 0.4236\n",
            "Epoch 369/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.5055 - accuracy: 0.5513\n",
            "Epoch 369: val_accuracy did not improve from 0.52471\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.5055 - accuracy: 0.5513 - val_loss: 2.2316 - val_accuracy: 0.3839\n",
            "Epoch 370/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.5500 - accuracy: 0.5362\n",
            "Epoch 370: val_accuracy did not improve from 0.52471\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.5500 - accuracy: 0.5362 - val_loss: 2.0448 - val_accuracy: 0.4437\n",
            "Epoch 371/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.5409 - accuracy: 0.5380\n",
            "Epoch 371: val_accuracy did not improve from 0.52471\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.5404 - accuracy: 0.5382 - val_loss: 1.7441 - val_accuracy: 0.5190\n",
            "Epoch 372/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.5738 - accuracy: 0.5367\n",
            "Epoch 372: val_accuracy did not improve from 0.52471\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.5712 - accuracy: 0.5375 - val_loss: 1.7937 - val_accuracy: 0.5080\n",
            "Epoch 373/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.5446 - accuracy: 0.5312\n",
            "Epoch 373: val_accuracy did not improve from 0.52471\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.5474 - accuracy: 0.5307 - val_loss: 1.7883 - val_accuracy: 0.5023\n",
            "Epoch 374/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.4882 - accuracy: 0.5566\n",
            "Epoch 374: val_accuracy did not improve from 0.52471\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.4890 - accuracy: 0.5562 - val_loss: 1.7649 - val_accuracy: 0.5201\n",
            "Epoch 375/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.5546 - accuracy: 0.5372\n",
            "Epoch 375: val_accuracy did not improve from 0.52471\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.5548 - accuracy: 0.5371 - val_loss: 1.9472 - val_accuracy: 0.4489\n",
            "Epoch 376/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.5371 - accuracy: 0.5372\n",
            "Epoch 376: val_accuracy did not improve from 0.52471\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.5345 - accuracy: 0.5384 - val_loss: 1.7732 - val_accuracy: 0.5115\n",
            "Epoch 377/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.4663 - accuracy: 0.5657\n",
            "Epoch 377: val_accuracy improved from 0.52471 to 0.52644, saving model to /content/asl/Adam/cp-377-0.53.hdf5\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.4642 - accuracy: 0.5659 - val_loss: 1.7517 - val_accuracy: 0.5264\n",
            "Epoch 378/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.4664 - accuracy: 0.5639\n",
            "Epoch 378: val_accuracy did not improve from 0.52644\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.4664 - accuracy: 0.5639 - val_loss: 1.8320 - val_accuracy: 0.4920\n",
            "Epoch 379/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.5401 - accuracy: 0.5391\n",
            "Epoch 379: val_accuracy did not improve from 0.52644\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.5395 - accuracy: 0.5394 - val_loss: 1.8785 - val_accuracy: 0.4575\n",
            "Epoch 380/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.5092 - accuracy: 0.5434\n",
            "Epoch 380: val_accuracy did not improve from 0.52644\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.5092 - accuracy: 0.5434 - val_loss: 1.8334 - val_accuracy: 0.4793\n",
            "Epoch 381/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.5116 - accuracy: 0.5467\n",
            "Epoch 381: val_accuracy did not improve from 0.52644\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.5127 - accuracy: 0.5463 - val_loss: 1.8568 - val_accuracy: 0.4649\n",
            "Epoch 382/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.4964 - accuracy: 0.5483\n",
            "Epoch 382: val_accuracy did not improve from 0.52644\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.4991 - accuracy: 0.5478 - val_loss: 1.8342 - val_accuracy: 0.4914\n",
            "Epoch 383/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.5534 - accuracy: 0.5443\n",
            "Epoch 383: val_accuracy did not improve from 0.52644\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.5549 - accuracy: 0.5424 - val_loss: 1.8125 - val_accuracy: 0.4885\n",
            "Epoch 384/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.5616 - accuracy: 0.5284\n",
            "Epoch 384: val_accuracy improved from 0.52644 to 0.53391, saving model to /content/asl/Adam/cp-384-0.53.hdf5\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.5591 - accuracy: 0.5295 - val_loss: 1.7042 - val_accuracy: 0.5339\n",
            "Epoch 385/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.4876 - accuracy: 0.5533\n",
            "Epoch 385: val_accuracy did not improve from 0.53391\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.4865 - accuracy: 0.5537 - val_loss: 1.7432 - val_accuracy: 0.5115\n",
            "Epoch 386/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.4878 - accuracy: 0.5506\n",
            "Epoch 386: val_accuracy did not improve from 0.53391\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.4903 - accuracy: 0.5500 - val_loss: 1.7446 - val_accuracy: 0.5149\n",
            "Epoch 387/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.4477 - accuracy: 0.5646\n",
            "Epoch 387: val_accuracy did not improve from 0.53391\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.4461 - accuracy: 0.5641 - val_loss: 1.7677 - val_accuracy: 0.5000\n",
            "Epoch 388/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 1.5055 - accuracy: 0.5473\n",
            "Epoch 388: val_accuracy did not improve from 0.53391\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.5096 - accuracy: 0.5460 - val_loss: 2.1972 - val_accuracy: 0.3793\n",
            "Epoch 389/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.5367 - accuracy: 0.5280\n",
            "Epoch 389: val_accuracy did not improve from 0.53391\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.5399 - accuracy: 0.5282 - val_loss: 2.1712 - val_accuracy: 0.4006\n",
            "Epoch 390/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.4426 - accuracy: 0.5669\n",
            "Epoch 390: val_accuracy did not improve from 0.53391\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.4443 - accuracy: 0.5664 - val_loss: 1.7742 - val_accuracy: 0.5046\n",
            "Epoch 391/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.5430 - accuracy: 0.5390\n",
            "Epoch 391: val_accuracy did not improve from 0.53391\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.5428 - accuracy: 0.5388 - val_loss: 1.8903 - val_accuracy: 0.4845\n",
            "Epoch 392/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.5936 - accuracy: 0.5190\n",
            "Epoch 392: val_accuracy did not improve from 0.53391\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.5896 - accuracy: 0.5198 - val_loss: 1.7502 - val_accuracy: 0.5040\n",
            "Epoch 393/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.4345 - accuracy: 0.5688\n",
            "Epoch 393: val_accuracy did not improve from 0.53391\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.4344 - accuracy: 0.5687 - val_loss: 1.7841 - val_accuracy: 0.5011\n",
            "Epoch 394/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.4631 - accuracy: 0.5612\n",
            "Epoch 394: val_accuracy did not improve from 0.53391\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.4631 - accuracy: 0.5612 - val_loss: 1.8128 - val_accuracy: 0.4862\n",
            "Epoch 395/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.4655 - accuracy: 0.5601\n",
            "Epoch 395: val_accuracy did not improve from 0.53391\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.4673 - accuracy: 0.5595 - val_loss: 1.9465 - val_accuracy: 0.4471\n",
            "Epoch 396/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.3977 - accuracy: 0.5856\n",
            "Epoch 396: val_accuracy did not improve from 0.53391\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.3977 - accuracy: 0.5856 - val_loss: 1.7355 - val_accuracy: 0.5167\n",
            "Epoch 397/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.4690 - accuracy: 0.5594\n",
            "Epoch 397: val_accuracy did not improve from 0.53391\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.4684 - accuracy: 0.5598 - val_loss: 1.9643 - val_accuracy: 0.4477\n",
            "Epoch 398/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.4692 - accuracy: 0.5546\n",
            "Epoch 398: val_accuracy did not improve from 0.53391\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.4692 - accuracy: 0.5546 - val_loss: 1.7322 - val_accuracy: 0.5236\n",
            "Epoch 399/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.4453 - accuracy: 0.5650\n",
            "Epoch 399: val_accuracy did not improve from 0.53391\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.4459 - accuracy: 0.5648 - val_loss: 1.7423 - val_accuracy: 0.5115\n",
            "Epoch 400/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.4507 - accuracy: 0.5600\n",
            "Epoch 400: val_accuracy improved from 0.53391 to 0.54598, saving model to /content/asl/Adam/cp-400-0.55.hdf5\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.4537 - accuracy: 0.5591 - val_loss: 1.6787 - val_accuracy: 0.5460\n",
            "Epoch 401/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.3917 - accuracy: 0.5815\n",
            "Epoch 401: val_accuracy did not improve from 0.54598\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.3966 - accuracy: 0.5797 - val_loss: 1.7644 - val_accuracy: 0.5052\n",
            "Epoch 402/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.4756 - accuracy: 0.5503\n",
            "Epoch 402: val_accuracy did not improve from 0.54598\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.4743 - accuracy: 0.5511 - val_loss: 1.9425 - val_accuracy: 0.4420\n",
            "Epoch 403/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 1.4798 - accuracy: 0.5610\n",
            "Epoch 403: val_accuracy did not improve from 0.54598\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.4705 - accuracy: 0.5634 - val_loss: 1.6805 - val_accuracy: 0.5408\n",
            "Epoch 404/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.4881 - accuracy: 0.5486\n",
            "Epoch 404: val_accuracy did not improve from 0.54598\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.4897 - accuracy: 0.5486 - val_loss: 1.7218 - val_accuracy: 0.5270\n",
            "Epoch 405/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.4921 - accuracy: 0.5498\n",
            "Epoch 405: val_accuracy did not improve from 0.54598\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.4913 - accuracy: 0.5494 - val_loss: 2.0066 - val_accuracy: 0.4362\n",
            "Epoch 406/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.4409 - accuracy: 0.5705\n",
            "Epoch 406: val_accuracy did not improve from 0.54598\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.4384 - accuracy: 0.5718 - val_loss: 1.8238 - val_accuracy: 0.4856\n",
            "Epoch 407/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.4059 - accuracy: 0.5739\n",
            "Epoch 407: val_accuracy did not improve from 0.54598\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.4086 - accuracy: 0.5731 - val_loss: 1.7211 - val_accuracy: 0.5230\n",
            "Epoch 408/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.5121 - accuracy: 0.5460\n",
            "Epoch 408: val_accuracy improved from 0.54598 to 0.55172, saving model to /content/asl/Adam/cp-408-0.55.hdf5\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.5141 - accuracy: 0.5457 - val_loss: 1.6555 - val_accuracy: 0.5517\n",
            "Epoch 409/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.4410 - accuracy: 0.5624\n",
            "Epoch 409: val_accuracy did not improve from 0.55172\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.4404 - accuracy: 0.5628 - val_loss: 1.6656 - val_accuracy: 0.5448\n",
            "Epoch 410/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.4712 - accuracy: 0.5568\n",
            "Epoch 410: val_accuracy did not improve from 0.55172\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.4670 - accuracy: 0.5579 - val_loss: 1.8032 - val_accuracy: 0.4948\n",
            "Epoch 411/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.4091 - accuracy: 0.5701\n",
            "Epoch 411: val_accuracy did not improve from 0.55172\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.4091 - accuracy: 0.5701 - val_loss: 1.6920 - val_accuracy: 0.5437\n",
            "Epoch 412/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.4817 - accuracy: 0.5540\n",
            "Epoch 412: val_accuracy did not improve from 0.55172\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.4811 - accuracy: 0.5534 - val_loss: 1.8221 - val_accuracy: 0.4851\n",
            "Epoch 413/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.4354 - accuracy: 0.5609\n",
            "Epoch 413: val_accuracy did not improve from 0.55172\n",
            "218/218 [==============================] - 3s 13ms/step - loss: 1.4339 - accuracy: 0.5615 - val_loss: 1.7049 - val_accuracy: 0.5259\n",
            "Epoch 414/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.4063 - accuracy: 0.5749\n",
            "Epoch 414: val_accuracy did not improve from 0.55172\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.4063 - accuracy: 0.5749 - val_loss: 1.9486 - val_accuracy: 0.4448\n",
            "Epoch 415/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.4566 - accuracy: 0.5621\n",
            "Epoch 415: val_accuracy did not improve from 0.55172\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.4626 - accuracy: 0.5609 - val_loss: 2.5534 - val_accuracy: 0.3523\n",
            "Epoch 416/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.6341 - accuracy: 0.5153\n",
            "Epoch 416: val_accuracy did not improve from 0.55172\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.6320 - accuracy: 0.5161 - val_loss: 1.7501 - val_accuracy: 0.5063\n",
            "Epoch 417/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.4080 - accuracy: 0.5710\n",
            "Epoch 417: val_accuracy did not improve from 0.55172\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.4083 - accuracy: 0.5701 - val_loss: 1.7163 - val_accuracy: 0.5178\n",
            "Epoch 418/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.4358 - accuracy: 0.5626\n",
            "Epoch 418: val_accuracy did not improve from 0.55172\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.4358 - accuracy: 0.5626 - val_loss: 1.6944 - val_accuracy: 0.5310\n",
            "Epoch 419/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.4751 - accuracy: 0.5549\n",
            "Epoch 419: val_accuracy did not improve from 0.55172\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.4751 - accuracy: 0.5549 - val_loss: 1.9208 - val_accuracy: 0.4569\n",
            "Epoch 420/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.3758 - accuracy: 0.5804\n",
            "Epoch 420: val_accuracy did not improve from 0.55172\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.3792 - accuracy: 0.5796 - val_loss: 1.7430 - val_accuracy: 0.5149\n",
            "Epoch 421/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.4100 - accuracy: 0.5720\n",
            "Epoch 421: val_accuracy did not improve from 0.55172\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.4107 - accuracy: 0.5717 - val_loss: 1.8159 - val_accuracy: 0.4770\n",
            "Epoch 422/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.4076 - accuracy: 0.5685\n",
            "Epoch 422: val_accuracy improved from 0.55172 to 0.55287, saving model to /content/asl/Adam/cp-422-0.55.hdf5\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.4060 - accuracy: 0.5693 - val_loss: 1.6356 - val_accuracy: 0.5529\n",
            "Epoch 423/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.3550 - accuracy: 0.5865\n",
            "Epoch 423: val_accuracy did not improve from 0.55287\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.3550 - accuracy: 0.5865 - val_loss: 1.7568 - val_accuracy: 0.5069\n",
            "Epoch 424/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.5293 - accuracy: 0.5502\n",
            "Epoch 424: val_accuracy did not improve from 0.55287\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.5298 - accuracy: 0.5486 - val_loss: 1.9355 - val_accuracy: 0.4477\n",
            "Epoch 425/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.4451 - accuracy: 0.5583\n",
            "Epoch 425: val_accuracy did not improve from 0.55287\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.4450 - accuracy: 0.5583 - val_loss: 1.7150 - val_accuracy: 0.5190\n",
            "Epoch 426/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.3596 - accuracy: 0.5867\n",
            "Epoch 426: val_accuracy did not improve from 0.55287\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.3596 - accuracy: 0.5866 - val_loss: 1.6695 - val_accuracy: 0.5345\n",
            "Epoch 427/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.5248 - accuracy: 0.5385\n",
            "Epoch 427: val_accuracy did not improve from 0.55287\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.5216 - accuracy: 0.5389 - val_loss: 1.9216 - val_accuracy: 0.4603\n",
            "Epoch 428/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.4316 - accuracy: 0.5635\n",
            "Epoch 428: val_accuracy did not improve from 0.55287\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.4274 - accuracy: 0.5645 - val_loss: 1.6926 - val_accuracy: 0.5247\n",
            "Epoch 429/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.3483 - accuracy: 0.5936\n",
            "Epoch 429: val_accuracy did not improve from 0.55287\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.3499 - accuracy: 0.5925 - val_loss: 1.7596 - val_accuracy: 0.5011\n",
            "Epoch 430/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.3990 - accuracy: 0.5734\n",
            "Epoch 430: val_accuracy did not improve from 0.55287\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.3998 - accuracy: 0.5739 - val_loss: 1.7704 - val_accuracy: 0.5023\n",
            "Epoch 431/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.4344 - accuracy: 0.5631\n",
            "Epoch 431: val_accuracy did not improve from 0.55287\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.4331 - accuracy: 0.5635 - val_loss: 1.7113 - val_accuracy: 0.5339\n",
            "Epoch 432/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.3743 - accuracy: 0.5819\n",
            "Epoch 432: val_accuracy improved from 0.55287 to 0.56724, saving model to /content/asl/Adam/cp-432-0.57.hdf5\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.3729 - accuracy: 0.5828 - val_loss: 1.6097 - val_accuracy: 0.5672\n",
            "Epoch 433/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.4290 - accuracy: 0.5628\n",
            "Epoch 433: val_accuracy did not improve from 0.56724\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.4290 - accuracy: 0.5628 - val_loss: 1.6505 - val_accuracy: 0.5511\n",
            "Epoch 434/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.4139 - accuracy: 0.5683\n",
            "Epoch 434: val_accuracy did not improve from 0.56724\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.4133 - accuracy: 0.5693 - val_loss: 1.6608 - val_accuracy: 0.5443\n",
            "Epoch 435/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.3711 - accuracy: 0.5835\n",
            "Epoch 435: val_accuracy did not improve from 0.56724\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.3689 - accuracy: 0.5846 - val_loss: 1.6394 - val_accuracy: 0.5626\n",
            "Epoch 436/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.3545 - accuracy: 0.5850\n",
            "Epoch 436: val_accuracy did not improve from 0.56724\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.3537 - accuracy: 0.5851 - val_loss: 1.8135 - val_accuracy: 0.4851\n",
            "Epoch 437/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.4004 - accuracy: 0.5760\n",
            "Epoch 437: val_accuracy did not improve from 0.56724\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.4024 - accuracy: 0.5749 - val_loss: 1.7822 - val_accuracy: 0.5023\n",
            "Epoch 438/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.4253 - accuracy: 0.5687\n",
            "Epoch 438: val_accuracy did not improve from 0.56724\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.4243 - accuracy: 0.5693 - val_loss: 1.6981 - val_accuracy: 0.5247\n",
            "Epoch 439/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.3771 - accuracy: 0.5815\n",
            "Epoch 439: val_accuracy did not improve from 0.56724\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.3779 - accuracy: 0.5812 - val_loss: 1.7152 - val_accuracy: 0.5236\n",
            "Epoch 440/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.3581 - accuracy: 0.5841\n",
            "Epoch 440: val_accuracy did not improve from 0.56724\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.3588 - accuracy: 0.5839 - val_loss: 1.6068 - val_accuracy: 0.5546\n",
            "Epoch 441/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.3526 - accuracy: 0.5868\n",
            "Epoch 441: val_accuracy did not improve from 0.56724\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.3526 - accuracy: 0.5868 - val_loss: 1.6783 - val_accuracy: 0.5420\n",
            "Epoch 442/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.3780 - accuracy: 0.5778\n",
            "Epoch 442: val_accuracy did not improve from 0.56724\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.3760 - accuracy: 0.5784 - val_loss: 1.6559 - val_accuracy: 0.5408\n",
            "Epoch 443/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.3014 - accuracy: 0.6085\n",
            "Epoch 443: val_accuracy did not improve from 0.56724\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.3014 - accuracy: 0.6085 - val_loss: 1.8861 - val_accuracy: 0.4684\n",
            "Epoch 444/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.4666 - accuracy: 0.5605\n",
            "Epoch 444: val_accuracy did not improve from 0.56724\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.4666 - accuracy: 0.5605 - val_loss: 1.9179 - val_accuracy: 0.4615\n",
            "Epoch 445/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.3725 - accuracy: 0.5844\n",
            "Epoch 445: val_accuracy did not improve from 0.56724\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.3707 - accuracy: 0.5845 - val_loss: 2.3474 - val_accuracy: 0.3793\n",
            "Epoch 446/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.4065 - accuracy: 0.5689\n",
            "Epoch 446: val_accuracy did not improve from 0.56724\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.4046 - accuracy: 0.5690 - val_loss: 1.6043 - val_accuracy: 0.5575\n",
            "Epoch 447/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.2936 - accuracy: 0.6104\n",
            "Epoch 447: val_accuracy did not improve from 0.56724\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.2911 - accuracy: 0.6112 - val_loss: 1.6627 - val_accuracy: 0.5586\n",
            "Epoch 448/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.3658 - accuracy: 0.5876\n",
            "Epoch 448: val_accuracy did not improve from 0.56724\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.3645 - accuracy: 0.5879 - val_loss: 1.6168 - val_accuracy: 0.5506\n",
            "Epoch 449/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.4010 - accuracy: 0.5821\n",
            "Epoch 449: val_accuracy did not improve from 0.56724\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.3974 - accuracy: 0.5830 - val_loss: 1.7089 - val_accuracy: 0.5207\n",
            "Epoch 450/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.2894 - accuracy: 0.6074\n",
            "Epoch 450: val_accuracy did not improve from 0.56724\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.2903 - accuracy: 0.6075 - val_loss: 1.7212 - val_accuracy: 0.5121\n",
            "Epoch 451/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.3044 - accuracy: 0.6014\n",
            "Epoch 451: val_accuracy improved from 0.56724 to 0.57241, saving model to /content/asl/Adam/cp-451-0.57.hdf5\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.3038 - accuracy: 0.6019 - val_loss: 1.5569 - val_accuracy: 0.5724\n",
            "Epoch 452/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.3494 - accuracy: 0.5936\n",
            "Epoch 452: val_accuracy did not improve from 0.57241\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.3514 - accuracy: 0.5925 - val_loss: 1.6582 - val_accuracy: 0.5500\n",
            "Epoch 453/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.3790 - accuracy: 0.5832\n",
            "Epoch 453: val_accuracy did not improve from 0.57241\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.3784 - accuracy: 0.5835 - val_loss: 1.8071 - val_accuracy: 0.4931\n",
            "Epoch 454/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.3609 - accuracy: 0.5864\n",
            "Epoch 454: val_accuracy did not improve from 0.57241\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.3647 - accuracy: 0.5858 - val_loss: 1.8203 - val_accuracy: 0.4828\n",
            "Epoch 455/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.3556 - accuracy: 0.5852\n",
            "Epoch 455: val_accuracy did not improve from 0.57241\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.3569 - accuracy: 0.5851 - val_loss: 1.7077 - val_accuracy: 0.5086\n",
            "Epoch 456/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 1.4241 - accuracy: 0.5647\n",
            "Epoch 456: val_accuracy did not improve from 0.57241\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.4164 - accuracy: 0.5665 - val_loss: 1.6353 - val_accuracy: 0.5425\n",
            "Epoch 457/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 1.3090 - accuracy: 0.6022\n",
            "Epoch 457: val_accuracy did not improve from 0.57241\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.3114 - accuracy: 0.6013 - val_loss: 1.6112 - val_accuracy: 0.5517\n",
            "Epoch 458/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.3915 - accuracy: 0.5740\n",
            "Epoch 458: val_accuracy did not improve from 0.57241\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.3905 - accuracy: 0.5744 - val_loss: 1.6274 - val_accuracy: 0.5523\n",
            "Epoch 459/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.3175 - accuracy: 0.6046\n",
            "Epoch 459: val_accuracy did not improve from 0.57241\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.3269 - accuracy: 0.6022 - val_loss: 1.7560 - val_accuracy: 0.5098\n",
            "Epoch 460/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.3495 - accuracy: 0.5856\n",
            "Epoch 460: val_accuracy did not improve from 0.57241\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.3484 - accuracy: 0.5861 - val_loss: 1.7378 - val_accuracy: 0.5092\n",
            "Epoch 461/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.3272 - accuracy: 0.5980\n",
            "Epoch 461: val_accuracy did not improve from 0.57241\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.3231 - accuracy: 0.5990 - val_loss: 1.5881 - val_accuracy: 0.5563\n",
            "Epoch 462/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 1.3187 - accuracy: 0.5896\n",
            "Epoch 462: val_accuracy did not improve from 0.57241\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.3264 - accuracy: 0.5882 - val_loss: 2.5215 - val_accuracy: 0.3626\n",
            "Epoch 463/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.3110 - accuracy: 0.6100\n",
            "Epoch 463: val_accuracy did not improve from 0.57241\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.3121 - accuracy: 0.6096 - val_loss: 1.7785 - val_accuracy: 0.5184\n",
            "Epoch 464/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.3186 - accuracy: 0.6014\n",
            "Epoch 464: val_accuracy did not improve from 0.57241\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.3188 - accuracy: 0.6016 - val_loss: 1.6052 - val_accuracy: 0.5598\n",
            "Epoch 465/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.3165 - accuracy: 0.5989\n",
            "Epoch 465: val_accuracy did not improve from 0.57241\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.3168 - accuracy: 0.5983 - val_loss: 1.6085 - val_accuracy: 0.5534\n",
            "Epoch 466/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.2333 - accuracy: 0.6264\n",
            "Epoch 466: val_accuracy did not improve from 0.57241\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.2307 - accuracy: 0.6277 - val_loss: 1.6071 - val_accuracy: 0.5598\n",
            "Epoch 467/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.2925 - accuracy: 0.6075\n",
            "Epoch 467: val_accuracy did not improve from 0.57241\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.2913 - accuracy: 0.6085 - val_loss: 1.6611 - val_accuracy: 0.5414\n",
            "Epoch 468/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.3009 - accuracy: 0.6035\n",
            "Epoch 468: val_accuracy did not improve from 0.57241\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.3005 - accuracy: 0.6034 - val_loss: 1.6293 - val_accuracy: 0.5506\n",
            "Epoch 469/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.3808 - accuracy: 0.5825\n",
            "Epoch 469: val_accuracy did not improve from 0.57241\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.3804 - accuracy: 0.5823 - val_loss: 1.6637 - val_accuracy: 0.5293\n",
            "Epoch 470/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.2713 - accuracy: 0.6152\n",
            "Epoch 470: val_accuracy did not improve from 0.57241\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.2684 - accuracy: 0.6165 - val_loss: 1.6629 - val_accuracy: 0.5282\n",
            "Epoch 471/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.3350 - accuracy: 0.5864\n",
            "Epoch 471: val_accuracy did not improve from 0.57241\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.3366 - accuracy: 0.5866 - val_loss: 1.7909 - val_accuracy: 0.4908\n",
            "Epoch 472/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.2856 - accuracy: 0.6090\n",
            "Epoch 472: val_accuracy did not improve from 0.57241\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.2815 - accuracy: 0.6105 - val_loss: 1.6463 - val_accuracy: 0.5454\n",
            "Epoch 473/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.2779 - accuracy: 0.6130\n",
            "Epoch 473: val_accuracy improved from 0.57241 to 0.57701, saving model to /content/asl/Adam/cp-473-0.58.hdf5\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.2790 - accuracy: 0.6126 - val_loss: 1.5638 - val_accuracy: 0.5770\n",
            "Epoch 474/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.3052 - accuracy: 0.6040\n",
            "Epoch 474: val_accuracy did not improve from 0.57701\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.3041 - accuracy: 0.6045 - val_loss: 1.5315 - val_accuracy: 0.5730\n",
            "Epoch 475/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 1.2952 - accuracy: 0.5957\n",
            "Epoch 475: val_accuracy did not improve from 0.57701\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.2955 - accuracy: 0.5960 - val_loss: 1.7072 - val_accuracy: 0.5305\n",
            "Epoch 476/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.5114 - accuracy: 0.5566\n",
            "Epoch 476: val_accuracy did not improve from 0.57701\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.5114 - accuracy: 0.5566 - val_loss: 1.5877 - val_accuracy: 0.5632\n",
            "Epoch 477/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.2395 - accuracy: 0.6177\n",
            "Epoch 477: val_accuracy did not improve from 0.57701\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.2403 - accuracy: 0.6175 - val_loss: 1.5738 - val_accuracy: 0.5695\n",
            "Epoch 478/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.3514 - accuracy: 0.5839\n",
            "Epoch 478: val_accuracy did not improve from 0.57701\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.3545 - accuracy: 0.5829 - val_loss: 1.8186 - val_accuracy: 0.5017\n",
            "Epoch 479/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.2815 - accuracy: 0.6112\n",
            "Epoch 479: val_accuracy did not improve from 0.57701\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.2812 - accuracy: 0.6115 - val_loss: 2.0250 - val_accuracy: 0.4517\n",
            "Epoch 480/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.3278 - accuracy: 0.5972\n",
            "Epoch 480: val_accuracy did not improve from 0.57701\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.3266 - accuracy: 0.5976 - val_loss: 1.6186 - val_accuracy: 0.5402\n",
            "Epoch 481/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.2760 - accuracy: 0.6060\n",
            "Epoch 481: val_accuracy did not improve from 0.57701\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.2759 - accuracy: 0.6059 - val_loss: 2.3818 - val_accuracy: 0.3931\n",
            "Epoch 482/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.2529 - accuracy: 0.6145\n",
            "Epoch 482: val_accuracy did not improve from 0.57701\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.2522 - accuracy: 0.6149 - val_loss: 1.7157 - val_accuracy: 0.5149\n",
            "Epoch 483/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.2464 - accuracy: 0.6222\n",
            "Epoch 483: val_accuracy did not improve from 0.57701\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.2513 - accuracy: 0.6203 - val_loss: 1.7168 - val_accuracy: 0.5195\n",
            "Epoch 484/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.3065 - accuracy: 0.5983\n",
            "Epoch 484: val_accuracy did not improve from 0.57701\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.3102 - accuracy: 0.5973 - val_loss: 1.6225 - val_accuracy: 0.5374\n",
            "Epoch 485/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.2684 - accuracy: 0.6091\n",
            "Epoch 485: val_accuracy did not improve from 0.57701\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.2684 - accuracy: 0.6091 - val_loss: 1.5725 - val_accuracy: 0.5724\n",
            "Epoch 486/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.2488 - accuracy: 0.6161\n",
            "Epoch 486: val_accuracy did not improve from 0.57701\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.2488 - accuracy: 0.6161 - val_loss: 1.5528 - val_accuracy: 0.5724\n",
            "Epoch 487/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.2593 - accuracy: 0.6171\n",
            "Epoch 487: val_accuracy did not improve from 0.57701\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.2599 - accuracy: 0.6167 - val_loss: 1.6428 - val_accuracy: 0.5385\n",
            "Epoch 488/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.2053 - accuracy: 0.6332\n",
            "Epoch 488: val_accuracy did not improve from 0.57701\n",
            "218/218 [==============================] - 3s 13ms/step - loss: 1.2045 - accuracy: 0.6336 - val_loss: 1.5573 - val_accuracy: 0.5770\n",
            "Epoch 489/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.2715 - accuracy: 0.6020\n",
            "Epoch 489: val_accuracy did not improve from 0.57701\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.2714 - accuracy: 0.6019 - val_loss: 1.9089 - val_accuracy: 0.4540\n",
            "Epoch 490/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.2866 - accuracy: 0.6074\n",
            "Epoch 490: val_accuracy did not improve from 0.57701\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.2859 - accuracy: 0.6078 - val_loss: 1.9596 - val_accuracy: 0.4615\n",
            "Epoch 491/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.2082 - accuracy: 0.6301\n",
            "Epoch 491: val_accuracy did not improve from 0.57701\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.2073 - accuracy: 0.6302 - val_loss: 1.6083 - val_accuracy: 0.5448\n",
            "Epoch 492/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.2568 - accuracy: 0.6180\n",
            "Epoch 492: val_accuracy did not improve from 0.57701\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.2698 - accuracy: 0.6145 - val_loss: 1.8753 - val_accuracy: 0.4816\n",
            "Epoch 493/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.3100 - accuracy: 0.5981\n",
            "Epoch 493: val_accuracy did not improve from 0.57701\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.3098 - accuracy: 0.5978 - val_loss: 1.6220 - val_accuracy: 0.5592\n",
            "Epoch 494/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.2326 - accuracy: 0.6234\n",
            "Epoch 494: val_accuracy did not improve from 0.57701\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.2315 - accuracy: 0.6233 - val_loss: 1.7414 - val_accuracy: 0.5052\n",
            "Epoch 495/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.2673 - accuracy: 0.6104\n",
            "Epoch 495: val_accuracy did not improve from 0.57701\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.2670 - accuracy: 0.6109 - val_loss: 1.5653 - val_accuracy: 0.5644\n",
            "Epoch 496/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.2583 - accuracy: 0.6115\n",
            "Epoch 496: val_accuracy did not improve from 0.57701\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.2583 - accuracy: 0.6115 - val_loss: 1.5848 - val_accuracy: 0.5598\n",
            "Epoch 497/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.2880 - accuracy: 0.6076\n",
            "Epoch 497: val_accuracy did not improve from 0.57701\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.2981 - accuracy: 0.6052 - val_loss: 3.3892 - val_accuracy: 0.2851\n",
            "Epoch 498/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.4202 - accuracy: 0.5708\n",
            "Epoch 498: val_accuracy did not improve from 0.57701\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.4202 - accuracy: 0.5708 - val_loss: 1.5237 - val_accuracy: 0.5552\n",
            "Epoch 499/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.2277 - accuracy: 0.6230\n",
            "Epoch 499: val_accuracy did not improve from 0.57701\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.2269 - accuracy: 0.6236 - val_loss: 1.6305 - val_accuracy: 0.5408\n",
            "Epoch 500/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.2300 - accuracy: 0.6249\n",
            "Epoch 500: val_accuracy did not improve from 0.57701\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.2300 - accuracy: 0.6249 - val_loss: 1.7700 - val_accuracy: 0.5069\n",
            "Epoch 501/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.3106 - accuracy: 0.6030\n",
            "Epoch 501: val_accuracy did not improve from 0.57701\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.3101 - accuracy: 0.6033 - val_loss: 1.7173 - val_accuracy: 0.5270\n",
            "Epoch 502/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.2490 - accuracy: 0.6215\n",
            "Epoch 502: val_accuracy did not improve from 0.57701\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.2504 - accuracy: 0.6201 - val_loss: 1.5348 - val_accuracy: 0.5747\n",
            "Epoch 503/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.2091 - accuracy: 0.6293\n",
            "Epoch 503: val_accuracy did not improve from 0.57701\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.2103 - accuracy: 0.6290 - val_loss: 1.7083 - val_accuracy: 0.5230\n",
            "Epoch 504/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.2400 - accuracy: 0.6204\n",
            "Epoch 504: val_accuracy did not improve from 0.57701\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.2389 - accuracy: 0.6207 - val_loss: 1.5272 - val_accuracy: 0.5724\n",
            "Epoch 505/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.2417 - accuracy: 0.6127\n",
            "Epoch 505: val_accuracy did not improve from 0.57701\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.2409 - accuracy: 0.6131 - val_loss: 1.6627 - val_accuracy: 0.5310\n",
            "Epoch 506/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.2616 - accuracy: 0.6177\n",
            "Epoch 506: val_accuracy did not improve from 0.57701\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.2603 - accuracy: 0.6180 - val_loss: 1.5917 - val_accuracy: 0.5546\n",
            "Epoch 507/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.2653 - accuracy: 0.6126\n",
            "Epoch 507: val_accuracy did not improve from 0.57701\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.2668 - accuracy: 0.6125 - val_loss: 1.7485 - val_accuracy: 0.5075\n",
            "Epoch 508/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.1550 - accuracy: 0.6487\n",
            "Epoch 508: val_accuracy improved from 0.57701 to 0.61379, saving model to /content/asl/Adam/cp-508-0.61.hdf5\n",
            "218/218 [==============================] - 3s 13ms/step - loss: 1.1565 - accuracy: 0.6476 - val_loss: 1.4500 - val_accuracy: 0.6138\n",
            "Epoch 509/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.2027 - accuracy: 0.6291\n",
            "Epoch 509: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.1999 - accuracy: 0.6297 - val_loss: 1.6079 - val_accuracy: 0.5402\n",
            "Epoch 510/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.2876 - accuracy: 0.6004\n",
            "Epoch 510: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.2887 - accuracy: 0.6007 - val_loss: 1.5606 - val_accuracy: 0.5770\n",
            "Epoch 511/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.2734 - accuracy: 0.6061\n",
            "Epoch 511: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.2734 - accuracy: 0.6060 - val_loss: 2.2228 - val_accuracy: 0.4029\n",
            "Epoch 512/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.3111 - accuracy: 0.5994\n",
            "Epoch 512: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.3111 - accuracy: 0.5994 - val_loss: 1.7275 - val_accuracy: 0.5132\n",
            "Epoch 513/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.1914 - accuracy: 0.6412\n",
            "Epoch 513: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.1973 - accuracy: 0.6392 - val_loss: 1.7994 - val_accuracy: 0.5034\n",
            "Epoch 514/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.2218 - accuracy: 0.6243\n",
            "Epoch 514: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 3s 13ms/step - loss: 1.2243 - accuracy: 0.6239 - val_loss: 1.4850 - val_accuracy: 0.5971\n",
            "Epoch 515/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.1979 - accuracy: 0.6349\n",
            "Epoch 515: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.1979 - accuracy: 0.6349 - val_loss: 1.6014 - val_accuracy: 0.5529\n",
            "Epoch 516/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.2270 - accuracy: 0.6293\n",
            "Epoch 516: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.2271 - accuracy: 0.6293 - val_loss: 1.8084 - val_accuracy: 0.4948\n",
            "Epoch 517/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.3296 - accuracy: 0.5956\n",
            "Epoch 517: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.3308 - accuracy: 0.5945 - val_loss: 2.0327 - val_accuracy: 0.4247\n",
            "Epoch 518/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.1889 - accuracy: 0.6390\n",
            "Epoch 518: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.1891 - accuracy: 0.6391 - val_loss: 1.6354 - val_accuracy: 0.5494\n",
            "Epoch 519/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.3012 - accuracy: 0.6000\n",
            "Epoch 519: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.2994 - accuracy: 0.6003 - val_loss: 1.5098 - val_accuracy: 0.5879\n",
            "Epoch 520/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.1534 - accuracy: 0.6478\n",
            "Epoch 520: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.1523 - accuracy: 0.6481 - val_loss: 1.4727 - val_accuracy: 0.5856\n",
            "Epoch 521/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.1744 - accuracy: 0.6423\n",
            "Epoch 521: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.1721 - accuracy: 0.6430 - val_loss: 1.5098 - val_accuracy: 0.5810\n",
            "Epoch 522/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.1456 - accuracy: 0.6477\n",
            "Epoch 522: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.1465 - accuracy: 0.6477 - val_loss: 1.5044 - val_accuracy: 0.5943\n",
            "Epoch 523/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.2609 - accuracy: 0.6128\n",
            "Epoch 523: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.2628 - accuracy: 0.6121 - val_loss: 1.6996 - val_accuracy: 0.5207\n",
            "Epoch 524/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 1.1648 - accuracy: 0.6380\n",
            "Epoch 524: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.1631 - accuracy: 0.6388 - val_loss: 1.5485 - val_accuracy: 0.5805\n",
            "Epoch 525/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.1749 - accuracy: 0.6367\n",
            "Epoch 525: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.1731 - accuracy: 0.6375 - val_loss: 1.6002 - val_accuracy: 0.5546\n",
            "Epoch 526/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.2140 - accuracy: 0.6280\n",
            "Epoch 526: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.2128 - accuracy: 0.6283 - val_loss: 1.6321 - val_accuracy: 0.5385\n",
            "Epoch 527/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.1346 - accuracy: 0.6541\n",
            "Epoch 527: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.1327 - accuracy: 0.6547 - val_loss: 1.4743 - val_accuracy: 0.5920\n",
            "Epoch 528/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.1986 - accuracy: 0.6308\n",
            "Epoch 528: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.2000 - accuracy: 0.6310 - val_loss: 1.6223 - val_accuracy: 0.5397\n",
            "Epoch 529/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.1323 - accuracy: 0.6580\n",
            "Epoch 529: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.1326 - accuracy: 0.6576 - val_loss: 1.4619 - val_accuracy: 0.5966\n",
            "Epoch 530/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.2648 - accuracy: 0.6111\n",
            "Epoch 530: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.2628 - accuracy: 0.6121 - val_loss: 1.4909 - val_accuracy: 0.5891\n",
            "Epoch 531/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.2751 - accuracy: 0.6060\n",
            "Epoch 531: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.2765 - accuracy: 0.6059 - val_loss: 1.5119 - val_accuracy: 0.5759\n",
            "Epoch 532/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.1601 - accuracy: 0.6377\n",
            "Epoch 532: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.1606 - accuracy: 0.6384 - val_loss: 1.5706 - val_accuracy: 0.5632\n",
            "Epoch 533/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.2003 - accuracy: 0.6260\n",
            "Epoch 533: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.1977 - accuracy: 0.6267 - val_loss: 1.5068 - val_accuracy: 0.5845\n",
            "Epoch 534/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.1579 - accuracy: 0.6458\n",
            "Epoch 534: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.1579 - accuracy: 0.6458 - val_loss: 1.8337 - val_accuracy: 0.4920\n",
            "Epoch 535/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.2669 - accuracy: 0.6117\n",
            "Epoch 535: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 3s 13ms/step - loss: 1.2675 - accuracy: 0.6122 - val_loss: 1.5041 - val_accuracy: 0.5810\n",
            "Epoch 536/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.1779 - accuracy: 0.6402\n",
            "Epoch 536: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.1779 - accuracy: 0.6402 - val_loss: 1.5242 - val_accuracy: 0.5776\n",
            "Epoch 537/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.1622 - accuracy: 0.6441\n",
            "Epoch 537: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.1607 - accuracy: 0.6441 - val_loss: 1.6330 - val_accuracy: 0.5345\n",
            "Epoch 538/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.1832 - accuracy: 0.6341\n",
            "Epoch 538: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.1832 - accuracy: 0.6341 - val_loss: 1.4812 - val_accuracy: 0.5839\n",
            "Epoch 539/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.1682 - accuracy: 0.6403\n",
            "Epoch 539: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.1661 - accuracy: 0.6407 - val_loss: 1.4475 - val_accuracy: 0.5954\n",
            "Epoch 540/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.1437 - accuracy: 0.6457\n",
            "Epoch 540: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.1406 - accuracy: 0.6471 - val_loss: 1.5332 - val_accuracy: 0.5707\n",
            "Epoch 541/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.1578 - accuracy: 0.6388\n",
            "Epoch 541: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 3s 13ms/step - loss: 1.1578 - accuracy: 0.6388 - val_loss: 1.9947 - val_accuracy: 0.4511\n",
            "Epoch 542/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.1726 - accuracy: 0.6385\n",
            "Epoch 542: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.1760 - accuracy: 0.6374 - val_loss: 1.8036 - val_accuracy: 0.5006\n",
            "Epoch 543/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.1365 - accuracy: 0.6489\n",
            "Epoch 543: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.1365 - accuracy: 0.6489 - val_loss: 1.4421 - val_accuracy: 0.6098\n",
            "Epoch 544/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.1600 - accuracy: 0.6397\n",
            "Epoch 544: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.1600 - accuracy: 0.6397 - val_loss: 1.5292 - val_accuracy: 0.5718\n",
            "Epoch 545/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.2060 - accuracy: 0.6228\n",
            "Epoch 545: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.2073 - accuracy: 0.6223 - val_loss: 1.4648 - val_accuracy: 0.5862\n",
            "Epoch 546/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.0960 - accuracy: 0.6611\n",
            "Epoch 546: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.0960 - accuracy: 0.6611 - val_loss: 1.5535 - val_accuracy: 0.5638\n",
            "Epoch 547/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.1211 - accuracy: 0.6531\n",
            "Epoch 547: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.1248 - accuracy: 0.6519 - val_loss: 1.4887 - val_accuracy: 0.5891\n",
            "Epoch 548/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.1875 - accuracy: 0.6265\n",
            "Epoch 548: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.1888 - accuracy: 0.6266 - val_loss: 1.5329 - val_accuracy: 0.5644\n",
            "Epoch 549/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.1407 - accuracy: 0.6451\n",
            "Epoch 549: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.1407 - accuracy: 0.6451 - val_loss: 1.5474 - val_accuracy: 0.5799\n",
            "Epoch 550/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.1343 - accuracy: 0.6503\n",
            "Epoch 550: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.1348 - accuracy: 0.6497 - val_loss: 1.5143 - val_accuracy: 0.5753\n",
            "Epoch 551/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.1628 - accuracy: 0.6428\n",
            "Epoch 551: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.1628 - accuracy: 0.6428 - val_loss: 1.8148 - val_accuracy: 0.4770\n",
            "Epoch 552/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.1382 - accuracy: 0.6466\n",
            "Epoch 552: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.1382 - accuracy: 0.6466 - val_loss: 1.5471 - val_accuracy: 0.5736\n",
            "Epoch 553/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.1748 - accuracy: 0.6355\n",
            "Epoch 553: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.1758 - accuracy: 0.6352 - val_loss: 1.6252 - val_accuracy: 0.5483\n",
            "Epoch 554/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.1923 - accuracy: 0.6265\n",
            "Epoch 554: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.1928 - accuracy: 0.6267 - val_loss: 1.5833 - val_accuracy: 0.5569\n",
            "Epoch 555/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.1623 - accuracy: 0.6382\n",
            "Epoch 555: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 3s 14ms/step - loss: 1.1617 - accuracy: 0.6382 - val_loss: 1.7646 - val_accuracy: 0.5103\n",
            "Epoch 556/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.1276 - accuracy: 0.6492\n",
            "Epoch 556: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.1278 - accuracy: 0.6490 - val_loss: 1.5552 - val_accuracy: 0.5782\n",
            "Epoch 557/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.0758 - accuracy: 0.6698\n",
            "Epoch 557: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.0775 - accuracy: 0.6697 - val_loss: 1.4690 - val_accuracy: 0.5966\n",
            "Epoch 558/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.2445 - accuracy: 0.6118\n",
            "Epoch 558: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.2405 - accuracy: 0.6126 - val_loss: 1.6039 - val_accuracy: 0.5408\n",
            "Epoch 559/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.0936 - accuracy: 0.6564\n",
            "Epoch 559: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.0919 - accuracy: 0.6572 - val_loss: 1.5422 - val_accuracy: 0.5701\n",
            "Epoch 560/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.1347 - accuracy: 0.6413\n",
            "Epoch 560: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.1343 - accuracy: 0.6412 - val_loss: 1.5746 - val_accuracy: 0.5649\n",
            "Epoch 561/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.1682 - accuracy: 0.6409\n",
            "Epoch 561: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.1670 - accuracy: 0.6415 - val_loss: 1.6295 - val_accuracy: 0.5351\n",
            "Epoch 562/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.1079 - accuracy: 0.6561\n",
            "Epoch 562: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.1090 - accuracy: 0.6556 - val_loss: 1.5261 - val_accuracy: 0.5736\n",
            "Epoch 563/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.1695 - accuracy: 0.6359\n",
            "Epoch 563: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.1695 - accuracy: 0.6361 - val_loss: 1.4820 - val_accuracy: 0.5868\n",
            "Epoch 564/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.1096 - accuracy: 0.6514\n",
            "Epoch 564: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.1102 - accuracy: 0.6513 - val_loss: 1.4170 - val_accuracy: 0.6046\n",
            "Epoch 565/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.0928 - accuracy: 0.6639\n",
            "Epoch 565: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.0923 - accuracy: 0.6639 - val_loss: 1.6659 - val_accuracy: 0.5144\n",
            "Epoch 566/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.2104 - accuracy: 0.6241\n",
            "Epoch 566: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.2085 - accuracy: 0.6243 - val_loss: 1.6280 - val_accuracy: 0.5374\n",
            "Epoch 567/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.1295 - accuracy: 0.6532\n",
            "Epoch 567: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 3s 11ms/step - loss: 1.1288 - accuracy: 0.6537 - val_loss: 1.4509 - val_accuracy: 0.5960\n",
            "Epoch 568/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.0415 - accuracy: 0.6779\n",
            "Epoch 568: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 3s 13ms/step - loss: 1.0403 - accuracy: 0.6779 - val_loss: 1.5445 - val_accuracy: 0.5776\n",
            "Epoch 569/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.1553 - accuracy: 0.6432\n",
            "Epoch 569: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.1559 - accuracy: 0.6431 - val_loss: 1.5420 - val_accuracy: 0.5736\n",
            "Epoch 570/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.1821 - accuracy: 0.6298\n",
            "Epoch 570: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.1824 - accuracy: 0.6295 - val_loss: 1.5994 - val_accuracy: 0.5425\n",
            "Epoch 571/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.0783 - accuracy: 0.6641\n",
            "Epoch 571: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.0783 - accuracy: 0.6641 - val_loss: 1.6942 - val_accuracy: 0.5259\n",
            "Epoch 572/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.1095 - accuracy: 0.6538\n",
            "Epoch 572: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.1075 - accuracy: 0.6552 - val_loss: 1.4596 - val_accuracy: 0.5862\n",
            "Epoch 573/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.0674 - accuracy: 0.6727\n",
            "Epoch 573: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.0647 - accuracy: 0.6739 - val_loss: 1.5883 - val_accuracy: 0.5626\n",
            "Epoch 574/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.0939 - accuracy: 0.6574\n",
            "Epoch 574: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.0945 - accuracy: 0.6578 - val_loss: 1.4995 - val_accuracy: 0.5833\n",
            "Epoch 575/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.0390 - accuracy: 0.6759\n",
            "Epoch 575: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.0429 - accuracy: 0.6746 - val_loss: 1.8017 - val_accuracy: 0.4960\n",
            "Epoch 576/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.0985 - accuracy: 0.6557\n",
            "Epoch 576: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.0985 - accuracy: 0.6557 - val_loss: 1.4563 - val_accuracy: 0.5908\n",
            "Epoch 577/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.1035 - accuracy: 0.6547\n",
            "Epoch 577: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.1035 - accuracy: 0.6547 - val_loss: 1.5213 - val_accuracy: 0.5736\n",
            "Epoch 578/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.0554 - accuracy: 0.6736\n",
            "Epoch 578: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.0554 - accuracy: 0.6736 - val_loss: 1.5154 - val_accuracy: 0.5759\n",
            "Epoch 579/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.1388 - accuracy: 0.6474\n",
            "Epoch 579: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.1393 - accuracy: 0.6473 - val_loss: 1.5020 - val_accuracy: 0.5799\n",
            "Epoch 580/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.1537 - accuracy: 0.6408\n",
            "Epoch 580: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.1570 - accuracy: 0.6391 - val_loss: 1.5161 - val_accuracy: 0.5667\n",
            "Epoch 581/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.0914 - accuracy: 0.6618\n",
            "Epoch 581: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.0914 - accuracy: 0.6618 - val_loss: 1.5121 - val_accuracy: 0.5828\n",
            "Epoch 582/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.0909 - accuracy: 0.6623\n",
            "Epoch 582: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.0902 - accuracy: 0.6625 - val_loss: 1.8620 - val_accuracy: 0.4868\n",
            "Epoch 583/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.0756 - accuracy: 0.6635\n",
            "Epoch 583: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.0756 - accuracy: 0.6629 - val_loss: 1.4454 - val_accuracy: 0.5983\n",
            "Epoch 584/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.2260 - accuracy: 0.6107\n",
            "Epoch 584: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.2198 - accuracy: 0.6129 - val_loss: 1.5433 - val_accuracy: 0.5540\n",
            "Epoch 585/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.0496 - accuracy: 0.6813\n",
            "Epoch 585: val_accuracy did not improve from 0.61379\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.0457 - accuracy: 0.6823 - val_loss: 1.5251 - val_accuracy: 0.5695\n",
            "Epoch 586/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.0836 - accuracy: 0.6518\n",
            "Epoch 586: val_accuracy improved from 0.61379 to 0.63506, saving model to /content/asl/Adam/cp-586-0.64.hdf5\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.0829 - accuracy: 0.6519 - val_loss: 1.3638 - val_accuracy: 0.6351\n",
            "Epoch 587/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.0279 - accuracy: 0.6822\n",
            "Epoch 587: val_accuracy did not improve from 0.63506\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.0295 - accuracy: 0.6816 - val_loss: 2.5558 - val_accuracy: 0.4201\n",
            "Epoch 588/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.2301 - accuracy: 0.6200\n",
            "Epoch 588: val_accuracy did not improve from 0.63506\n",
            "218/218 [==============================] - 3s 14ms/step - loss: 1.2301 - accuracy: 0.6200 - val_loss: 1.4677 - val_accuracy: 0.5983\n",
            "Epoch 589/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.0460 - accuracy: 0.6746\n",
            "Epoch 589: val_accuracy did not improve from 0.63506\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.0454 - accuracy: 0.6747 - val_loss: 1.4150 - val_accuracy: 0.6161\n",
            "Epoch 590/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.0507 - accuracy: 0.6730\n",
            "Epoch 590: val_accuracy did not improve from 0.63506\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.0585 - accuracy: 0.6707 - val_loss: 2.4331 - val_accuracy: 0.3833\n",
            "Epoch 591/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.0748 - accuracy: 0.6646\n",
            "Epoch 591: val_accuracy did not improve from 0.63506\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.0792 - accuracy: 0.6641 - val_loss: 1.4626 - val_accuracy: 0.5914\n",
            "Epoch 592/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.0694 - accuracy: 0.6648\n",
            "Epoch 592: val_accuracy did not improve from 0.63506\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.0694 - accuracy: 0.6648 - val_loss: 1.5310 - val_accuracy: 0.5793\n",
            "Epoch 593/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.0402 - accuracy: 0.6775\n",
            "Epoch 593: val_accuracy did not improve from 0.63506\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.0409 - accuracy: 0.6776 - val_loss: 1.5165 - val_accuracy: 0.5753\n",
            "Epoch 594/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.0673 - accuracy: 0.6632\n",
            "Epoch 594: val_accuracy did not improve from 0.63506\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.0673 - accuracy: 0.6632 - val_loss: 1.5803 - val_accuracy: 0.5477\n",
            "Epoch 595/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.0220 - accuracy: 0.6781\n",
            "Epoch 595: val_accuracy did not improve from 0.63506\n",
            "218/218 [==============================] - 3s 13ms/step - loss: 1.0206 - accuracy: 0.6789 - val_loss: 1.4101 - val_accuracy: 0.6259\n",
            "Epoch 596/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.0393 - accuracy: 0.6741\n",
            "Epoch 596: val_accuracy did not improve from 0.63506\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.0393 - accuracy: 0.6741 - val_loss: 1.7306 - val_accuracy: 0.5207\n",
            "Epoch 597/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.0854 - accuracy: 0.6636\n",
            "Epoch 597: val_accuracy did not improve from 0.63506\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.0842 - accuracy: 0.6639 - val_loss: 1.6344 - val_accuracy: 0.5339\n",
            "Epoch 598/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.1786 - accuracy: 0.6340\n",
            "Epoch 598: val_accuracy did not improve from 0.63506\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.1779 - accuracy: 0.6346 - val_loss: 1.5821 - val_accuracy: 0.5477\n",
            "Epoch 599/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.1341 - accuracy: 0.6415\n",
            "Epoch 599: val_accuracy did not improve from 0.63506\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.1317 - accuracy: 0.6424 - val_loss: 1.5577 - val_accuracy: 0.5649\n",
            "Epoch 600/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.0768 - accuracy: 0.6578\n",
            "Epoch 600: val_accuracy did not improve from 0.63506\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.0775 - accuracy: 0.6573 - val_loss: 1.7991 - val_accuracy: 0.5236\n",
            "Epoch 601/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.0636 - accuracy: 0.6681\n",
            "Epoch 601: val_accuracy did not improve from 0.63506\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.0612 - accuracy: 0.6694 - val_loss: 1.6332 - val_accuracy: 0.5489\n",
            "Epoch 602/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.0342 - accuracy: 0.6741\n",
            "Epoch 602: val_accuracy did not improve from 0.63506\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.0339 - accuracy: 0.6743 - val_loss: 1.4698 - val_accuracy: 0.5989\n",
            "Epoch 603/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.0458 - accuracy: 0.6725\n",
            "Epoch 603: val_accuracy did not improve from 0.63506\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.0454 - accuracy: 0.6731 - val_loss: 1.4005 - val_accuracy: 0.6178\n",
            "Epoch 604/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 0.9858 - accuracy: 0.6945\n",
            "Epoch 604: val_accuracy did not improve from 0.63506\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 0.9861 - accuracy: 0.6953 - val_loss: 1.4407 - val_accuracy: 0.6184\n",
            "Epoch 605/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.1674 - accuracy: 0.6396\n",
            "Epoch 605: val_accuracy did not improve from 0.63506\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.1640 - accuracy: 0.6407 - val_loss: 1.5995 - val_accuracy: 0.5569\n",
            "Epoch 606/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.0697 - accuracy: 0.6673\n",
            "Epoch 606: val_accuracy did not improve from 0.63506\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.0677 - accuracy: 0.6678 - val_loss: 1.6124 - val_accuracy: 0.5557\n",
            "Epoch 607/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.0182 - accuracy: 0.6787\n",
            "Epoch 607: val_accuracy did not improve from 0.63506\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.0195 - accuracy: 0.6787 - val_loss: 1.3914 - val_accuracy: 0.6236\n",
            "Epoch 608/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.0426 - accuracy: 0.6804\n",
            "Epoch 608: val_accuracy did not improve from 0.63506\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.0412 - accuracy: 0.6810 - val_loss: 1.6917 - val_accuracy: 0.5282\n",
            "Epoch 609/700\n",
            "212/218 [============================>.] - ETA: 0s - loss: 1.0352 - accuracy: 0.6753\n",
            "Epoch 609: val_accuracy did not improve from 0.63506\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.0385 - accuracy: 0.6741 - val_loss: 1.3899 - val_accuracy: 0.6178\n",
            "Epoch 610/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.0303 - accuracy: 0.6805\n",
            "Epoch 610: val_accuracy did not improve from 0.63506\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.0335 - accuracy: 0.6797 - val_loss: 1.3870 - val_accuracy: 0.6224\n",
            "Epoch 611/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.1165 - accuracy: 0.6443\n",
            "Epoch 611: val_accuracy did not improve from 0.63506\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.1159 - accuracy: 0.6447 - val_loss: 1.4532 - val_accuracy: 0.5776\n",
            "Epoch 612/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.1553 - accuracy: 0.6497\n",
            "Epoch 612: val_accuracy did not improve from 0.63506\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.1541 - accuracy: 0.6499 - val_loss: 1.5717 - val_accuracy: 0.5466\n",
            "Epoch 613/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.0363 - accuracy: 0.6701\n",
            "Epoch 613: val_accuracy did not improve from 0.63506\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.0363 - accuracy: 0.6701 - val_loss: 1.5422 - val_accuracy: 0.5724\n",
            "Epoch 614/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 0.9952 - accuracy: 0.6928\n",
            "Epoch 614: val_accuracy did not improve from 0.63506\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 0.9952 - accuracy: 0.6928 - val_loss: 1.5048 - val_accuracy: 0.5822\n",
            "Epoch 615/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.0464 - accuracy: 0.6743\n",
            "Epoch 615: val_accuracy did not improve from 0.63506\n",
            "218/218 [==============================] - 3s 13ms/step - loss: 1.0470 - accuracy: 0.6734 - val_loss: 1.4078 - val_accuracy: 0.6034\n",
            "Epoch 616/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.2899 - accuracy: 0.6074\n",
            "Epoch 616: val_accuracy did not improve from 0.63506\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.2887 - accuracy: 0.6076 - val_loss: 1.6616 - val_accuracy: 0.5420\n",
            "Epoch 617/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.0670 - accuracy: 0.6680\n",
            "Epoch 617: val_accuracy did not improve from 0.63506\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.0670 - accuracy: 0.6680 - val_loss: 1.6889 - val_accuracy: 0.5259\n",
            "Epoch 618/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 0.9654 - accuracy: 0.6972\n",
            "Epoch 618: val_accuracy did not improve from 0.63506\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 0.9666 - accuracy: 0.6967 - val_loss: 1.3674 - val_accuracy: 0.6287\n",
            "Epoch 619/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.0222 - accuracy: 0.6869\n",
            "Epoch 619: val_accuracy improved from 0.63506 to 0.63736, saving model to /content/asl/Adam/cp-619-0.64.hdf5\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.0182 - accuracy: 0.6889 - val_loss: 1.3377 - val_accuracy: 0.6374\n",
            "Epoch 620/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 0.9609 - accuracy: 0.7033\n",
            "Epoch 620: val_accuracy did not improve from 0.63736\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 0.9609 - accuracy: 0.7033 - val_loss: 1.3839 - val_accuracy: 0.6161\n",
            "Epoch 621/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.1597 - accuracy: 0.6339\n",
            "Epoch 621: val_accuracy did not improve from 0.63736\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.1597 - accuracy: 0.6339 - val_loss: 1.4293 - val_accuracy: 0.6011\n",
            "Epoch 622/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.0101 - accuracy: 0.6832\n",
            "Epoch 622: val_accuracy did not improve from 0.63736\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.0100 - accuracy: 0.6832 - val_loss: 1.4561 - val_accuracy: 0.6006\n",
            "Epoch 623/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.1031 - accuracy: 0.6532\n",
            "Epoch 623: val_accuracy did not improve from 0.63736\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.1031 - accuracy: 0.6532 - val_loss: 1.3800 - val_accuracy: 0.6103\n",
            "Epoch 624/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 0.9810 - accuracy: 0.6944\n",
            "Epoch 624: val_accuracy did not improve from 0.63736\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 0.9799 - accuracy: 0.6953 - val_loss: 1.3661 - val_accuracy: 0.6230\n",
            "Epoch 625/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 0.9701 - accuracy: 0.6924\n",
            "Epoch 625: val_accuracy did not improve from 0.63736\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 0.9691 - accuracy: 0.6928 - val_loss: 1.4915 - val_accuracy: 0.5793\n",
            "Epoch 626/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 0.9860 - accuracy: 0.6885\n",
            "Epoch 626: val_accuracy did not improve from 0.63736\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 0.9849 - accuracy: 0.6886 - val_loss: 1.3416 - val_accuracy: 0.6328\n",
            "Epoch 627/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.0490 - accuracy: 0.6722\n",
            "Epoch 627: val_accuracy did not improve from 0.63736\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.0518 - accuracy: 0.6717 - val_loss: 1.4390 - val_accuracy: 0.5948\n",
            "Epoch 628/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.1716 - accuracy: 0.6355\n",
            "Epoch 628: val_accuracy did not improve from 0.63736\n",
            "218/218 [==============================] - 3s 13ms/step - loss: 1.1697 - accuracy: 0.6358 - val_loss: 1.3843 - val_accuracy: 0.6167\n",
            "Epoch 629/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.0369 - accuracy: 0.6731\n",
            "Epoch 629: val_accuracy did not improve from 0.63736\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.0378 - accuracy: 0.6724 - val_loss: 1.6332 - val_accuracy: 0.5626\n",
            "Epoch 630/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.0776 - accuracy: 0.6579\n",
            "Epoch 630: val_accuracy did not improve from 0.63736\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.0775 - accuracy: 0.6579 - val_loss: 1.3757 - val_accuracy: 0.6201\n",
            "Epoch 631/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 0.9681 - accuracy: 0.6949\n",
            "Epoch 631: val_accuracy did not improve from 0.63736\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 0.9652 - accuracy: 0.6954 - val_loss: 1.3379 - val_accuracy: 0.6351\n",
            "Epoch 632/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 0.9728 - accuracy: 0.6951\n",
            "Epoch 632: val_accuracy did not improve from 0.63736\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 0.9747 - accuracy: 0.6943 - val_loss: 1.4714 - val_accuracy: 0.5994\n",
            "Epoch 633/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 0.9200 - accuracy: 0.7116\n",
            "Epoch 633: val_accuracy did not improve from 0.63736\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 0.9221 - accuracy: 0.7115 - val_loss: 1.5062 - val_accuracy: 0.5874\n",
            "Epoch 634/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.1185 - accuracy: 0.6539\n",
            "Epoch 634: val_accuracy did not improve from 0.63736\n",
            "218/218 [==============================] - 3s 13ms/step - loss: 1.1183 - accuracy: 0.6537 - val_loss: 1.4381 - val_accuracy: 0.6213\n",
            "Epoch 635/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.0679 - accuracy: 0.6631\n",
            "Epoch 635: val_accuracy did not improve from 0.63736\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.0679 - accuracy: 0.6631 - val_loss: 1.3912 - val_accuracy: 0.6282\n",
            "Epoch 636/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 0.9959 - accuracy: 0.6845\n",
            "Epoch 636: val_accuracy did not improve from 0.63736\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 0.9959 - accuracy: 0.6845 - val_loss: 1.3653 - val_accuracy: 0.6063\n",
            "Epoch 637/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 0.9639 - accuracy: 0.6945\n",
            "Epoch 637: val_accuracy did not improve from 0.63736\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 0.9646 - accuracy: 0.6944 - val_loss: 1.6077 - val_accuracy: 0.5402\n",
            "Epoch 638/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.0537 - accuracy: 0.6660\n",
            "Epoch 638: val_accuracy did not improve from 0.63736\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.0536 - accuracy: 0.6658 - val_loss: 1.6145 - val_accuracy: 0.5420\n",
            "Epoch 639/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.0573 - accuracy: 0.6703\n",
            "Epoch 639: val_accuracy did not improve from 0.63736\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.0556 - accuracy: 0.6710 - val_loss: 1.4189 - val_accuracy: 0.6080\n",
            "Epoch 640/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.0226 - accuracy: 0.6758\n",
            "Epoch 640: val_accuracy did not improve from 0.63736\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.0249 - accuracy: 0.6750 - val_loss: 1.3731 - val_accuracy: 0.6270\n",
            "Epoch 641/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.0175 - accuracy: 0.6829\n",
            "Epoch 641: val_accuracy did not improve from 0.63736\n",
            "218/218 [==============================] - 3s 13ms/step - loss: 1.0175 - accuracy: 0.6829 - val_loss: 1.3752 - val_accuracy: 0.6253\n",
            "Epoch 642/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.0408 - accuracy: 0.6683\n",
            "Epoch 642: val_accuracy did not improve from 0.63736\n",
            "218/218 [==============================] - 3s 13ms/step - loss: 1.0423 - accuracy: 0.6675 - val_loss: 1.3836 - val_accuracy: 0.6063\n",
            "Epoch 643/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.0702 - accuracy: 0.6648\n",
            "Epoch 643: val_accuracy did not improve from 0.63736\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.0702 - accuracy: 0.6648 - val_loss: 1.3786 - val_accuracy: 0.6201\n",
            "Epoch 644/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 0.9528 - accuracy: 0.7022\n",
            "Epoch 644: val_accuracy did not improve from 0.63736\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 0.9537 - accuracy: 0.7020 - val_loss: 1.3834 - val_accuracy: 0.6236\n",
            "Epoch 645/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.0145 - accuracy: 0.6779\n",
            "Epoch 645: val_accuracy did not improve from 0.63736\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.0156 - accuracy: 0.6774 - val_loss: 1.4987 - val_accuracy: 0.5787\n",
            "Epoch 646/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.0055 - accuracy: 0.6799\n",
            "Epoch 646: val_accuracy did not improve from 0.63736\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.0055 - accuracy: 0.6799 - val_loss: 1.3560 - val_accuracy: 0.6132\n",
            "Epoch 647/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.0736 - accuracy: 0.6652\n",
            "Epoch 647: val_accuracy did not improve from 0.63736\n",
            "218/218 [==============================] - 3s 13ms/step - loss: 1.0727 - accuracy: 0.6655 - val_loss: 1.4725 - val_accuracy: 0.6057\n",
            "Epoch 648/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 0.9785 - accuracy: 0.6881\n",
            "Epoch 648: val_accuracy did not improve from 0.63736\n",
            "218/218 [==============================] - 3s 14ms/step - loss: 0.9787 - accuracy: 0.6882 - val_loss: 1.3824 - val_accuracy: 0.6276\n",
            "Epoch 649/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 0.9070 - accuracy: 0.7195\n",
            "Epoch 649: val_accuracy did not improve from 0.63736\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 0.9062 - accuracy: 0.7197 - val_loss: 1.3280 - val_accuracy: 0.6333\n",
            "Epoch 650/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.0089 - accuracy: 0.6787\n",
            "Epoch 650: val_accuracy did not improve from 0.63736\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.0072 - accuracy: 0.6789 - val_loss: 1.5729 - val_accuracy: 0.5534\n",
            "Epoch 651/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 0.9703 - accuracy: 0.6953\n",
            "Epoch 651: val_accuracy did not improve from 0.63736\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 0.9689 - accuracy: 0.6957 - val_loss: 1.3914 - val_accuracy: 0.6190\n",
            "Epoch 652/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 0.9445 - accuracy: 0.7064\n",
            "Epoch 652: val_accuracy did not improve from 0.63736\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 0.9441 - accuracy: 0.7066 - val_loss: 1.4904 - val_accuracy: 0.5937\n",
            "Epoch 653/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 0.9930 - accuracy: 0.6815\n",
            "Epoch 653: val_accuracy improved from 0.63736 to 0.64828, saving model to /content/asl/Adam/cp-653-0.65.hdf5\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 0.9936 - accuracy: 0.6816 - val_loss: 1.2928 - val_accuracy: 0.6483\n",
            "Epoch 654/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 0.9157 - accuracy: 0.7082\n",
            "Epoch 654: val_accuracy did not improve from 0.64828\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 0.9169 - accuracy: 0.7080 - val_loss: 1.3584 - val_accuracy: 0.6264\n",
            "Epoch 655/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.0075 - accuracy: 0.6781\n",
            "Epoch 655: val_accuracy did not improve from 0.64828\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 1.0067 - accuracy: 0.6784 - val_loss: 1.4358 - val_accuracy: 0.5954\n",
            "Epoch 656/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 0.9722 - accuracy: 0.6917\n",
            "Epoch 656: val_accuracy did not improve from 0.64828\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 0.9706 - accuracy: 0.6928 - val_loss: 1.3062 - val_accuracy: 0.6454\n",
            "Epoch 657/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.1146 - accuracy: 0.6527\n",
            "Epoch 657: val_accuracy did not improve from 0.64828\n",
            "218/218 [==============================] - 2s 9ms/step - loss: 1.1096 - accuracy: 0.6533 - val_loss: 1.4331 - val_accuracy: 0.6161\n",
            "Epoch 658/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 0.9514 - accuracy: 0.7009\n",
            "Epoch 658: val_accuracy did not improve from 0.64828\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 0.9522 - accuracy: 0.7007 - val_loss: 1.3580 - val_accuracy: 0.6414\n",
            "Epoch 659/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 0.9601 - accuracy: 0.6984\n",
            "Epoch 659: val_accuracy did not improve from 0.64828\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 0.9605 - accuracy: 0.6981 - val_loss: 1.8766 - val_accuracy: 0.4874\n",
            "Epoch 660/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 0.9599 - accuracy: 0.6923\n",
            "Epoch 660: val_accuracy did not improve from 0.64828\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 0.9552 - accuracy: 0.6940 - val_loss: 1.4608 - val_accuracy: 0.6040\n",
            "Epoch 661/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.0104 - accuracy: 0.6819\n",
            "Epoch 661: val_accuracy did not improve from 0.64828\n",
            "218/218 [==============================] - 3s 14ms/step - loss: 1.0101 - accuracy: 0.6820 - val_loss: 1.4107 - val_accuracy: 0.6023\n",
            "Epoch 662/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 0.9753 - accuracy: 0.6843\n",
            "Epoch 662: val_accuracy did not improve from 0.64828\n",
            "218/218 [==============================] - 3s 11ms/step - loss: 0.9749 - accuracy: 0.6838 - val_loss: 1.3286 - val_accuracy: 0.6287\n",
            "Epoch 663/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 1.0117 - accuracy: 0.6758\n",
            "Epoch 663: val_accuracy did not improve from 0.64828\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.0098 - accuracy: 0.6766 - val_loss: 1.7771 - val_accuracy: 0.4983\n",
            "Epoch 664/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 0.9617 - accuracy: 0.6924\n",
            "Epoch 664: val_accuracy improved from 0.64828 to 0.66494, saving model to /content/asl/Adam/cp-664-0.66.hdf5\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 0.9609 - accuracy: 0.6928 - val_loss: 1.2433 - val_accuracy: 0.6649\n",
            "Epoch 665/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 0.8914 - accuracy: 0.7147\n",
            "Epoch 665: val_accuracy did not improve from 0.66494\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 0.8936 - accuracy: 0.7136 - val_loss: 1.3201 - val_accuracy: 0.6374\n",
            "Epoch 666/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 0.8857 - accuracy: 0.7224\n",
            "Epoch 666: val_accuracy did not improve from 0.66494\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 0.8824 - accuracy: 0.7240 - val_loss: 1.3333 - val_accuracy: 0.6408\n",
            "Epoch 667/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.0221 - accuracy: 0.6828\n",
            "Epoch 667: val_accuracy did not improve from 0.66494\n",
            "218/218 [==============================] - 3s 13ms/step - loss: 1.0215 - accuracy: 0.6832 - val_loss: 1.5363 - val_accuracy: 0.5701\n",
            "Epoch 668/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 0.9080 - accuracy: 0.7083\n",
            "Epoch 668: val_accuracy did not improve from 0.66494\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 0.9088 - accuracy: 0.7079 - val_loss: 1.5423 - val_accuracy: 0.5672\n",
            "Epoch 669/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 0.9497 - accuracy: 0.6951\n",
            "Epoch 669: val_accuracy did not improve from 0.66494\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 0.9483 - accuracy: 0.6951 - val_loss: 1.3153 - val_accuracy: 0.6351\n",
            "Epoch 670/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 0.8905 - accuracy: 0.7141\n",
            "Epoch 670: val_accuracy did not improve from 0.66494\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 0.8895 - accuracy: 0.7142 - val_loss: 1.6198 - val_accuracy: 0.5397\n",
            "Epoch 671/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.0442 - accuracy: 0.6631\n",
            "Epoch 671: val_accuracy did not improve from 0.66494\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.0446 - accuracy: 0.6628 - val_loss: 1.4706 - val_accuracy: 0.5822\n",
            "Epoch 672/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 0.9553 - accuracy: 0.6938\n",
            "Epoch 672: val_accuracy did not improve from 0.66494\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 0.9553 - accuracy: 0.6934 - val_loss: 1.3827 - val_accuracy: 0.6149\n",
            "Epoch 673/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.1344 - accuracy: 0.6516\n",
            "Epoch 673: val_accuracy did not improve from 0.66494\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 1.1269 - accuracy: 0.6539 - val_loss: 1.2530 - val_accuracy: 0.6580\n",
            "Epoch 674/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 0.9424 - accuracy: 0.6868\n",
            "Epoch 674: val_accuracy did not improve from 0.66494\n",
            "218/218 [==============================] - 3s 13ms/step - loss: 0.9440 - accuracy: 0.6859 - val_loss: 1.3918 - val_accuracy: 0.6253\n",
            "Epoch 675/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 0.9512 - accuracy: 0.6964\n",
            "Epoch 675: val_accuracy did not improve from 0.66494\n",
            "218/218 [==============================] - 3s 13ms/step - loss: 0.9512 - accuracy: 0.6964 - val_loss: 1.3891 - val_accuracy: 0.6103\n",
            "Epoch 676/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 0.8886 - accuracy: 0.7158\n",
            "Epoch 676: val_accuracy did not improve from 0.66494\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 0.8868 - accuracy: 0.7168 - val_loss: 1.3180 - val_accuracy: 0.6374\n",
            "Epoch 677/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 0.9217 - accuracy: 0.7029\n",
            "Epoch 677: val_accuracy did not improve from 0.66494\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 0.9217 - accuracy: 0.7029 - val_loss: 1.2925 - val_accuracy: 0.6557\n",
            "Epoch 678/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 1.0029 - accuracy: 0.6817\n",
            "Epoch 678: val_accuracy did not improve from 0.66494\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.0031 - accuracy: 0.6816 - val_loss: 1.3428 - val_accuracy: 0.6213\n",
            "Epoch 679/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 0.9740 - accuracy: 0.6890\n",
            "Epoch 679: val_accuracy did not improve from 0.66494\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 0.9708 - accuracy: 0.6909 - val_loss: 1.4034 - val_accuracy: 0.6069\n",
            "Epoch 680/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 0.9267 - accuracy: 0.7055\n",
            "Epoch 680: val_accuracy did not improve from 0.66494\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 0.9273 - accuracy: 0.7050 - val_loss: 1.3990 - val_accuracy: 0.6080\n",
            "Epoch 681/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 0.9097 - accuracy: 0.7148\n",
            "Epoch 681: val_accuracy did not improve from 0.66494\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 0.9097 - accuracy: 0.7148 - val_loss: 1.3124 - val_accuracy: 0.6437\n",
            "Epoch 682/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 0.8914 - accuracy: 0.7194\n",
            "Epoch 682: val_accuracy did not improve from 0.66494\n",
            "218/218 [==============================] - 2s 11ms/step - loss: 0.8914 - accuracy: 0.7194 - val_loss: 1.7748 - val_accuracy: 0.5121\n",
            "Epoch 683/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 1.0181 - accuracy: 0.6750\n",
            "Epoch 683: val_accuracy did not improve from 0.66494\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.0150 - accuracy: 0.6761 - val_loss: 1.5735 - val_accuracy: 0.5586\n",
            "Epoch 684/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 0.9202 - accuracy: 0.7100\n",
            "Epoch 684: val_accuracy did not improve from 0.66494\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 0.9210 - accuracy: 0.7098 - val_loss: 1.3427 - val_accuracy: 0.6207\n",
            "Epoch 685/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 0.9910 - accuracy: 0.6852\n",
            "Epoch 685: val_accuracy did not improve from 0.66494\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 0.9910 - accuracy: 0.6852 - val_loss: 1.6496 - val_accuracy: 0.5333\n",
            "Epoch 686/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 1.0122 - accuracy: 0.6818\n",
            "Epoch 686: val_accuracy did not improve from 0.66494\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.0130 - accuracy: 0.6807 - val_loss: 1.3837 - val_accuracy: 0.6253\n",
            "Epoch 687/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 0.8587 - accuracy: 0.7269\n",
            "Epoch 687: val_accuracy did not improve from 0.66494\n",
            "218/218 [==============================] - 3s 15ms/step - loss: 0.8583 - accuracy: 0.7267 - val_loss: 1.3514 - val_accuracy: 0.6299\n",
            "Epoch 688/700\n",
            "216/218 [============================>.] - ETA: 0s - loss: 0.9265 - accuracy: 0.6992\n",
            "Epoch 688: val_accuracy did not improve from 0.66494\n",
            "218/218 [==============================] - 3s 12ms/step - loss: 0.9254 - accuracy: 0.6997 - val_loss: 1.2815 - val_accuracy: 0.6569\n",
            "Epoch 689/700\n",
            "213/218 [============================>.] - ETA: 0s - loss: 0.8643 - accuracy: 0.7328\n",
            "Epoch 689: val_accuracy did not improve from 0.66494\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 0.8624 - accuracy: 0.7335 - val_loss: 1.2786 - val_accuracy: 0.6529\n",
            "Epoch 690/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.0232 - accuracy: 0.6786\n",
            "Epoch 690: val_accuracy did not improve from 0.66494\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.0228 - accuracy: 0.6787 - val_loss: 1.6291 - val_accuracy: 0.5385\n",
            "Epoch 691/700\n",
            "215/218 [============================>.] - ETA: 0s - loss: 0.9597 - accuracy: 0.6919\n",
            "Epoch 691: val_accuracy did not improve from 0.66494\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 0.9668 - accuracy: 0.6898 - val_loss: 1.8580 - val_accuracy: 0.4793\n",
            "Epoch 692/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 0.9704 - accuracy: 0.6862\n",
            "Epoch 692: val_accuracy did not improve from 0.66494\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 0.9709 - accuracy: 0.6858 - val_loss: 1.4826 - val_accuracy: 0.5891\n",
            "Epoch 693/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 0.8816 - accuracy: 0.7185\n",
            "Epoch 693: val_accuracy did not improve from 0.66494\n",
            "218/218 [==============================] - 3s 14ms/step - loss: 0.8810 - accuracy: 0.7184 - val_loss: 1.3402 - val_accuracy: 0.6230\n",
            "Epoch 694/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 0.8723 - accuracy: 0.7269\n",
            "Epoch 694: val_accuracy did not improve from 0.66494\n",
            "218/218 [==============================] - 3s 14ms/step - loss: 0.8723 - accuracy: 0.7269 - val_loss: 1.3222 - val_accuracy: 0.6466\n",
            "Epoch 695/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 0.9078 - accuracy: 0.7050\n",
            "Epoch 695: val_accuracy did not improve from 0.66494\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 0.9078 - accuracy: 0.7050 - val_loss: 1.4797 - val_accuracy: 0.5862\n",
            "Epoch 696/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 1.0349 - accuracy: 0.6695\n",
            "Epoch 696: val_accuracy did not improve from 0.66494\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 1.0353 - accuracy: 0.6694 - val_loss: 1.5025 - val_accuracy: 0.5787\n",
            "Epoch 697/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 0.9475 - accuracy: 0.6982\n",
            "Epoch 697: val_accuracy did not improve from 0.66494\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 0.9475 - accuracy: 0.6981 - val_loss: 1.2818 - val_accuracy: 0.6500\n",
            "Epoch 698/700\n",
            "214/218 [============================>.] - ETA: 0s - loss: 0.9147 - accuracy: 0.7036\n",
            "Epoch 698: val_accuracy did not improve from 0.66494\n",
            "218/218 [==============================] - 2s 10ms/step - loss: 0.9162 - accuracy: 0.7036 - val_loss: 1.6068 - val_accuracy: 0.5494\n",
            "Epoch 699/700\n",
            "217/218 [============================>.] - ETA: 0s - loss: 0.8666 - accuracy: 0.7208\n",
            "Epoch 699: val_accuracy did not improve from 0.66494\n",
            "218/218 [==============================] - 3s 14ms/step - loss: 0.8664 - accuracy: 0.7210 - val_loss: 1.5904 - val_accuracy: 0.5580\n",
            "Epoch 700/700\n",
            "218/218 [==============================] - ETA: 0s - loss: 1.2305 - accuracy: 0.6162\n",
            "Epoch 700: val_accuracy did not improve from 0.66494\n",
            "218/218 [==============================] - 3s 13ms/step - loss: 1.2305 - accuracy: 0.6162 - val_loss: 1.4952 - val_accuracy: 0.5805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model with deferent batch size 64"
      ],
      "metadata": {
        "id": "4ipvE1yFgzaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filepath       = \"/content/asl/Adam/cp-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint     = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "history = model.fit(X_train, y_train_encoded, validation_data=(X_test, y_test_encoded), epochs=700, batch_size=64,callbacks=callbacks_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPXyclih3n3i",
        "outputId": "40ab7476-02ff-41c4-dc2c-73ea1a00a773"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 5.1317 - accuracy: 0.0114\n",
            "Epoch 1: val_accuracy improved from -inf to 0.01120, saving model to /content/asl/Adam/cp-01-0.01.hdf5\n",
            "196/196 [==============================] - 9s 19ms/step - loss: 5.1317 - accuracy: 0.0114 - val_loss: 5.1099 - val_accuracy: 0.0112\n",
            "Epoch 2/700\n",
            "  6/196 [..............................] - ETA: 2s - loss: 5.0993 - accuracy: 0.0078    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "191/196 [============================>.] - ETA: 0s - loss: 5.0160 - accuracy: 0.0176\n",
            "Epoch 2: val_accuracy improved from 0.01120 to 0.01825, saving model to /content/asl/Adam/cp-02-0.02.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 5.0135 - accuracy: 0.0175 - val_loss: 4.9346 - val_accuracy: 0.0182\n",
            "Epoch 3/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 4.8835 - accuracy: 0.0238\n",
            "Epoch 3: val_accuracy improved from 0.01825 to 0.02273, saving model to /content/asl/Adam/cp-03-0.02.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 4.8828 - accuracy: 0.0238 - val_loss: 4.8758 - val_accuracy: 0.0227\n",
            "Epoch 4/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 4.7976 - accuracy: 0.0256\n",
            "Epoch 4: val_accuracy improved from 0.02273 to 0.02561, saving model to /content/asl/Adam/cp-04-0.03.hdf5\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 4.7974 - accuracy: 0.0254 - val_loss: 4.7500 - val_accuracy: 0.0256\n",
            "Epoch 5/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 4.7433 - accuracy: 0.0293\n",
            "Epoch 5: val_accuracy improved from 0.02561 to 0.03393, saving model to /content/asl/Adam/cp-05-0.03.hdf5\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 4.7397 - accuracy: 0.0298 - val_loss: 4.6966 - val_accuracy: 0.0339\n",
            "Epoch 6/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 4.6953 - accuracy: 0.0340\n",
            "Epoch 6: val_accuracy did not improve from 0.03393\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 4.6949 - accuracy: 0.0341 - val_loss: 4.6477 - val_accuracy: 0.0291\n",
            "Epoch 7/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 4.5542 - accuracy: 0.0404\n",
            "Epoch 7: val_accuracy improved from 0.03393 to 0.04738, saving model to /content/asl/Adam/cp-07-0.05.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 4.5542 - accuracy: 0.0404 - val_loss: 4.4304 - val_accuracy: 0.0474\n",
            "Epoch 8/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 4.4007 - accuracy: 0.0493\n",
            "Epoch 8: val_accuracy improved from 0.04738 to 0.04834, saving model to /content/asl/Adam/cp-08-0.05.hdf5\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 4.4003 - accuracy: 0.0494 - val_loss: 4.3356 - val_accuracy: 0.0483\n",
            "Epoch 9/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 4.2861 - accuracy: 0.0564\n",
            "Epoch 9: val_accuracy improved from 0.04834 to 0.05858, saving model to /content/asl/Adam/cp-09-0.06.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 4.2855 - accuracy: 0.0565 - val_loss: 4.2310 - val_accuracy: 0.0586\n",
            "Epoch 10/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 4.2057 - accuracy: 0.0575\n",
            "Epoch 10: val_accuracy improved from 0.05858 to 0.06562, saving model to /content/asl/Adam/cp-10-0.07.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 4.2065 - accuracy: 0.0577 - val_loss: 4.1867 - val_accuracy: 0.0656\n",
            "Epoch 11/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 4.1296 - accuracy: 0.0648\n",
            "Epoch 11: val_accuracy did not improve from 0.06562\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 4.1291 - accuracy: 0.0649 - val_loss: 4.1071 - val_accuracy: 0.0579\n",
            "Epoch 12/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 4.0729 - accuracy: 0.0705\n",
            "Epoch 12: val_accuracy improved from 0.06562 to 0.06786, saving model to /content/asl/Adam/cp-12-0.07.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 4.0707 - accuracy: 0.0702 - val_loss: 4.0647 - val_accuracy: 0.0679\n",
            "Epoch 13/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 4.0155 - accuracy: 0.0708\n",
            "Epoch 13: val_accuracy did not improve from 0.06786\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 4.0160 - accuracy: 0.0711 - val_loss: 4.1117 - val_accuracy: 0.0528\n",
            "Epoch 14/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 3.9806 - accuracy: 0.0729\n",
            "Epoch 14: val_accuracy improved from 0.06786 to 0.07618, saving model to /content/asl/Adam/cp-14-0.08.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 3.9791 - accuracy: 0.0733 - val_loss: 3.9764 - val_accuracy: 0.0762\n",
            "Epoch 15/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 3.9092 - accuracy: 0.0801\n",
            "Epoch 15: val_accuracy improved from 0.07618 to 0.07778, saving model to /content/asl/Adam/cp-15-0.08.hdf5\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 3.9091 - accuracy: 0.0803 - val_loss: 3.8889 - val_accuracy: 0.0778\n",
            "Epoch 16/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 3.8669 - accuracy: 0.0849\n",
            "Epoch 16: val_accuracy improved from 0.07778 to 0.09251, saving model to /content/asl/Adam/cp-16-0.09.hdf5\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 3.8660 - accuracy: 0.0841 - val_loss: 3.8176 - val_accuracy: 0.0925\n",
            "Epoch 17/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.8591 - accuracy: 0.0834\n",
            "Epoch 17: val_accuracy did not improve from 0.09251\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 3.8591 - accuracy: 0.0834 - val_loss: 3.8944 - val_accuracy: 0.0794\n",
            "Epoch 18/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 3.7958 - accuracy: 0.0917\n",
            "Epoch 18: val_accuracy did not improve from 0.09251\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 3.7956 - accuracy: 0.0918 - val_loss: 3.7808 - val_accuracy: 0.0896\n",
            "Epoch 19/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.7741 - accuracy: 0.0923\n",
            "Epoch 19: val_accuracy improved from 0.09251 to 0.10563, saving model to /content/asl/Adam/cp-19-0.11.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 3.7741 - accuracy: 0.0923 - val_loss: 3.7260 - val_accuracy: 0.1056\n",
            "Epoch 20/700\n",
            "189/196 [===========================>..] - ETA: 0s - loss: 3.7145 - accuracy: 0.1017\n",
            "Epoch 20: val_accuracy did not improve from 0.10563\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 3.7140 - accuracy: 0.1024 - val_loss: 3.7903 - val_accuracy: 0.0903\n",
            "Epoch 21/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.6881 - accuracy: 0.1050\n",
            "Epoch 21: val_accuracy improved from 0.10563 to 0.11972, saving model to /content/asl/Adam/cp-21-0.12.hdf5\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 3.6881 - accuracy: 0.1050 - val_loss: 3.6102 - val_accuracy: 0.1197\n",
            "Epoch 22/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 3.6814 - accuracy: 0.1027\n",
            "Epoch 22: val_accuracy did not improve from 0.11972\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 3.6806 - accuracy: 0.1033 - val_loss: 3.6827 - val_accuracy: 0.1124\n",
            "Epoch 23/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 3.6193 - accuracy: 0.1151\n",
            "Epoch 23: val_accuracy improved from 0.11972 to 0.12356, saving model to /content/asl/Adam/cp-23-0.12.hdf5\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 3.6188 - accuracy: 0.1153 - val_loss: 3.5527 - val_accuracy: 0.1236\n",
            "Epoch 24/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 3.5844 - accuracy: 0.1211\n",
            "Epoch 24: val_accuracy improved from 0.12356 to 0.14309, saving model to /content/asl/Adam/cp-24-0.14.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 3.5845 - accuracy: 0.1210 - val_loss: 3.5106 - val_accuracy: 0.1431\n",
            "Epoch 25/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 3.5514 - accuracy: 0.1293\n",
            "Epoch 25: val_accuracy did not improve from 0.14309\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 3.5500 - accuracy: 0.1296 - val_loss: 3.5828 - val_accuracy: 0.1146\n",
            "Epoch 26/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 3.5061 - accuracy: 0.1355\n",
            "Epoch 26: val_accuracy did not improve from 0.14309\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 3.5057 - accuracy: 0.1353 - val_loss: 3.5770 - val_accuracy: 0.1268\n",
            "Epoch 27/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 3.4875 - accuracy: 0.1376\n",
            "Epoch 27: val_accuracy did not improve from 0.14309\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 3.4890 - accuracy: 0.1372 - val_loss: 3.6534 - val_accuracy: 0.1050\n",
            "Epoch 28/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.4599 - accuracy: 0.1416\n",
            "Epoch 28: val_accuracy improved from 0.14309 to 0.15429, saving model to /content/asl/Adam/cp-28-0.15.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 3.4599 - accuracy: 0.1416 - val_loss: 3.3863 - val_accuracy: 0.1543\n",
            "Epoch 29/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.4018 - accuracy: 0.1573\n",
            "Epoch 29: val_accuracy improved from 0.15429 to 0.16261, saving model to /content/asl/Adam/cp-29-0.16.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 3.4018 - accuracy: 0.1573 - val_loss: 3.3622 - val_accuracy: 0.1626\n",
            "Epoch 30/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.4477 - accuracy: 0.1428\n",
            "Epoch 30: val_accuracy did not improve from 0.16261\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 3.4477 - accuracy: 0.1428 - val_loss: 3.6758 - val_accuracy: 0.1088\n",
            "Epoch 31/700\n",
            "189/196 [===========================>..] - ETA: 0s - loss: 3.3528 - accuracy: 0.1614\n",
            "Epoch 31: val_accuracy did not improve from 0.16261\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 3.3505 - accuracy: 0.1617 - val_loss: 3.3934 - val_accuracy: 0.1488\n",
            "Epoch 32/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 3.3219 - accuracy: 0.1615\n",
            "Epoch 32: val_accuracy did not improve from 0.16261\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 3.3202 - accuracy: 0.1624 - val_loss: 3.3218 - val_accuracy: 0.1601\n",
            "Epoch 33/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 3.3250 - accuracy: 0.1643\n",
            "Epoch 33: val_accuracy improved from 0.16261 to 0.18374, saving model to /content/asl/Adam/cp-33-0.18.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 3.3247 - accuracy: 0.1644 - val_loss: 3.2441 - val_accuracy: 0.1837\n",
            "Epoch 34/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.2848 - accuracy: 0.1715\n",
            "Epoch 34: val_accuracy did not improve from 0.18374\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 3.2848 - accuracy: 0.1715 - val_loss: 3.5811 - val_accuracy: 0.1277\n",
            "Epoch 35/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 3.2621 - accuracy: 0.1785\n",
            "Epoch 35: val_accuracy did not improve from 0.18374\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 3.2620 - accuracy: 0.1785 - val_loss: 3.2314 - val_accuracy: 0.1796\n",
            "Epoch 36/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 3.2179 - accuracy: 0.1863\n",
            "Epoch 36: val_accuracy did not improve from 0.18374\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 3.2164 - accuracy: 0.1860 - val_loss: 3.6827 - val_accuracy: 0.1188\n",
            "Epoch 37/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.2142 - accuracy: 0.1887\n",
            "Epoch 37: val_accuracy did not improve from 0.18374\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 3.2142 - accuracy: 0.1887 - val_loss: 3.5726 - val_accuracy: 0.1277\n",
            "Epoch 38/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 3.2013 - accuracy: 0.1885\n",
            "Epoch 38: val_accuracy did not improve from 0.18374\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 3.2032 - accuracy: 0.1878 - val_loss: 3.3738 - val_accuracy: 0.1536\n",
            "Epoch 39/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.1651 - accuracy: 0.1961\n",
            "Epoch 39: val_accuracy improved from 0.18374 to 0.20615, saving model to /content/asl/Adam/cp-39-0.21.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 3.1651 - accuracy: 0.1961 - val_loss: 3.0894 - val_accuracy: 0.2061\n",
            "Epoch 40/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.1180 - accuracy: 0.2091\n",
            "Epoch 40: val_accuracy improved from 0.20615 to 0.20903, saving model to /content/asl/Adam/cp-40-0.21.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 3.1180 - accuracy: 0.2091 - val_loss: 3.0842 - val_accuracy: 0.2090\n",
            "Epoch 41/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 3.1242 - accuracy: 0.2072\n",
            "Epoch 41: val_accuracy did not improve from 0.20903\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 3.1248 - accuracy: 0.2064 - val_loss: 3.1634 - val_accuracy: 0.1834\n",
            "Epoch 42/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 3.1184 - accuracy: 0.2015\n",
            "Epoch 42: val_accuracy did not improve from 0.20903\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 3.1172 - accuracy: 0.2016 - val_loss: 3.1060 - val_accuracy: 0.2081\n",
            "Epoch 43/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.0995 - accuracy: 0.2031\n",
            "Epoch 43: val_accuracy did not improve from 0.20903\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 3.0995 - accuracy: 0.2031 - val_loss: 3.1509 - val_accuracy: 0.1844\n",
            "Epoch 44/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 3.0590 - accuracy: 0.2128\n",
            "Epoch 44: val_accuracy improved from 0.20903 to 0.22631, saving model to /content/asl/Adam/cp-44-0.23.hdf5\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 3.0609 - accuracy: 0.2128 - val_loss: 3.0038 - val_accuracy: 0.2263\n",
            "Epoch 45/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 3.0920 - accuracy: 0.2027\n",
            "Epoch 45: val_accuracy improved from 0.22631 to 0.22919, saving model to /content/asl/Adam/cp-45-0.23.hdf5\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 3.0895 - accuracy: 0.2033 - val_loss: 2.9994 - val_accuracy: 0.2292\n",
            "Epoch 46/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 3.0715 - accuracy: 0.2068\n",
            "Epoch 46: val_accuracy did not improve from 0.22919\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 3.0702 - accuracy: 0.2073 - val_loss: 3.0065 - val_accuracy: 0.2231\n",
            "Epoch 47/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 3.0091 - accuracy: 0.2181\n",
            "Epoch 47: val_accuracy did not improve from 0.22919\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 3.0078 - accuracy: 0.2192 - val_loss: 2.9771 - val_accuracy: 0.2161\n",
            "Epoch 48/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 2.9992 - accuracy: 0.2199\n",
            "Epoch 48: val_accuracy did not improve from 0.22919\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 2.9992 - accuracy: 0.2198 - val_loss: 3.1070 - val_accuracy: 0.1921\n",
            "Epoch 49/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 3.0020 - accuracy: 0.2204\n",
            "Epoch 49: val_accuracy did not improve from 0.22919\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 3.0023 - accuracy: 0.2202 - val_loss: 3.0783 - val_accuracy: 0.2033\n",
            "Epoch 50/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.9588 - accuracy: 0.2293\n",
            "Epoch 50: val_accuracy improved from 0.22919 to 0.24616, saving model to /content/asl/Adam/cp-50-0.25.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 2.9588 - accuracy: 0.2293 - val_loss: 2.9069 - val_accuracy: 0.2462\n",
            "Epoch 51/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 2.9620 - accuracy: 0.2262\n",
            "Epoch 51: val_accuracy did not improve from 0.24616\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.9623 - accuracy: 0.2262 - val_loss: 3.1123 - val_accuracy: 0.1991\n",
            "Epoch 52/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 2.9538 - accuracy: 0.2253\n",
            "Epoch 52: val_accuracy did not improve from 0.24616\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.9540 - accuracy: 0.2248 - val_loss: 2.8767 - val_accuracy: 0.2452\n",
            "Epoch 53/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.9368 - accuracy: 0.2303\n",
            "Epoch 53: val_accuracy did not improve from 0.24616\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.9368 - accuracy: 0.2303 - val_loss: 2.9258 - val_accuracy: 0.2337\n",
            "Epoch 54/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 2.9623 - accuracy: 0.2276\n",
            "Epoch 54: val_accuracy did not improve from 0.24616\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.9651 - accuracy: 0.2278 - val_loss: 3.3058 - val_accuracy: 0.1613\n",
            "Epoch 55/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.8930 - accuracy: 0.2406\n",
            "Epoch 55: val_accuracy did not improve from 0.24616\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.8930 - accuracy: 0.2406 - val_loss: 3.0922 - val_accuracy: 0.2039\n",
            "Epoch 56/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 2.8868 - accuracy: 0.2402\n",
            "Epoch 56: val_accuracy improved from 0.24616 to 0.25224, saving model to /content/asl/Adam/cp-56-0.25.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 2.8865 - accuracy: 0.2402 - val_loss: 2.8205 - val_accuracy: 0.2522\n",
            "Epoch 57/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 2.8757 - accuracy: 0.2385\n",
            "Epoch 57: val_accuracy improved from 0.25224 to 0.26376, saving model to /content/asl/Adam/cp-57-0.26.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 2.8734 - accuracy: 0.2386 - val_loss: 2.7976 - val_accuracy: 0.2638\n",
            "Epoch 58/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 2.8592 - accuracy: 0.2425\n",
            "Epoch 58: val_accuracy did not improve from 0.26376\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.8598 - accuracy: 0.2424 - val_loss: 3.1082 - val_accuracy: 0.1873\n",
            "Epoch 59/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 2.8468 - accuracy: 0.2482\n",
            "Epoch 59: val_accuracy did not improve from 0.26376\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.8445 - accuracy: 0.2495 - val_loss: 2.7756 - val_accuracy: 0.2609\n",
            "Epoch 60/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 2.8227 - accuracy: 0.2522\n",
            "Epoch 60: val_accuracy improved from 0.26376 to 0.27049, saving model to /content/asl/Adam/cp-60-0.27.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 2.8264 - accuracy: 0.2514 - val_loss: 2.7475 - val_accuracy: 0.2705\n",
            "Epoch 61/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 2.7937 - accuracy: 0.2589\n",
            "Epoch 61: val_accuracy did not improve from 0.27049\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.7916 - accuracy: 0.2587 - val_loss: 2.7463 - val_accuracy: 0.2682\n",
            "Epoch 62/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 2.7807 - accuracy: 0.2609\n",
            "Epoch 62: val_accuracy did not improve from 0.27049\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.7809 - accuracy: 0.2598 - val_loss: 2.8297 - val_accuracy: 0.2452\n",
            "Epoch 63/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.8031 - accuracy: 0.2554\n",
            "Epoch 63: val_accuracy did not improve from 0.27049\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.8031 - accuracy: 0.2554 - val_loss: 2.7306 - val_accuracy: 0.2698\n",
            "Epoch 64/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 2.7364 - accuracy: 0.2651\n",
            "Epoch 64: val_accuracy improved from 0.27049 to 0.28521, saving model to /content/asl/Adam/cp-64-0.29.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 2.7352 - accuracy: 0.2658 - val_loss: 2.6733 - val_accuracy: 0.2852\n",
            "Epoch 65/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 2.7387 - accuracy: 0.2665\n",
            "Epoch 65: val_accuracy did not improve from 0.28521\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.7387 - accuracy: 0.2659 - val_loss: 2.7769 - val_accuracy: 0.2593\n",
            "Epoch 66/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.7056 - accuracy: 0.2733\n",
            "Epoch 66: val_accuracy did not improve from 0.28521\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.7056 - accuracy: 0.2733 - val_loss: 2.8232 - val_accuracy: 0.2449\n",
            "Epoch 67/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 2.6816 - accuracy: 0.2787\n",
            "Epoch 67: val_accuracy did not improve from 0.28521\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.6812 - accuracy: 0.2786 - val_loss: 2.6930 - val_accuracy: 0.2663\n",
            "Epoch 68/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 2.6837 - accuracy: 0.2792\n",
            "Epoch 68: val_accuracy did not improve from 0.28521\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.6833 - accuracy: 0.2791 - val_loss: 2.7770 - val_accuracy: 0.2478\n",
            "Epoch 69/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 2.6612 - accuracy: 0.2812\n",
            "Epoch 69: val_accuracy did not improve from 0.28521\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.6627 - accuracy: 0.2800 - val_loss: 2.7895 - val_accuracy: 0.2270\n",
            "Epoch 70/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 2.6324 - accuracy: 0.2906\n",
            "Epoch 70: val_accuracy improved from 0.28521 to 0.29193, saving model to /content/asl/Adam/cp-70-0.29.hdf5\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.6334 - accuracy: 0.2903 - val_loss: 2.5965 - val_accuracy: 0.2919\n",
            "Epoch 71/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.6561 - accuracy: 0.2843\n",
            "Epoch 71: val_accuracy improved from 0.29193 to 0.30154, saving model to /content/asl/Adam/cp-71-0.30.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 2.6561 - accuracy: 0.2843 - val_loss: 2.5608 - val_accuracy: 0.3015\n",
            "Epoch 72/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 2.6502 - accuracy: 0.2814\n",
            "Epoch 72: val_accuracy did not improve from 0.30154\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.6487 - accuracy: 0.2820 - val_loss: 2.5654 - val_accuracy: 0.2945\n",
            "Epoch 73/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 2.5755 - accuracy: 0.2979\n",
            "Epoch 73: val_accuracy did not improve from 0.30154\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 2.5742 - accuracy: 0.2977 - val_loss: 2.6460 - val_accuracy: 0.2762\n",
            "Epoch 74/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 2.5592 - accuracy: 0.3057\n",
            "Epoch 74: val_accuracy did not improve from 0.30154\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.5588 - accuracy: 0.3058 - val_loss: 2.8220 - val_accuracy: 0.2407\n",
            "Epoch 75/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 2.5766 - accuracy: 0.2957\n",
            "Epoch 75: val_accuracy did not improve from 0.30154\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 2.5762 - accuracy: 0.2955 - val_loss: 2.5950 - val_accuracy: 0.2971\n",
            "Epoch 76/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 2.5872 - accuracy: 0.2889\n",
            "Epoch 76: val_accuracy improved from 0.30154 to 0.33419, saving model to /content/asl/Adam/cp-76-0.33.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 2.5852 - accuracy: 0.2899 - val_loss: 2.4630 - val_accuracy: 0.3342\n",
            "Epoch 77/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 2.5561 - accuracy: 0.3010\n",
            "Epoch 77: val_accuracy did not improve from 0.33419\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.5550 - accuracy: 0.3016 - val_loss: 2.8379 - val_accuracy: 0.2241\n",
            "Epoch 78/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 2.5083 - accuracy: 0.3098\n",
            "Epoch 78: val_accuracy did not improve from 0.33419\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.5096 - accuracy: 0.3103 - val_loss: 2.6148 - val_accuracy: 0.2782\n",
            "Epoch 79/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 2.4863 - accuracy: 0.3114\n",
            "Epoch 79: val_accuracy did not improve from 0.33419\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.4876 - accuracy: 0.3112 - val_loss: 2.4440 - val_accuracy: 0.3127\n",
            "Epoch 80/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 2.4844 - accuracy: 0.3170\n",
            "Epoch 80: val_accuracy did not improve from 0.33419\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.4840 - accuracy: 0.3167 - val_loss: 2.5238 - val_accuracy: 0.3172\n",
            "Epoch 81/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 2.5303 - accuracy: 0.3056\n",
            "Epoch 81: val_accuracy improved from 0.33419 to 0.34283, saving model to /content/asl/Adam/cp-81-0.34.hdf5\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.5265 - accuracy: 0.3063 - val_loss: 2.4279 - val_accuracy: 0.3428\n",
            "Epoch 82/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 2.4597 - accuracy: 0.3211\n",
            "Epoch 82: val_accuracy did not improve from 0.34283\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.4601 - accuracy: 0.3212 - val_loss: 2.4889 - val_accuracy: 0.3041\n",
            "Epoch 83/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.4540 - accuracy: 0.3248\n",
            "Epoch 83: val_accuracy improved from 0.34283 to 0.34475, saving model to /content/asl/Adam/cp-83-0.34.hdf5\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.4540 - accuracy: 0.3248 - val_loss: 2.3759 - val_accuracy: 0.3448\n",
            "Epoch 84/700\n",
            "189/196 [===========================>..] - ETA: 0s - loss: 2.4146 - accuracy: 0.3291\n",
            "Epoch 84: val_accuracy did not improve from 0.34475\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.4154 - accuracy: 0.3286 - val_loss: 2.3871 - val_accuracy: 0.3275\n",
            "Epoch 85/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 2.4114 - accuracy: 0.3330\n",
            "Epoch 85: val_accuracy did not improve from 0.34475\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.4129 - accuracy: 0.3325 - val_loss: 2.3509 - val_accuracy: 0.3313\n",
            "Epoch 86/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 2.3986 - accuracy: 0.3312\n",
            "Epoch 86: val_accuracy improved from 0.34475 to 0.35595, saving model to /content/asl/Adam/cp-86-0.36.hdf5\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.3975 - accuracy: 0.3311 - val_loss: 2.3448 - val_accuracy: 0.3560\n",
            "Epoch 87/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 2.3792 - accuracy: 0.3383\n",
            "Epoch 87: val_accuracy did not improve from 0.35595\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.3774 - accuracy: 0.3391 - val_loss: 2.3093 - val_accuracy: 0.3534\n",
            "Epoch 88/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 2.3473 - accuracy: 0.3482\n",
            "Epoch 88: val_accuracy did not improve from 0.35595\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.3471 - accuracy: 0.3481 - val_loss: 2.4810 - val_accuracy: 0.3159\n",
            "Epoch 89/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.3280 - accuracy: 0.3556\n",
            "Epoch 89: val_accuracy did not improve from 0.35595\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.3280 - accuracy: 0.3556 - val_loss: 2.3221 - val_accuracy: 0.3476\n",
            "Epoch 90/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 2.3171 - accuracy: 0.3588\n",
            "Epoch 90: val_accuracy improved from 0.35595 to 0.36652, saving model to /content/asl/Adam/cp-90-0.37.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 2.3151 - accuracy: 0.3592 - val_loss: 2.2646 - val_accuracy: 0.3665\n",
            "Epoch 91/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 2.2959 - accuracy: 0.3577\n",
            "Epoch 91: val_accuracy did not improve from 0.36652\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.2959 - accuracy: 0.3582 - val_loss: 2.3397 - val_accuracy: 0.3393\n",
            "Epoch 92/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 2.3246 - accuracy: 0.3486\n",
            "Epoch 92: val_accuracy did not improve from 0.36652\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.3246 - accuracy: 0.3486 - val_loss: 2.2647 - val_accuracy: 0.3665\n",
            "Epoch 93/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 2.2888 - accuracy: 0.3618\n",
            "Epoch 93: val_accuracy improved from 0.36652 to 0.39181, saving model to /content/asl/Adam/cp-93-0.39.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 2.2884 - accuracy: 0.3620 - val_loss: 2.2086 - val_accuracy: 0.3918\n",
            "Epoch 94/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 2.2209 - accuracy: 0.3778\n",
            "Epoch 94: val_accuracy did not improve from 0.39181\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.2210 - accuracy: 0.3779 - val_loss: 2.1956 - val_accuracy: 0.3822\n",
            "Epoch 95/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 2.2534 - accuracy: 0.3674\n",
            "Epoch 95: val_accuracy improved from 0.39181 to 0.39213, saving model to /content/asl/Adam/cp-95-0.39.hdf5\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.2501 - accuracy: 0.3684 - val_loss: 2.1646 - val_accuracy: 0.3921\n",
            "Epoch 96/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.2338 - accuracy: 0.3736\n",
            "Epoch 96: val_accuracy did not improve from 0.39213\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 2.2338 - accuracy: 0.3736 - val_loss: 2.1735 - val_accuracy: 0.3812\n",
            "Epoch 97/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 2.2049 - accuracy: 0.3760\n",
            "Epoch 97: val_accuracy did not improve from 0.39213\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.2070 - accuracy: 0.3763 - val_loss: 2.2339 - val_accuracy: 0.3784\n",
            "Epoch 98/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 2.2184 - accuracy: 0.3795\n",
            "Epoch 98: val_accuracy improved from 0.39213 to 0.39565, saving model to /content/asl/Adam/cp-98-0.40.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 2.2194 - accuracy: 0.3792 - val_loss: 2.1518 - val_accuracy: 0.3956\n",
            "Epoch 99/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 2.2518 - accuracy: 0.3669\n",
            "Epoch 99: val_accuracy did not improve from 0.39565\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 2.2519 - accuracy: 0.3665 - val_loss: 2.1757 - val_accuracy: 0.3956\n",
            "Epoch 100/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 2.1720 - accuracy: 0.3876\n",
            "Epoch 100: val_accuracy did not improve from 0.39565\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.1721 - accuracy: 0.3880 - val_loss: 2.2311 - val_accuracy: 0.3726\n",
            "Epoch 101/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 2.1250 - accuracy: 0.4027\n",
            "Epoch 101: val_accuracy improved from 0.39565 to 0.42189, saving model to /content/asl/Adam/cp-101-0.42.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 2.1259 - accuracy: 0.4032 - val_loss: 2.0626 - val_accuracy: 0.4219\n",
            "Epoch 102/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 2.1191 - accuracy: 0.4067\n",
            "Epoch 102: val_accuracy did not improve from 0.42189\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.1226 - accuracy: 0.4065 - val_loss: 2.1528 - val_accuracy: 0.3931\n",
            "Epoch 103/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 2.1269 - accuracy: 0.4036\n",
            "Epoch 103: val_accuracy did not improve from 0.42189\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.1275 - accuracy: 0.4034 - val_loss: 2.0828 - val_accuracy: 0.4139\n",
            "Epoch 104/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 2.1377 - accuracy: 0.3981\n",
            "Epoch 104: val_accuracy did not improve from 0.42189\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.1384 - accuracy: 0.3978 - val_loss: 2.0848 - val_accuracy: 0.4142\n",
            "Epoch 105/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 2.0908 - accuracy: 0.4107\n",
            "Epoch 105: val_accuracy did not improve from 0.42189\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.0910 - accuracy: 0.4107 - val_loss: 2.0437 - val_accuracy: 0.4203\n",
            "Epoch 106/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 2.0780 - accuracy: 0.4084\n",
            "Epoch 106: val_accuracy did not improve from 0.42189\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.0807 - accuracy: 0.4072 - val_loss: 2.0949 - val_accuracy: 0.4123\n",
            "Epoch 107/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 2.0597 - accuracy: 0.4154\n",
            "Epoch 107: val_accuracy did not improve from 0.42189\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.0606 - accuracy: 0.4154 - val_loss: 2.1185 - val_accuracy: 0.3972\n",
            "Epoch 108/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 2.1041 - accuracy: 0.4016\n",
            "Epoch 108: val_accuracy did not improve from 0.42189\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.1034 - accuracy: 0.4018 - val_loss: 2.1233 - val_accuracy: 0.3768\n",
            "Epoch 109/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.0504 - accuracy: 0.4155\n",
            "Epoch 109: val_accuracy improved from 0.42189 to 0.42798, saving model to /content/asl/Adam/cp-109-0.43.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 2.0504 - accuracy: 0.4155 - val_loss: 2.0184 - val_accuracy: 0.4280\n",
            "Epoch 110/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 2.0064 - accuracy: 0.4339\n",
            "Epoch 110: val_accuracy did not improve from 0.42798\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 2.0066 - accuracy: 0.4340 - val_loss: 2.1505 - val_accuracy: 0.3864\n",
            "Epoch 111/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 2.0431 - accuracy: 0.4225\n",
            "Epoch 111: val_accuracy improved from 0.42798 to 0.45134, saving model to /content/asl/Adam/cp-111-0.45.hdf5\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 2.0434 - accuracy: 0.4225 - val_loss: 1.9314 - val_accuracy: 0.4513\n",
            "Epoch 112/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 2.0135 - accuracy: 0.4287\n",
            "Epoch 112: val_accuracy did not improve from 0.45134\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 2.0138 - accuracy: 0.4281 - val_loss: 1.9544 - val_accuracy: 0.4472\n",
            "Epoch 113/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 1.9713 - accuracy: 0.4370\n",
            "Epoch 113: val_accuracy did not improve from 0.45134\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.9729 - accuracy: 0.4362 - val_loss: 2.0331 - val_accuracy: 0.4123\n",
            "Epoch 114/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.9906 - accuracy: 0.4310\n",
            "Epoch 114: val_accuracy did not improve from 0.45134\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.9906 - accuracy: 0.4310 - val_loss: 1.9747 - val_accuracy: 0.4341\n",
            "Epoch 115/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 1.9896 - accuracy: 0.4335\n",
            "Epoch 115: val_accuracy did not improve from 0.45134\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.9869 - accuracy: 0.4339 - val_loss: 1.9965 - val_accuracy: 0.4168\n",
            "Epoch 116/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 1.9643 - accuracy: 0.4406\n",
            "Epoch 116: val_accuracy did not improve from 0.45134\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.9645 - accuracy: 0.4407 - val_loss: 2.3432 - val_accuracy: 0.3460\n",
            "Epoch 117/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 2.0020 - accuracy: 0.4228\n",
            "Epoch 117: val_accuracy did not improve from 0.45134\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 2.0008 - accuracy: 0.4233 - val_loss: 2.0110 - val_accuracy: 0.4257\n",
            "Epoch 118/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 1.9679 - accuracy: 0.4366\n",
            "Epoch 118: val_accuracy did not improve from 0.45134\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 1.9647 - accuracy: 0.4376 - val_loss: 1.9607 - val_accuracy: 0.4257\n",
            "Epoch 119/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 1.9825 - accuracy: 0.4284\n",
            "Epoch 119: val_accuracy did not improve from 0.45134\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 1.9818 - accuracy: 0.4289 - val_loss: 1.9012 - val_accuracy: 0.4478\n",
            "Epoch 120/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 1.8945 - accuracy: 0.4574\n",
            "Epoch 120: val_accuracy did not improve from 0.45134\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.8938 - accuracy: 0.4577 - val_loss: 1.9510 - val_accuracy: 0.4360\n",
            "Epoch 121/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 1.9066 - accuracy: 0.4550\n",
            "Epoch 121: val_accuracy did not improve from 0.45134\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.9071 - accuracy: 0.4549 - val_loss: 2.0350 - val_accuracy: 0.4152\n",
            "Epoch 122/700\n",
            "189/196 [===========================>..] - ETA: 0s - loss: 1.9074 - accuracy: 0.4470\n",
            "Epoch 122: val_accuracy improved from 0.45134 to 0.45391, saving model to /content/asl/Adam/cp-122-0.45.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.9020 - accuracy: 0.4490 - val_loss: 1.8617 - val_accuracy: 0.4539\n",
            "Epoch 123/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 1.9588 - accuracy: 0.4380\n",
            "Epoch 123: val_accuracy did not improve from 0.45391\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.9588 - accuracy: 0.4379 - val_loss: 1.9998 - val_accuracy: 0.4129\n",
            "Epoch 124/700\n",
            "189/196 [===========================>..] - ETA: 0s - loss: 1.8943 - accuracy: 0.4540\n",
            "Epoch 124: val_accuracy did not improve from 0.45391\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.8948 - accuracy: 0.4541 - val_loss: 2.4488 - val_accuracy: 0.3291\n",
            "Epoch 125/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 1.8827 - accuracy: 0.4517\n",
            "Epoch 125: val_accuracy did not improve from 0.45391\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.8826 - accuracy: 0.4521 - val_loss: 1.8954 - val_accuracy: 0.4395\n",
            "Epoch 126/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 1.8272 - accuracy: 0.4743\n",
            "Epoch 126: val_accuracy did not improve from 0.45391\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 1.8281 - accuracy: 0.4736 - val_loss: 1.9529 - val_accuracy: 0.4289\n",
            "Epoch 127/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 1.9310 - accuracy: 0.4439\n",
            "Epoch 127: val_accuracy did not improve from 0.45391\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.9314 - accuracy: 0.4433 - val_loss: 2.1099 - val_accuracy: 0.3995\n",
            "Epoch 128/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 1.8627 - accuracy: 0.4644\n",
            "Epoch 128: val_accuracy improved from 0.45391 to 0.48399, saving model to /content/asl/Adam/cp-128-0.48.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.8623 - accuracy: 0.4648 - val_loss: 1.7888 - val_accuracy: 0.4840\n",
            "Epoch 129/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 1.8026 - accuracy: 0.4856\n",
            "Epoch 129: val_accuracy did not improve from 0.48399\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.8031 - accuracy: 0.4849 - val_loss: 1.8624 - val_accuracy: 0.4590\n",
            "Epoch 130/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.8319 - accuracy: 0.4643\n",
            "Epoch 130: val_accuracy did not improve from 0.48399\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.8319 - accuracy: 0.4643 - val_loss: 1.9511 - val_accuracy: 0.4245\n",
            "Epoch 131/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 1.8589 - accuracy: 0.4600\n",
            "Epoch 131: val_accuracy did not improve from 0.48399\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.8591 - accuracy: 0.4596 - val_loss: 1.8920 - val_accuracy: 0.4517\n",
            "Epoch 132/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 1.8270 - accuracy: 0.4704\n",
            "Epoch 132: val_accuracy did not improve from 0.48399\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.8283 - accuracy: 0.4697 - val_loss: 2.0328 - val_accuracy: 0.4001\n",
            "Epoch 133/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.8006 - accuracy: 0.4773\n",
            "Epoch 133: val_accuracy did not improve from 0.48399\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 1.8006 - accuracy: 0.4773 - val_loss: 2.1241 - val_accuracy: 0.3844\n",
            "Epoch 134/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 1.8540 - accuracy: 0.4544\n",
            "Epoch 134: val_accuracy improved from 0.48399 to 0.49072, saving model to /content/asl/Adam/cp-134-0.49.hdf5\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 1.8531 - accuracy: 0.4549 - val_loss: 1.7600 - val_accuracy: 0.4907\n",
            "Epoch 135/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.8461 - accuracy: 0.4665\n",
            "Epoch 135: val_accuracy did not improve from 0.49072\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.8461 - accuracy: 0.4665 - val_loss: 1.8146 - val_accuracy: 0.4651\n",
            "Epoch 136/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 1.7989 - accuracy: 0.4797\n",
            "Epoch 136: val_accuracy improved from 0.49072 to 0.49584, saving model to /content/asl/Adam/cp-136-0.50.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.7988 - accuracy: 0.4794 - val_loss: 1.7638 - val_accuracy: 0.4958\n",
            "Epoch 137/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 1.7819 - accuracy: 0.4820\n",
            "Epoch 137: val_accuracy did not improve from 0.49584\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.7827 - accuracy: 0.4819 - val_loss: 2.1204 - val_accuracy: 0.4024\n",
            "Epoch 138/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 1.7325 - accuracy: 0.4968\n",
            "Epoch 138: val_accuracy did not improve from 0.49584\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.7325 - accuracy: 0.4968 - val_loss: 1.7771 - val_accuracy: 0.4862\n",
            "Epoch 139/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 1.7601 - accuracy: 0.4900\n",
            "Epoch 139: val_accuracy did not improve from 0.49584\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.7587 - accuracy: 0.4903 - val_loss: 2.1368 - val_accuracy: 0.3924\n",
            "Epoch 140/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 1.7320 - accuracy: 0.4986\n",
            "Epoch 140: val_accuracy did not improve from 0.49584\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 1.7320 - accuracy: 0.4989 - val_loss: 1.7717 - val_accuracy: 0.4888\n",
            "Epoch 141/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.7679 - accuracy: 0.4857\n",
            "Epoch 141: val_accuracy improved from 0.49584 to 0.50928, saving model to /content/asl/Adam/cp-141-0.51.hdf5\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 1.7679 - accuracy: 0.4857 - val_loss: 1.7141 - val_accuracy: 0.5093\n",
            "Epoch 142/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 1.7300 - accuracy: 0.4946\n",
            "Epoch 142: val_accuracy improved from 0.50928 to 0.51088, saving model to /content/asl/Adam/cp-142-0.51.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.7275 - accuracy: 0.4952 - val_loss: 1.6740 - val_accuracy: 0.5109\n",
            "Epoch 143/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 1.6982 - accuracy: 0.5067\n",
            "Epoch 143: val_accuracy improved from 0.51088 to 0.51761, saving model to /content/asl/Adam/cp-143-0.52.hdf5\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 1.6991 - accuracy: 0.5061 - val_loss: 1.6885 - val_accuracy: 0.5176\n",
            "Epoch 144/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 1.6865 - accuracy: 0.5148\n",
            "Epoch 144: val_accuracy improved from 0.51761 to 0.52401, saving model to /content/asl/Adam/cp-144-0.52.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.6868 - accuracy: 0.5150 - val_loss: 1.6761 - val_accuracy: 0.5240\n",
            "Epoch 145/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 1.7122 - accuracy: 0.4965\n",
            "Epoch 145: val_accuracy did not improve from 0.52401\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.7106 - accuracy: 0.4970 - val_loss: 1.7613 - val_accuracy: 0.4898\n",
            "Epoch 146/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 1.6887 - accuracy: 0.5099\n",
            "Epoch 146: val_accuracy did not improve from 0.52401\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.6914 - accuracy: 0.5097 - val_loss: 1.9784 - val_accuracy: 0.4424\n",
            "Epoch 147/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 1.7389 - accuracy: 0.4922\n",
            "Epoch 147: val_accuracy did not improve from 0.52401\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 1.7382 - accuracy: 0.4914 - val_loss: 1.7572 - val_accuracy: 0.4853\n",
            "Epoch 148/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 1.6470 - accuracy: 0.5241\n",
            "Epoch 148: val_accuracy did not improve from 0.52401\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 1.6471 - accuracy: 0.5242 - val_loss: 1.9208 - val_accuracy: 0.4405\n",
            "Epoch 149/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 1.6735 - accuracy: 0.5095\n",
            "Epoch 149: val_accuracy did not improve from 0.52401\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.6738 - accuracy: 0.5094 - val_loss: 1.6959 - val_accuracy: 0.5077\n",
            "Epoch 150/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 1.6928 - accuracy: 0.5058\n",
            "Epoch 150: val_accuracy did not improve from 0.52401\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.6929 - accuracy: 0.5056 - val_loss: 1.7181 - val_accuracy: 0.4946\n",
            "Epoch 151/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 1.6957 - accuracy: 0.5052\n",
            "Epoch 151: val_accuracy did not improve from 0.52401\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.6960 - accuracy: 0.5049 - val_loss: 1.8432 - val_accuracy: 0.4648\n",
            "Epoch 152/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.6493 - accuracy: 0.5186\n",
            "Epoch 152: val_accuracy did not improve from 0.52401\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.6493 - accuracy: 0.5186 - val_loss: 1.6326 - val_accuracy: 0.5230\n",
            "Epoch 153/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 1.6123 - accuracy: 0.5296\n",
            "Epoch 153: val_accuracy did not improve from 0.52401\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.6101 - accuracy: 0.5315 - val_loss: 1.7689 - val_accuracy: 0.4792\n",
            "Epoch 154/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.6453 - accuracy: 0.5166\n",
            "Epoch 154: val_accuracy did not improve from 0.52401\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.6453 - accuracy: 0.5166 - val_loss: 1.7963 - val_accuracy: 0.4725\n",
            "Epoch 155/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 1.6036 - accuracy: 0.5326\n",
            "Epoch 155: val_accuracy did not improve from 0.52401\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 1.6023 - accuracy: 0.5335 - val_loss: 1.6731 - val_accuracy: 0.5026\n",
            "Epoch 156/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 1.6744 - accuracy: 0.5095\n",
            "Epoch 156: val_accuracy did not improve from 0.52401\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.6765 - accuracy: 0.5086 - val_loss: 2.3832 - val_accuracy: 0.3496\n",
            "Epoch 157/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 1.6757 - accuracy: 0.5088\n",
            "Epoch 157: val_accuracy did not improve from 0.52401\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.6759 - accuracy: 0.5086 - val_loss: 1.7409 - val_accuracy: 0.4779\n",
            "Epoch 158/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 1.6203 - accuracy: 0.5238\n",
            "Epoch 158: val_accuracy improved from 0.52401 to 0.52977, saving model to /content/asl/Adam/cp-158-0.53.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.6225 - accuracy: 0.5235 - val_loss: 1.6373 - val_accuracy: 0.5298\n",
            "Epoch 159/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.6057 - accuracy: 0.5311\n",
            "Epoch 159: val_accuracy did not improve from 0.52977\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.6057 - accuracy: 0.5311 - val_loss: 1.7485 - val_accuracy: 0.4981\n",
            "Epoch 160/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 1.6439 - accuracy: 0.5160\n",
            "Epoch 160: val_accuracy did not improve from 0.52977\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.6446 - accuracy: 0.5156 - val_loss: 1.7391 - val_accuracy: 0.4827\n",
            "Epoch 161/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 1.5905 - accuracy: 0.5318\n",
            "Epoch 161: val_accuracy did not improve from 0.52977\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.5904 - accuracy: 0.5319 - val_loss: 2.0780 - val_accuracy: 0.3988\n",
            "Epoch 162/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 1.6085 - accuracy: 0.5294\n",
            "Epoch 162: val_accuracy improved from 0.52977 to 0.53329, saving model to /content/asl/Adam/cp-162-0.53.hdf5\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 1.6094 - accuracy: 0.5285 - val_loss: 1.5969 - val_accuracy: 0.5333\n",
            "Epoch 163/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 1.6123 - accuracy: 0.5252\n",
            "Epoch 163: val_accuracy did not improve from 0.53329\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 1.6115 - accuracy: 0.5262 - val_loss: 1.5904 - val_accuracy: 0.5269\n",
            "Epoch 164/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 1.5965 - accuracy: 0.5293\n",
            "Epoch 164: val_accuracy did not improve from 0.53329\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.5976 - accuracy: 0.5293 - val_loss: 1.7749 - val_accuracy: 0.4818\n",
            "Epoch 165/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 1.5608 - accuracy: 0.5412\n",
            "Epoch 165: val_accuracy did not improve from 0.53329\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.5623 - accuracy: 0.5410 - val_loss: 1.8593 - val_accuracy: 0.4446\n",
            "Epoch 166/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 1.5851 - accuracy: 0.5373\n",
            "Epoch 166: val_accuracy did not improve from 0.53329\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.5881 - accuracy: 0.5359 - val_loss: 1.7122 - val_accuracy: 0.5003\n",
            "Epoch 167/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 1.5745 - accuracy: 0.5396\n",
            "Epoch 167: val_accuracy did not improve from 0.53329\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.5727 - accuracy: 0.5399 - val_loss: 1.9208 - val_accuracy: 0.4587\n",
            "Epoch 168/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 1.5836 - accuracy: 0.5371\n",
            "Epoch 168: val_accuracy did not improve from 0.53329\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.5807 - accuracy: 0.5376 - val_loss: 1.7429 - val_accuracy: 0.4821\n",
            "Epoch 169/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 1.5673 - accuracy: 0.5357\n",
            "Epoch 169: val_accuracy did not improve from 0.53329\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 1.5678 - accuracy: 0.5355 - val_loss: 1.8295 - val_accuracy: 0.4673\n",
            "Epoch 170/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 1.5750 - accuracy: 0.5308\n",
            "Epoch 170: val_accuracy improved from 0.53329 to 0.56402, saving model to /content/asl/Adam/cp-170-0.56.hdf5\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 1.5756 - accuracy: 0.5303 - val_loss: 1.5089 - val_accuracy: 0.5640\n",
            "Epoch 171/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 1.5598 - accuracy: 0.5428\n",
            "Epoch 171: val_accuracy did not improve from 0.56402\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.5621 - accuracy: 0.5417 - val_loss: 1.5954 - val_accuracy: 0.5243\n",
            "Epoch 172/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 1.5085 - accuracy: 0.5579\n",
            "Epoch 172: val_accuracy did not improve from 0.56402\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.5115 - accuracy: 0.5567 - val_loss: 1.6741 - val_accuracy: 0.4990\n",
            "Epoch 173/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 1.5281 - accuracy: 0.5502\n",
            "Epoch 173: val_accuracy improved from 0.56402 to 0.56978, saving model to /content/asl/Adam/cp-173-0.57.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.5282 - accuracy: 0.5503 - val_loss: 1.4912 - val_accuracy: 0.5698\n",
            "Epoch 174/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.4840 - accuracy: 0.5649\n",
            "Epoch 174: val_accuracy did not improve from 0.56978\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.4840 - accuracy: 0.5649 - val_loss: 1.8593 - val_accuracy: 0.4555\n",
            "Epoch 175/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 1.5080 - accuracy: 0.5545\n",
            "Epoch 175: val_accuracy did not improve from 0.56978\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.5079 - accuracy: 0.5547 - val_loss: 1.5429 - val_accuracy: 0.5499\n",
            "Epoch 176/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 1.5183 - accuracy: 0.5506\n",
            "Epoch 176: val_accuracy did not improve from 0.56978\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 1.5209 - accuracy: 0.5499 - val_loss: 1.5696 - val_accuracy: 0.5435\n",
            "Epoch 177/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 1.4876 - accuracy: 0.5608\n",
            "Epoch 177: val_accuracy did not improve from 0.56978\n",
            "196/196 [==============================] - 3s 15ms/step - loss: 1.4875 - accuracy: 0.5606 - val_loss: 1.6052 - val_accuracy: 0.5343\n",
            "Epoch 178/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.5333 - accuracy: 0.5466\n",
            "Epoch 178: val_accuracy did not improve from 0.56978\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.5333 - accuracy: 0.5466 - val_loss: 1.8010 - val_accuracy: 0.4629\n",
            "Epoch 179/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 1.5071 - accuracy: 0.5572\n",
            "Epoch 179: val_accuracy did not improve from 0.56978\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.5055 - accuracy: 0.5576 - val_loss: 1.4920 - val_accuracy: 0.5560\n",
            "Epoch 180/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 1.4611 - accuracy: 0.5699\n",
            "Epoch 180: val_accuracy did not improve from 0.56978\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.4612 - accuracy: 0.5699 - val_loss: 1.5880 - val_accuracy: 0.5150\n",
            "Epoch 181/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 1.4801 - accuracy: 0.5603\n",
            "Epoch 181: val_accuracy did not improve from 0.56978\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.4814 - accuracy: 0.5598 - val_loss: 1.6711 - val_accuracy: 0.5106\n",
            "Epoch 182/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.5474 - accuracy: 0.5435\n",
            "Epoch 182: val_accuracy did not improve from 0.56978\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.5474 - accuracy: 0.5435 - val_loss: 1.7816 - val_accuracy: 0.4507\n",
            "Epoch 183/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.5134 - accuracy: 0.5490\n",
            "Epoch 183: val_accuracy did not improve from 0.56978\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 1.5134 - accuracy: 0.5490 - val_loss: 1.5149 - val_accuracy: 0.5608\n",
            "Epoch 184/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 1.4573 - accuracy: 0.5702\n",
            "Epoch 184: val_accuracy did not improve from 0.56978\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 1.4570 - accuracy: 0.5700 - val_loss: 1.5167 - val_accuracy: 0.5599\n",
            "Epoch 185/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 1.4921 - accuracy: 0.5610\n",
            "Epoch 185: val_accuracy did not improve from 0.56978\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.4956 - accuracy: 0.5596 - val_loss: 1.6524 - val_accuracy: 0.5000\n",
            "Epoch 186/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 1.4515 - accuracy: 0.5682\n",
            "Epoch 186: val_accuracy improved from 0.56978 to 0.57810, saving model to /content/asl/Adam/cp-186-0.58.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.4537 - accuracy: 0.5673 - val_loss: 1.4406 - val_accuracy: 0.5781\n",
            "Epoch 187/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 1.4288 - accuracy: 0.5787\n",
            "Epoch 187: val_accuracy did not improve from 0.57810\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.4289 - accuracy: 0.5788 - val_loss: 1.4783 - val_accuracy: 0.5663\n",
            "Epoch 188/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 1.4951 - accuracy: 0.5557\n",
            "Epoch 188: val_accuracy did not improve from 0.57810\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.4951 - accuracy: 0.5555 - val_loss: 1.6575 - val_accuracy: 0.5077\n",
            "Epoch 189/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.4128 - accuracy: 0.5832\n",
            "Epoch 189: val_accuracy did not improve from 0.57810\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.4128 - accuracy: 0.5832 - val_loss: 1.5647 - val_accuracy: 0.5269\n",
            "Epoch 190/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 1.4323 - accuracy: 0.5747\n",
            "Epoch 190: val_accuracy did not improve from 0.57810\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.4338 - accuracy: 0.5747 - val_loss: 1.6666 - val_accuracy: 0.5045\n",
            "Epoch 191/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 1.4079 - accuracy: 0.5818\n",
            "Epoch 191: val_accuracy did not improve from 0.57810\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 1.4079 - accuracy: 0.5816 - val_loss: 1.4500 - val_accuracy: 0.5743\n",
            "Epoch 192/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 1.4200 - accuracy: 0.5792\n",
            "Epoch 192: val_accuracy did not improve from 0.57810\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 1.4199 - accuracy: 0.5793 - val_loss: 1.7634 - val_accuracy: 0.4728\n",
            "Epoch 193/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 1.4964 - accuracy: 0.5595\n",
            "Epoch 193: val_accuracy did not improve from 0.57810\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.4937 - accuracy: 0.5606 - val_loss: 1.6974 - val_accuracy: 0.5016\n",
            "Epoch 194/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 1.4748 - accuracy: 0.5596\n",
            "Epoch 194: val_accuracy did not improve from 0.57810\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.4743 - accuracy: 0.5598 - val_loss: 1.5030 - val_accuracy: 0.5525\n",
            "Epoch 195/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 1.4271 - accuracy: 0.5745\n",
            "Epoch 195: val_accuracy improved from 0.57810 to 0.59315, saving model to /content/asl/Adam/cp-195-0.59.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.4249 - accuracy: 0.5755 - val_loss: 1.3929 - val_accuracy: 0.5931\n",
            "Epoch 196/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 1.3643 - accuracy: 0.5990\n",
            "Epoch 196: val_accuracy did not improve from 0.59315\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.3667 - accuracy: 0.5984 - val_loss: 1.5036 - val_accuracy: 0.5538\n",
            "Epoch 197/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 1.4272 - accuracy: 0.5739\n",
            "Epoch 197: val_accuracy did not improve from 0.59315\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.4275 - accuracy: 0.5738 - val_loss: 1.4876 - val_accuracy: 0.5538\n",
            "Epoch 198/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 1.4077 - accuracy: 0.5836\n",
            "Epoch 198: val_accuracy did not improve from 0.59315\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 1.4066 - accuracy: 0.5839 - val_loss: 1.5305 - val_accuracy: 0.5487\n",
            "Epoch 199/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 1.3888 - accuracy: 0.5854\n",
            "Epoch 199: val_accuracy did not improve from 0.59315\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 1.3885 - accuracy: 0.5855 - val_loss: 1.4630 - val_accuracy: 0.5656\n",
            "Epoch 200/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.4131 - accuracy: 0.5800\n",
            "Epoch 200: val_accuracy did not improve from 0.59315\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.4131 - accuracy: 0.5800 - val_loss: 1.6543 - val_accuracy: 0.5080\n",
            "Epoch 201/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 1.4060 - accuracy: 0.5770\n",
            "Epoch 201: val_accuracy improved from 0.59315 to 0.59475, saving model to /content/asl/Adam/cp-201-0.59.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.4085 - accuracy: 0.5763 - val_loss: 1.3707 - val_accuracy: 0.5948\n",
            "Epoch 202/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 1.3651 - accuracy: 0.5911\n",
            "Epoch 202: val_accuracy did not improve from 0.59475\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.3651 - accuracy: 0.5912 - val_loss: 1.4176 - val_accuracy: 0.5832\n",
            "Epoch 203/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 1.3513 - accuracy: 0.5965\n",
            "Epoch 203: val_accuracy improved from 0.59475 to 0.60019, saving model to /content/asl/Adam/cp-203-0.60.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.3521 - accuracy: 0.5964 - val_loss: 1.3570 - val_accuracy: 0.6002\n",
            "Epoch 204/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 1.3770 - accuracy: 0.5874\n",
            "Epoch 204: val_accuracy did not improve from 0.60019\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.3791 - accuracy: 0.5862 - val_loss: 1.6518 - val_accuracy: 0.5086\n",
            "Epoch 205/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 1.3408 - accuracy: 0.6048\n",
            "Epoch 205: val_accuracy did not improve from 0.60019\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.3424 - accuracy: 0.6044 - val_loss: 1.3748 - val_accuracy: 0.5941\n",
            "Epoch 206/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 1.3356 - accuracy: 0.6006\n",
            "Epoch 206: val_accuracy did not improve from 0.60019\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 1.3358 - accuracy: 0.6004 - val_loss: 1.4890 - val_accuracy: 0.5595\n",
            "Epoch 207/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 1.3950 - accuracy: 0.5803\n",
            "Epoch 207: val_accuracy did not improve from 0.60019\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.3937 - accuracy: 0.5804 - val_loss: 1.5193 - val_accuracy: 0.5503\n",
            "Epoch 208/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 1.3186 - accuracy: 0.6123\n",
            "Epoch 208: val_accuracy did not improve from 0.60019\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.3226 - accuracy: 0.6100 - val_loss: 1.4956 - val_accuracy: 0.5541\n",
            "Epoch 209/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 1.4270 - accuracy: 0.5725\n",
            "Epoch 209: val_accuracy did not improve from 0.60019\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.4234 - accuracy: 0.5728 - val_loss: 1.5019 - val_accuracy: 0.5576\n",
            "Epoch 210/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 1.3512 - accuracy: 0.5946\n",
            "Epoch 210: val_accuracy did not improve from 0.60019\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.3529 - accuracy: 0.5946 - val_loss: 1.7639 - val_accuracy: 0.4770\n",
            "Epoch 211/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 1.3514 - accuracy: 0.5970\n",
            "Epoch 211: val_accuracy did not improve from 0.60019\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.3511 - accuracy: 0.5972 - val_loss: 1.3950 - val_accuracy: 0.5835\n",
            "Epoch 212/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 1.3674 - accuracy: 0.5909\n",
            "Epoch 212: val_accuracy did not improve from 0.60019\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.3641 - accuracy: 0.5917 - val_loss: 1.7006 - val_accuracy: 0.4904\n",
            "Epoch 213/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.3251 - accuracy: 0.6038\n",
            "Epoch 213: val_accuracy improved from 0.60019 to 0.60115, saving model to /content/asl/Adam/cp-213-0.60.hdf5\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 1.3251 - accuracy: 0.6038 - val_loss: 1.3282 - val_accuracy: 0.6012\n",
            "Epoch 214/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 1.3173 - accuracy: 0.6035\n",
            "Epoch 214: val_accuracy did not improve from 0.60115\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 1.3177 - accuracy: 0.6030 - val_loss: 1.4304 - val_accuracy: 0.5695\n",
            "Epoch 215/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 1.3598 - accuracy: 0.5931\n",
            "Epoch 215: val_accuracy did not improve from 0.60115\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.3584 - accuracy: 0.5936 - val_loss: 1.4609 - val_accuracy: 0.5605\n",
            "Epoch 216/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 1.3289 - accuracy: 0.6004\n",
            "Epoch 216: val_accuracy did not improve from 0.60115\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.3300 - accuracy: 0.6001 - val_loss: 1.4155 - val_accuracy: 0.5842\n",
            "Epoch 217/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 1.3394 - accuracy: 0.5962\n",
            "Epoch 217: val_accuracy did not improve from 0.60115\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.3419 - accuracy: 0.5956 - val_loss: 1.4385 - val_accuracy: 0.5803\n",
            "Epoch 218/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.3460 - accuracy: 0.5945\n",
            "Epoch 218: val_accuracy did not improve from 0.60115\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.3460 - accuracy: 0.5945 - val_loss: 1.3614 - val_accuracy: 0.6002\n",
            "Epoch 219/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 1.2881 - accuracy: 0.6152\n",
            "Epoch 219: val_accuracy did not improve from 0.60115\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.2884 - accuracy: 0.6150 - val_loss: 1.4541 - val_accuracy: 0.5663\n",
            "Epoch 220/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.3041 - accuracy: 0.6096\n",
            "Epoch 220: val_accuracy did not improve from 0.60115\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 1.3041 - accuracy: 0.6096 - val_loss: 1.4617 - val_accuracy: 0.5675\n",
            "Epoch 221/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 1.3154 - accuracy: 0.6057\n",
            "Epoch 221: val_accuracy did not improve from 0.60115\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 1.3143 - accuracy: 0.6057 - val_loss: 1.5439 - val_accuracy: 0.5423\n",
            "Epoch 222/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 1.2724 - accuracy: 0.6180\n",
            "Epoch 222: val_accuracy did not improve from 0.60115\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.2718 - accuracy: 0.6184 - val_loss: 1.4598 - val_accuracy: 0.5557\n",
            "Epoch 223/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 1.3283 - accuracy: 0.5994\n",
            "Epoch 223: val_accuracy did not improve from 0.60115\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.3272 - accuracy: 0.5994 - val_loss: 1.3569 - val_accuracy: 0.5919\n",
            "Epoch 224/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 1.2814 - accuracy: 0.6187\n",
            "Epoch 224: val_accuracy improved from 0.60115 to 0.60627, saving model to /content/asl/Adam/cp-224-0.61.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.2798 - accuracy: 0.6188 - val_loss: 1.3314 - val_accuracy: 0.6063\n",
            "Epoch 225/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 1.3675 - accuracy: 0.5896\n",
            "Epoch 225: val_accuracy did not improve from 0.60627\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.3644 - accuracy: 0.5902 - val_loss: 1.8527 - val_accuracy: 0.4690\n",
            "Epoch 226/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.3579 - accuracy: 0.5939\n",
            "Epoch 226: val_accuracy did not improve from 0.60627\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.3579 - accuracy: 0.5939 - val_loss: 1.3473 - val_accuracy: 0.5999\n",
            "Epoch 227/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 1.2579 - accuracy: 0.6227\n",
            "Epoch 227: val_accuracy did not improve from 0.60627\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.2580 - accuracy: 0.6226 - val_loss: 1.5889 - val_accuracy: 0.5336\n",
            "Epoch 228/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 1.2739 - accuracy: 0.6183\n",
            "Epoch 228: val_accuracy improved from 0.60627 to 0.61460, saving model to /content/asl/Adam/cp-228-0.61.hdf5\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 1.2735 - accuracy: 0.6185 - val_loss: 1.3217 - val_accuracy: 0.6146\n",
            "Epoch 229/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 1.2503 - accuracy: 0.6256\n",
            "Epoch 229: val_accuracy did not improve from 0.61460\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 1.2509 - accuracy: 0.6252 - val_loss: 1.6209 - val_accuracy: 0.5109\n",
            "Epoch 230/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 1.3244 - accuracy: 0.5993\n",
            "Epoch 230: val_accuracy did not improve from 0.61460\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.3227 - accuracy: 0.5995 - val_loss: 1.5220 - val_accuracy: 0.5397\n",
            "Epoch 231/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 1.2309 - accuracy: 0.6302\n",
            "Epoch 231: val_accuracy improved from 0.61460 to 0.61620, saving model to /content/asl/Adam/cp-231-0.62.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.2310 - accuracy: 0.6305 - val_loss: 1.2970 - val_accuracy: 0.6162\n",
            "Epoch 232/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 1.2545 - accuracy: 0.6215\n",
            "Epoch 232: val_accuracy did not improve from 0.61620\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.2537 - accuracy: 0.6216 - val_loss: 1.3172 - val_accuracy: 0.6124\n",
            "Epoch 233/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 1.3218 - accuracy: 0.6007\n",
            "Epoch 233: val_accuracy improved from 0.61620 to 0.63252, saving model to /content/asl/Adam/cp-233-0.63.hdf5\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 1.3186 - accuracy: 0.6020 - val_loss: 1.2743 - val_accuracy: 0.6325\n",
            "Epoch 234/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 1.2562 - accuracy: 0.6215\n",
            "Epoch 234: val_accuracy did not improve from 0.63252\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.2584 - accuracy: 0.6205 - val_loss: 1.3851 - val_accuracy: 0.5890\n",
            "Epoch 235/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.2671 - accuracy: 0.6207\n",
            "Epoch 235: val_accuracy did not improve from 0.63252\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 1.2671 - accuracy: 0.6207 - val_loss: 1.8010 - val_accuracy: 0.4866\n",
            "Epoch 236/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 1.2508 - accuracy: 0.6198\n",
            "Epoch 236: val_accuracy did not improve from 0.63252\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 1.2497 - accuracy: 0.6204 - val_loss: 1.3816 - val_accuracy: 0.5919\n",
            "Epoch 237/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.3090 - accuracy: 0.6044\n",
            "Epoch 237: val_accuracy did not improve from 0.63252\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.3090 - accuracy: 0.6044 - val_loss: 1.3895 - val_accuracy: 0.5803\n",
            "Epoch 238/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 1.2642 - accuracy: 0.6185\n",
            "Epoch 238: val_accuracy did not improve from 0.63252\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.2671 - accuracy: 0.6178 - val_loss: 2.0585 - val_accuracy: 0.4337\n",
            "Epoch 239/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 1.3232 - accuracy: 0.6017\n",
            "Epoch 239: val_accuracy did not improve from 0.63252\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.3271 - accuracy: 0.6002 - val_loss: 1.2898 - val_accuracy: 0.6242\n",
            "Epoch 240/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 1.2177 - accuracy: 0.6325\n",
            "Epoch 240: val_accuracy did not improve from 0.63252\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.2173 - accuracy: 0.6325 - val_loss: 1.4440 - val_accuracy: 0.5707\n",
            "Epoch 241/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 1.2072 - accuracy: 0.6383\n",
            "Epoch 241: val_accuracy did not improve from 0.63252\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.2015 - accuracy: 0.6403 - val_loss: 1.2937 - val_accuracy: 0.6213\n",
            "Epoch 242/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 1.2009 - accuracy: 0.6396\n",
            "Epoch 242: val_accuracy did not improve from 0.63252\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 1.1999 - accuracy: 0.6401 - val_loss: 1.3439 - val_accuracy: 0.5941\n",
            "Epoch 243/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 1.1950 - accuracy: 0.6397\n",
            "Epoch 243: val_accuracy did not improve from 0.63252\n",
            "196/196 [==============================] - 2s 13ms/step - loss: 1.1949 - accuracy: 0.6398 - val_loss: 1.3767 - val_accuracy: 0.5826\n",
            "Epoch 244/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.2226 - accuracy: 0.6276\n",
            "Epoch 244: val_accuracy improved from 0.63252 to 0.63380, saving model to /content/asl/Adam/cp-244-0.63.hdf5\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 1.2226 - accuracy: 0.6276 - val_loss: 1.2647 - val_accuracy: 0.6338\n",
            "Epoch 245/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 1.1825 - accuracy: 0.6457\n",
            "Epoch 245: val_accuracy did not improve from 0.63380\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 1.1815 - accuracy: 0.6460 - val_loss: 1.3536 - val_accuracy: 0.5919\n",
            "Epoch 246/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 1.2551 - accuracy: 0.6226\n",
            "Epoch 246: val_accuracy improved from 0.63380 to 0.63572, saving model to /content/asl/Adam/cp-246-0.64.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.2549 - accuracy: 0.6227 - val_loss: 1.2401 - val_accuracy: 0.6357\n",
            "Epoch 247/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 1.2346 - accuracy: 0.6252\n",
            "Epoch 247: val_accuracy did not improve from 0.63572\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.2343 - accuracy: 0.6252 - val_loss: 1.3689 - val_accuracy: 0.5944\n",
            "Epoch 248/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 1.2636 - accuracy: 0.6158\n",
            "Epoch 248: val_accuracy did not improve from 0.63572\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.2635 - accuracy: 0.6155 - val_loss: 1.6532 - val_accuracy: 0.5109\n",
            "Epoch 249/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 1.2621 - accuracy: 0.6195\n",
            "Epoch 249: val_accuracy did not improve from 0.63572\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 1.2583 - accuracy: 0.6205 - val_loss: 1.2571 - val_accuracy: 0.6296\n",
            "Epoch 250/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 1.2230 - accuracy: 0.6320\n",
            "Epoch 250: val_accuracy did not improve from 0.63572\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 1.2272 - accuracy: 0.6303 - val_loss: 1.5019 - val_accuracy: 0.5551\n",
            "Epoch 251/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 1.2086 - accuracy: 0.6338\n",
            "Epoch 251: val_accuracy did not improve from 0.63572\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.2079 - accuracy: 0.6340 - val_loss: 1.3812 - val_accuracy: 0.5787\n",
            "Epoch 252/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 1.1878 - accuracy: 0.6448\n",
            "Epoch 252: val_accuracy did not improve from 0.63572\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.1914 - accuracy: 0.6444 - val_loss: 1.3254 - val_accuracy: 0.6060\n",
            "Epoch 253/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.1943 - accuracy: 0.6375\n",
            "Epoch 253: val_accuracy did not improve from 0.63572\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.1943 - accuracy: 0.6375 - val_loss: 1.7230 - val_accuracy: 0.4914\n",
            "Epoch 254/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.1631 - accuracy: 0.6471\n",
            "Epoch 254: val_accuracy did not improve from 0.63572\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.1631 - accuracy: 0.6471 - val_loss: 1.2570 - val_accuracy: 0.6306\n",
            "Epoch 255/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 1.1789 - accuracy: 0.6426\n",
            "Epoch 255: val_accuracy improved from 0.63572 to 0.63892, saving model to /content/asl/Adam/cp-255-0.64.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.1800 - accuracy: 0.6424 - val_loss: 1.2182 - val_accuracy: 0.6389\n",
            "Epoch 256/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 1.2121 - accuracy: 0.6278\n",
            "Epoch 256: val_accuracy did not improve from 0.63892\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.2121 - accuracy: 0.6280 - val_loss: 1.5903 - val_accuracy: 0.5243\n",
            "Epoch 257/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 1.2153 - accuracy: 0.6312\n",
            "Epoch 257: val_accuracy did not improve from 0.63892\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 1.2147 - accuracy: 0.6312 - val_loss: 1.2948 - val_accuracy: 0.6079\n",
            "Epoch 258/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 1.2090 - accuracy: 0.6324\n",
            "Epoch 258: val_accuracy did not improve from 0.63892\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 1.2087 - accuracy: 0.6324 - val_loss: 1.3086 - val_accuracy: 0.6136\n",
            "Epoch 259/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.1466 - accuracy: 0.6559\n",
            "Epoch 259: val_accuracy did not improve from 0.63892\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.1466 - accuracy: 0.6559 - val_loss: 1.2776 - val_accuracy: 0.6088\n",
            "Epoch 260/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 1.1805 - accuracy: 0.6418\n",
            "Epoch 260: val_accuracy did not improve from 0.63892\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.1803 - accuracy: 0.6412 - val_loss: 1.3677 - val_accuracy: 0.5880\n",
            "Epoch 261/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.1545 - accuracy: 0.6480\n",
            "Epoch 261: val_accuracy did not improve from 0.63892\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.1545 - accuracy: 0.6480 - val_loss: 1.6213 - val_accuracy: 0.5141\n",
            "Epoch 262/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 1.1744 - accuracy: 0.6443\n",
            "Epoch 262: val_accuracy did not improve from 0.63892\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.1753 - accuracy: 0.6442 - val_loss: 1.3039 - val_accuracy: 0.6098\n",
            "Epoch 263/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 1.1613 - accuracy: 0.6515\n",
            "Epoch 263: val_accuracy did not improve from 0.63892\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.1610 - accuracy: 0.6512 - val_loss: 1.2623 - val_accuracy: 0.6194\n",
            "Epoch 264/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 1.1524 - accuracy: 0.6533\n",
            "Epoch 264: val_accuracy did not improve from 0.63892\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 1.1530 - accuracy: 0.6528 - val_loss: 1.2976 - val_accuracy: 0.6104\n",
            "Epoch 265/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.2222 - accuracy: 0.6257\n",
            "Epoch 265: val_accuracy did not improve from 0.63892\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 1.2222 - accuracy: 0.6257 - val_loss: 1.8130 - val_accuracy: 0.4891\n",
            "Epoch 266/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 1.1285 - accuracy: 0.6567\n",
            "Epoch 266: val_accuracy did not improve from 0.63892\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.1327 - accuracy: 0.6556 - val_loss: 1.2639 - val_accuracy: 0.6226\n",
            "Epoch 267/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.1940 - accuracy: 0.6347\n",
            "Epoch 267: val_accuracy did not improve from 0.63892\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.1940 - accuracy: 0.6347 - val_loss: 1.2453 - val_accuracy: 0.6229\n",
            "Epoch 268/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.1312 - accuracy: 0.6534\n",
            "Epoch 268: val_accuracy did not improve from 0.63892\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 1.1312 - accuracy: 0.6534 - val_loss: 1.3418 - val_accuracy: 0.6015\n",
            "Epoch 269/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 1.1346 - accuracy: 0.6571\n",
            "Epoch 269: val_accuracy did not improve from 0.63892\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.1338 - accuracy: 0.6571 - val_loss: 1.4268 - val_accuracy: 0.5871\n",
            "Epoch 270/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 1.2006 - accuracy: 0.6333\n",
            "Epoch 270: val_accuracy did not improve from 0.63892\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.1964 - accuracy: 0.6343 - val_loss: 1.3445 - val_accuracy: 0.5928\n",
            "Epoch 271/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 1.1557 - accuracy: 0.6438\n",
            "Epoch 271: val_accuracy did not improve from 0.63892\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 1.1627 - accuracy: 0.6425 - val_loss: 1.6348 - val_accuracy: 0.5112\n",
            "Epoch 272/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 1.1605 - accuracy: 0.6422\n",
            "Epoch 272: val_accuracy did not improve from 0.63892\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 1.1595 - accuracy: 0.6423 - val_loss: 1.3105 - val_accuracy: 0.6053\n",
            "Epoch 273/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 1.1418 - accuracy: 0.6507\n",
            "Epoch 273: val_accuracy did not improve from 0.63892\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.1414 - accuracy: 0.6507 - val_loss: 1.2682 - val_accuracy: 0.6181\n",
            "Epoch 274/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 1.2507 - accuracy: 0.6245\n",
            "Epoch 274: val_accuracy improved from 0.63892 to 0.63956, saving model to /content/asl/Adam/cp-274-0.64.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.2475 - accuracy: 0.6252 - val_loss: 1.2095 - val_accuracy: 0.6396\n",
            "Epoch 275/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 1.1050 - accuracy: 0.6629\n",
            "Epoch 275: val_accuracy did not improve from 0.63956\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.1051 - accuracy: 0.6634 - val_loss: 1.3954 - val_accuracy: 0.5797\n",
            "Epoch 276/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 1.1315 - accuracy: 0.6519\n",
            "Epoch 276: val_accuracy did not improve from 0.63956\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.1324 - accuracy: 0.6524 - val_loss: 1.3203 - val_accuracy: 0.6034\n",
            "Epoch 277/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 1.1347 - accuracy: 0.6503\n",
            "Epoch 277: val_accuracy did not improve from 0.63956\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.1334 - accuracy: 0.6510 - val_loss: 1.2907 - val_accuracy: 0.6136\n",
            "Epoch 278/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 1.1308 - accuracy: 0.6541\n",
            "Epoch 278: val_accuracy did not improve from 0.63956\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 1.1322 - accuracy: 0.6532 - val_loss: 1.2577 - val_accuracy: 0.6261\n",
            "Epoch 279/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 1.1218 - accuracy: 0.6549\n",
            "Epoch 279: val_accuracy did not improve from 0.63956\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 1.1214 - accuracy: 0.6553 - val_loss: 1.2494 - val_accuracy: 0.6300\n",
            "Epoch 280/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 1.1034 - accuracy: 0.6655\n",
            "Epoch 280: val_accuracy did not improve from 0.63956\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 1.1031 - accuracy: 0.6655 - val_loss: 1.2593 - val_accuracy: 0.6210\n",
            "Epoch 281/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.0875 - accuracy: 0.6669\n",
            "Epoch 281: val_accuracy did not improve from 0.63956\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.0875 - accuracy: 0.6669 - val_loss: 1.2879 - val_accuracy: 0.6117\n",
            "Epoch 282/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 1.1108 - accuracy: 0.6602\n",
            "Epoch 282: val_accuracy did not improve from 0.63956\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.1111 - accuracy: 0.6601 - val_loss: 1.2546 - val_accuracy: 0.6248\n",
            "Epoch 283/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 1.1055 - accuracy: 0.6645\n",
            "Epoch 283: val_accuracy improved from 0.63956 to 0.64565, saving model to /content/asl/Adam/cp-283-0.65.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.1047 - accuracy: 0.6652 - val_loss: 1.1886 - val_accuracy: 0.6456\n",
            "Epoch 284/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 1.1165 - accuracy: 0.6591\n",
            "Epoch 284: val_accuracy did not improve from 0.64565\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.1185 - accuracy: 0.6585 - val_loss: 1.2268 - val_accuracy: 0.6370\n",
            "Epoch 285/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 1.1163 - accuracy: 0.6579\n",
            "Epoch 285: val_accuracy did not improve from 0.64565\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.1149 - accuracy: 0.6581 - val_loss: 1.3015 - val_accuracy: 0.6076\n",
            "Epoch 286/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 1.0954 - accuracy: 0.6623\n",
            "Epoch 286: val_accuracy did not improve from 0.64565\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 1.0960 - accuracy: 0.6621 - val_loss: 1.1872 - val_accuracy: 0.6402\n",
            "Epoch 287/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 1.0873 - accuracy: 0.6729\n",
            "Epoch 287: val_accuracy did not improve from 0.64565\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 1.0858 - accuracy: 0.6733 - val_loss: 1.6161 - val_accuracy: 0.5333\n",
            "Epoch 288/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 1.1982 - accuracy: 0.6288\n",
            "Epoch 288: val_accuracy did not improve from 0.64565\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.1984 - accuracy: 0.6288 - val_loss: 1.4461 - val_accuracy: 0.5611\n",
            "Epoch 289/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 1.0568 - accuracy: 0.6790\n",
            "Epoch 289: val_accuracy did not improve from 0.64565\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.0575 - accuracy: 0.6785 - val_loss: 1.5112 - val_accuracy: 0.5423\n",
            "Epoch 290/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 1.0707 - accuracy: 0.6720\n",
            "Epoch 290: val_accuracy did not improve from 0.64565\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.0712 - accuracy: 0.6718 - val_loss: 1.4243 - val_accuracy: 0.5787\n",
            "Epoch 291/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 1.1327 - accuracy: 0.6549\n",
            "Epoch 291: val_accuracy did not improve from 0.64565\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.1317 - accuracy: 0.6554 - val_loss: 1.2743 - val_accuracy: 0.6236\n",
            "Epoch 292/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 1.0492 - accuracy: 0.6792\n",
            "Epoch 292: val_accuracy improved from 0.64565 to 0.64853, saving model to /content/asl/Adam/cp-292-0.65.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.0491 - accuracy: 0.6789 - val_loss: 1.1918 - val_accuracy: 0.6485\n",
            "Epoch 293/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.0650 - accuracy: 0.6726\n",
            "Epoch 293: val_accuracy did not improve from 0.64853\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 1.0650 - accuracy: 0.6726 - val_loss: 1.3486 - val_accuracy: 0.5880\n",
            "Epoch 294/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 1.1948 - accuracy: 0.6299\n",
            "Epoch 294: val_accuracy did not improve from 0.64853\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 1.1952 - accuracy: 0.6298 - val_loss: 2.0207 - val_accuracy: 0.4664\n",
            "Epoch 295/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 1.1308 - accuracy: 0.6518\n",
            "Epoch 295: val_accuracy improved from 0.64853 to 0.66837, saving model to /content/asl/Adam/cp-295-0.67.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.1303 - accuracy: 0.6522 - val_loss: 1.1319 - val_accuracy: 0.6684\n",
            "Epoch 296/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 1.0928 - accuracy: 0.6635\n",
            "Epoch 296: val_accuracy did not improve from 0.66837\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.0946 - accuracy: 0.6629 - val_loss: 1.2423 - val_accuracy: 0.6168\n",
            "Epoch 297/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 1.0881 - accuracy: 0.6683\n",
            "Epoch 297: val_accuracy did not improve from 0.66837\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.0875 - accuracy: 0.6686 - val_loss: 1.1206 - val_accuracy: 0.6652\n",
            "Epoch 298/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 1.0559 - accuracy: 0.6776\n",
            "Epoch 298: val_accuracy did not improve from 0.66837\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.0523 - accuracy: 0.6787 - val_loss: 1.2585 - val_accuracy: 0.6210\n",
            "Epoch 299/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 1.1112 - accuracy: 0.6579\n",
            "Epoch 299: val_accuracy did not improve from 0.66837\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.1103 - accuracy: 0.6583 - val_loss: 1.2779 - val_accuracy: 0.5973\n",
            "Epoch 300/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 1.0790 - accuracy: 0.6690\n",
            "Epoch 300: val_accuracy did not improve from 0.66837\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 1.0799 - accuracy: 0.6686 - val_loss: 1.6572 - val_accuracy: 0.5291\n",
            "Epoch 301/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 1.0704 - accuracy: 0.6687\n",
            "Epoch 301: val_accuracy did not improve from 0.66837\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 1.0681 - accuracy: 0.6697 - val_loss: 1.1662 - val_accuracy: 0.6415\n",
            "Epoch 302/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 1.0859 - accuracy: 0.6670\n",
            "Epoch 302: val_accuracy did not improve from 0.66837\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.0828 - accuracy: 0.6681 - val_loss: 1.1913 - val_accuracy: 0.6424\n",
            "Epoch 303/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 1.0530 - accuracy: 0.6725\n",
            "Epoch 303: val_accuracy did not improve from 0.66837\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.0521 - accuracy: 0.6729 - val_loss: 1.3991 - val_accuracy: 0.5762\n",
            "Epoch 304/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 1.0639 - accuracy: 0.6715\n",
            "Epoch 304: val_accuracy did not improve from 0.66837\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.0668 - accuracy: 0.6703 - val_loss: 1.4848 - val_accuracy: 0.5567\n",
            "Epoch 305/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 1.1444 - accuracy: 0.6450\n",
            "Epoch 305: val_accuracy did not improve from 0.66837\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.1449 - accuracy: 0.6452 - val_loss: 1.2373 - val_accuracy: 0.6248\n",
            "Epoch 306/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 1.0750 - accuracy: 0.6683\n",
            "Epoch 306: val_accuracy did not improve from 0.66837\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 1.0754 - accuracy: 0.6682 - val_loss: 1.1466 - val_accuracy: 0.6633\n",
            "Epoch 307/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 1.0249 - accuracy: 0.6877\n",
            "Epoch 307: val_accuracy did not improve from 0.66837\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 1.0252 - accuracy: 0.6872 - val_loss: 1.1600 - val_accuracy: 0.6581\n",
            "Epoch 308/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 1.0289 - accuracy: 0.6845\n",
            "Epoch 308: val_accuracy did not improve from 0.66837\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 1.0286 - accuracy: 0.6845 - val_loss: 1.2934 - val_accuracy: 0.6133\n",
            "Epoch 309/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 1.0488 - accuracy: 0.6777\n",
            "Epoch 309: val_accuracy did not improve from 0.66837\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.0512 - accuracy: 0.6761 - val_loss: 1.2683 - val_accuracy: 0.6143\n",
            "Epoch 310/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 1.1596 - accuracy: 0.6452\n",
            "Epoch 310: val_accuracy did not improve from 0.66837\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.1578 - accuracy: 0.6456 - val_loss: 1.3275 - val_accuracy: 0.5896\n",
            "Epoch 311/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 1.0572 - accuracy: 0.6733\n",
            "Epoch 311: val_accuracy did not improve from 0.66837\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.0567 - accuracy: 0.6733 - val_loss: 1.3413 - val_accuracy: 0.5880\n",
            "Epoch 312/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 1.0385 - accuracy: 0.6797\n",
            "Epoch 312: val_accuracy did not improve from 0.66837\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.0388 - accuracy: 0.6791 - val_loss: 1.2082 - val_accuracy: 0.6332\n",
            "Epoch 313/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.0319 - accuracy: 0.6818\n",
            "Epoch 313: val_accuracy did not improve from 0.66837\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 1.0319 - accuracy: 0.6818 - val_loss: 1.1640 - val_accuracy: 0.6623\n",
            "Epoch 314/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.9854 - accuracy: 0.6943\n",
            "Epoch 314: val_accuracy did not improve from 0.66837\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9868 - accuracy: 0.6921 - val_loss: 1.2774 - val_accuracy: 0.6050\n",
            "Epoch 315/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 1.1076 - accuracy: 0.6558\n",
            "Epoch 315: val_accuracy did not improve from 0.66837\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 1.1059 - accuracy: 0.6565 - val_loss: 1.1395 - val_accuracy: 0.6610\n",
            "Epoch 316/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.9603 - accuracy: 0.7027\n",
            "Epoch 316: val_accuracy improved from 0.66837 to 0.67734, saving model to /content/asl/Adam/cp-316-0.68.hdf5\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.9598 - accuracy: 0.7029 - val_loss: 1.1030 - val_accuracy: 0.6773\n",
            "Epoch 317/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 1.1071 - accuracy: 0.6606\n",
            "Epoch 317: val_accuracy did not improve from 0.67734\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.1059 - accuracy: 0.6604 - val_loss: 1.2951 - val_accuracy: 0.5980\n",
            "Epoch 318/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.9663 - accuracy: 0.7045\n",
            "Epoch 318: val_accuracy did not improve from 0.67734\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9671 - accuracy: 0.7045 - val_loss: 1.2190 - val_accuracy: 0.6223\n",
            "Epoch 319/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 1.0089 - accuracy: 0.6866\n",
            "Epoch 319: val_accuracy did not improve from 0.67734\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.0073 - accuracy: 0.6870 - val_loss: 1.1470 - val_accuracy: 0.6543\n",
            "Epoch 320/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 1.0199 - accuracy: 0.6823\n",
            "Epoch 320: val_accuracy did not improve from 0.67734\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.0197 - accuracy: 0.6823 - val_loss: 1.1256 - val_accuracy: 0.6629\n",
            "Epoch 321/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 1.0304 - accuracy: 0.6801\n",
            "Epoch 321: val_accuracy did not improve from 0.67734\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.0276 - accuracy: 0.6811 - val_loss: 1.5955 - val_accuracy: 0.5288\n",
            "Epoch 322/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 1.0298 - accuracy: 0.6798\n",
            "Epoch 322: val_accuracy did not improve from 0.67734\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 1.0302 - accuracy: 0.6793 - val_loss: 1.3238 - val_accuracy: 0.6037\n",
            "Epoch 323/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 1.0790 - accuracy: 0.6663\n",
            "Epoch 323: val_accuracy did not improve from 0.67734\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 1.0803 - accuracy: 0.6660 - val_loss: 1.5304 - val_accuracy: 0.5448\n",
            "Epoch 324/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 1.0131 - accuracy: 0.6845\n",
            "Epoch 324: val_accuracy did not improve from 0.67734\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.0126 - accuracy: 0.6848 - val_loss: 1.0864 - val_accuracy: 0.6751\n",
            "Epoch 325/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.9919 - accuracy: 0.6947\n",
            "Epoch 325: val_accuracy did not improve from 0.67734\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9943 - accuracy: 0.6940 - val_loss: 1.2596 - val_accuracy: 0.6188\n",
            "Epoch 326/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 1.0704 - accuracy: 0.6659\n",
            "Epoch 326: val_accuracy did not improve from 0.67734\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.0732 - accuracy: 0.6649 - val_loss: 1.2395 - val_accuracy: 0.6149\n",
            "Epoch 327/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.9806 - accuracy: 0.6958\n",
            "Epoch 327: val_accuracy did not improve from 0.67734\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9813 - accuracy: 0.6957 - val_loss: 1.2021 - val_accuracy: 0.6370\n",
            "Epoch 328/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 1.0917 - accuracy: 0.6678\n",
            "Epoch 328: val_accuracy did not improve from 0.67734\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.0914 - accuracy: 0.6679 - val_loss: 1.4257 - val_accuracy: 0.5823\n",
            "Epoch 329/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.9992 - accuracy: 0.6908\n",
            "Epoch 329: val_accuracy did not improve from 0.67734\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.9992 - accuracy: 0.6908 - val_loss: 1.1193 - val_accuracy: 0.6661\n",
            "Epoch 330/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 1.0273 - accuracy: 0.6786\n",
            "Epoch 330: val_accuracy did not improve from 0.67734\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 1.0240 - accuracy: 0.6794 - val_loss: 1.2526 - val_accuracy: 0.6152\n",
            "Epoch 331/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 1.0572 - accuracy: 0.6723\n",
            "Epoch 331: val_accuracy did not improve from 0.67734\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 1.0572 - accuracy: 0.6724 - val_loss: 1.2160 - val_accuracy: 0.6319\n",
            "Epoch 332/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 0.9301 - accuracy: 0.7146\n",
            "Epoch 332: val_accuracy did not improve from 0.67734\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9319 - accuracy: 0.7136 - val_loss: 1.3047 - val_accuracy: 0.6053\n",
            "Epoch 333/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 1.0144 - accuracy: 0.6835\n",
            "Epoch 333: val_accuracy did not improve from 0.67734\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.0136 - accuracy: 0.6837 - val_loss: 1.1543 - val_accuracy: 0.6511\n",
            "Epoch 334/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 0.9744 - accuracy: 0.7007\n",
            "Epoch 334: val_accuracy did not improve from 0.67734\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.9736 - accuracy: 0.6994 - val_loss: 1.3719 - val_accuracy: 0.5800\n",
            "Epoch 335/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.9815 - accuracy: 0.6959\n",
            "Epoch 335: val_accuracy did not improve from 0.67734\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9809 - accuracy: 0.6957 - val_loss: 1.1834 - val_accuracy: 0.6367\n",
            "Epoch 336/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 1.0245 - accuracy: 0.6814\n",
            "Epoch 336: val_accuracy did not improve from 0.67734\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.0250 - accuracy: 0.6810 - val_loss: 1.0904 - val_accuracy: 0.6757\n",
            "Epoch 337/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.9722 - accuracy: 0.6970\n",
            "Epoch 337: val_accuracy improved from 0.67734 to 0.67766, saving model to /content/asl/Adam/cp-337-0.68.hdf5\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 0.9719 - accuracy: 0.6974 - val_loss: 1.0830 - val_accuracy: 0.6777\n",
            "Epoch 338/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 1.0052 - accuracy: 0.6859\n",
            "Epoch 338: val_accuracy did not improve from 0.67766\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 1.0042 - accuracy: 0.6863 - val_loss: 1.2686 - val_accuracy: 0.6200\n",
            "Epoch 339/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 1.0184 - accuracy: 0.6827\n",
            "Epoch 339: val_accuracy did not improve from 0.67766\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.0162 - accuracy: 0.6837 - val_loss: 1.1390 - val_accuracy: 0.6488\n",
            "Epoch 340/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 1.0383 - accuracy: 0.6791\n",
            "Epoch 340: val_accuracy did not improve from 0.67766\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.0383 - accuracy: 0.6792 - val_loss: 1.2628 - val_accuracy: 0.6156\n",
            "Epoch 341/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.9517 - accuracy: 0.7061\n",
            "Epoch 341: val_accuracy did not improve from 0.67766\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9515 - accuracy: 0.7059 - val_loss: 1.2397 - val_accuracy: 0.6245\n",
            "Epoch 342/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.0014 - accuracy: 0.6891\n",
            "Epoch 342: val_accuracy did not improve from 0.67766\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.0014 - accuracy: 0.6891 - val_loss: 1.1691 - val_accuracy: 0.6418\n",
            "Epoch 343/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.9723 - accuracy: 0.6947\n",
            "Epoch 343: val_accuracy did not improve from 0.67766\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9726 - accuracy: 0.6948 - val_loss: 1.2423 - val_accuracy: 0.6204\n",
            "Epoch 344/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.9588 - accuracy: 0.6998\n",
            "Epoch 344: val_accuracy did not improve from 0.67766\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.9589 - accuracy: 0.6999 - val_loss: 1.0692 - val_accuracy: 0.6770\n",
            "Epoch 345/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 0.9325 - accuracy: 0.7120\n",
            "Epoch 345: val_accuracy did not improve from 0.67766\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.9322 - accuracy: 0.7127 - val_loss: 1.8773 - val_accuracy: 0.4763\n",
            "Epoch 346/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.9943 - accuracy: 0.6921\n",
            "Epoch 346: val_accuracy did not improve from 0.67766\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9943 - accuracy: 0.6921 - val_loss: 1.1432 - val_accuracy: 0.6591\n",
            "Epoch 347/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.9602 - accuracy: 0.7021\n",
            "Epoch 347: val_accuracy did not improve from 0.67766\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9602 - accuracy: 0.7021 - val_loss: 1.4595 - val_accuracy: 0.5560\n",
            "Epoch 348/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 1.0710 - accuracy: 0.6687\n",
            "Epoch 348: val_accuracy did not improve from 0.67766\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.0711 - accuracy: 0.6688 - val_loss: 1.0803 - val_accuracy: 0.6770\n",
            "Epoch 349/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.9360 - accuracy: 0.7126\n",
            "Epoch 349: val_accuracy improved from 0.67766 to 0.67894, saving model to /content/asl/Adam/cp-349-0.68.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9360 - accuracy: 0.7126 - val_loss: 1.0761 - val_accuracy: 0.6789\n",
            "Epoch 350/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.9957 - accuracy: 0.6915\n",
            "Epoch 350: val_accuracy did not improve from 0.67894\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9957 - accuracy: 0.6915 - val_loss: 1.1542 - val_accuracy: 0.6418\n",
            "Epoch 351/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.9546 - accuracy: 0.7009\n",
            "Epoch 351: val_accuracy did not improve from 0.67894\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.9526 - accuracy: 0.7014 - val_loss: 1.1735 - val_accuracy: 0.6466\n",
            "Epoch 352/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.9767 - accuracy: 0.6933\n",
            "Epoch 352: val_accuracy did not improve from 0.67894\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.9766 - accuracy: 0.6932 - val_loss: 1.4706 - val_accuracy: 0.5592\n",
            "Epoch 353/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.8998 - accuracy: 0.7212\n",
            "Epoch 353: val_accuracy did not improve from 0.67894\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8998 - accuracy: 0.7212 - val_loss: 1.1247 - val_accuracy: 0.6530\n",
            "Epoch 354/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.9687 - accuracy: 0.6991\n",
            "Epoch 354: val_accuracy did not improve from 0.67894\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9672 - accuracy: 0.6993 - val_loss: 1.1560 - val_accuracy: 0.6440\n",
            "Epoch 355/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.9692 - accuracy: 0.6965\n",
            "Epoch 355: val_accuracy did not improve from 0.67894\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9798 - accuracy: 0.6941 - val_loss: 2.2751 - val_accuracy: 0.4424\n",
            "Epoch 356/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.9573 - accuracy: 0.7044\n",
            "Epoch 356: val_accuracy did not improve from 0.67894\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9568 - accuracy: 0.7045 - val_loss: 1.1287 - val_accuracy: 0.6562\n",
            "Epoch 357/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 1.0190 - accuracy: 0.6859\n",
            "Epoch 357: val_accuracy did not improve from 0.67894\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.0172 - accuracy: 0.6858 - val_loss: 1.1201 - val_accuracy: 0.6569\n",
            "Epoch 358/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.9740 - accuracy: 0.6890\n",
            "Epoch 358: val_accuracy did not improve from 0.67894\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.9746 - accuracy: 0.6887 - val_loss: 1.2763 - val_accuracy: 0.6140\n",
            "Epoch 359/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.9622 - accuracy: 0.6974\n",
            "Epoch 359: val_accuracy did not improve from 0.67894\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 0.9634 - accuracy: 0.6971 - val_loss: 1.0866 - val_accuracy: 0.6722\n",
            "Epoch 360/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.9425 - accuracy: 0.7037\n",
            "Epoch 360: val_accuracy did not improve from 0.67894\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.9425 - accuracy: 0.7037 - val_loss: 1.0877 - val_accuracy: 0.6684\n",
            "Epoch 361/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.9553 - accuracy: 0.6999\n",
            "Epoch 361: val_accuracy did not improve from 0.67894\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9578 - accuracy: 0.6991 - val_loss: 1.2070 - val_accuracy: 0.6258\n",
            "Epoch 362/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 0.9769 - accuracy: 0.6951\n",
            "Epoch 362: val_accuracy did not improve from 0.67894\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.9763 - accuracy: 0.6953 - val_loss: 1.1017 - val_accuracy: 0.6601\n",
            "Epoch 363/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.9274 - accuracy: 0.7146\n",
            "Epoch 363: val_accuracy did not improve from 0.67894\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9278 - accuracy: 0.7147 - val_loss: 1.1502 - val_accuracy: 0.6597\n",
            "Epoch 364/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.9998 - accuracy: 0.6845\n",
            "Epoch 364: val_accuracy did not improve from 0.67894\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9998 - accuracy: 0.6845 - val_loss: 1.2229 - val_accuracy: 0.6252\n",
            "Epoch 365/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.9275 - accuracy: 0.7128\n",
            "Epoch 365: val_accuracy did not improve from 0.67894\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9250 - accuracy: 0.7136 - val_loss: 1.1500 - val_accuracy: 0.6498\n",
            "Epoch 366/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.9460 - accuracy: 0.7058\n",
            "Epoch 366: val_accuracy did not improve from 0.67894\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.9460 - accuracy: 0.7058 - val_loss: 1.2963 - val_accuracy: 0.5922\n",
            "Epoch 367/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 0.9079 - accuracy: 0.7162\n",
            "Epoch 367: val_accuracy did not improve from 0.67894\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.9084 - accuracy: 0.7166 - val_loss: 1.0846 - val_accuracy: 0.6594\n",
            "Epoch 368/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 0.9252 - accuracy: 0.7088\n",
            "Epoch 368: val_accuracy did not improve from 0.67894\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9270 - accuracy: 0.7080 - val_loss: 1.1559 - val_accuracy: 0.6389\n",
            "Epoch 369/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.9497 - accuracy: 0.7022\n",
            "Epoch 369: val_accuracy did not improve from 0.67894\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9479 - accuracy: 0.7028 - val_loss: 1.2069 - val_accuracy: 0.6252\n",
            "Epoch 370/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 0.9339 - accuracy: 0.7072\n",
            "Epoch 370: val_accuracy improved from 0.67894 to 0.69302, saving model to /content/asl/Adam/cp-370-0.69.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9294 - accuracy: 0.7090 - val_loss: 1.0274 - val_accuracy: 0.6930\n",
            "Epoch 371/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 0.8821 - accuracy: 0.7216\n",
            "Epoch 371: val_accuracy did not improve from 0.69302\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8818 - accuracy: 0.7216 - val_loss: 1.2190 - val_accuracy: 0.6258\n",
            "Epoch 372/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.8943 - accuracy: 0.7172\n",
            "Epoch 372: val_accuracy did not improve from 0.69302\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8943 - accuracy: 0.7172 - val_loss: 1.2175 - val_accuracy: 0.6357\n",
            "Epoch 373/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.9403 - accuracy: 0.7075\n",
            "Epoch 373: val_accuracy did not improve from 0.69302\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.9407 - accuracy: 0.7073 - val_loss: 1.3146 - val_accuracy: 0.5839\n",
            "Epoch 374/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.9136 - accuracy: 0.7127\n",
            "Epoch 374: val_accuracy did not improve from 0.69302\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.9141 - accuracy: 0.7124 - val_loss: 1.1430 - val_accuracy: 0.6476\n",
            "Epoch 375/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 0.9263 - accuracy: 0.7078\n",
            "Epoch 375: val_accuracy did not improve from 0.69302\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9262 - accuracy: 0.7077 - val_loss: 1.1229 - val_accuracy: 0.6572\n",
            "Epoch 376/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.8881 - accuracy: 0.7200\n",
            "Epoch 376: val_accuracy did not improve from 0.69302\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8852 - accuracy: 0.7211 - val_loss: 1.0346 - val_accuracy: 0.6930\n",
            "Epoch 377/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.9249 - accuracy: 0.7106\n",
            "Epoch 377: val_accuracy did not improve from 0.69302\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9225 - accuracy: 0.7113 - val_loss: 1.1173 - val_accuracy: 0.6572\n",
            "Epoch 378/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.9694 - accuracy: 0.6936\n",
            "Epoch 378: val_accuracy did not improve from 0.69302\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9685 - accuracy: 0.6939 - val_loss: 1.0695 - val_accuracy: 0.6745\n",
            "Epoch 379/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.9136 - accuracy: 0.7146\n",
            "Epoch 379: val_accuracy did not improve from 0.69302\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9132 - accuracy: 0.7143 - val_loss: 1.1256 - val_accuracy: 0.6524\n",
            "Epoch 380/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.9404 - accuracy: 0.7016\n",
            "Epoch 380: val_accuracy did not improve from 0.69302\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.9404 - accuracy: 0.7016 - val_loss: 1.4351 - val_accuracy: 0.5691\n",
            "Epoch 381/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.9157 - accuracy: 0.7175\n",
            "Epoch 381: val_accuracy did not improve from 0.69302\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 0.9154 - accuracy: 0.7174 - val_loss: 1.1513 - val_accuracy: 0.6501\n",
            "Epoch 382/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.8628 - accuracy: 0.7267\n",
            "Epoch 382: val_accuracy did not improve from 0.69302\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8639 - accuracy: 0.7265 - val_loss: 1.2150 - val_accuracy: 0.6239\n",
            "Epoch 383/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.8974 - accuracy: 0.7192\n",
            "Epoch 383: val_accuracy did not improve from 0.69302\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8970 - accuracy: 0.7194 - val_loss: 1.0752 - val_accuracy: 0.6709\n",
            "Epoch 384/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 0.8922 - accuracy: 0.7177\n",
            "Epoch 384: val_accuracy did not improve from 0.69302\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.8920 - accuracy: 0.7178 - val_loss: 1.0834 - val_accuracy: 0.6629\n",
            "Epoch 385/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 0.8731 - accuracy: 0.7264\n",
            "Epoch 385: val_accuracy did not improve from 0.69302\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.8706 - accuracy: 0.7266 - val_loss: 1.0807 - val_accuracy: 0.6706\n",
            "Epoch 386/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.9588 - accuracy: 0.6981\n",
            "Epoch 386: val_accuracy did not improve from 0.69302\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9588 - accuracy: 0.6981 - val_loss: 1.4947 - val_accuracy: 0.5535\n",
            "Epoch 387/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.9688 - accuracy: 0.6971\n",
            "Epoch 387: val_accuracy did not improve from 0.69302\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9681 - accuracy: 0.6973 - val_loss: 1.2640 - val_accuracy: 0.6136\n",
            "Epoch 388/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.9122 - accuracy: 0.7119\n",
            "Epoch 388: val_accuracy did not improve from 0.69302\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 0.9116 - accuracy: 0.7123 - val_loss: 1.4990 - val_accuracy: 0.5701\n",
            "Epoch 389/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.9344 - accuracy: 0.7063\n",
            "Epoch 389: val_accuracy did not improve from 0.69302\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.9342 - accuracy: 0.7063 - val_loss: 1.3323 - val_accuracy: 0.5957\n",
            "Epoch 390/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 0.9519 - accuracy: 0.7018\n",
            "Epoch 390: val_accuracy did not improve from 0.69302\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9510 - accuracy: 0.7017 - val_loss: 1.0518 - val_accuracy: 0.6738\n",
            "Epoch 391/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 0.8872 - accuracy: 0.7210\n",
            "Epoch 391: val_accuracy did not improve from 0.69302\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8894 - accuracy: 0.7205 - val_loss: 1.0536 - val_accuracy: 0.6799\n",
            "Epoch 392/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.8649 - accuracy: 0.7240\n",
            "Epoch 392: val_accuracy improved from 0.69302 to 0.69526, saving model to /content/asl/Adam/cp-392-0.70.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8651 - accuracy: 0.7238 - val_loss: 1.0192 - val_accuracy: 0.6953\n",
            "Epoch 393/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 0.9942 - accuracy: 0.6884\n",
            "Epoch 393: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.9959 - accuracy: 0.6877 - val_loss: 1.1469 - val_accuracy: 0.6453\n",
            "Epoch 394/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.9500 - accuracy: 0.6993\n",
            "Epoch 394: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9491 - accuracy: 0.6993 - val_loss: 1.1581 - val_accuracy: 0.6338\n",
            "Epoch 395/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.9098 - accuracy: 0.7175\n",
            "Epoch 395: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.9100 - accuracy: 0.7173 - val_loss: 1.0722 - val_accuracy: 0.6738\n",
            "Epoch 396/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.9470 - accuracy: 0.7048\n",
            "Epoch 396: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 0.9459 - accuracy: 0.7049 - val_loss: 1.0259 - val_accuracy: 0.6869\n",
            "Epoch 397/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.8580 - accuracy: 0.7267\n",
            "Epoch 397: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8591 - accuracy: 0.7262 - val_loss: 1.1063 - val_accuracy: 0.6649\n",
            "Epoch 398/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.8620 - accuracy: 0.7302\n",
            "Epoch 398: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8616 - accuracy: 0.7303 - val_loss: 1.1889 - val_accuracy: 0.6437\n",
            "Epoch 399/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.8755 - accuracy: 0.7241\n",
            "Epoch 399: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8743 - accuracy: 0.7244 - val_loss: 1.0412 - val_accuracy: 0.6770\n",
            "Epoch 400/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.8724 - accuracy: 0.7276\n",
            "Epoch 400: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8751 - accuracy: 0.7271 - val_loss: 1.1322 - val_accuracy: 0.6607\n",
            "Epoch 401/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.9034 - accuracy: 0.7150\n",
            "Epoch 401: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9030 - accuracy: 0.7153 - val_loss: 1.0128 - val_accuracy: 0.6905\n",
            "Epoch 402/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.8573 - accuracy: 0.7320\n",
            "Epoch 402: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.8572 - accuracy: 0.7319 - val_loss: 1.0754 - val_accuracy: 0.6780\n",
            "Epoch 403/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.8527 - accuracy: 0.7329\n",
            "Epoch 403: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 13ms/step - loss: 0.8518 - accuracy: 0.7332 - val_loss: 1.2990 - val_accuracy: 0.6136\n",
            "Epoch 404/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 0.9405 - accuracy: 0.7047\n",
            "Epoch 404: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9386 - accuracy: 0.7053 - val_loss: 1.0926 - val_accuracy: 0.6594\n",
            "Epoch 405/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.8625 - accuracy: 0.7243\n",
            "Epoch 405: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8660 - accuracy: 0.7235 - val_loss: 1.1047 - val_accuracy: 0.6597\n",
            "Epoch 406/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.9374 - accuracy: 0.7015\n",
            "Epoch 406: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9358 - accuracy: 0.7017 - val_loss: 1.1132 - val_accuracy: 0.6633\n",
            "Epoch 407/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 0.8910 - accuracy: 0.7165\n",
            "Epoch 407: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8950 - accuracy: 0.7159 - val_loss: 1.2121 - val_accuracy: 0.6415\n",
            "Epoch 408/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.8409 - accuracy: 0.7374\n",
            "Epoch 408: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8409 - accuracy: 0.7374 - val_loss: 1.7021 - val_accuracy: 0.5256\n",
            "Epoch 409/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.8819 - accuracy: 0.7220\n",
            "Epoch 409: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8851 - accuracy: 0.7203 - val_loss: 1.0649 - val_accuracy: 0.6786\n",
            "Epoch 410/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.8922 - accuracy: 0.7188\n",
            "Epoch 410: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 0.8938 - accuracy: 0.7186 - val_loss: 1.3294 - val_accuracy: 0.5980\n",
            "Epoch 411/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.8348 - accuracy: 0.7346\n",
            "Epoch 411: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.8346 - accuracy: 0.7350 - val_loss: 1.2464 - val_accuracy: 0.6194\n",
            "Epoch 412/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.8465 - accuracy: 0.7312\n",
            "Epoch 412: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8465 - accuracy: 0.7312 - val_loss: 1.1597 - val_accuracy: 0.6511\n",
            "Epoch 413/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.9719 - accuracy: 0.6960\n",
            "Epoch 413: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9711 - accuracy: 0.6958 - val_loss: 1.0994 - val_accuracy: 0.6549\n",
            "Epoch 414/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.9252 - accuracy: 0.7103\n",
            "Epoch 414: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9258 - accuracy: 0.7102 - val_loss: 1.1134 - val_accuracy: 0.6591\n",
            "Epoch 415/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.8313 - accuracy: 0.7392\n",
            "Epoch 415: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8316 - accuracy: 0.7389 - val_loss: 1.1854 - val_accuracy: 0.6421\n",
            "Epoch 416/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.8799 - accuracy: 0.7212\n",
            "Epoch 416: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8811 - accuracy: 0.7209 - val_loss: 1.7202 - val_accuracy: 0.5157\n",
            "Epoch 417/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.8594 - accuracy: 0.7309\n",
            "Epoch 417: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.8595 - accuracy: 0.7301 - val_loss: 1.3986 - val_accuracy: 0.5890\n",
            "Epoch 418/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.9083 - accuracy: 0.7130\n",
            "Epoch 418: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 0.9081 - accuracy: 0.7133 - val_loss: 1.0547 - val_accuracy: 0.6738\n",
            "Epoch 419/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.8815 - accuracy: 0.7167\n",
            "Epoch 419: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8817 - accuracy: 0.7166 - val_loss: 1.1352 - val_accuracy: 0.6591\n",
            "Epoch 420/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.8530 - accuracy: 0.7318\n",
            "Epoch 420: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8537 - accuracy: 0.7311 - val_loss: 1.2453 - val_accuracy: 0.6204\n",
            "Epoch 421/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.8190 - accuracy: 0.7448\n",
            "Epoch 421: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8187 - accuracy: 0.7452 - val_loss: 1.0992 - val_accuracy: 0.6629\n",
            "Epoch 422/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 0.8667 - accuracy: 0.7284\n",
            "Epoch 422: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8685 - accuracy: 0.7278 - val_loss: 1.4963 - val_accuracy: 0.5621\n",
            "Epoch 423/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.8789 - accuracy: 0.7225\n",
            "Epoch 423: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8779 - accuracy: 0.7228 - val_loss: 1.0298 - val_accuracy: 0.6770\n",
            "Epoch 424/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.8379 - accuracy: 0.7357\n",
            "Epoch 424: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.8387 - accuracy: 0.7353 - val_loss: 1.0750 - val_accuracy: 0.6783\n",
            "Epoch 425/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.8490 - accuracy: 0.7285\n",
            "Epoch 425: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 0.8490 - accuracy: 0.7285 - val_loss: 1.0825 - val_accuracy: 0.6636\n",
            "Epoch 426/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 0.8970 - accuracy: 0.7174\n",
            "Epoch 426: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9007 - accuracy: 0.7161 - val_loss: 1.3545 - val_accuracy: 0.5967\n",
            "Epoch 427/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.8295 - accuracy: 0.7404\n",
            "Epoch 427: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8298 - accuracy: 0.7405 - val_loss: 1.1143 - val_accuracy: 0.6460\n",
            "Epoch 428/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.8162 - accuracy: 0.7426\n",
            "Epoch 428: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8176 - accuracy: 0.7419 - val_loss: 1.6099 - val_accuracy: 0.5493\n",
            "Epoch 429/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.9847 - accuracy: 0.6953\n",
            "Epoch 429: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9809 - accuracy: 0.6964 - val_loss: 1.0354 - val_accuracy: 0.6799\n",
            "Epoch 430/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.8684 - accuracy: 0.7277\n",
            "Epoch 430: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8684 - accuracy: 0.7277 - val_loss: 1.0341 - val_accuracy: 0.6866\n",
            "Epoch 431/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.9252 - accuracy: 0.7064\n",
            "Epoch 431: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9247 - accuracy: 0.7064 - val_loss: 1.9147 - val_accuracy: 0.4888\n",
            "Epoch 432/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.8743 - accuracy: 0.7251\n",
            "Epoch 432: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.8757 - accuracy: 0.7243 - val_loss: 1.0346 - val_accuracy: 0.6828\n",
            "Epoch 433/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 0.8130 - accuracy: 0.7429\n",
            "Epoch 433: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.8138 - accuracy: 0.7426 - val_loss: 1.1054 - val_accuracy: 0.6504\n",
            "Epoch 434/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.8367 - accuracy: 0.7311\n",
            "Epoch 434: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8348 - accuracy: 0.7317 - val_loss: 0.9960 - val_accuracy: 0.6908\n",
            "Epoch 435/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.8090 - accuracy: 0.7442\n",
            "Epoch 435: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8088 - accuracy: 0.7442 - val_loss: 0.9936 - val_accuracy: 0.6882\n",
            "Epoch 436/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.8330 - accuracy: 0.7388\n",
            "Epoch 436: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8332 - accuracy: 0.7388 - val_loss: 1.0796 - val_accuracy: 0.6661\n",
            "Epoch 437/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.8615 - accuracy: 0.7237\n",
            "Epoch 437: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8604 - accuracy: 0.7239 - val_loss: 1.1153 - val_accuracy: 0.6533\n",
            "Epoch 438/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.7935 - accuracy: 0.7454\n",
            "Epoch 438: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7924 - accuracy: 0.7456 - val_loss: 1.0748 - val_accuracy: 0.6697\n",
            "Epoch 439/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.8321 - accuracy: 0.7362\n",
            "Epoch 439: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.8319 - accuracy: 0.7359 - val_loss: 1.2307 - val_accuracy: 0.6232\n",
            "Epoch 440/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.8180 - accuracy: 0.7380\n",
            "Epoch 440: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 0.8180 - accuracy: 0.7380 - val_loss: 1.0862 - val_accuracy: 0.6709\n",
            "Epoch 441/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.8057 - accuracy: 0.7406\n",
            "Epoch 441: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8057 - accuracy: 0.7406 - val_loss: 1.0229 - val_accuracy: 0.6879\n",
            "Epoch 442/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 0.8667 - accuracy: 0.7267\n",
            "Epoch 442: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.8654 - accuracy: 0.7268 - val_loss: 1.0781 - val_accuracy: 0.6719\n",
            "Epoch 443/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.8085 - accuracy: 0.7448\n",
            "Epoch 443: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8092 - accuracy: 0.7443 - val_loss: 1.1374 - val_accuracy: 0.6677\n",
            "Epoch 444/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.8153 - accuracy: 0.7406\n",
            "Epoch 444: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8129 - accuracy: 0.7413 - val_loss: 1.0469 - val_accuracy: 0.6780\n",
            "Epoch 445/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.8437 - accuracy: 0.7312\n",
            "Epoch 445: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8481 - accuracy: 0.7303 - val_loss: 1.1159 - val_accuracy: 0.6636\n",
            "Epoch 446/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.8761 - accuracy: 0.7211\n",
            "Epoch 446: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.8750 - accuracy: 0.7213 - val_loss: 1.0630 - val_accuracy: 0.6655\n",
            "Epoch 447/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.8742 - accuracy: 0.7248\n",
            "Epoch 447: val_accuracy did not improve from 0.69526\n",
            "196/196 [==============================] - 2s 13ms/step - loss: 0.8730 - accuracy: 0.7255 - val_loss: 1.1309 - val_accuracy: 0.6440\n",
            "Epoch 448/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.7801 - accuracy: 0.7487\n",
            "Epoch 448: val_accuracy improved from 0.69526 to 0.71063, saving model to /content/asl/Adam/cp-448-0.71.hdf5\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.7797 - accuracy: 0.7491 - val_loss: 0.9598 - val_accuracy: 0.7106\n",
            "Epoch 449/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.7837 - accuracy: 0.7478\n",
            "Epoch 449: val_accuracy did not improve from 0.71063\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7834 - accuracy: 0.7479 - val_loss: 1.0550 - val_accuracy: 0.6709\n",
            "Epoch 450/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.8265 - accuracy: 0.7349\n",
            "Epoch 450: val_accuracy did not improve from 0.71063\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8288 - accuracy: 0.7345 - val_loss: 1.5845 - val_accuracy: 0.5506\n",
            "Epoch 451/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.7814 - accuracy: 0.7492\n",
            "Epoch 451: val_accuracy did not improve from 0.71063\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7874 - accuracy: 0.7474 - val_loss: 1.0593 - val_accuracy: 0.6783\n",
            "Epoch 452/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.8489 - accuracy: 0.7297\n",
            "Epoch 452: val_accuracy did not improve from 0.71063\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8477 - accuracy: 0.7299 - val_loss: 1.3000 - val_accuracy: 0.5964\n",
            "Epoch 453/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.9499 - accuracy: 0.6973\n",
            "Epoch 453: val_accuracy did not improve from 0.71063\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9472 - accuracy: 0.6979 - val_loss: 1.0189 - val_accuracy: 0.6969\n",
            "Epoch 454/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 0.8266 - accuracy: 0.7361\n",
            "Epoch 454: val_accuracy did not improve from 0.71063\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 0.8267 - accuracy: 0.7358 - val_loss: 1.0680 - val_accuracy: 0.6815\n",
            "Epoch 455/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.8718 - accuracy: 0.7221\n",
            "Epoch 455: val_accuracy did not improve from 0.71063\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 0.8711 - accuracy: 0.7217 - val_loss: 1.1775 - val_accuracy: 0.6328\n",
            "Epoch 456/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.7845 - accuracy: 0.7502\n",
            "Epoch 456: val_accuracy did not improve from 0.71063\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7839 - accuracy: 0.7504 - val_loss: 1.1993 - val_accuracy: 0.6440\n",
            "Epoch 457/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 0.7829 - accuracy: 0.7523\n",
            "Epoch 457: val_accuracy did not improve from 0.71063\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7854 - accuracy: 0.7516 - val_loss: 1.0754 - val_accuracy: 0.6594\n",
            "Epoch 458/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.8728 - accuracy: 0.7208\n",
            "Epoch 458: val_accuracy did not improve from 0.71063\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8731 - accuracy: 0.7208 - val_loss: 1.1100 - val_accuracy: 0.6719\n",
            "Epoch 459/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 0.8550 - accuracy: 0.7294\n",
            "Epoch 459: val_accuracy did not improve from 0.71063\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8534 - accuracy: 0.7297 - val_loss: 0.9933 - val_accuracy: 0.6937\n",
            "Epoch 460/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 0.7589 - accuracy: 0.7585\n",
            "Epoch 460: val_accuracy did not improve from 0.71063\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7597 - accuracy: 0.7590 - val_loss: 1.0249 - val_accuracy: 0.6860\n",
            "Epoch 461/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.7633 - accuracy: 0.7573\n",
            "Epoch 461: val_accuracy did not improve from 0.71063\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.7652 - accuracy: 0.7567 - val_loss: 0.9904 - val_accuracy: 0.6937\n",
            "Epoch 462/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.8231 - accuracy: 0.7406\n",
            "Epoch 462: val_accuracy did not improve from 0.71063\n",
            "196/196 [==============================] - 2s 13ms/step - loss: 0.8261 - accuracy: 0.7398 - val_loss: 1.4394 - val_accuracy: 0.5810\n",
            "Epoch 463/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.8709 - accuracy: 0.7193\n",
            "Epoch 463: val_accuracy did not improve from 0.71063\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8707 - accuracy: 0.7194 - val_loss: 1.0595 - val_accuracy: 0.6773\n",
            "Epoch 464/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.7655 - accuracy: 0.7570\n",
            "Epoch 464: val_accuracy did not improve from 0.71063\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7669 - accuracy: 0.7563 - val_loss: 1.0627 - val_accuracy: 0.6802\n",
            "Epoch 465/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.8150 - accuracy: 0.7396\n",
            "Epoch 465: val_accuracy did not improve from 0.71063\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.8122 - accuracy: 0.7403 - val_loss: 0.9952 - val_accuracy: 0.6972\n",
            "Epoch 466/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 0.8138 - accuracy: 0.7426\n",
            "Epoch 466: val_accuracy did not improve from 0.71063\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8166 - accuracy: 0.7414 - val_loss: 1.2555 - val_accuracy: 0.6117\n",
            "Epoch 467/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.8869 - accuracy: 0.7135\n",
            "Epoch 467: val_accuracy did not improve from 0.71063\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8861 - accuracy: 0.7137 - val_loss: 0.9740 - val_accuracy: 0.6978\n",
            "Epoch 468/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.8175 - accuracy: 0.7368\n",
            "Epoch 468: val_accuracy did not improve from 0.71063\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.8175 - accuracy: 0.7366 - val_loss: 1.0793 - val_accuracy: 0.6706\n",
            "Epoch 469/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.7767 - accuracy: 0.7528\n",
            "Epoch 469: val_accuracy improved from 0.71063 to 0.71223, saving model to /content/asl/Adam/cp-469-0.71.hdf5\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 0.7763 - accuracy: 0.7524 - val_loss: 0.9601 - val_accuracy: 0.7122\n",
            "Epoch 470/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.7616 - accuracy: 0.7588\n",
            "Epoch 470: val_accuracy did not improve from 0.71223\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.7626 - accuracy: 0.7587 - val_loss: 0.9950 - val_accuracy: 0.6927\n",
            "Epoch 471/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.8134 - accuracy: 0.7358\n",
            "Epoch 471: val_accuracy did not improve from 0.71223\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8132 - accuracy: 0.7357 - val_loss: 1.2669 - val_accuracy: 0.6165\n",
            "Epoch 472/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 0.7555 - accuracy: 0.7581\n",
            "Epoch 472: val_accuracy did not improve from 0.71223\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7554 - accuracy: 0.7584 - val_loss: 0.9785 - val_accuracy: 0.6994\n",
            "Epoch 473/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.7912 - accuracy: 0.7493\n",
            "Epoch 473: val_accuracy did not improve from 0.71223\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7959 - accuracy: 0.7475 - val_loss: 1.4685 - val_accuracy: 0.5695\n",
            "Epoch 474/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.7595 - accuracy: 0.7586\n",
            "Epoch 474: val_accuracy did not improve from 0.71223\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7592 - accuracy: 0.7589 - val_loss: 1.1334 - val_accuracy: 0.6674\n",
            "Epoch 475/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.8527 - accuracy: 0.7282\n",
            "Epoch 475: val_accuracy did not improve from 0.71223\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8519 - accuracy: 0.7282 - val_loss: 1.1064 - val_accuracy: 0.6511\n",
            "Epoch 476/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.7520 - accuracy: 0.7610\n",
            "Epoch 476: val_accuracy did not improve from 0.71223\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 0.7508 - accuracy: 0.7615 - val_loss: 0.9970 - val_accuracy: 0.6956\n",
            "Epoch 477/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.8770 - accuracy: 0.7271\n",
            "Epoch 477: val_accuracy did not improve from 0.71223\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 0.8795 - accuracy: 0.7265 - val_loss: 1.1433 - val_accuracy: 0.6533\n",
            "Epoch 478/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.7653 - accuracy: 0.7537\n",
            "Epoch 478: val_accuracy did not improve from 0.71223\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7652 - accuracy: 0.7533 - val_loss: 0.9494 - val_accuracy: 0.7122\n",
            "Epoch 479/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.7526 - accuracy: 0.7572\n",
            "Epoch 479: val_accuracy did not improve from 0.71223\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7519 - accuracy: 0.7576 - val_loss: 1.2232 - val_accuracy: 0.6328\n",
            "Epoch 480/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.8557 - accuracy: 0.7273\n",
            "Epoch 480: val_accuracy did not improve from 0.71223\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8557 - accuracy: 0.7273 - val_loss: 1.1658 - val_accuracy: 0.6437\n",
            "Epoch 481/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.7731 - accuracy: 0.7502\n",
            "Epoch 481: val_accuracy did not improve from 0.71223\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7731 - accuracy: 0.7502 - val_loss: 1.2568 - val_accuracy: 0.6245\n",
            "Epoch 482/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 0.7736 - accuracy: 0.7531\n",
            "Epoch 482: val_accuracy did not improve from 0.71223\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7713 - accuracy: 0.7542 - val_loss: 0.9746 - val_accuracy: 0.6981\n",
            "Epoch 483/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.8233 - accuracy: 0.7384\n",
            "Epoch 483: val_accuracy did not improve from 0.71223\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.8222 - accuracy: 0.7391 - val_loss: 0.9663 - val_accuracy: 0.7081\n",
            "Epoch 484/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.7983 - accuracy: 0.7442\n",
            "Epoch 484: val_accuracy did not improve from 0.71223\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 0.7979 - accuracy: 0.7442 - val_loss: 1.0749 - val_accuracy: 0.6652\n",
            "Epoch 485/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.7641 - accuracy: 0.7579\n",
            "Epoch 485: val_accuracy did not improve from 0.71223\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7648 - accuracy: 0.7575 - val_loss: 1.0153 - val_accuracy: 0.6818\n",
            "Epoch 486/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.8469 - accuracy: 0.7238\n",
            "Epoch 486: val_accuracy did not improve from 0.71223\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8469 - accuracy: 0.7238 - val_loss: 1.0688 - val_accuracy: 0.6661\n",
            "Epoch 487/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.7633 - accuracy: 0.7554\n",
            "Epoch 487: val_accuracy did not improve from 0.71223\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7633 - accuracy: 0.7554 - val_loss: 0.9597 - val_accuracy: 0.6997\n",
            "Epoch 488/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.7791 - accuracy: 0.7494\n",
            "Epoch 488: val_accuracy did not improve from 0.71223\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7786 - accuracy: 0.7497 - val_loss: 1.0687 - val_accuracy: 0.6783\n",
            "Epoch 489/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.7864 - accuracy: 0.7504\n",
            "Epoch 489: val_accuracy did not improve from 0.71223\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.7861 - accuracy: 0.7505 - val_loss: 1.0309 - val_accuracy: 0.6799\n",
            "Epoch 490/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.8213 - accuracy: 0.7376\n",
            "Epoch 490: val_accuracy did not improve from 0.71223\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.8213 - accuracy: 0.7376 - val_loss: 0.9739 - val_accuracy: 0.7055\n",
            "Epoch 491/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.7700 - accuracy: 0.7511\n",
            "Epoch 491: val_accuracy did not improve from 0.71223\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 0.7698 - accuracy: 0.7513 - val_loss: 0.9491 - val_accuracy: 0.7045\n",
            "Epoch 492/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.7673 - accuracy: 0.7570\n",
            "Epoch 492: val_accuracy did not improve from 0.71223\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.7673 - accuracy: 0.7571 - val_loss: 1.1551 - val_accuracy: 0.6348\n",
            "Epoch 493/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.8164 - accuracy: 0.7357\n",
            "Epoch 493: val_accuracy did not improve from 0.71223\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.8148 - accuracy: 0.7364 - val_loss: 1.1696 - val_accuracy: 0.6450\n",
            "Epoch 494/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 0.7457 - accuracy: 0.7627\n",
            "Epoch 494: val_accuracy did not improve from 0.71223\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7465 - accuracy: 0.7625 - val_loss: 1.0073 - val_accuracy: 0.6847\n",
            "Epoch 495/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.7375 - accuracy: 0.7656\n",
            "Epoch 495: val_accuracy did not improve from 0.71223\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7357 - accuracy: 0.7665 - val_loss: 0.9931 - val_accuracy: 0.7010\n",
            "Epoch 496/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.7403 - accuracy: 0.7613\n",
            "Epoch 496: val_accuracy did not improve from 0.71223\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.7403 - accuracy: 0.7613 - val_loss: 1.0838 - val_accuracy: 0.6681\n",
            "Epoch 497/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.9411 - accuracy: 0.7054\n",
            "Epoch 497: val_accuracy did not improve from 0.71223\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.9472 - accuracy: 0.7043 - val_loss: 1.2092 - val_accuracy: 0.6303\n",
            "Epoch 498/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.8580 - accuracy: 0.7273\n",
            "Epoch 498: val_accuracy did not improve from 0.71223\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 0.8565 - accuracy: 0.7274 - val_loss: 1.0475 - val_accuracy: 0.6828\n",
            "Epoch 499/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.7185 - accuracy: 0.7733\n",
            "Epoch 499: val_accuracy did not improve from 0.71223\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.7185 - accuracy: 0.7733 - val_loss: 0.9521 - val_accuracy: 0.7077\n",
            "Epoch 500/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.7533 - accuracy: 0.7610\n",
            "Epoch 500: val_accuracy did not improve from 0.71223\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7556 - accuracy: 0.7601 - val_loss: 1.2252 - val_accuracy: 0.6431\n",
            "Epoch 501/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.7728 - accuracy: 0.7500\n",
            "Epoch 501: val_accuracy improved from 0.71223 to 0.71831, saving model to /content/asl/Adam/cp-501-0.72.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7722 - accuracy: 0.7503 - val_loss: 0.9092 - val_accuracy: 0.7183\n",
            "Epoch 502/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 0.7583 - accuracy: 0.7551\n",
            "Epoch 502: val_accuracy did not improve from 0.71831\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7565 - accuracy: 0.7560 - val_loss: 0.9673 - val_accuracy: 0.7042\n",
            "Epoch 503/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.7131 - accuracy: 0.7716\n",
            "Epoch 503: val_accuracy did not improve from 0.71831\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7163 - accuracy: 0.7707 - val_loss: 1.0427 - val_accuracy: 0.6825\n",
            "Epoch 504/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.7484 - accuracy: 0.7587\n",
            "Epoch 504: val_accuracy did not improve from 0.71831\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7486 - accuracy: 0.7586 - val_loss: 1.0028 - val_accuracy: 0.6921\n",
            "Epoch 505/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.7435 - accuracy: 0.7618\n",
            "Epoch 505: val_accuracy did not improve from 0.71831\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.7427 - accuracy: 0.7618 - val_loss: 1.0330 - val_accuracy: 0.6892\n",
            "Epoch 506/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.7436 - accuracy: 0.7659\n",
            "Epoch 506: val_accuracy did not improve from 0.71831\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 0.7435 - accuracy: 0.7654 - val_loss: 1.2623 - val_accuracy: 0.6338\n",
            "Epoch 507/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.8165 - accuracy: 0.7370\n",
            "Epoch 507: val_accuracy did not improve from 0.71831\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.8152 - accuracy: 0.7372 - val_loss: 0.9634 - val_accuracy: 0.7039\n",
            "Epoch 508/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.8634 - accuracy: 0.7257\n",
            "Epoch 508: val_accuracy did not improve from 0.71831\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8634 - accuracy: 0.7257 - val_loss: 1.0558 - val_accuracy: 0.6757\n",
            "Epoch 509/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.7354 - accuracy: 0.7630\n",
            "Epoch 509: val_accuracy did not improve from 0.71831\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7348 - accuracy: 0.7630 - val_loss: 0.9904 - val_accuracy: 0.7045\n",
            "Epoch 510/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.7037 - accuracy: 0.7759\n",
            "Epoch 510: val_accuracy did not improve from 0.71831\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7029 - accuracy: 0.7763 - val_loss: 1.0510 - val_accuracy: 0.6780\n",
            "Epoch 511/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.7743 - accuracy: 0.7510\n",
            "Epoch 511: val_accuracy did not improve from 0.71831\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7743 - accuracy: 0.7509 - val_loss: 1.0901 - val_accuracy: 0.6649\n",
            "Epoch 512/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.7713 - accuracy: 0.7507\n",
            "Epoch 512: val_accuracy did not improve from 0.71831\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.7712 - accuracy: 0.7508 - val_loss: 2.8901 - val_accuracy: 0.4097\n",
            "Epoch 513/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.8745 - accuracy: 0.7303\n",
            "Epoch 513: val_accuracy did not improve from 0.71831\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 0.8747 - accuracy: 0.7300 - val_loss: 0.9575 - val_accuracy: 0.7081\n",
            "Epoch 514/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.8031 - accuracy: 0.7430\n",
            "Epoch 514: val_accuracy did not improve from 0.71831\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.8031 - accuracy: 0.7430 - val_loss: 1.0535 - val_accuracy: 0.6764\n",
            "Epoch 515/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.7592 - accuracy: 0.7545\n",
            "Epoch 515: val_accuracy did not improve from 0.71831\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7576 - accuracy: 0.7549 - val_loss: 1.0481 - val_accuracy: 0.6818\n",
            "Epoch 516/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 0.7931 - accuracy: 0.7471\n",
            "Epoch 516: val_accuracy did not improve from 0.71831\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7921 - accuracy: 0.7474 - val_loss: 1.2612 - val_accuracy: 0.6156\n",
            "Epoch 517/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.7249 - accuracy: 0.7689\n",
            "Epoch 517: val_accuracy did not improve from 0.71831\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7229 - accuracy: 0.7694 - val_loss: 1.0248 - val_accuracy: 0.6930\n",
            "Epoch 518/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.7058 - accuracy: 0.7724\n",
            "Epoch 518: val_accuracy improved from 0.71831 to 0.72119, saving model to /content/asl/Adam/cp-518-0.72.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7064 - accuracy: 0.7722 - val_loss: 0.9260 - val_accuracy: 0.7212\n",
            "Epoch 519/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.6902 - accuracy: 0.7825\n",
            "Epoch 519: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6901 - accuracy: 0.7825 - val_loss: 0.9740 - val_accuracy: 0.7081\n",
            "Epoch 520/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.8115 - accuracy: 0.7393\n",
            "Epoch 520: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 0.8117 - accuracy: 0.7391 - val_loss: 1.0276 - val_accuracy: 0.6921\n",
            "Epoch 521/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 0.8136 - accuracy: 0.7376\n",
            "Epoch 521: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.8211 - accuracy: 0.7354 - val_loss: 1.1026 - val_accuracy: 0.6617\n",
            "Epoch 522/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.7286 - accuracy: 0.7656\n",
            "Epoch 522: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7287 - accuracy: 0.7659 - val_loss: 1.1003 - val_accuracy: 0.6581\n",
            "Epoch 523/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.7225 - accuracy: 0.7683\n",
            "Epoch 523: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7223 - accuracy: 0.7683 - val_loss: 1.2489 - val_accuracy: 0.6447\n",
            "Epoch 524/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.8118 - accuracy: 0.7387\n",
            "Epoch 524: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.8118 - accuracy: 0.7387 - val_loss: 1.2395 - val_accuracy: 0.6402\n",
            "Epoch 525/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.7470 - accuracy: 0.7626\n",
            "Epoch 525: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7470 - accuracy: 0.7626 - val_loss: 0.9678 - val_accuracy: 0.7023\n",
            "Epoch 526/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.6776 - accuracy: 0.7828\n",
            "Epoch 526: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6768 - accuracy: 0.7831 - val_loss: 1.0268 - val_accuracy: 0.6793\n",
            "Epoch 527/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.7225 - accuracy: 0.7674\n",
            "Epoch 527: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 0.7225 - accuracy: 0.7674 - val_loss: 1.0542 - val_accuracy: 0.6821\n",
            "Epoch 528/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 0.7232 - accuracy: 0.7701\n",
            "Epoch 528: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 0.7244 - accuracy: 0.7690 - val_loss: 0.9688 - val_accuracy: 0.7093\n",
            "Epoch 529/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.7181 - accuracy: 0.7730\n",
            "Epoch 529: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7177 - accuracy: 0.7729 - val_loss: 0.9666 - val_accuracy: 0.6962\n",
            "Epoch 530/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.8359 - accuracy: 0.7358\n",
            "Epoch 530: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8335 - accuracy: 0.7364 - val_loss: 0.9933 - val_accuracy: 0.6933\n",
            "Epoch 531/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 0.7521 - accuracy: 0.7587\n",
            "Epoch 531: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7499 - accuracy: 0.7594 - val_loss: 0.9916 - val_accuracy: 0.6981\n",
            "Epoch 532/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.8524 - accuracy: 0.7349\n",
            "Epoch 532: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8497 - accuracy: 0.7361 - val_loss: 1.0161 - val_accuracy: 0.6873\n",
            "Epoch 533/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 0.7097 - accuracy: 0.7722\n",
            "Epoch 533: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7076 - accuracy: 0.7724 - val_loss: 0.9607 - val_accuracy: 0.7039\n",
            "Epoch 534/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.7308 - accuracy: 0.7663\n",
            "Epoch 534: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.7317 - accuracy: 0.7662 - val_loss: 1.1290 - val_accuracy: 0.6617\n",
            "Epoch 535/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.7146 - accuracy: 0.7674\n",
            "Epoch 535: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 13ms/step - loss: 0.7149 - accuracy: 0.7674 - val_loss: 0.9221 - val_accuracy: 0.7196\n",
            "Epoch 536/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 0.7065 - accuracy: 0.7724\n",
            "Epoch 536: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.7087 - accuracy: 0.7724 - val_loss: 1.0738 - val_accuracy: 0.6815\n",
            "Epoch 537/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.8130 - accuracy: 0.7443\n",
            "Epoch 537: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8130 - accuracy: 0.7443 - val_loss: 1.0150 - val_accuracy: 0.6895\n",
            "Epoch 538/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.6836 - accuracy: 0.7796\n",
            "Epoch 538: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6839 - accuracy: 0.7795 - val_loss: 0.9855 - val_accuracy: 0.6994\n",
            "Epoch 539/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.7196 - accuracy: 0.7692\n",
            "Epoch 539: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7199 - accuracy: 0.7691 - val_loss: 1.1389 - val_accuracy: 0.6665\n",
            "Epoch 540/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.7617 - accuracy: 0.7556\n",
            "Epoch 540: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.7607 - accuracy: 0.7558 - val_loss: 1.1601 - val_accuracy: 0.6556\n",
            "Epoch 541/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.8399 - accuracy: 0.7258\n",
            "Epoch 541: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.8396 - accuracy: 0.7258 - val_loss: 1.2658 - val_accuracy: 0.6216\n",
            "Epoch 542/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.7441 - accuracy: 0.7591\n",
            "Epoch 542: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 0.7443 - accuracy: 0.7591 - val_loss: 0.9832 - val_accuracy: 0.7036\n",
            "Epoch 543/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.7015 - accuracy: 0.7724\n",
            "Epoch 543: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.7032 - accuracy: 0.7719 - val_loss: 1.1316 - val_accuracy: 0.6668\n",
            "Epoch 544/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.7229 - accuracy: 0.7669\n",
            "Epoch 544: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7220 - accuracy: 0.7672 - val_loss: 0.9758 - val_accuracy: 0.7026\n",
            "Epoch 545/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 0.6787 - accuracy: 0.7829\n",
            "Epoch 545: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6770 - accuracy: 0.7831 - val_loss: 0.9872 - val_accuracy: 0.6949\n",
            "Epoch 546/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 0.7960 - accuracy: 0.7409\n",
            "Epoch 546: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7943 - accuracy: 0.7412 - val_loss: 1.0964 - val_accuracy: 0.6668\n",
            "Epoch 547/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.7133 - accuracy: 0.7680\n",
            "Epoch 547: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7132 - accuracy: 0.7681 - val_loss: 1.2931 - val_accuracy: 0.6175\n",
            "Epoch 548/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.7015 - accuracy: 0.7745\n",
            "Epoch 548: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7011 - accuracy: 0.7746 - val_loss: 0.9239 - val_accuracy: 0.7173\n",
            "Epoch 549/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.7396 - accuracy: 0.7631\n",
            "Epoch 549: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 0.7378 - accuracy: 0.7634 - val_loss: 0.9856 - val_accuracy: 0.7023\n",
            "Epoch 550/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.8460 - accuracy: 0.7310\n",
            "Epoch 550: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.8460 - accuracy: 0.7310 - val_loss: 1.1136 - val_accuracy: 0.6617\n",
            "Epoch 551/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.6903 - accuracy: 0.7785\n",
            "Epoch 551: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.6890 - accuracy: 0.7790 - val_loss: 0.9420 - val_accuracy: 0.7183\n",
            "Epoch 552/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.7104 - accuracy: 0.7709\n",
            "Epoch 552: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7099 - accuracy: 0.7710 - val_loss: 0.9438 - val_accuracy: 0.7145\n",
            "Epoch 553/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 0.6886 - accuracy: 0.7812\n",
            "Epoch 553: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6893 - accuracy: 0.7809 - val_loss: 1.0148 - val_accuracy: 0.6956\n",
            "Epoch 554/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.6796 - accuracy: 0.7786\n",
            "Epoch 554: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6795 - accuracy: 0.7786 - val_loss: 0.9542 - val_accuracy: 0.7157\n",
            "Epoch 555/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.7367 - accuracy: 0.7646\n",
            "Epoch 555: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7361 - accuracy: 0.7649 - val_loss: 0.9483 - val_accuracy: 0.7183\n",
            "Epoch 556/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.8048 - accuracy: 0.7441\n",
            "Epoch 556: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 0.8044 - accuracy: 0.7442 - val_loss: 1.1340 - val_accuracy: 0.6511\n",
            "Epoch 557/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.7159 - accuracy: 0.7689\n",
            "Epoch 557: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 0.7152 - accuracy: 0.7692 - val_loss: 1.1678 - val_accuracy: 0.6469\n",
            "Epoch 558/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.6734 - accuracy: 0.7849\n",
            "Epoch 558: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6732 - accuracy: 0.7849 - val_loss: 1.1941 - val_accuracy: 0.6392\n",
            "Epoch 559/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 0.7578 - accuracy: 0.7581\n",
            "Epoch 559: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7543 - accuracy: 0.7590 - val_loss: 1.2052 - val_accuracy: 0.6482\n",
            "Epoch 560/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.6576 - accuracy: 0.7884\n",
            "Epoch 560: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6603 - accuracy: 0.7878 - val_loss: 1.0954 - val_accuracy: 0.6713\n",
            "Epoch 561/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.7319 - accuracy: 0.7674\n",
            "Epoch 561: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7320 - accuracy: 0.7674 - val_loss: 1.5672 - val_accuracy: 0.5707\n",
            "Epoch 562/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.7601 - accuracy: 0.7565\n",
            "Epoch 562: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7617 - accuracy: 0.7562 - val_loss: 1.2306 - val_accuracy: 0.6428\n",
            "Epoch 563/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.7029 - accuracy: 0.7725\n",
            "Epoch 563: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.7062 - accuracy: 0.7716 - val_loss: 1.0495 - val_accuracy: 0.6917\n",
            "Epoch 564/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.6873 - accuracy: 0.7791\n",
            "Epoch 564: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 13ms/step - loss: 0.6877 - accuracy: 0.7787 - val_loss: 0.9735 - val_accuracy: 0.7103\n",
            "Epoch 565/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.6960 - accuracy: 0.7728\n",
            "Epoch 565: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.6960 - accuracy: 0.7727 - val_loss: 0.9369 - val_accuracy: 0.7186\n",
            "Epoch 566/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.7287 - accuracy: 0.7640\n",
            "Epoch 566: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7300 - accuracy: 0.7635 - val_loss: 1.0378 - val_accuracy: 0.6847\n",
            "Epoch 567/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.6610 - accuracy: 0.7874\n",
            "Epoch 567: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6597 - accuracy: 0.7872 - val_loss: 0.9679 - val_accuracy: 0.7116\n",
            "Epoch 568/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 0.6909 - accuracy: 0.7798\n",
            "Epoch 568: val_accuracy did not improve from 0.72119\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6929 - accuracy: 0.7788 - val_loss: 1.1200 - val_accuracy: 0.6655\n",
            "Epoch 569/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.6875 - accuracy: 0.7779\n",
            "Epoch 569: val_accuracy improved from 0.72119 to 0.72343, saving model to /content/asl/Adam/cp-569-0.72.hdf5\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.6859 - accuracy: 0.7785 - val_loss: 0.9127 - val_accuracy: 0.7234\n",
            "Epoch 570/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 0.7424 - accuracy: 0.7601\n",
            "Epoch 570: val_accuracy did not improve from 0.72343\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7408 - accuracy: 0.7602 - val_loss: 1.1889 - val_accuracy: 0.6540\n",
            "Epoch 571/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.7132 - accuracy: 0.7681\n",
            "Epoch 571: val_accuracy did not improve from 0.72343\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 0.7140 - accuracy: 0.7678 - val_loss: 0.9338 - val_accuracy: 0.7180\n",
            "Epoch 572/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.6705 - accuracy: 0.7810\n",
            "Epoch 572: val_accuracy did not improve from 0.72343\n",
            "196/196 [==============================] - 2s 13ms/step - loss: 0.6711 - accuracy: 0.7810 - val_loss: 0.9444 - val_accuracy: 0.7109\n",
            "Epoch 573/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.7445 - accuracy: 0.7586\n",
            "Epoch 573: val_accuracy improved from 0.72343 to 0.72951, saving model to /content/asl/Adam/cp-573-0.73.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7445 - accuracy: 0.7586 - val_loss: 0.9275 - val_accuracy: 0.7295\n",
            "Epoch 574/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 0.7757 - accuracy: 0.7536\n",
            "Epoch 574: val_accuracy did not improve from 0.72951\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7823 - accuracy: 0.7516 - val_loss: 1.1286 - val_accuracy: 0.6725\n",
            "Epoch 575/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.6889 - accuracy: 0.7762\n",
            "Epoch 575: val_accuracy did not improve from 0.72951\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6881 - accuracy: 0.7763 - val_loss: 0.9558 - val_accuracy: 0.7093\n",
            "Epoch 576/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.6478 - accuracy: 0.7903\n",
            "Epoch 576: val_accuracy did not improve from 0.72951\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6473 - accuracy: 0.7905 - val_loss: 0.9712 - val_accuracy: 0.7154\n",
            "Epoch 577/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.6571 - accuracy: 0.7870\n",
            "Epoch 577: val_accuracy did not improve from 0.72951\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6567 - accuracy: 0.7867 - val_loss: 1.1879 - val_accuracy: 0.6415\n",
            "Epoch 578/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.7193 - accuracy: 0.7722\n",
            "Epoch 578: val_accuracy did not improve from 0.72951\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.7181 - accuracy: 0.7727 - val_loss: 1.0467 - val_accuracy: 0.6834\n",
            "Epoch 579/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.6684 - accuracy: 0.7795\n",
            "Epoch 579: val_accuracy improved from 0.72951 to 0.73367, saving model to /content/asl/Adam/cp-579-0.73.hdf5\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 0.6680 - accuracy: 0.7798 - val_loss: 0.9003 - val_accuracy: 0.7337\n",
            "Epoch 580/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.7249 - accuracy: 0.7648\n",
            "Epoch 580: val_accuracy did not improve from 0.73367\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7258 - accuracy: 0.7644 - val_loss: 1.0877 - val_accuracy: 0.6677\n",
            "Epoch 581/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.7015 - accuracy: 0.7740\n",
            "Epoch 581: val_accuracy did not improve from 0.73367\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.7035 - accuracy: 0.7734 - val_loss: 1.0095 - val_accuracy: 0.7004\n",
            "Epoch 582/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.7261 - accuracy: 0.7623\n",
            "Epoch 582: val_accuracy did not improve from 0.73367\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7261 - accuracy: 0.7623 - val_loss: 0.9626 - val_accuracy: 0.7065\n",
            "Epoch 583/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 0.7410 - accuracy: 0.7591\n",
            "Epoch 583: val_accuracy did not improve from 0.73367\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7452 - accuracy: 0.7583 - val_loss: 1.2240 - val_accuracy: 0.6335\n",
            "Epoch 584/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.7066 - accuracy: 0.7712\n",
            "Epoch 584: val_accuracy did not improve from 0.73367\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7062 - accuracy: 0.7718 - val_loss: 0.9947 - val_accuracy: 0.7065\n",
            "Epoch 585/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.6553 - accuracy: 0.7871\n",
            "Epoch 585: val_accuracy did not improve from 0.73367\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.6553 - accuracy: 0.7871 - val_loss: 1.2885 - val_accuracy: 0.6188\n",
            "Epoch 586/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.9058 - accuracy: 0.7198\n",
            "Epoch 586: val_accuracy did not improve from 0.73367\n",
            "196/196 [==============================] - 2s 13ms/step - loss: 0.9041 - accuracy: 0.7202 - val_loss: 1.0962 - val_accuracy: 0.6738\n",
            "Epoch 587/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.6761 - accuracy: 0.7815\n",
            "Epoch 587: val_accuracy did not improve from 0.73367\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6781 - accuracy: 0.7807 - val_loss: 0.9385 - val_accuracy: 0.7222\n",
            "Epoch 588/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.6572 - accuracy: 0.7931\n",
            "Epoch 588: val_accuracy did not improve from 0.73367\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6573 - accuracy: 0.7930 - val_loss: 0.9411 - val_accuracy: 0.7334\n",
            "Epoch 589/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.6649 - accuracy: 0.7896\n",
            "Epoch 589: val_accuracy did not improve from 0.73367\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6646 - accuracy: 0.7896 - val_loss: 1.0691 - val_accuracy: 0.6745\n",
            "Epoch 590/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.6311 - accuracy: 0.7958\n",
            "Epoch 590: val_accuracy did not improve from 0.73367\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6329 - accuracy: 0.7951 - val_loss: 0.9786 - val_accuracy: 0.7154\n",
            "Epoch 591/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 0.6750 - accuracy: 0.7835\n",
            "Epoch 591: val_accuracy did not improve from 0.73367\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6794 - accuracy: 0.7823 - val_loss: 1.1802 - val_accuracy: 0.6482\n",
            "Epoch 592/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.6816 - accuracy: 0.7770\n",
            "Epoch 592: val_accuracy did not improve from 0.73367\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.6801 - accuracy: 0.7774 - val_loss: 1.7307 - val_accuracy: 0.5343\n",
            "Epoch 593/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.7289 - accuracy: 0.7601\n",
            "Epoch 593: val_accuracy did not improve from 0.73367\n",
            "196/196 [==============================] - 2s 13ms/step - loss: 0.7291 - accuracy: 0.7598 - val_loss: 1.0725 - val_accuracy: 0.6729\n",
            "Epoch 594/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.6594 - accuracy: 0.7880\n",
            "Epoch 594: val_accuracy did not improve from 0.73367\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.6594 - accuracy: 0.7880 - val_loss: 0.9060 - val_accuracy: 0.7244\n",
            "Epoch 595/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.6913 - accuracy: 0.7736\n",
            "Epoch 595: val_accuracy did not improve from 0.73367\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6920 - accuracy: 0.7733 - val_loss: 1.1033 - val_accuracy: 0.6697\n",
            "Epoch 596/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.7562 - accuracy: 0.7576\n",
            "Epoch 596: val_accuracy did not improve from 0.73367\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7562 - accuracy: 0.7576 - val_loss: 0.9653 - val_accuracy: 0.7004\n",
            "Epoch 597/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.6851 - accuracy: 0.7752\n",
            "Epoch 597: val_accuracy did not improve from 0.73367\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6853 - accuracy: 0.7751 - val_loss: 0.9225 - val_accuracy: 0.7244\n",
            "Epoch 598/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.6838 - accuracy: 0.7774\n",
            "Epoch 598: val_accuracy did not improve from 0.73367\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6838 - accuracy: 0.7774 - val_loss: 1.0185 - val_accuracy: 0.6937\n",
            "Epoch 599/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.7027 - accuracy: 0.7732\n",
            "Epoch 599: val_accuracy did not improve from 0.73367\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7027 - accuracy: 0.7732 - val_loss: 0.9736 - val_accuracy: 0.7151\n",
            "Epoch 600/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.6433 - accuracy: 0.7916\n",
            "Epoch 600: val_accuracy did not improve from 0.73367\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 0.6433 - accuracy: 0.7917 - val_loss: 0.9362 - val_accuracy: 0.7231\n",
            "Epoch 601/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.6026 - accuracy: 0.8062\n",
            "Epoch 601: val_accuracy did not improve from 0.73367\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 0.6041 - accuracy: 0.8052 - val_loss: 0.9302 - val_accuracy: 0.7199\n",
            "Epoch 602/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.7040 - accuracy: 0.7680\n",
            "Epoch 602: val_accuracy did not improve from 0.73367\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7040 - accuracy: 0.7680 - val_loss: 1.0549 - val_accuracy: 0.6930\n",
            "Epoch 603/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.6519 - accuracy: 0.7902\n",
            "Epoch 603: val_accuracy did not improve from 0.73367\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6520 - accuracy: 0.7899 - val_loss: 1.2127 - val_accuracy: 0.6399\n",
            "Epoch 604/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 0.6805 - accuracy: 0.7816\n",
            "Epoch 604: val_accuracy did not improve from 0.73367\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6787 - accuracy: 0.7819 - val_loss: 1.0270 - val_accuracy: 0.6953\n",
            "Epoch 605/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 0.7600 - accuracy: 0.7534\n",
            "Epoch 605: val_accuracy did not improve from 0.73367\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7594 - accuracy: 0.7542 - val_loss: 1.1661 - val_accuracy: 0.6687\n",
            "Epoch 606/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.6732 - accuracy: 0.7841\n",
            "Epoch 606: val_accuracy did not improve from 0.73367\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6732 - accuracy: 0.7841 - val_loss: 0.9792 - val_accuracy: 0.7023\n",
            "Epoch 607/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.7072 - accuracy: 0.7646\n",
            "Epoch 607: val_accuracy did not improve from 0.73367\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.7087 - accuracy: 0.7641 - val_loss: 1.0535 - val_accuracy: 0.6917\n",
            "Epoch 608/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.7608 - accuracy: 0.7573\n",
            "Epoch 608: val_accuracy did not improve from 0.73367\n",
            "196/196 [==============================] - 2s 13ms/step - loss: 0.7612 - accuracy: 0.7573 - val_loss: 1.0476 - val_accuracy: 0.6863\n",
            "Epoch 609/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 0.6384 - accuracy: 0.7950\n",
            "Epoch 609: val_accuracy improved from 0.73367 to 0.73496, saving model to /content/asl/Adam/cp-609-0.73.hdf5\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.6373 - accuracy: 0.7951 - val_loss: 0.9155 - val_accuracy: 0.7350\n",
            "Epoch 610/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.6220 - accuracy: 0.8000\n",
            "Epoch 610: val_accuracy did not improve from 0.73496\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6215 - accuracy: 0.7999 - val_loss: 1.0648 - val_accuracy: 0.6841\n",
            "Epoch 611/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.7094 - accuracy: 0.7707\n",
            "Epoch 611: val_accuracy did not improve from 0.73496\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7110 - accuracy: 0.7697 - val_loss: 0.9976 - val_accuracy: 0.7045\n",
            "Epoch 612/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.6725 - accuracy: 0.7805\n",
            "Epoch 612: val_accuracy did not improve from 0.73496\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6726 - accuracy: 0.7806 - val_loss: 0.9716 - val_accuracy: 0.7116\n",
            "Epoch 613/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 0.6373 - accuracy: 0.7962\n",
            "Epoch 613: val_accuracy did not improve from 0.73496\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6409 - accuracy: 0.7947 - val_loss: 1.2160 - val_accuracy: 0.6501\n",
            "Epoch 614/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.6624 - accuracy: 0.7838\n",
            "Epoch 614: val_accuracy did not improve from 0.73496\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.6606 - accuracy: 0.7844 - val_loss: 1.2102 - val_accuracy: 0.6620\n",
            "Epoch 615/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.6798 - accuracy: 0.7786\n",
            "Epoch 615: val_accuracy did not improve from 0.73496\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 0.6804 - accuracy: 0.7783 - val_loss: 1.4509 - val_accuracy: 0.5871\n",
            "Epoch 616/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 0.7853 - accuracy: 0.7503\n",
            "Epoch 616: val_accuracy did not improve from 0.73496\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.7840 - accuracy: 0.7504 - val_loss: 0.9459 - val_accuracy: 0.7190\n",
            "Epoch 617/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.6598 - accuracy: 0.7835\n",
            "Epoch 617: val_accuracy did not improve from 0.73496\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6596 - accuracy: 0.7835 - val_loss: 0.9723 - val_accuracy: 0.7007\n",
            "Epoch 618/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.6939 - accuracy: 0.7766\n",
            "Epoch 618: val_accuracy did not improve from 0.73496\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6939 - accuracy: 0.7766 - val_loss: 0.9444 - val_accuracy: 0.7167\n",
            "Epoch 619/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.6633 - accuracy: 0.7875\n",
            "Epoch 619: val_accuracy did not improve from 0.73496\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6630 - accuracy: 0.7877 - val_loss: 1.1632 - val_accuracy: 0.6440\n",
            "Epoch 620/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 0.6160 - accuracy: 0.7995\n",
            "Epoch 620: val_accuracy did not improve from 0.73496\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6211 - accuracy: 0.7977 - val_loss: 0.9450 - val_accuracy: 0.7125\n",
            "Epoch 621/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.6721 - accuracy: 0.7806\n",
            "Epoch 621: val_accuracy did not improve from 0.73496\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.6721 - accuracy: 0.7806 - val_loss: 0.9467 - val_accuracy: 0.7148\n",
            "Epoch 622/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.6550 - accuracy: 0.7854\n",
            "Epoch 622: val_accuracy did not improve from 0.73496\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 0.6535 - accuracy: 0.7859 - val_loss: 0.9642 - val_accuracy: 0.7145\n",
            "Epoch 623/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.6303 - accuracy: 0.7953\n",
            "Epoch 623: val_accuracy did not improve from 0.73496\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 0.6305 - accuracy: 0.7951 - val_loss: 1.0828 - val_accuracy: 0.6789\n",
            "Epoch 624/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.6899 - accuracy: 0.7726\n",
            "Epoch 624: val_accuracy did not improve from 0.73496\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6896 - accuracy: 0.7728 - val_loss: 1.5765 - val_accuracy: 0.5515\n",
            "Epoch 625/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.7729 - accuracy: 0.7545\n",
            "Epoch 625: val_accuracy did not improve from 0.73496\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7762 - accuracy: 0.7527 - val_loss: 1.5923 - val_accuracy: 0.5883\n",
            "Epoch 626/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.6941 - accuracy: 0.7745\n",
            "Epoch 626: val_accuracy did not improve from 0.73496\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6941 - accuracy: 0.7745 - val_loss: 1.2120 - val_accuracy: 0.6450\n",
            "Epoch 627/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 0.6580 - accuracy: 0.7873\n",
            "Epoch 627: val_accuracy did not improve from 0.73496\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6587 - accuracy: 0.7867 - val_loss: 1.1157 - val_accuracy: 0.6658\n",
            "Epoch 628/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 0.6533 - accuracy: 0.7889\n",
            "Epoch 628: val_accuracy did not improve from 0.73496\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6543 - accuracy: 0.7883 - val_loss: 1.0228 - val_accuracy: 0.6956\n",
            "Epoch 629/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.6724 - accuracy: 0.7819\n",
            "Epoch 629: val_accuracy did not improve from 0.73496\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 0.6724 - accuracy: 0.7819 - val_loss: 1.2732 - val_accuracy: 0.6293\n",
            "Epoch 630/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.6977 - accuracy: 0.7712\n",
            "Epoch 630: val_accuracy did not improve from 0.73496\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 0.6975 - accuracy: 0.7712 - val_loss: 1.2211 - val_accuracy: 0.6332\n",
            "Epoch 631/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 0.6845 - accuracy: 0.7787\n",
            "Epoch 631: val_accuracy did not improve from 0.73496\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6964 - accuracy: 0.7755 - val_loss: 1.5148 - val_accuracy: 0.5787\n",
            "Epoch 632/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.6761 - accuracy: 0.7799\n",
            "Epoch 632: val_accuracy did not improve from 0.73496\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6780 - accuracy: 0.7792 - val_loss: 1.1565 - val_accuracy: 0.6597\n",
            "Epoch 633/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.6413 - accuracy: 0.7885\n",
            "Epoch 633: val_accuracy improved from 0.73496 to 0.74008, saving model to /content/asl/Adam/cp-633-0.74.hdf5\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.6420 - accuracy: 0.7884 - val_loss: 0.8849 - val_accuracy: 0.7401\n",
            "Epoch 634/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.5932 - accuracy: 0.8085\n",
            "Epoch 634: val_accuracy did not improve from 0.74008\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.5939 - accuracy: 0.8083 - val_loss: 0.9088 - val_accuracy: 0.7343\n",
            "Epoch 635/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.6335 - accuracy: 0.7939\n",
            "Epoch 635: val_accuracy did not improve from 0.74008\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6335 - accuracy: 0.7939 - val_loss: 1.2038 - val_accuracy: 0.6434\n",
            "Epoch 636/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.6298 - accuracy: 0.7953\n",
            "Epoch 636: val_accuracy did not improve from 0.74008\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.6282 - accuracy: 0.7958 - val_loss: 0.8672 - val_accuracy: 0.7401\n",
            "Epoch 637/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.7170 - accuracy: 0.7694\n",
            "Epoch 637: val_accuracy did not improve from 0.74008\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 0.7154 - accuracy: 0.7698 - val_loss: 1.0837 - val_accuracy: 0.6677\n",
            "Epoch 638/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.6722 - accuracy: 0.7776\n",
            "Epoch 638: val_accuracy did not improve from 0.74008\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6721 - accuracy: 0.7778 - val_loss: 1.0038 - val_accuracy: 0.6965\n",
            "Epoch 639/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.6529 - accuracy: 0.7848\n",
            "Epoch 639: val_accuracy did not improve from 0.74008\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6529 - accuracy: 0.7848 - val_loss: 1.1023 - val_accuracy: 0.6735\n",
            "Epoch 640/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.6498 - accuracy: 0.7871\n",
            "Epoch 640: val_accuracy did not improve from 0.74008\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6501 - accuracy: 0.7867 - val_loss: 1.1546 - val_accuracy: 0.6652\n",
            "Epoch 641/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.6562 - accuracy: 0.7826\n",
            "Epoch 641: val_accuracy did not improve from 0.74008\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6562 - accuracy: 0.7826 - val_loss: 0.8837 - val_accuracy: 0.7337\n",
            "Epoch 642/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.6131 - accuracy: 0.8036\n",
            "Epoch 642: val_accuracy did not improve from 0.74008\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6140 - accuracy: 0.8035 - val_loss: 0.9767 - val_accuracy: 0.7049\n",
            "Epoch 643/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.6762 - accuracy: 0.7791\n",
            "Epoch 643: val_accuracy did not improve from 0.74008\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.6762 - accuracy: 0.7791 - val_loss: 1.1598 - val_accuracy: 0.6508\n",
            "Epoch 644/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.6359 - accuracy: 0.7888\n",
            "Epoch 644: val_accuracy did not improve from 0.74008\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 0.6367 - accuracy: 0.7883 - val_loss: 0.9934 - val_accuracy: 0.7068\n",
            "Epoch 645/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.6457 - accuracy: 0.7914\n",
            "Epoch 645: val_accuracy did not improve from 0.74008\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.6456 - accuracy: 0.7914 - val_loss: 1.0142 - val_accuracy: 0.6959\n",
            "Epoch 646/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 0.6290 - accuracy: 0.7981\n",
            "Epoch 646: val_accuracy did not improve from 0.74008\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.6303 - accuracy: 0.7975 - val_loss: 1.0248 - val_accuracy: 0.6988\n",
            "Epoch 647/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 0.6870 - accuracy: 0.7750\n",
            "Epoch 647: val_accuracy did not improve from 0.74008\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6862 - accuracy: 0.7752 - val_loss: 1.0760 - val_accuracy: 0.6876\n",
            "Epoch 648/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.6694 - accuracy: 0.7794\n",
            "Epoch 648: val_accuracy did not improve from 0.74008\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6694 - accuracy: 0.7794 - val_loss: 1.0837 - val_accuracy: 0.6818\n",
            "Epoch 649/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.6329 - accuracy: 0.7951\n",
            "Epoch 649: val_accuracy did not improve from 0.74008\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.6327 - accuracy: 0.7953 - val_loss: 0.9023 - val_accuracy: 0.7302\n",
            "Epoch 650/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.6183 - accuracy: 0.7980\n",
            "Epoch 650: val_accuracy did not improve from 0.74008\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.6159 - accuracy: 0.7991 - val_loss: 1.0496 - val_accuracy: 0.6860\n",
            "Epoch 651/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.6514 - accuracy: 0.7876\n",
            "Epoch 651: val_accuracy did not improve from 0.74008\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 0.6488 - accuracy: 0.7886 - val_loss: 1.2835 - val_accuracy: 0.6376\n",
            "Epoch 652/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.6696 - accuracy: 0.7824\n",
            "Epoch 652: val_accuracy did not improve from 0.74008\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.6695 - accuracy: 0.7821 - val_loss: 0.9365 - val_accuracy: 0.7215\n",
            "Epoch 653/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.6436 - accuracy: 0.7899\n",
            "Epoch 653: val_accuracy did not improve from 0.74008\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6436 - accuracy: 0.7901 - val_loss: 0.9798 - val_accuracy: 0.7141\n",
            "Epoch 654/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.6185 - accuracy: 0.7979\n",
            "Epoch 654: val_accuracy improved from 0.74008 to 0.75192, saving model to /content/asl/Adam/cp-654-0.75.hdf5\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6185 - accuracy: 0.7979 - val_loss: 0.8500 - val_accuracy: 0.7519\n",
            "Epoch 655/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.7009 - accuracy: 0.7697\n",
            "Epoch 655: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.7003 - accuracy: 0.7701 - val_loss: 0.9624 - val_accuracy: 0.7084\n",
            "Epoch 656/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.6608 - accuracy: 0.7855\n",
            "Epoch 656: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6608 - accuracy: 0.7855 - val_loss: 0.9297 - val_accuracy: 0.7282\n",
            "Epoch 657/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.6439 - accuracy: 0.7889\n",
            "Epoch 657: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.6433 - accuracy: 0.7892 - val_loss: 0.8863 - val_accuracy: 0.7420\n",
            "Epoch 658/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.5716 - accuracy: 0.8138\n",
            "Epoch 658: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 0.5717 - accuracy: 0.8139 - val_loss: 0.9776 - val_accuracy: 0.7186\n",
            "Epoch 659/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.6284 - accuracy: 0.7987\n",
            "Epoch 659: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.6290 - accuracy: 0.7984 - val_loss: 1.0410 - val_accuracy: 0.6949\n",
            "Epoch 660/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.6097 - accuracy: 0.8006\n",
            "Epoch 660: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.6074 - accuracy: 0.8018 - val_loss: 1.0061 - val_accuracy: 0.6943\n",
            "Epoch 661/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.7013 - accuracy: 0.7694\n",
            "Epoch 661: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7012 - accuracy: 0.7690 - val_loss: 1.5692 - val_accuracy: 0.5720\n",
            "Epoch 662/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.6928 - accuracy: 0.7758\n",
            "Epoch 662: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6928 - accuracy: 0.7758 - val_loss: 0.9071 - val_accuracy: 0.7276\n",
            "Epoch 663/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.5698 - accuracy: 0.8151\n",
            "Epoch 663: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.5698 - accuracy: 0.8151 - val_loss: 1.0305 - val_accuracy: 0.6911\n",
            "Epoch 664/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.8313 - accuracy: 0.7370\n",
            "Epoch 664: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.8283 - accuracy: 0.7374 - val_loss: 1.0955 - val_accuracy: 0.6761\n",
            "Epoch 665/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.5880 - accuracy: 0.8130\n",
            "Epoch 665: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 3s 14ms/step - loss: 0.5876 - accuracy: 0.8131 - val_loss: 0.8873 - val_accuracy: 0.7385\n",
            "Epoch 666/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.6559 - accuracy: 0.7859\n",
            "Epoch 666: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.6559 - accuracy: 0.7859 - val_loss: 1.0291 - val_accuracy: 0.6946\n",
            "Epoch 667/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.6403 - accuracy: 0.7883\n",
            "Epoch 667: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6392 - accuracy: 0.7887 - val_loss: 0.9205 - val_accuracy: 0.7270\n",
            "Epoch 668/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.6139 - accuracy: 0.7944\n",
            "Epoch 668: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6178 - accuracy: 0.7934 - val_loss: 1.1529 - val_accuracy: 0.6751\n",
            "Epoch 669/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.6998 - accuracy: 0.7707\n",
            "Epoch 669: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.6998 - accuracy: 0.7707 - val_loss: 1.0281 - val_accuracy: 0.6853\n",
            "Epoch 670/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.6199 - accuracy: 0.7989\n",
            "Epoch 670: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6186 - accuracy: 0.7994 - val_loss: 0.8963 - val_accuracy: 0.7330\n",
            "Epoch 671/700\n",
            "194/196 [============================>.] - ETA: 0s - loss: 0.6332 - accuracy: 0.7951\n",
            "Epoch 671: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.6334 - accuracy: 0.7951 - val_loss: 1.0349 - val_accuracy: 0.6953\n",
            "Epoch 672/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.6123 - accuracy: 0.8000\n",
            "Epoch 672: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 13ms/step - loss: 0.6123 - accuracy: 0.8000 - val_loss: 1.0702 - val_accuracy: 0.6812\n",
            "Epoch 673/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.6208 - accuracy: 0.7949\n",
            "Epoch 673: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.6223 - accuracy: 0.7943 - val_loss: 0.8692 - val_accuracy: 0.7417\n",
            "Epoch 674/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.6413 - accuracy: 0.7906\n",
            "Epoch 674: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6413 - accuracy: 0.7906 - val_loss: 1.1858 - val_accuracy: 0.6552\n",
            "Epoch 675/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.7671 - accuracy: 0.7514\n",
            "Epoch 675: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7672 - accuracy: 0.7514 - val_loss: 0.9478 - val_accuracy: 0.7183\n",
            "Epoch 676/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.5732 - accuracy: 0.8132\n",
            "Epoch 676: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.5728 - accuracy: 0.8134 - val_loss: 0.9046 - val_accuracy: 0.7250\n",
            "Epoch 677/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.6115 - accuracy: 0.8019\n",
            "Epoch 677: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6115 - accuracy: 0.8019 - val_loss: 1.4147 - val_accuracy: 0.6117\n",
            "Epoch 678/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.6873 - accuracy: 0.7786\n",
            "Epoch 678: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6854 - accuracy: 0.7790 - val_loss: 1.0267 - val_accuracy: 0.7017\n",
            "Epoch 679/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 0.6947 - accuracy: 0.7741\n",
            "Epoch 679: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 13ms/step - loss: 0.6938 - accuracy: 0.7746 - val_loss: 1.0041 - val_accuracy: 0.6991\n",
            "Epoch 680/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.5948 - accuracy: 0.8032\n",
            "Epoch 680: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 12ms/step - loss: 0.5947 - accuracy: 0.8034 - val_loss: 0.9311 - val_accuracy: 0.7190\n",
            "Epoch 681/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.5765 - accuracy: 0.8159\n",
            "Epoch 681: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.5762 - accuracy: 0.8159 - val_loss: 0.9563 - val_accuracy: 0.7106\n",
            "Epoch 682/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 0.8202 - accuracy: 0.7349\n",
            "Epoch 682: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8179 - accuracy: 0.7359 - val_loss: 1.0244 - val_accuracy: 0.7007\n",
            "Epoch 683/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 0.5576 - accuracy: 0.8182\n",
            "Epoch 683: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.5562 - accuracy: 0.8184 - val_loss: 1.1566 - val_accuracy: 0.6642\n",
            "Epoch 684/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.6594 - accuracy: 0.7861\n",
            "Epoch 684: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6591 - accuracy: 0.7863 - val_loss: 0.9154 - val_accuracy: 0.7330\n",
            "Epoch 685/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.6552 - accuracy: 0.7833\n",
            "Epoch 685: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6547 - accuracy: 0.7836 - val_loss: 0.9574 - val_accuracy: 0.7244\n",
            "Epoch 686/700\n",
            "193/196 [============================>.] - ETA: 0s - loss: 0.5758 - accuracy: 0.8100\n",
            "Epoch 686: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.5754 - accuracy: 0.8097 - val_loss: 0.8915 - val_accuracy: 0.7388\n",
            "Epoch 687/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.5540 - accuracy: 0.8166\n",
            "Epoch 687: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 0.5540 - accuracy: 0.8166 - val_loss: 0.8569 - val_accuracy: 0.7452\n",
            "Epoch 688/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.5981 - accuracy: 0.8031\n",
            "Epoch 688: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.5981 - accuracy: 0.8031 - val_loss: 0.9771 - val_accuracy: 0.7100\n",
            "Epoch 689/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 0.8421 - accuracy: 0.7281\n",
            "Epoch 689: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.8357 - accuracy: 0.7304 - val_loss: 0.9555 - val_accuracy: 0.7135\n",
            "Epoch 690/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 0.5622 - accuracy: 0.8127\n",
            "Epoch 690: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.5621 - accuracy: 0.8132 - val_loss: 0.8912 - val_accuracy: 0.7401\n",
            "Epoch 691/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 0.5819 - accuracy: 0.8115\n",
            "Epoch 691: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.5846 - accuracy: 0.8100 - val_loss: 1.5587 - val_accuracy: 0.5880\n",
            "Epoch 692/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.6545 - accuracy: 0.7873\n",
            "Epoch 692: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.6534 - accuracy: 0.7872 - val_loss: 0.8833 - val_accuracy: 0.7372\n",
            "Epoch 693/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.5400 - accuracy: 0.8272\n",
            "Epoch 693: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.5398 - accuracy: 0.8271 - val_loss: 0.9084 - val_accuracy: 0.7385\n",
            "Epoch 694/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.7494 - accuracy: 0.7603\n",
            "Epoch 694: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 3s 13ms/step - loss: 0.7494 - accuracy: 0.7602 - val_loss: 1.2952 - val_accuracy: 0.6239\n",
            "Epoch 695/700\n",
            "190/196 [============================>.] - ETA: 0s - loss: 0.6085 - accuracy: 0.8003\n",
            "Epoch 695: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.6090 - accuracy: 0.8002 - val_loss: 1.4832 - val_accuracy: 0.5980\n",
            "Epoch 696/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.6752 - accuracy: 0.7767\n",
            "Epoch 696: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.6752 - accuracy: 0.7767 - val_loss: 1.1211 - val_accuracy: 0.6748\n",
            "Epoch 697/700\n",
            "195/196 [============================>.] - ETA: 0s - loss: 0.6056 - accuracy: 0.8000\n",
            "Epoch 697: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.6056 - accuracy: 0.8000 - val_loss: 0.9385 - val_accuracy: 0.7206\n",
            "Epoch 698/700\n",
            "191/196 [============================>.] - ETA: 0s - loss: 0.6052 - accuracy: 0.8017\n",
            "Epoch 698: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.6034 - accuracy: 0.8019 - val_loss: 0.9504 - val_accuracy: 0.7122\n",
            "Epoch 699/700\n",
            "192/196 [============================>.] - ETA: 0s - loss: 0.6502 - accuracy: 0.7922\n",
            "Epoch 699: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.6478 - accuracy: 0.7929 - val_loss: 1.1874 - val_accuracy: 0.6536\n",
            "Epoch 700/700\n",
            "196/196 [==============================] - ETA: 0s - loss: 0.6963 - accuracy: 0.7718\n",
            "Epoch 700: val_accuracy did not improve from 0.75192\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.6963 - accuracy: 0.7718 - val_loss: 1.2413 - val_accuracy: 0.6527\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3JznEKq729GG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make another model"
      ],
      "metadata": {
        "id": "kvwTgo3P3ogp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 174\n",
        "\n",
        "model = Sequential()\n",
        "model.add(GRU(256, return_sequences=True, input_shape=(1, 543)))\n",
        "model.add(GRU(128, return_sequences=True))\n",
        "model.add(GRU(64, return_sequences=True))\n",
        "model.add(GRU(32, return_sequences=True))\n",
        "model.add(GRU(16))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bo7e-KvW1zJC",
        "outputId": "15cbc2af-d671-4866-de01-04e95a1ab09e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_3 (GRU)                 (None, 1, 256)            615168    \n",
            "                                                                 \n",
            " gru_4 (GRU)                 (None, 1, 128)            148224    \n",
            "                                                                 \n",
            " gru_5 (GRU)                 (None, 1, 64)             37248     \n",
            "                                                                 \n",
            " gru_6 (GRU)                 (None, 1, 32)             9408      \n",
            "                                                                 \n",
            " gru_7 (GRU)                 (None, 16)                2400      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               8704      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 174)               44718     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 997198 (3.80 MB)\n",
            "Trainable params: 997198 (3.80 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath       = \"/content/asl/Adam2/cp-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint     = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history2 = model.fit(X_train, y_train_encoded, validation_data=(X_test, y_test_encoded), epochs=700, batch_size=32,callbacks=callbacks_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yj_vA9J714kS",
        "outputId": "72c533a9-0ebc-4a42-a75e-004c39fdd614"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 5.1284 - accuracy: 0.0122\n",
            "Epoch 1: val_accuracy improved from -inf to 0.01184, saving model to /content/asl/Adam2/cp-01-0.01.hdf5\n",
            "391/391 [==============================] - 14s 15ms/step - loss: 5.1284 - accuracy: 0.0122 - val_loss: 5.1068 - val_accuracy: 0.0118\n",
            "Epoch 2/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 5.1055 - accuracy: 0.0144\n",
            "Epoch 2: val_accuracy improved from 0.01184 to 0.01280, saving model to /content/asl/Adam2/cp-02-0.01.hdf5\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 5.1055 - accuracy: 0.0144 - val_loss: 5.0980 - val_accuracy: 0.0128\n",
            "Epoch 3/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 5.1017 - accuracy: 0.0124\n",
            "Epoch 3: val_accuracy did not improve from 0.01280\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 5.1017 - accuracy: 0.0125 - val_loss: 5.0964 - val_accuracy: 0.0115\n",
            "Epoch 4/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 5.0997 - accuracy: 0.0136\n",
            "Epoch 4: val_accuracy did not improve from 0.01280\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 5.0997 - accuracy: 0.0136 - val_loss: 5.0947 - val_accuracy: 0.0115\n",
            "Epoch 5/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 5.0990 - accuracy: 0.0130\n",
            "Epoch 5: val_accuracy did not improve from 0.01280\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 5.0990 - accuracy: 0.0131 - val_loss: 5.0941 - val_accuracy: 0.0115\n",
            "Epoch 6/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 5.0971 - accuracy: 0.0137\n",
            "Epoch 6: val_accuracy improved from 0.01280 to 0.01633, saving model to /content/asl/Adam2/cp-06-0.02.hdf5\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 5.0972 - accuracy: 0.0136 - val_loss: 5.0931 - val_accuracy: 0.0163\n",
            "Epoch 7/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 5.0958 - accuracy: 0.0145\n",
            "Epoch 7: val_accuracy did not improve from 0.01633\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 5.0958 - accuracy: 0.0145 - val_loss: 5.0922 - val_accuracy: 0.0160\n",
            "Epoch 8/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 5.0947 - accuracy: 0.0135\n",
            "Epoch 8: val_accuracy did not improve from 0.01633\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 5.0949 - accuracy: 0.0134 - val_loss: 5.0912 - val_accuracy: 0.0134\n",
            "Epoch 9/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 5.0940 - accuracy: 0.0143\n",
            "Epoch 9: val_accuracy did not improve from 0.01633\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 5.0940 - accuracy: 0.0144 - val_loss: 5.0902 - val_accuracy: 0.0125\n",
            "Epoch 10/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 5.0929 - accuracy: 0.0142\n",
            "Epoch 10: val_accuracy did not improve from 0.01633\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 5.0927 - accuracy: 0.0142 - val_loss: 5.0906 - val_accuracy: 0.0147\n",
            "Epoch 11/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 5.0931 - accuracy: 0.0131\n",
            "Epoch 11: val_accuracy did not improve from 0.01633\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 5.0932 - accuracy: 0.0131 - val_loss: 5.0907 - val_accuracy: 0.0125\n",
            "Epoch 12/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 5.0925 - accuracy: 0.0137\n",
            "Epoch 12: val_accuracy did not improve from 0.01633\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 5.0929 - accuracy: 0.0137 - val_loss: 5.0908 - val_accuracy: 0.0122\n",
            "Epoch 13/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 5.0928 - accuracy: 0.0135\n",
            "Epoch 13: val_accuracy did not improve from 0.01633\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 5.0928 - accuracy: 0.0135 - val_loss: 5.0910 - val_accuracy: 0.0122\n",
            "Epoch 14/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 5.0928 - accuracy: 0.0135\n",
            "Epoch 14: val_accuracy did not improve from 0.01633\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 5.0927 - accuracy: 0.0134 - val_loss: 5.0908 - val_accuracy: 0.0122\n",
            "Epoch 15/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 5.0923 - accuracy: 0.0141\n",
            "Epoch 15: val_accuracy did not improve from 0.01633\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 5.0924 - accuracy: 0.0140 - val_loss: 5.0896 - val_accuracy: 0.0122\n",
            "Epoch 16/700\n",
            "385/391 [============================>.] - ETA: 0s - loss: 5.0923 - accuracy: 0.0147\n",
            "Epoch 16: val_accuracy did not improve from 0.01633\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 5.0922 - accuracy: 0.0147 - val_loss: 5.0917 - val_accuracy: 0.0122\n",
            "Epoch 17/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 5.0920 - accuracy: 0.0142\n",
            "Epoch 17: val_accuracy did not improve from 0.01633\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 5.0922 - accuracy: 0.0142 - val_loss: 5.0917 - val_accuracy: 0.0122\n",
            "Epoch 18/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 5.0917 - accuracy: 0.0143\n",
            "Epoch 18: val_accuracy did not improve from 0.01633\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 5.0917 - accuracy: 0.0143 - val_loss: 5.0901 - val_accuracy: 0.0122\n",
            "Epoch 19/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 5.0843 - accuracy: 0.0144\n",
            "Epoch 19: val_accuracy did not improve from 0.01633\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 5.0843 - accuracy: 0.0144 - val_loss: 5.0907 - val_accuracy: 0.0122\n",
            "Epoch 20/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 5.0874 - accuracy: 0.0145\n",
            "Epoch 20: val_accuracy improved from 0.01633 to 0.01665, saving model to /content/asl/Adam2/cp-20-0.02.hdf5\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 5.0873 - accuracy: 0.0145 - val_loss: 4.9563 - val_accuracy: 0.0166\n",
            "Epoch 21/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 4.5155 - accuracy: 0.0284\n",
            "Epoch 21: val_accuracy improved from 0.01665 to 0.03457, saving model to /content/asl/Adam2/cp-21-0.03.hdf5\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 4.5148 - accuracy: 0.0282 - val_loss: 4.2507 - val_accuracy: 0.0346\n",
            "Epoch 22/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 4.2539 - accuracy: 0.0392\n",
            "Epoch 22: val_accuracy improved from 0.03457 to 0.03745, saving model to /content/asl/Adam2/cp-22-0.04.hdf5\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 4.2536 - accuracy: 0.0392 - val_loss: 4.2380 - val_accuracy: 0.0375\n",
            "Epoch 23/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 4.1150 - accuracy: 0.0451\n",
            "Epoch 23: val_accuracy improved from 0.03745 to 0.05442, saving model to /content/asl/Adam2/cp-23-0.05.hdf5\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 4.1150 - accuracy: 0.0451 - val_loss: 4.0320 - val_accuracy: 0.0544\n",
            "Epoch 24/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 4.0766 - accuracy: 0.0437\n",
            "Epoch 24: val_accuracy did not improve from 0.05442\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 4.0762 - accuracy: 0.0436 - val_loss: 3.9554 - val_accuracy: 0.0365\n",
            "Epoch 25/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.9882 - accuracy: 0.0485\n",
            "Epoch 25: val_accuracy did not improve from 0.05442\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 3.9882 - accuracy: 0.0485 - val_loss: 3.9473 - val_accuracy: 0.0461\n",
            "Epoch 26/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 3.9358 - accuracy: 0.0539\n",
            "Epoch 26: val_accuracy improved from 0.05442 to 0.05890, saving model to /content/asl/Adam2/cp-26-0.06.hdf5\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 3.9376 - accuracy: 0.0538 - val_loss: 3.8429 - val_accuracy: 0.0589\n",
            "Epoch 27/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.8292 - accuracy: 0.0617\n",
            "Epoch 27: val_accuracy improved from 0.05890 to 0.06370, saving model to /content/asl/Adam2/cp-27-0.06.hdf5\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 3.8292 - accuracy: 0.0617 - val_loss: 3.7148 - val_accuracy: 0.0637\n",
            "Epoch 28/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 3.6883 - accuracy: 0.0807\n",
            "Epoch 28: val_accuracy improved from 0.06370 to 0.07490, saving model to /content/asl/Adam2/cp-28-0.07.hdf5\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 3.6876 - accuracy: 0.0810 - val_loss: 3.6040 - val_accuracy: 0.0749\n",
            "Epoch 29/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 3.5744 - accuracy: 0.0909\n",
            "Epoch 29: val_accuracy improved from 0.07490 to 0.12004, saving model to /content/asl/Adam2/cp-29-0.12.hdf5\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 3.5737 - accuracy: 0.0914 - val_loss: 3.4360 - val_accuracy: 0.1200\n",
            "Epoch 30/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 3.4964 - accuracy: 0.1063\n",
            "Epoch 30: val_accuracy did not improve from 0.12004\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 3.4945 - accuracy: 0.1063 - val_loss: 3.3831 - val_accuracy: 0.1098\n",
            "Epoch 31/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.4074 - accuracy: 0.1161\n",
            "Epoch 31: val_accuracy did not improve from 0.12004\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 3.4074 - accuracy: 0.1161 - val_loss: 3.3087 - val_accuracy: 0.1194\n",
            "Epoch 32/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 3.3483 - accuracy: 0.1275\n",
            "Epoch 32: val_accuracy improved from 0.12004 to 0.14821, saving model to /content/asl/Adam2/cp-32-0.15.hdf5\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 3.3478 - accuracy: 0.1278 - val_loss: 3.2064 - val_accuracy: 0.1482\n",
            "Epoch 33/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 3.3017 - accuracy: 0.1311\n",
            "Epoch 33: val_accuracy did not improve from 0.14821\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 3.3022 - accuracy: 0.1309 - val_loss: 3.2422 - val_accuracy: 0.1322\n",
            "Epoch 34/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.2451 - accuracy: 0.1410\n",
            "Epoch 34: val_accuracy did not improve from 0.14821\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 3.2451 - accuracy: 0.1410 - val_loss: 3.1845 - val_accuracy: 0.1344\n",
            "Epoch 35/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 3.2140 - accuracy: 0.1453\n",
            "Epoch 35: val_accuracy improved from 0.14821 to 0.15685, saving model to /content/asl/Adam2/cp-35-0.16.hdf5\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 3.2164 - accuracy: 0.1454 - val_loss: 3.1447 - val_accuracy: 0.1569\n",
            "Epoch 36/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.1473 - accuracy: 0.1564\n",
            "Epoch 36: val_accuracy improved from 0.15685 to 0.17222, saving model to /content/asl/Adam2/cp-36-0.17.hdf5\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 3.1473 - accuracy: 0.1564 - val_loss: 3.0770 - val_accuracy: 0.1722\n",
            "Epoch 37/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 3.0834 - accuracy: 0.1730\n",
            "Epoch 37: val_accuracy did not improve from 0.17222\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 3.0848 - accuracy: 0.1726 - val_loss: 3.3476 - val_accuracy: 0.1210\n",
            "Epoch 38/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 3.0580 - accuracy: 0.1734\n",
            "Epoch 38: val_accuracy did not improve from 0.17222\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 3.0581 - accuracy: 0.1736 - val_loss: 3.4194 - val_accuracy: 0.1008\n",
            "Epoch 39/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 3.0604 - accuracy: 0.1750\n",
            "Epoch 39: val_accuracy did not improve from 0.17222\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 3.0604 - accuracy: 0.1750 - val_loss: 3.1971 - val_accuracy: 0.1687\n",
            "Epoch 40/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 3.0142 - accuracy: 0.1840\n",
            "Epoch 40: val_accuracy improved from 0.17222 to 0.19142, saving model to /content/asl/Adam2/cp-40-0.19.hdf5\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 3.0137 - accuracy: 0.1841 - val_loss: 2.9368 - val_accuracy: 0.1914\n",
            "Epoch 41/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.9776 - accuracy: 0.1909\n",
            "Epoch 41: val_accuracy improved from 0.19142 to 0.20006, saving model to /content/asl/Adam2/cp-41-0.20.hdf5\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 2.9776 - accuracy: 0.1909 - val_loss: 2.9094 - val_accuracy: 0.2001\n",
            "Epoch 42/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 2.9098 - accuracy: 0.2017\n",
            "Epoch 42: val_accuracy improved from 0.20006 to 0.22247, saving model to /content/asl/Adam2/cp-42-0.22.hdf5\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 2.9081 - accuracy: 0.2022 - val_loss: 2.8429 - val_accuracy: 0.2225\n",
            "Epoch 43/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 2.9203 - accuracy: 0.2002\n",
            "Epoch 43: val_accuracy did not improve from 0.22247\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 2.9202 - accuracy: 0.2000 - val_loss: 2.8324 - val_accuracy: 0.2097\n",
            "Epoch 44/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 2.9056 - accuracy: 0.2055\n",
            "Epoch 44: val_accuracy did not improve from 0.22247\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 2.9056 - accuracy: 0.2053 - val_loss: 2.8166 - val_accuracy: 0.2212\n",
            "Epoch 45/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.8635 - accuracy: 0.2153\n",
            "Epoch 45: val_accuracy did not improve from 0.22247\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 2.8635 - accuracy: 0.2153 - val_loss: 2.9667 - val_accuracy: 0.1841\n",
            "Epoch 46/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 2.7998 - accuracy: 0.2234\n",
            "Epoch 46: val_accuracy improved from 0.22247 to 0.23752, saving model to /content/asl/Adam2/cp-46-0.24.hdf5\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 2.8011 - accuracy: 0.2234 - val_loss: 2.7463 - val_accuracy: 0.2375\n",
            "Epoch 47/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 2.8294 - accuracy: 0.2126\n",
            "Epoch 47: val_accuracy did not improve from 0.23752\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 2.8272 - accuracy: 0.2135 - val_loss: 2.7593 - val_accuracy: 0.2292\n",
            "Epoch 48/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.7908 - accuracy: 0.2227\n",
            "Epoch 48: val_accuracy did not improve from 0.23752\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 2.7908 - accuracy: 0.2227 - val_loss: 2.7365 - val_accuracy: 0.2305\n",
            "Epoch 49/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 2.7574 - accuracy: 0.2299\n",
            "Epoch 49: val_accuracy improved from 0.23752 to 0.24744, saving model to /content/asl/Adam2/cp-49-0.25.hdf5\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 2.7554 - accuracy: 0.2303 - val_loss: 2.6965 - val_accuracy: 0.2474\n",
            "Epoch 50/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 2.7294 - accuracy: 0.2368\n",
            "Epoch 50: val_accuracy improved from 0.24744 to 0.25576, saving model to /content/asl/Adam2/cp-50-0.26.hdf5\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 2.7301 - accuracy: 0.2366 - val_loss: 2.6470 - val_accuracy: 0.2558\n",
            "Epoch 51/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 2.7409 - accuracy: 0.2335\n",
            "Epoch 51: val_accuracy did not improve from 0.25576\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 2.7400 - accuracy: 0.2335 - val_loss: 3.0587 - val_accuracy: 0.1751\n",
            "Epoch 52/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 2.6758 - accuracy: 0.2429\n",
            "Epoch 52: val_accuracy improved from 0.25576 to 0.25640, saving model to /content/asl/Adam2/cp-52-0.26.hdf5\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 2.6758 - accuracy: 0.2430 - val_loss: 2.6370 - val_accuracy: 0.2564\n",
            "Epoch 53/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 2.6818 - accuracy: 0.2456\n",
            "Epoch 53: val_accuracy did not improve from 0.25640\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 2.6831 - accuracy: 0.2457 - val_loss: 2.6200 - val_accuracy: 0.2449\n",
            "Epoch 54/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 2.6610 - accuracy: 0.2474\n",
            "Epoch 54: val_accuracy improved from 0.25640 to 0.27209, saving model to /content/asl/Adam2/cp-54-0.27.hdf5\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 2.6590 - accuracy: 0.2478 - val_loss: 2.6064 - val_accuracy: 0.2721\n",
            "Epoch 55/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 2.6530 - accuracy: 0.2543\n",
            "Epoch 55: val_accuracy improved from 0.27209 to 0.27561, saving model to /content/asl/Adam2/cp-55-0.28.hdf5\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 2.6514 - accuracy: 0.2549 - val_loss: 2.6016 - val_accuracy: 0.2756\n",
            "Epoch 56/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 2.5894 - accuracy: 0.2661\n",
            "Epoch 56: val_accuracy improved from 0.27561 to 0.28233, saving model to /content/asl/Adam2/cp-56-0.28.hdf5\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 2.5901 - accuracy: 0.2660 - val_loss: 2.5506 - val_accuracy: 0.2823\n",
            "Epoch 57/700\n",
            "385/391 [============================>.] - ETA: 0s - loss: 2.6330 - accuracy: 0.2622\n",
            "Epoch 57: val_accuracy did not improve from 0.28233\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 2.6310 - accuracy: 0.2630 - val_loss: 2.6435 - val_accuracy: 0.2602\n",
            "Epoch 58/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.5455 - accuracy: 0.2766\n",
            "Epoch 58: val_accuracy did not improve from 0.28233\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 2.5455 - accuracy: 0.2766 - val_loss: 2.5095 - val_accuracy: 0.2810\n",
            "Epoch 59/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 2.5509 - accuracy: 0.2727\n",
            "Epoch 59: val_accuracy did not improve from 0.28233\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 2.5500 - accuracy: 0.2730 - val_loss: 2.6022 - val_accuracy: 0.2650\n",
            "Epoch 60/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 2.5382 - accuracy: 0.2741\n",
            "Epoch 60: val_accuracy improved from 0.28233 to 0.29834, saving model to /content/asl/Adam2/cp-60-0.30.hdf5\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 2.5382 - accuracy: 0.2744 - val_loss: 2.4208 - val_accuracy: 0.2983\n",
            "Epoch 61/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 2.4960 - accuracy: 0.2871\n",
            "Epoch 61: val_accuracy did not improve from 0.29834\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 2.4959 - accuracy: 0.2871 - val_loss: 2.4617 - val_accuracy: 0.2875\n",
            "Epoch 62/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 2.4563 - accuracy: 0.2964\n",
            "Epoch 62: val_accuracy improved from 0.29834 to 0.33995, saving model to /content/asl/Adam2/cp-62-0.34.hdf5\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 2.4539 - accuracy: 0.2966 - val_loss: 2.3357 - val_accuracy: 0.3399\n",
            "Epoch 63/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 2.3798 - accuracy: 0.3127\n",
            "Epoch 63: val_accuracy did not improve from 0.33995\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 2.3821 - accuracy: 0.3123 - val_loss: 2.3711 - val_accuracy: 0.3227\n",
            "Epoch 64/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 2.3172 - accuracy: 0.3197\n",
            "Epoch 64: val_accuracy did not improve from 0.33995\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 2.3142 - accuracy: 0.3203 - val_loss: 2.3114 - val_accuracy: 0.3185\n",
            "Epoch 65/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 2.3338 - accuracy: 0.3161\n",
            "Epoch 65: val_accuracy did not improve from 0.33995\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 2.3364 - accuracy: 0.3159 - val_loss: 2.4877 - val_accuracy: 0.3038\n",
            "Epoch 66/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.3385 - accuracy: 0.3154\n",
            "Epoch 66: val_accuracy improved from 0.33995 to 0.35211, saving model to /content/asl/Adam2/cp-66-0.35.hdf5\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 2.3385 - accuracy: 0.3154 - val_loss: 2.2241 - val_accuracy: 0.3521\n",
            "Epoch 67/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 2.2526 - accuracy: 0.3319\n",
            "Epoch 67: val_accuracy did not improve from 0.35211\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 2.2525 - accuracy: 0.3319 - val_loss: 2.3041 - val_accuracy: 0.3147\n",
            "Epoch 68/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 2.2197 - accuracy: 0.3443\n",
            "Epoch 68: val_accuracy did not improve from 0.35211\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 2.2196 - accuracy: 0.3444 - val_loss: 2.3179 - val_accuracy: 0.3182\n",
            "Epoch 69/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 2.2082 - accuracy: 0.3513\n",
            "Epoch 69: val_accuracy improved from 0.35211 to 0.37516, saving model to /content/asl/Adam2/cp-69-0.38.hdf5\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 2.2107 - accuracy: 0.3508 - val_loss: 2.1415 - val_accuracy: 0.3752\n",
            "Epoch 70/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 2.1879 - accuracy: 0.3493\n",
            "Epoch 70: val_accuracy did not improve from 0.37516\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 2.1854 - accuracy: 0.3500 - val_loss: 2.1586 - val_accuracy: 0.3713\n",
            "Epoch 71/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 2.1438 - accuracy: 0.3625\n",
            "Epoch 71: val_accuracy did not improve from 0.37516\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 2.1451 - accuracy: 0.3622 - val_loss: 2.1330 - val_accuracy: 0.3726\n",
            "Epoch 72/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.0932 - accuracy: 0.3763\n",
            "Epoch 72: val_accuracy did not improve from 0.37516\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 2.0932 - accuracy: 0.3763 - val_loss: 2.1659 - val_accuracy: 0.3684\n",
            "Epoch 73/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 2.1140 - accuracy: 0.3680\n",
            "Epoch 73: val_accuracy did not improve from 0.37516\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 2.1132 - accuracy: 0.3682 - val_loss: 2.1511 - val_accuracy: 0.3457\n",
            "Epoch 74/700\n",
            "385/391 [============================>.] - ETA: 0s - loss: 2.0858 - accuracy: 0.3769\n",
            "Epoch 74: val_accuracy improved from 0.37516 to 0.38796, saving model to /content/asl/Adam2/cp-74-0.39.hdf5\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 2.0836 - accuracy: 0.3780 - val_loss: 2.0996 - val_accuracy: 0.3880\n",
            "Epoch 75/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 2.0203 - accuracy: 0.3916\n",
            "Epoch 75: val_accuracy did not improve from 0.38796\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 2.0203 - accuracy: 0.3916 - val_loss: 2.1919 - val_accuracy: 0.3643\n",
            "Epoch 76/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 2.0655 - accuracy: 0.3805\n",
            "Epoch 76: val_accuracy improved from 0.38796 to 0.39052, saving model to /content/asl/Adam2/cp-76-0.39.hdf5\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 2.0646 - accuracy: 0.3808 - val_loss: 2.0750 - val_accuracy: 0.3905\n",
            "Epoch 77/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 2.0279 - accuracy: 0.3957\n",
            "Epoch 77: val_accuracy improved from 0.39052 to 0.41325, saving model to /content/asl/Adam2/cp-77-0.41.hdf5\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 2.0274 - accuracy: 0.3964 - val_loss: 1.9909 - val_accuracy: 0.4133\n",
            "Epoch 78/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 1.9930 - accuracy: 0.4048\n",
            "Epoch 78: val_accuracy did not improve from 0.41325\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.9921 - accuracy: 0.4048 - val_loss: 2.1209 - val_accuracy: 0.3681\n",
            "Epoch 79/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.9853 - accuracy: 0.3956\n",
            "Epoch 79: val_accuracy did not improve from 0.41325\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.9853 - accuracy: 0.3956 - val_loss: 2.1901 - val_accuracy: 0.3713\n",
            "Epoch 80/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.9469 - accuracy: 0.4049\n",
            "Epoch 80: val_accuracy did not improve from 0.41325\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.9468 - accuracy: 0.4051 - val_loss: 2.3272 - val_accuracy: 0.3387\n",
            "Epoch 81/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.9534 - accuracy: 0.4065\n",
            "Epoch 81: val_accuracy did not improve from 0.41325\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.9564 - accuracy: 0.4054 - val_loss: 2.4678 - val_accuracy: 0.3143\n",
            "Epoch 82/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.9218 - accuracy: 0.4139\n",
            "Epoch 82: val_accuracy improved from 0.41325 to 0.45230, saving model to /content/asl/Adam2/cp-82-0.45.hdf5\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.9218 - accuracy: 0.4139 - val_loss: 1.8729 - val_accuracy: 0.4523\n",
            "Epoch 83/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.8858 - accuracy: 0.4254\n",
            "Epoch 83: val_accuracy did not improve from 0.45230\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.8851 - accuracy: 0.4257 - val_loss: 1.8959 - val_accuracy: 0.4453\n",
            "Epoch 84/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.9007 - accuracy: 0.4176\n",
            "Epoch 84: val_accuracy did not improve from 0.45230\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.9001 - accuracy: 0.4179 - val_loss: 1.9399 - val_accuracy: 0.4123\n",
            "Epoch 85/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.8755 - accuracy: 0.4270\n",
            "Epoch 85: val_accuracy did not improve from 0.45230\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.8759 - accuracy: 0.4269 - val_loss: 1.9353 - val_accuracy: 0.4113\n",
            "Epoch 86/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.8565 - accuracy: 0.4287\n",
            "Epoch 86: val_accuracy did not improve from 0.45230\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.8578 - accuracy: 0.4283 - val_loss: 2.0911 - val_accuracy: 0.3716\n",
            "Epoch 87/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.8329 - accuracy: 0.4293\n",
            "Epoch 87: val_accuracy did not improve from 0.45230\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.8318 - accuracy: 0.4301 - val_loss: 1.8930 - val_accuracy: 0.4321\n",
            "Epoch 88/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 1.8674 - accuracy: 0.4233\n",
            "Epoch 88: val_accuracy did not improve from 0.45230\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.8663 - accuracy: 0.4238 - val_loss: 1.9277 - val_accuracy: 0.4248\n",
            "Epoch 89/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.8013 - accuracy: 0.4357\n",
            "Epoch 89: val_accuracy did not improve from 0.45230\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.8004 - accuracy: 0.4359 - val_loss: 1.9758 - val_accuracy: 0.4075\n",
            "Epoch 90/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.8078 - accuracy: 0.4378\n",
            "Epoch 90: val_accuracy did not improve from 0.45230\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.8078 - accuracy: 0.4378 - val_loss: 2.0921 - val_accuracy: 0.3700\n",
            "Epoch 91/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.7702 - accuracy: 0.4468\n",
            "Epoch 91: val_accuracy did not improve from 0.45230\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.7702 - accuracy: 0.4468 - val_loss: 2.1149 - val_accuracy: 0.3752\n",
            "Epoch 92/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.7622 - accuracy: 0.4498\n",
            "Epoch 92: val_accuracy did not improve from 0.45230\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.7625 - accuracy: 0.4498 - val_loss: 2.1392 - val_accuracy: 0.3835\n",
            "Epoch 93/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.7266 - accuracy: 0.4536\n",
            "Epoch 93: val_accuracy did not improve from 0.45230\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.7270 - accuracy: 0.4534 - val_loss: 1.8776 - val_accuracy: 0.4395\n",
            "Epoch 94/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.7636 - accuracy: 0.4505\n",
            "Epoch 94: val_accuracy did not improve from 0.45230\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.7636 - accuracy: 0.4505 - val_loss: 1.8752 - val_accuracy: 0.4424\n",
            "Epoch 95/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.7155 - accuracy: 0.4540\n",
            "Epoch 95: val_accuracy improved from 0.45230 to 0.47599, saving model to /content/asl/Adam2/cp-95-0.48.hdf5\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.7151 - accuracy: 0.4542 - val_loss: 1.7467 - val_accuracy: 0.4760\n",
            "Epoch 96/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.6843 - accuracy: 0.4648\n",
            "Epoch 96: val_accuracy improved from 0.47599 to 0.47759, saving model to /content/asl/Adam2/cp-96-0.48.hdf5\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.6845 - accuracy: 0.4647 - val_loss: 1.6939 - val_accuracy: 0.4776\n",
            "Epoch 97/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.7545 - accuracy: 0.4545\n",
            "Epoch 97: val_accuracy did not improve from 0.47759\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.7548 - accuracy: 0.4540 - val_loss: 1.7746 - val_accuracy: 0.4667\n",
            "Epoch 98/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.7192 - accuracy: 0.4586\n",
            "Epoch 98: val_accuracy improved from 0.47759 to 0.48848, saving model to /content/asl/Adam2/cp-98-0.49.hdf5\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.7182 - accuracy: 0.4587 - val_loss: 1.6603 - val_accuracy: 0.4885\n",
            "Epoch 99/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.6701 - accuracy: 0.4753\n",
            "Epoch 99: val_accuracy did not improve from 0.48848\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.6703 - accuracy: 0.4750 - val_loss: 1.6844 - val_accuracy: 0.4789\n",
            "Epoch 100/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.6138 - accuracy: 0.4817\n",
            "Epoch 100: val_accuracy did not improve from 0.48848\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.6138 - accuracy: 0.4817 - val_loss: 2.5709 - val_accuracy: 0.3198\n",
            "Epoch 101/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.7457 - accuracy: 0.4545\n",
            "Epoch 101: val_accuracy improved from 0.48848 to 0.51569, saving model to /content/asl/Adam2/cp-101-0.52.hdf5\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.7457 - accuracy: 0.4545 - val_loss: 1.5745 - val_accuracy: 0.5157\n",
            "Epoch 102/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.6875 - accuracy: 0.4696\n",
            "Epoch 102: val_accuracy improved from 0.51569 to 0.52593, saving model to /content/asl/Adam2/cp-102-0.53.hdf5\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.6868 - accuracy: 0.4695 - val_loss: 1.5690 - val_accuracy: 0.5259\n",
            "Epoch 103/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.6063 - accuracy: 0.4893\n",
            "Epoch 103: val_accuracy did not improve from 0.52593\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.6063 - accuracy: 0.4894 - val_loss: 2.6363 - val_accuracy: 0.3124\n",
            "Epoch 104/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.5906 - accuracy: 0.4923\n",
            "Epoch 104: val_accuracy did not improve from 0.52593\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.5876 - accuracy: 0.4930 - val_loss: 1.6096 - val_accuracy: 0.5042\n",
            "Epoch 105/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.5791 - accuracy: 0.5012\n",
            "Epoch 105: val_accuracy did not improve from 0.52593\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.5787 - accuracy: 0.5014 - val_loss: 1.8722 - val_accuracy: 0.4248\n",
            "Epoch 106/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.6443 - accuracy: 0.4795\n",
            "Epoch 106: val_accuracy did not improve from 0.52593\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.6443 - accuracy: 0.4795 - val_loss: 2.0813 - val_accuracy: 0.3825\n",
            "Epoch 107/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.5996 - accuracy: 0.4851\n",
            "Epoch 107: val_accuracy did not improve from 0.52593\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.5996 - accuracy: 0.4851 - val_loss: 1.6056 - val_accuracy: 0.4958\n",
            "Epoch 108/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.5426 - accuracy: 0.5051\n",
            "Epoch 108: val_accuracy did not improve from 0.52593\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.5444 - accuracy: 0.5046 - val_loss: 2.0797 - val_accuracy: 0.3832\n",
            "Epoch 109/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.5798 - accuracy: 0.4943\n",
            "Epoch 109: val_accuracy did not improve from 0.52593\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.5803 - accuracy: 0.4942 - val_loss: 2.0147 - val_accuracy: 0.3790\n",
            "Epoch 110/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.5812 - accuracy: 0.4962\n",
            "Epoch 110: val_accuracy did not improve from 0.52593\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.5812 - accuracy: 0.4962 - val_loss: 1.5837 - val_accuracy: 0.5096\n",
            "Epoch 111/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 1.5628 - accuracy: 0.5001\n",
            "Epoch 111: val_accuracy did not improve from 0.52593\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.5618 - accuracy: 0.5002 - val_loss: 1.7135 - val_accuracy: 0.4693\n",
            "Epoch 112/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.5387 - accuracy: 0.5079\n",
            "Epoch 112: val_accuracy did not improve from 0.52593\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.5392 - accuracy: 0.5074 - val_loss: 1.6817 - val_accuracy: 0.4798\n",
            "Epoch 113/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.5752 - accuracy: 0.4955\n",
            "Epoch 113: val_accuracy improved from 0.52593 to 0.53393, saving model to /content/asl/Adam2/cp-113-0.53.hdf5\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.5760 - accuracy: 0.4951 - val_loss: 1.5614 - val_accuracy: 0.5339\n",
            "Epoch 114/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.5733 - accuracy: 0.4941\n",
            "Epoch 114: val_accuracy did not improve from 0.53393\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.5732 - accuracy: 0.4938 - val_loss: 1.8264 - val_accuracy: 0.4526\n",
            "Epoch 115/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 1.5249 - accuracy: 0.5047\n",
            "Epoch 115: val_accuracy improved from 0.53393 to 0.54834, saving model to /content/asl/Adam2/cp-115-0.55.hdf5\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.5257 - accuracy: 0.5050 - val_loss: 1.4890 - val_accuracy: 0.5483\n",
            "Epoch 116/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.5299 - accuracy: 0.5100\n",
            "Epoch 116: val_accuracy did not improve from 0.54834\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.5290 - accuracy: 0.5103 - val_loss: 1.5431 - val_accuracy: 0.5134\n",
            "Epoch 117/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.5158 - accuracy: 0.5066\n",
            "Epoch 117: val_accuracy did not improve from 0.54834\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.5175 - accuracy: 0.5063 - val_loss: 1.8586 - val_accuracy: 0.4430\n",
            "Epoch 118/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.5093 - accuracy: 0.5110\n",
            "Epoch 118: val_accuracy did not improve from 0.54834\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.5087 - accuracy: 0.5113 - val_loss: 1.4597 - val_accuracy: 0.5474\n",
            "Epoch 119/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.4758 - accuracy: 0.5212\n",
            "Epoch 119: val_accuracy did not improve from 0.54834\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.4789 - accuracy: 0.5202 - val_loss: 2.9568 - val_accuracy: 0.3051\n",
            "Epoch 120/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.5393 - accuracy: 0.5048\n",
            "Epoch 120: val_accuracy did not improve from 0.54834\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.5413 - accuracy: 0.5042 - val_loss: 1.7506 - val_accuracy: 0.4478\n",
            "Epoch 121/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 1.4751 - accuracy: 0.5128\n",
            "Epoch 121: val_accuracy did not improve from 0.54834\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.4832 - accuracy: 0.5113 - val_loss: 1.9729 - val_accuracy: 0.4213\n",
            "Epoch 122/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.4602 - accuracy: 0.5235\n",
            "Epoch 122: val_accuracy did not improve from 0.54834\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.4599 - accuracy: 0.5235 - val_loss: 1.5490 - val_accuracy: 0.5343\n",
            "Epoch 123/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.4075 - accuracy: 0.5389\n",
            "Epoch 123: val_accuracy did not improve from 0.54834\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.4107 - accuracy: 0.5381 - val_loss: 1.7378 - val_accuracy: 0.4907\n",
            "Epoch 124/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 1.4986 - accuracy: 0.5134\n",
            "Epoch 124: val_accuracy did not improve from 0.54834\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.4999 - accuracy: 0.5130 - val_loss: 1.4928 - val_accuracy: 0.5355\n",
            "Epoch 125/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.4578 - accuracy: 0.5244\n",
            "Epoch 125: val_accuracy did not improve from 0.54834\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.4574 - accuracy: 0.5249 - val_loss: 1.4523 - val_accuracy: 0.5471\n",
            "Epoch 126/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.4743 - accuracy: 0.5212\n",
            "Epoch 126: val_accuracy improved from 0.54834 to 0.56626, saving model to /content/asl/Adam2/cp-126-0.57.hdf5\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.4742 - accuracy: 0.5208 - val_loss: 1.4154 - val_accuracy: 0.5663\n",
            "Epoch 127/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 1.5020 - accuracy: 0.5175\n",
            "Epoch 127: val_accuracy did not improve from 0.56626\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.5010 - accuracy: 0.5179 - val_loss: 1.4788 - val_accuracy: 0.5509\n",
            "Epoch 128/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.4335 - accuracy: 0.5292\n",
            "Epoch 128: val_accuracy did not improve from 0.56626\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.4332 - accuracy: 0.5297 - val_loss: 1.5375 - val_accuracy: 0.5317\n",
            "Epoch 129/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.5301 - accuracy: 0.5157\n",
            "Epoch 129: val_accuracy did not improve from 0.56626\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.5301 - accuracy: 0.5157 - val_loss: 1.5105 - val_accuracy: 0.5375\n",
            "Epoch 130/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.4361 - accuracy: 0.5342\n",
            "Epoch 130: val_accuracy improved from 0.56626 to 0.57394, saving model to /content/asl/Adam2/cp-130-0.57.hdf5\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.4357 - accuracy: 0.5346 - val_loss: 1.3884 - val_accuracy: 0.5739\n",
            "Epoch 131/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.3783 - accuracy: 0.5485\n",
            "Epoch 131: val_accuracy did not improve from 0.57394\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.3783 - accuracy: 0.5485 - val_loss: 1.6849 - val_accuracy: 0.4798\n",
            "Epoch 132/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.4069 - accuracy: 0.5357\n",
            "Epoch 132: val_accuracy did not improve from 0.57394\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.4056 - accuracy: 0.5362 - val_loss: 1.7762 - val_accuracy: 0.4766\n",
            "Epoch 133/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.4181 - accuracy: 0.5333\n",
            "Epoch 133: val_accuracy did not improve from 0.57394\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.4190 - accuracy: 0.5323 - val_loss: 1.5248 - val_accuracy: 0.5090\n",
            "Epoch 134/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.4178 - accuracy: 0.5338\n",
            "Epoch 134: val_accuracy did not improve from 0.57394\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.4189 - accuracy: 0.5335 - val_loss: 1.4679 - val_accuracy: 0.5519\n",
            "Epoch 135/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.4025 - accuracy: 0.5421\n",
            "Epoch 135: val_accuracy did not improve from 0.57394\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.4018 - accuracy: 0.5423 - val_loss: 1.5900 - val_accuracy: 0.5134\n",
            "Epoch 136/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.4016 - accuracy: 0.5365\n",
            "Epoch 136: val_accuracy did not improve from 0.57394\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.4036 - accuracy: 0.5359 - val_loss: 1.8856 - val_accuracy: 0.4286\n",
            "Epoch 137/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.4196 - accuracy: 0.5374\n",
            "Epoch 137: val_accuracy did not improve from 0.57394\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.4197 - accuracy: 0.5374 - val_loss: 1.5333 - val_accuracy: 0.5246\n",
            "Epoch 138/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.3961 - accuracy: 0.5403\n",
            "Epoch 138: val_accuracy did not improve from 0.57394\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.3972 - accuracy: 0.5398 - val_loss: 1.7020 - val_accuracy: 0.4846\n",
            "Epoch 139/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.4129 - accuracy: 0.5403\n",
            "Epoch 139: val_accuracy improved from 0.57394 to 0.58131, saving model to /content/asl/Adam2/cp-139-0.58.hdf5\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.4114 - accuracy: 0.5403 - val_loss: 1.3784 - val_accuracy: 0.5813\n",
            "Epoch 140/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.3842 - accuracy: 0.5486\n",
            "Epoch 140: val_accuracy did not improve from 0.58131\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.3854 - accuracy: 0.5479 - val_loss: 1.6310 - val_accuracy: 0.4923\n",
            "Epoch 141/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.3807 - accuracy: 0.5456\n",
            "Epoch 141: val_accuracy did not improve from 0.58131\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.3807 - accuracy: 0.5456 - val_loss: 1.4074 - val_accuracy: 0.5803\n",
            "Epoch 142/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.4104 - accuracy: 0.5363\n",
            "Epoch 142: val_accuracy did not improve from 0.58131\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.4105 - accuracy: 0.5362 - val_loss: 1.4888 - val_accuracy: 0.5320\n",
            "Epoch 143/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.3761 - accuracy: 0.5467\n",
            "Epoch 143: val_accuracy did not improve from 0.58131\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.3763 - accuracy: 0.5464 - val_loss: 1.5985 - val_accuracy: 0.5080\n",
            "Epoch 144/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.4007 - accuracy: 0.5413\n",
            "Epoch 144: val_accuracy did not improve from 0.58131\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.3991 - accuracy: 0.5419 - val_loss: 1.4475 - val_accuracy: 0.5483\n",
            "Epoch 145/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.3224 - accuracy: 0.5602\n",
            "Epoch 145: val_accuracy did not improve from 0.58131\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.3220 - accuracy: 0.5603 - val_loss: 1.4573 - val_accuracy: 0.5535\n",
            "Epoch 146/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.4368 - accuracy: 0.5347\n",
            "Epoch 146: val_accuracy did not improve from 0.58131\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.4378 - accuracy: 0.5346 - val_loss: 1.4268 - val_accuracy: 0.5570\n",
            "Epoch 147/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 1.3377 - accuracy: 0.5595\n",
            "Epoch 147: val_accuracy improved from 0.58131 to 0.59507, saving model to /content/asl/Adam2/cp-147-0.60.hdf5\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.3405 - accuracy: 0.5585 - val_loss: 1.3355 - val_accuracy: 0.5951\n",
            "Epoch 148/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.3277 - accuracy: 0.5635\n",
            "Epoch 148: val_accuracy did not improve from 0.59507\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.3280 - accuracy: 0.5635 - val_loss: 1.3871 - val_accuracy: 0.5759\n",
            "Epoch 149/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.3373 - accuracy: 0.5543\n",
            "Epoch 149: val_accuracy did not improve from 0.59507\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.3373 - accuracy: 0.5543 - val_loss: 1.5083 - val_accuracy: 0.5304\n",
            "Epoch 150/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.3576 - accuracy: 0.5534\n",
            "Epoch 150: val_accuracy did not improve from 0.59507\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.3580 - accuracy: 0.5534 - val_loss: 1.6320 - val_accuracy: 0.5051\n",
            "Epoch 151/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 1.3443 - accuracy: 0.5578\n",
            "Epoch 151: val_accuracy improved from 0.59507 to 0.60307, saving model to /content/asl/Adam2/cp-151-0.60.hdf5\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.3452 - accuracy: 0.5578 - val_loss: 1.2931 - val_accuracy: 0.6031\n",
            "Epoch 152/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.3847 - accuracy: 0.5494\n",
            "Epoch 152: val_accuracy did not improve from 0.60307\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.3856 - accuracy: 0.5489 - val_loss: 1.4903 - val_accuracy: 0.5435\n",
            "Epoch 153/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.2744 - accuracy: 0.5777\n",
            "Epoch 153: val_accuracy did not improve from 0.60307\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.2758 - accuracy: 0.5774 - val_loss: 1.4421 - val_accuracy: 0.5563\n",
            "Epoch 154/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.3296 - accuracy: 0.5577\n",
            "Epoch 154: val_accuracy did not improve from 0.60307\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.3286 - accuracy: 0.5581 - val_loss: 1.7448 - val_accuracy: 0.4686\n",
            "Epoch 155/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.3361 - accuracy: 0.5611\n",
            "Epoch 155: val_accuracy did not improve from 0.60307\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.3370 - accuracy: 0.5609 - val_loss: 1.9019 - val_accuracy: 0.4392\n",
            "Epoch 156/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.3481 - accuracy: 0.5562\n",
            "Epoch 156: val_accuracy did not improve from 0.60307\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.3481 - accuracy: 0.5560 - val_loss: 1.3826 - val_accuracy: 0.5624\n",
            "Epoch 157/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.3543 - accuracy: 0.5503\n",
            "Epoch 157: val_accuracy did not improve from 0.60307\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.3551 - accuracy: 0.5503 - val_loss: 1.4791 - val_accuracy: 0.5304\n",
            "Epoch 158/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.2462 - accuracy: 0.5846\n",
            "Epoch 158: val_accuracy did not improve from 0.60307\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.2455 - accuracy: 0.5847 - val_loss: 1.7427 - val_accuracy: 0.4622\n",
            "Epoch 159/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.3713 - accuracy: 0.5493\n",
            "Epoch 159: val_accuracy did not improve from 0.60307\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.3706 - accuracy: 0.5495 - val_loss: 1.3516 - val_accuracy: 0.5829\n",
            "Epoch 160/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.2628 - accuracy: 0.5793\n",
            "Epoch 160: val_accuracy did not improve from 0.60307\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.2645 - accuracy: 0.5788 - val_loss: 2.4996 - val_accuracy: 0.3265\n",
            "Epoch 161/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.4184 - accuracy: 0.5372\n",
            "Epoch 161: val_accuracy did not improve from 0.60307\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.4184 - accuracy: 0.5372 - val_loss: 1.4975 - val_accuracy: 0.5419\n",
            "Epoch 162/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.2538 - accuracy: 0.5821\n",
            "Epoch 162: val_accuracy did not improve from 0.60307\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.2538 - accuracy: 0.5822 - val_loss: 1.6401 - val_accuracy: 0.5099\n",
            "Epoch 163/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.3739 - accuracy: 0.5535\n",
            "Epoch 163: val_accuracy did not improve from 0.60307\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.3728 - accuracy: 0.5538 - val_loss: 1.3446 - val_accuracy: 0.5743\n",
            "Epoch 164/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.3157 - accuracy: 0.5639\n",
            "Epoch 164: val_accuracy did not improve from 0.60307\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.3149 - accuracy: 0.5639 - val_loss: 1.3414 - val_accuracy: 0.5848\n",
            "Epoch 165/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.2415 - accuracy: 0.5839\n",
            "Epoch 165: val_accuracy did not improve from 0.60307\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.2415 - accuracy: 0.5839 - val_loss: 1.5074 - val_accuracy: 0.5343\n",
            "Epoch 166/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.3214 - accuracy: 0.5630\n",
            "Epoch 166: val_accuracy did not improve from 0.60307\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.3220 - accuracy: 0.5630 - val_loss: 1.4241 - val_accuracy: 0.5631\n",
            "Epoch 167/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.3354 - accuracy: 0.5583\n",
            "Epoch 167: val_accuracy did not improve from 0.60307\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.3344 - accuracy: 0.5587 - val_loss: 1.7846 - val_accuracy: 0.4741\n",
            "Epoch 168/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.2967 - accuracy: 0.5750\n",
            "Epoch 168: val_accuracy did not improve from 0.60307\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.2958 - accuracy: 0.5752 - val_loss: 1.5250 - val_accuracy: 0.5378\n",
            "Epoch 169/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.2627 - accuracy: 0.5744\n",
            "Epoch 169: val_accuracy did not improve from 0.60307\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.2627 - accuracy: 0.5744 - val_loss: 1.3102 - val_accuracy: 0.6021\n",
            "Epoch 170/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.2845 - accuracy: 0.5726\n",
            "Epoch 170: val_accuracy did not improve from 0.60307\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.2845 - accuracy: 0.5726 - val_loss: 1.7417 - val_accuracy: 0.4776\n",
            "Epoch 171/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.2970 - accuracy: 0.5665\n",
            "Epoch 171: val_accuracy did not improve from 0.60307\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.2974 - accuracy: 0.5666 - val_loss: 1.4658 - val_accuracy: 0.5378\n",
            "Epoch 172/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.2919 - accuracy: 0.5723\n",
            "Epoch 172: val_accuracy did not improve from 0.60307\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.2914 - accuracy: 0.5723 - val_loss: 1.3395 - val_accuracy: 0.5887\n",
            "Epoch 173/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 1.3416 - accuracy: 0.5614\n",
            "Epoch 173: val_accuracy did not improve from 0.60307\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.3397 - accuracy: 0.5624 - val_loss: 1.3043 - val_accuracy: 0.6021\n",
            "Epoch 174/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 1.2535 - accuracy: 0.5820\n",
            "Epoch 174: val_accuracy did not improve from 0.60307\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.2545 - accuracy: 0.5816 - val_loss: 1.3406 - val_accuracy: 0.5813\n",
            "Epoch 175/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.2584 - accuracy: 0.5797\n",
            "Epoch 175: val_accuracy did not improve from 0.60307\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.2587 - accuracy: 0.5795 - val_loss: 1.4552 - val_accuracy: 0.5458\n",
            "Epoch 176/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 1.3175 - accuracy: 0.5590\n",
            "Epoch 176: val_accuracy did not improve from 0.60307\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.3162 - accuracy: 0.5595 - val_loss: 1.3764 - val_accuracy: 0.5816\n",
            "Epoch 177/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 1.2709 - accuracy: 0.5738\n",
            "Epoch 177: val_accuracy did not improve from 0.60307\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.2741 - accuracy: 0.5731 - val_loss: 1.4951 - val_accuracy: 0.5352\n",
            "Epoch 178/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.2171 - accuracy: 0.5891\n",
            "Epoch 178: val_accuracy did not improve from 0.60307\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.2183 - accuracy: 0.5889 - val_loss: 1.2824 - val_accuracy: 0.5999\n",
            "Epoch 179/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.2681 - accuracy: 0.5785\n",
            "Epoch 179: val_accuracy did not improve from 0.60307\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.2681 - accuracy: 0.5783 - val_loss: 1.7573 - val_accuracy: 0.4722\n",
            "Epoch 180/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.2482 - accuracy: 0.5775\n",
            "Epoch 180: val_accuracy did not improve from 0.60307\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.2482 - accuracy: 0.5775 - val_loss: 1.3218 - val_accuracy: 0.5861\n",
            "Epoch 181/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.2653 - accuracy: 0.5799\n",
            "Epoch 181: val_accuracy did not improve from 0.60307\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.2654 - accuracy: 0.5798 - val_loss: 1.5114 - val_accuracy: 0.5346\n",
            "Epoch 182/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.2605 - accuracy: 0.5773\n",
            "Epoch 182: val_accuracy did not improve from 0.60307\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.2604 - accuracy: 0.5772 - val_loss: 1.3976 - val_accuracy: 0.5538\n",
            "Epoch 183/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.2132 - accuracy: 0.5921\n",
            "Epoch 183: val_accuracy did not improve from 0.60307\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.2127 - accuracy: 0.5923 - val_loss: 1.3171 - val_accuracy: 0.5931\n",
            "Epoch 184/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.2801 - accuracy: 0.5744\n",
            "Epoch 184: val_accuracy did not improve from 0.60307\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.2781 - accuracy: 0.5749 - val_loss: 1.4127 - val_accuracy: 0.5746\n",
            "Epoch 185/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.2235 - accuracy: 0.5909\n",
            "Epoch 185: val_accuracy did not improve from 0.60307\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.2225 - accuracy: 0.5915 - val_loss: 1.4127 - val_accuracy: 0.5608\n",
            "Epoch 186/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.2622 - accuracy: 0.5747\n",
            "Epoch 186: val_accuracy did not improve from 0.60307\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.2633 - accuracy: 0.5746 - val_loss: 1.7586 - val_accuracy: 0.4878\n",
            "Epoch 187/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.2350 - accuracy: 0.5845\n",
            "Epoch 187: val_accuracy did not improve from 0.60307\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.2344 - accuracy: 0.5849 - val_loss: 2.0747 - val_accuracy: 0.4225\n",
            "Epoch 188/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.2425 - accuracy: 0.5885\n",
            "Epoch 188: val_accuracy improved from 0.60307 to 0.60948, saving model to /content/asl/Adam2/cp-188-0.61.hdf5\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.2424 - accuracy: 0.5883 - val_loss: 1.2892 - val_accuracy: 0.6095\n",
            "Epoch 189/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.1941 - accuracy: 0.5963\n",
            "Epoch 189: val_accuracy did not improve from 0.60948\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.1931 - accuracy: 0.5966 - val_loss: 1.3255 - val_accuracy: 0.5909\n",
            "Epoch 190/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.3041 - accuracy: 0.5674\n",
            "Epoch 190: val_accuracy did not improve from 0.60948\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.3024 - accuracy: 0.5679 - val_loss: 1.5025 - val_accuracy: 0.5237\n",
            "Epoch 191/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.2326 - accuracy: 0.5863\n",
            "Epoch 191: val_accuracy did not improve from 0.60948\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.2329 - accuracy: 0.5861 - val_loss: 1.4434 - val_accuracy: 0.5541\n",
            "Epoch 192/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.2360 - accuracy: 0.5809\n",
            "Epoch 192: val_accuracy did not improve from 0.60948\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.2362 - accuracy: 0.5804 - val_loss: 1.3386 - val_accuracy: 0.5835\n",
            "Epoch 193/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.2331 - accuracy: 0.5844\n",
            "Epoch 193: val_accuracy improved from 0.60948 to 0.62612, saving model to /content/asl/Adam2/cp-193-0.63.hdf5\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.2331 - accuracy: 0.5844 - val_loss: 1.2693 - val_accuracy: 0.6261\n",
            "Epoch 194/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.2337 - accuracy: 0.5838\n",
            "Epoch 194: val_accuracy did not improve from 0.62612\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.2344 - accuracy: 0.5834 - val_loss: 2.0579 - val_accuracy: 0.4209\n",
            "Epoch 195/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.1997 - accuracy: 0.5941\n",
            "Epoch 195: val_accuracy did not improve from 0.62612\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.2002 - accuracy: 0.5937 - val_loss: 1.5455 - val_accuracy: 0.5266\n",
            "Epoch 196/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.2153 - accuracy: 0.5888\n",
            "Epoch 196: val_accuracy did not improve from 0.62612\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.2155 - accuracy: 0.5886 - val_loss: 1.4115 - val_accuracy: 0.5688\n",
            "Epoch 197/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.2549 - accuracy: 0.5761\n",
            "Epoch 197: val_accuracy did not improve from 0.62612\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.2549 - accuracy: 0.5757 - val_loss: 1.4040 - val_accuracy: 0.5768\n",
            "Epoch 198/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.2299 - accuracy: 0.5894\n",
            "Epoch 198: val_accuracy did not improve from 0.62612\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.2299 - accuracy: 0.5894 - val_loss: 1.3305 - val_accuracy: 0.5909\n",
            "Epoch 199/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.1776 - accuracy: 0.6015\n",
            "Epoch 199: val_accuracy did not improve from 0.62612\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.1777 - accuracy: 0.6016 - val_loss: 1.6016 - val_accuracy: 0.5170\n",
            "Epoch 200/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.2696 - accuracy: 0.5784\n",
            "Epoch 200: val_accuracy did not improve from 0.62612\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.2727 - accuracy: 0.5774 - val_loss: 1.5734 - val_accuracy: 0.5138\n",
            "Epoch 201/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.2699 - accuracy: 0.5802\n",
            "Epoch 201: val_accuracy did not improve from 0.62612\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.2697 - accuracy: 0.5801 - val_loss: 1.3269 - val_accuracy: 0.5899\n",
            "Epoch 202/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.1564 - accuracy: 0.6055\n",
            "Epoch 202: val_accuracy did not improve from 0.62612\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.1570 - accuracy: 0.6052 - val_loss: 1.2962 - val_accuracy: 0.6056\n",
            "Epoch 203/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.2636 - accuracy: 0.5792\n",
            "Epoch 203: val_accuracy did not improve from 0.62612\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.2627 - accuracy: 0.5794 - val_loss: 1.4701 - val_accuracy: 0.5391\n",
            "Epoch 204/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.2711 - accuracy: 0.5770\n",
            "Epoch 204: val_accuracy did not improve from 0.62612\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.2696 - accuracy: 0.5776 - val_loss: 1.4491 - val_accuracy: 0.5602\n",
            "Epoch 205/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.1822 - accuracy: 0.5997\n",
            "Epoch 205: val_accuracy did not improve from 0.62612\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.1819 - accuracy: 0.6001 - val_loss: 1.4249 - val_accuracy: 0.5567\n",
            "Epoch 206/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.1906 - accuracy: 0.5998\n",
            "Epoch 206: val_accuracy did not improve from 0.62612\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.1905 - accuracy: 0.5999 - val_loss: 1.3651 - val_accuracy: 0.5749\n",
            "Epoch 207/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.2004 - accuracy: 0.5963\n",
            "Epoch 207: val_accuracy did not improve from 0.62612\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.2007 - accuracy: 0.5963 - val_loss: 1.2536 - val_accuracy: 0.6130\n",
            "Epoch 208/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.2183 - accuracy: 0.5933\n",
            "Epoch 208: val_accuracy did not improve from 0.62612\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.2182 - accuracy: 0.5933 - val_loss: 1.2520 - val_accuracy: 0.6149\n",
            "Epoch 209/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.2466 - accuracy: 0.5906\n",
            "Epoch 209: val_accuracy did not improve from 0.62612\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.2494 - accuracy: 0.5896 - val_loss: 1.5127 - val_accuracy: 0.5362\n",
            "Epoch 210/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.1464 - accuracy: 0.6097\n",
            "Epoch 210: val_accuracy did not improve from 0.62612\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.1450 - accuracy: 0.6104 - val_loss: 1.2646 - val_accuracy: 0.6146\n",
            "Epoch 211/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.1747 - accuracy: 0.5990\n",
            "Epoch 211: val_accuracy did not improve from 0.62612\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.1739 - accuracy: 0.5998 - val_loss: 1.6108 - val_accuracy: 0.5045\n",
            "Epoch 212/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.2573 - accuracy: 0.5858\n",
            "Epoch 212: val_accuracy did not improve from 0.62612\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.2573 - accuracy: 0.5858 - val_loss: 1.2615 - val_accuracy: 0.6085\n",
            "Epoch 213/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.1640 - accuracy: 0.6077\n",
            "Epoch 213: val_accuracy did not improve from 0.62612\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.1643 - accuracy: 0.6080 - val_loss: 1.3080 - val_accuracy: 0.6053\n",
            "Epoch 214/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.1971 - accuracy: 0.5965\n",
            "Epoch 214: val_accuracy did not improve from 0.62612\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.1970 - accuracy: 0.5965 - val_loss: 1.3470 - val_accuracy: 0.5704\n",
            "Epoch 215/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.1127 - accuracy: 0.6200\n",
            "Epoch 215: val_accuracy did not improve from 0.62612\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.1123 - accuracy: 0.6201 - val_loss: 1.3415 - val_accuracy: 0.5771\n",
            "Epoch 216/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.2132 - accuracy: 0.5877\n",
            "Epoch 216: val_accuracy did not improve from 0.62612\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.2099 - accuracy: 0.5891 - val_loss: 1.3652 - val_accuracy: 0.5791\n",
            "Epoch 217/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.1695 - accuracy: 0.6024\n",
            "Epoch 217: val_accuracy did not improve from 0.62612\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.1733 - accuracy: 0.6019 - val_loss: 1.3300 - val_accuracy: 0.5807\n",
            "Epoch 218/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.2465 - accuracy: 0.5851\n",
            "Epoch 218: val_accuracy did not improve from 0.62612\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.2465 - accuracy: 0.5851 - val_loss: 1.8337 - val_accuracy: 0.4584\n",
            "Epoch 219/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.2075 - accuracy: 0.5965\n",
            "Epoch 219: val_accuracy did not improve from 0.62612\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.2094 - accuracy: 0.5961 - val_loss: 1.3461 - val_accuracy: 0.5919\n",
            "Epoch 220/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 1.1821 - accuracy: 0.6054\n",
            "Epoch 220: val_accuracy did not improve from 0.62612\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.1827 - accuracy: 0.6048 - val_loss: 1.3027 - val_accuracy: 0.6005\n",
            "Epoch 221/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.1776 - accuracy: 0.6041\n",
            "Epoch 221: val_accuracy did not improve from 0.62612\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.1776 - accuracy: 0.6041 - val_loss: 1.2520 - val_accuracy: 0.6181\n",
            "Epoch 222/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 1.1865 - accuracy: 0.6019\n",
            "Epoch 222: val_accuracy did not improve from 0.62612\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.1890 - accuracy: 0.6013 - val_loss: 1.6933 - val_accuracy: 0.5013\n",
            "Epoch 223/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.1170 - accuracy: 0.6184\n",
            "Epoch 223: val_accuracy did not improve from 0.62612\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.1162 - accuracy: 0.6185 - val_loss: 1.3324 - val_accuracy: 0.6034\n",
            "Epoch 224/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.1824 - accuracy: 0.6040\n",
            "Epoch 224: val_accuracy did not improve from 0.62612\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.1824 - accuracy: 0.6040 - val_loss: 1.6172 - val_accuracy: 0.5035\n",
            "Epoch 225/700\n",
            "385/391 [============================>.] - ETA: 0s - loss: 1.2014 - accuracy: 0.5972\n",
            "Epoch 225: val_accuracy did not improve from 0.62612\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.2031 - accuracy: 0.5968 - val_loss: 1.8738 - val_accuracy: 0.4811\n",
            "Epoch 226/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.1790 - accuracy: 0.6054\n",
            "Epoch 226: val_accuracy improved from 0.62612 to 0.63476, saving model to /content/asl/Adam2/cp-226-0.63.hdf5\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.1786 - accuracy: 0.6055 - val_loss: 1.2100 - val_accuracy: 0.6348\n",
            "Epoch 227/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 1.1478 - accuracy: 0.6139\n",
            "Epoch 227: val_accuracy did not improve from 0.63476\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.1479 - accuracy: 0.6137 - val_loss: 1.2482 - val_accuracy: 0.6300\n",
            "Epoch 228/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.1663 - accuracy: 0.6064\n",
            "Epoch 228: val_accuracy did not improve from 0.63476\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.1663 - accuracy: 0.6064 - val_loss: 1.2630 - val_accuracy: 0.6194\n",
            "Epoch 229/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.1041 - accuracy: 0.6199\n",
            "Epoch 229: val_accuracy did not improve from 0.63476\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.1041 - accuracy: 0.6199 - val_loss: 1.2707 - val_accuracy: 0.6223\n",
            "Epoch 230/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.1934 - accuracy: 0.5953\n",
            "Epoch 230: val_accuracy did not improve from 0.63476\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.1916 - accuracy: 0.5959 - val_loss: 1.2985 - val_accuracy: 0.5967\n",
            "Epoch 231/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.1457 - accuracy: 0.6117\n",
            "Epoch 231: val_accuracy did not improve from 0.63476\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.1459 - accuracy: 0.6116 - val_loss: 1.2077 - val_accuracy: 0.6287\n",
            "Epoch 232/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.1735 - accuracy: 0.6075\n",
            "Epoch 232: val_accuracy did not improve from 0.63476\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.1730 - accuracy: 0.6078 - val_loss: 1.3517 - val_accuracy: 0.5890\n",
            "Epoch 233/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.1389 - accuracy: 0.6143\n",
            "Epoch 233: val_accuracy did not improve from 0.63476\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.1367 - accuracy: 0.6149 - val_loss: 1.3534 - val_accuracy: 0.5880\n",
            "Epoch 234/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.2082 - accuracy: 0.5975\n",
            "Epoch 234: val_accuracy did not improve from 0.63476\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.2082 - accuracy: 0.5975 - val_loss: 1.3954 - val_accuracy: 0.5915\n",
            "Epoch 235/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.1224 - accuracy: 0.6202\n",
            "Epoch 235: val_accuracy did not improve from 0.63476\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.1248 - accuracy: 0.6193 - val_loss: 1.5644 - val_accuracy: 0.5115\n",
            "Epoch 236/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.2204 - accuracy: 0.5895\n",
            "Epoch 236: val_accuracy did not improve from 0.63476\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.2199 - accuracy: 0.5897 - val_loss: 1.2898 - val_accuracy: 0.6130\n",
            "Epoch 237/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.1989 - accuracy: 0.6001\n",
            "Epoch 237: val_accuracy did not improve from 0.63476\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.1989 - accuracy: 0.6002 - val_loss: 1.2782 - val_accuracy: 0.6226\n",
            "Epoch 238/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 1.0511 - accuracy: 0.6380\n",
            "Epoch 238: val_accuracy did not improve from 0.63476\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.0519 - accuracy: 0.6379 - val_loss: 1.2716 - val_accuracy: 0.6069\n",
            "Epoch 239/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.0913 - accuracy: 0.6255\n",
            "Epoch 239: val_accuracy improved from 0.63476 to 0.64020, saving model to /content/asl/Adam2/cp-239-0.64.hdf5\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.0914 - accuracy: 0.6253 - val_loss: 1.2022 - val_accuracy: 0.6402\n",
            "Epoch 240/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 1.1891 - accuracy: 0.5997\n",
            "Epoch 240: val_accuracy did not improve from 0.64020\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.1888 - accuracy: 0.5995 - val_loss: 1.4552 - val_accuracy: 0.5637\n",
            "Epoch 241/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.1872 - accuracy: 0.6035\n",
            "Epoch 241: val_accuracy did not improve from 0.64020\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.1870 - accuracy: 0.6034 - val_loss: 1.2624 - val_accuracy: 0.6063\n",
            "Epoch 242/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.1423 - accuracy: 0.6124\n",
            "Epoch 242: val_accuracy did not improve from 0.64020\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.1423 - accuracy: 0.6124 - val_loss: 1.6390 - val_accuracy: 0.5163\n",
            "Epoch 243/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 1.0926 - accuracy: 0.6272\n",
            "Epoch 243: val_accuracy did not improve from 0.64020\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.0932 - accuracy: 0.6272 - val_loss: 1.2523 - val_accuracy: 0.6194\n",
            "Epoch 244/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.2000 - accuracy: 0.6005\n",
            "Epoch 244: val_accuracy did not improve from 0.64020\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.1996 - accuracy: 0.6001 - val_loss: 1.3051 - val_accuracy: 0.5890\n",
            "Epoch 245/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.1187 - accuracy: 0.6232\n",
            "Epoch 245: val_accuracy did not improve from 0.64020\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.1187 - accuracy: 0.6230 - val_loss: 1.3379 - val_accuracy: 0.6002\n",
            "Epoch 246/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.0718 - accuracy: 0.6404\n",
            "Epoch 246: val_accuracy did not improve from 0.64020\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.0735 - accuracy: 0.6398 - val_loss: 1.2783 - val_accuracy: 0.6015\n",
            "Epoch 247/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.1218 - accuracy: 0.6225\n",
            "Epoch 247: val_accuracy did not improve from 0.64020\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.1198 - accuracy: 0.6228 - val_loss: 1.1987 - val_accuracy: 0.6261\n",
            "Epoch 248/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 1.2394 - accuracy: 0.5883\n",
            "Epoch 248: val_accuracy did not improve from 0.64020\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.2360 - accuracy: 0.5894 - val_loss: 1.2898 - val_accuracy: 0.6018\n",
            "Epoch 249/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.1557 - accuracy: 0.6105\n",
            "Epoch 249: val_accuracy did not improve from 0.64020\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.1550 - accuracy: 0.6108 - val_loss: 1.2597 - val_accuracy: 0.6079\n",
            "Epoch 250/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.2139 - accuracy: 0.5948\n",
            "Epoch 250: val_accuracy did not improve from 0.64020\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.2139 - accuracy: 0.5948 - val_loss: 1.2584 - val_accuracy: 0.6136\n",
            "Epoch 251/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.0570 - accuracy: 0.6377\n",
            "Epoch 251: val_accuracy did not improve from 0.64020\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.0557 - accuracy: 0.6382 - val_loss: 1.5288 - val_accuracy: 0.5323\n",
            "Epoch 252/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.1674 - accuracy: 0.6158\n",
            "Epoch 252: val_accuracy did not improve from 0.64020\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.1667 - accuracy: 0.6156 - val_loss: 1.3862 - val_accuracy: 0.5647\n",
            "Epoch 253/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.1151 - accuracy: 0.6205\n",
            "Epoch 253: val_accuracy did not improve from 0.64020\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.1145 - accuracy: 0.6207 - val_loss: 1.5965 - val_accuracy: 0.5128\n",
            "Epoch 254/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.0932 - accuracy: 0.6294\n",
            "Epoch 254: val_accuracy did not improve from 0.64020\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.0954 - accuracy: 0.6283 - val_loss: 1.1861 - val_accuracy: 0.6370\n",
            "Epoch 255/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.0692 - accuracy: 0.6353\n",
            "Epoch 255: val_accuracy did not improve from 0.64020\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.0698 - accuracy: 0.6350 - val_loss: 1.2506 - val_accuracy: 0.6156\n",
            "Epoch 256/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.1373 - accuracy: 0.6112\n",
            "Epoch 256: val_accuracy did not improve from 0.64020\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.1373 - accuracy: 0.6112 - val_loss: 1.2756 - val_accuracy: 0.5893\n",
            "Epoch 257/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0279 - accuracy: 0.6470\n",
            "Epoch 257: val_accuracy did not improve from 0.64020\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.0279 - accuracy: 0.6470 - val_loss: 1.3099 - val_accuracy: 0.5906\n",
            "Epoch 258/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.0746 - accuracy: 0.6322\n",
            "Epoch 258: val_accuracy did not improve from 0.64020\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.0758 - accuracy: 0.6318 - val_loss: 1.4045 - val_accuracy: 0.5765\n",
            "Epoch 259/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.0706 - accuracy: 0.6343\n",
            "Epoch 259: val_accuracy did not improve from 0.64020\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.0703 - accuracy: 0.6343 - val_loss: 1.2516 - val_accuracy: 0.6188\n",
            "Epoch 260/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.1832 - accuracy: 0.6050\n",
            "Epoch 260: val_accuracy did not improve from 0.64020\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.1835 - accuracy: 0.6049 - val_loss: 1.2070 - val_accuracy: 0.6290\n",
            "Epoch 261/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 1.0803 - accuracy: 0.6305\n",
            "Epoch 261: val_accuracy did not improve from 0.64020\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.0852 - accuracy: 0.6296 - val_loss: 1.3234 - val_accuracy: 0.6021\n",
            "Epoch 262/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.1041 - accuracy: 0.6288\n",
            "Epoch 262: val_accuracy did not improve from 0.64020\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.1046 - accuracy: 0.6288 - val_loss: 1.2465 - val_accuracy: 0.6248\n",
            "Epoch 263/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 1.0694 - accuracy: 0.6318\n",
            "Epoch 263: val_accuracy did not improve from 0.64020\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.0695 - accuracy: 0.6318 - val_loss: 1.6798 - val_accuracy: 0.5090\n",
            "Epoch 264/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.0511 - accuracy: 0.6409\n",
            "Epoch 264: val_accuracy did not improve from 0.64020\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.0510 - accuracy: 0.6410 - val_loss: 1.5307 - val_accuracy: 0.5442\n",
            "Epoch 265/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.1124 - accuracy: 0.6230\n",
            "Epoch 265: val_accuracy did not improve from 0.64020\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.1124 - accuracy: 0.6230 - val_loss: 1.2909 - val_accuracy: 0.5954\n",
            "Epoch 266/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.0843 - accuracy: 0.6316\n",
            "Epoch 266: val_accuracy did not improve from 0.64020\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.0823 - accuracy: 0.6323 - val_loss: 1.2310 - val_accuracy: 0.6386\n",
            "Epoch 267/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.1162 - accuracy: 0.6212\n",
            "Epoch 267: val_accuracy did not improve from 0.64020\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.1162 - accuracy: 0.6212 - val_loss: 1.1881 - val_accuracy: 0.6399\n",
            "Epoch 268/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.1022 - accuracy: 0.6302\n",
            "Epoch 268: val_accuracy did not improve from 0.64020\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.0999 - accuracy: 0.6309 - val_loss: 1.5655 - val_accuracy: 0.5419\n",
            "Epoch 269/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 1.0615 - accuracy: 0.6398\n",
            "Epoch 269: val_accuracy improved from 0.64020 to 0.64341, saving model to /content/asl/Adam2/cp-269-0.64.hdf5\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.0598 - accuracy: 0.6407 - val_loss: 1.1751 - val_accuracy: 0.6434\n",
            "Epoch 270/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.0385 - accuracy: 0.6450\n",
            "Epoch 270: val_accuracy did not improve from 0.64341\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.0378 - accuracy: 0.6453 - val_loss: 1.2195 - val_accuracy: 0.6156\n",
            "Epoch 271/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.1276 - accuracy: 0.6220\n",
            "Epoch 271: val_accuracy did not improve from 0.64341\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.1278 - accuracy: 0.6218 - val_loss: 1.2153 - val_accuracy: 0.6271\n",
            "Epoch 272/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.0342 - accuracy: 0.6491\n",
            "Epoch 272: val_accuracy improved from 0.64341 to 0.65429, saving model to /content/asl/Adam2/cp-272-0.65.hdf5\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.0334 - accuracy: 0.6496 - val_loss: 1.1704 - val_accuracy: 0.6543\n",
            "Epoch 273/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.1635 - accuracy: 0.6098\n",
            "Epoch 273: val_accuracy did not improve from 0.65429\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.1635 - accuracy: 0.6098 - val_loss: 1.3607 - val_accuracy: 0.5723\n",
            "Epoch 274/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.0321 - accuracy: 0.6430\n",
            "Epoch 274: val_accuracy did not improve from 0.65429\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.0323 - accuracy: 0.6429 - val_loss: 1.2426 - val_accuracy: 0.6143\n",
            "Epoch 275/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.0533 - accuracy: 0.6392\n",
            "Epoch 275: val_accuracy improved from 0.65429 to 0.65813, saving model to /content/asl/Adam2/cp-275-0.66.hdf5\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.0522 - accuracy: 0.6395 - val_loss: 1.1385 - val_accuracy: 0.6581\n",
            "Epoch 276/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.0961 - accuracy: 0.6255\n",
            "Epoch 276: val_accuracy did not improve from 0.65813\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.0989 - accuracy: 0.6244 - val_loss: 1.3264 - val_accuracy: 0.5986\n",
            "Epoch 277/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0692 - accuracy: 0.6382\n",
            "Epoch 277: val_accuracy did not improve from 0.65813\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.0692 - accuracy: 0.6382 - val_loss: 1.2151 - val_accuracy: 0.6520\n",
            "Epoch 278/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.0228 - accuracy: 0.6461\n",
            "Epoch 278: val_accuracy did not improve from 0.65813\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.0231 - accuracy: 0.6460 - val_loss: 1.1455 - val_accuracy: 0.6543\n",
            "Epoch 279/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0945 - accuracy: 0.6272\n",
            "Epoch 279: val_accuracy did not improve from 0.65813\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.0945 - accuracy: 0.6272 - val_loss: 1.1642 - val_accuracy: 0.6463\n",
            "Epoch 280/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0923 - accuracy: 0.6295\n",
            "Epoch 280: val_accuracy did not improve from 0.65813\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.0923 - accuracy: 0.6295 - val_loss: 1.4264 - val_accuracy: 0.5711\n",
            "Epoch 281/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.0052 - accuracy: 0.6537\n",
            "Epoch 281: val_accuracy did not improve from 0.65813\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.0047 - accuracy: 0.6538 - val_loss: 1.8897 - val_accuracy: 0.4651\n",
            "Epoch 282/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.0745 - accuracy: 0.6329\n",
            "Epoch 282: val_accuracy did not improve from 0.65813\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.0729 - accuracy: 0.6334 - val_loss: 1.2076 - val_accuracy: 0.6332\n",
            "Epoch 283/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.0625 - accuracy: 0.6383\n",
            "Epoch 283: val_accuracy did not improve from 0.65813\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.0622 - accuracy: 0.6384 - val_loss: 1.2058 - val_accuracy: 0.6504\n",
            "Epoch 284/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0373 - accuracy: 0.6465\n",
            "Epoch 284: val_accuracy did not improve from 0.65813\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.0373 - accuracy: 0.6465 - val_loss: 1.4827 - val_accuracy: 0.5487\n",
            "Epoch 285/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.0785 - accuracy: 0.6349\n",
            "Epoch 285: val_accuracy did not improve from 0.65813\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.0781 - accuracy: 0.6351 - val_loss: 1.3260 - val_accuracy: 0.5941\n",
            "Epoch 286/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.0636 - accuracy: 0.6425\n",
            "Epoch 286: val_accuracy did not improve from 0.65813\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.0634 - accuracy: 0.6427 - val_loss: 1.2286 - val_accuracy: 0.6239\n",
            "Epoch 287/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0422 - accuracy: 0.6460\n",
            "Epoch 287: val_accuracy did not improve from 0.65813\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.0422 - accuracy: 0.6460 - val_loss: 1.2890 - val_accuracy: 0.6053\n",
            "Epoch 288/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.0277 - accuracy: 0.6431\n",
            "Epoch 288: val_accuracy improved from 0.65813 to 0.66517, saving model to /content/asl/Adam2/cp-288-0.67.hdf5\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.0275 - accuracy: 0.6432 - val_loss: 1.1199 - val_accuracy: 0.6652\n",
            "Epoch 289/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0045 - accuracy: 0.6575\n",
            "Epoch 289: val_accuracy did not improve from 0.66517\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.0045 - accuracy: 0.6575 - val_loss: 1.3022 - val_accuracy: 0.6034\n",
            "Epoch 290/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.0438 - accuracy: 0.6423\n",
            "Epoch 290: val_accuracy did not improve from 0.66517\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.0435 - accuracy: 0.6424 - val_loss: 2.4571 - val_accuracy: 0.3924\n",
            "Epoch 291/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.0464 - accuracy: 0.6363\n",
            "Epoch 291: val_accuracy did not improve from 0.66517\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.0470 - accuracy: 0.6362 - val_loss: 1.2837 - val_accuracy: 0.6140\n",
            "Epoch 292/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.0248 - accuracy: 0.6538\n",
            "Epoch 292: val_accuracy did not improve from 0.66517\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.0253 - accuracy: 0.6538 - val_loss: 1.2045 - val_accuracy: 0.6312\n",
            "Epoch 293/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.0457 - accuracy: 0.6441\n",
            "Epoch 293: val_accuracy did not improve from 0.66517\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.0453 - accuracy: 0.6440 - val_loss: 1.1438 - val_accuracy: 0.6581\n",
            "Epoch 294/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0095 - accuracy: 0.6521\n",
            "Epoch 294: val_accuracy did not improve from 0.66517\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.0095 - accuracy: 0.6521 - val_loss: 1.4944 - val_accuracy: 0.5618\n",
            "Epoch 295/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.0362 - accuracy: 0.6482\n",
            "Epoch 295: val_accuracy did not improve from 0.66517\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.0389 - accuracy: 0.6475 - val_loss: 1.7814 - val_accuracy: 0.4971\n",
            "Epoch 296/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.0045 - accuracy: 0.6561\n",
            "Epoch 296: val_accuracy did not improve from 0.66517\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.0032 - accuracy: 0.6565 - val_loss: 1.4071 - val_accuracy: 0.5755\n",
            "Epoch 297/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.0182 - accuracy: 0.6521\n",
            "Epoch 297: val_accuracy did not improve from 0.66517\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.0198 - accuracy: 0.6519 - val_loss: 2.3359 - val_accuracy: 0.4043\n",
            "Epoch 298/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.0999 - accuracy: 0.6302\n",
            "Epoch 298: val_accuracy did not improve from 0.66517\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.1007 - accuracy: 0.6296 - val_loss: 1.4739 - val_accuracy: 0.5515\n",
            "Epoch 299/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.9740 - accuracy: 0.6617\n",
            "Epoch 299: val_accuracy did not improve from 0.66517\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.9738 - accuracy: 0.6621 - val_loss: 1.1525 - val_accuracy: 0.6591\n",
            "Epoch 300/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.9922 - accuracy: 0.6659\n",
            "Epoch 300: val_accuracy did not improve from 0.66517\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.9911 - accuracy: 0.6658 - val_loss: 1.2512 - val_accuracy: 0.6146\n",
            "Epoch 301/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0212 - accuracy: 0.6512\n",
            "Epoch 301: val_accuracy did not improve from 0.66517\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.0212 - accuracy: 0.6512 - val_loss: 1.1142 - val_accuracy: 0.6591\n",
            "Epoch 302/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.0550 - accuracy: 0.6474\n",
            "Epoch 302: val_accuracy did not improve from 0.66517\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.0559 - accuracy: 0.6471 - val_loss: 1.2029 - val_accuracy: 0.6306\n",
            "Epoch 303/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.9839 - accuracy: 0.6655\n",
            "Epoch 303: val_accuracy did not improve from 0.66517\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.9847 - accuracy: 0.6653 - val_loss: 1.1852 - val_accuracy: 0.6463\n",
            "Epoch 304/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.0215 - accuracy: 0.6520\n",
            "Epoch 304: val_accuracy did not improve from 0.66517\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.0223 - accuracy: 0.6517 - val_loss: 1.1921 - val_accuracy: 0.6364\n",
            "Epoch 305/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.9947 - accuracy: 0.6553\n",
            "Epoch 305: val_accuracy did not improve from 0.66517\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.9949 - accuracy: 0.6557 - val_loss: 1.3191 - val_accuracy: 0.6095\n",
            "Epoch 306/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.9298 - accuracy: 0.6814\n",
            "Epoch 306: val_accuracy did not improve from 0.66517\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.9292 - accuracy: 0.6813 - val_loss: 1.1430 - val_accuracy: 0.6543\n",
            "Epoch 307/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.9865 - accuracy: 0.6676\n",
            "Epoch 307: val_accuracy did not improve from 0.66517\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.9859 - accuracy: 0.6672 - val_loss: 1.1339 - val_accuracy: 0.6604\n",
            "Epoch 308/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0501 - accuracy: 0.6538\n",
            "Epoch 308: val_accuracy improved from 0.66517 to 0.67061, saving model to /content/asl/Adam2/cp-308-0.67.hdf5\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.0501 - accuracy: 0.6538 - val_loss: 1.1216 - val_accuracy: 0.6706\n",
            "Epoch 309/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0617 - accuracy: 0.6397\n",
            "Epoch 309: val_accuracy did not improve from 0.67061\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.0617 - accuracy: 0.6397 - val_loss: 1.9571 - val_accuracy: 0.4533\n",
            "Epoch 310/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9579 - accuracy: 0.6704\n",
            "Epoch 310: val_accuracy improved from 0.67061 to 0.68566, saving model to /content/asl/Adam2/cp-310-0.69.hdf5\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.9579 - accuracy: 0.6704 - val_loss: 1.0717 - val_accuracy: 0.6857\n",
            "Epoch 311/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.0128 - accuracy: 0.6561\n",
            "Epoch 311: val_accuracy did not improve from 0.68566\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.0131 - accuracy: 0.6563 - val_loss: 1.1752 - val_accuracy: 0.6389\n",
            "Epoch 312/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9681 - accuracy: 0.6628\n",
            "Epoch 312: val_accuracy did not improve from 0.68566\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.9681 - accuracy: 0.6628 - val_loss: 1.2491 - val_accuracy: 0.6405\n",
            "Epoch 313/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.0070 - accuracy: 0.6551\n",
            "Epoch 313: val_accuracy improved from 0.68566 to 0.68822, saving model to /content/asl/Adam2/cp-313-0.69.hdf5\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.0062 - accuracy: 0.6553 - val_loss: 1.0807 - val_accuracy: 0.6882\n",
            "Epoch 314/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.9835 - accuracy: 0.6624\n",
            "Epoch 314: val_accuracy did not improve from 0.68822\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.9830 - accuracy: 0.6626 - val_loss: 1.5404 - val_accuracy: 0.5423\n",
            "Epoch 315/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0086 - accuracy: 0.6549\n",
            "Epoch 315: val_accuracy did not improve from 0.68822\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.0086 - accuracy: 0.6549 - val_loss: 1.2335 - val_accuracy: 0.6258\n",
            "Epoch 316/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0308 - accuracy: 0.6520\n",
            "Epoch 316: val_accuracy did not improve from 0.68822\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.0308 - accuracy: 0.6520 - val_loss: 1.1477 - val_accuracy: 0.6613\n",
            "Epoch 317/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9242 - accuracy: 0.6764\n",
            "Epoch 317: val_accuracy did not improve from 0.68822\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.9242 - accuracy: 0.6764 - val_loss: 1.1889 - val_accuracy: 0.6325\n",
            "Epoch 318/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 1.0674 - accuracy: 0.6455\n",
            "Epoch 318: val_accuracy did not improve from 0.68822\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.0667 - accuracy: 0.6457 - val_loss: 1.4306 - val_accuracy: 0.5666\n",
            "Epoch 319/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.9697 - accuracy: 0.6660\n",
            "Epoch 319: val_accuracy did not improve from 0.68822\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.9698 - accuracy: 0.6658 - val_loss: 1.0859 - val_accuracy: 0.6719\n",
            "Epoch 320/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 1.0087 - accuracy: 0.6614\n",
            "Epoch 320: val_accuracy did not improve from 0.68822\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.0088 - accuracy: 0.6609 - val_loss: 1.1681 - val_accuracy: 0.6543\n",
            "Epoch 321/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9072 - accuracy: 0.6836\n",
            "Epoch 321: val_accuracy did not improve from 0.68822\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.9072 - accuracy: 0.6836 - val_loss: 1.7116 - val_accuracy: 0.5365\n",
            "Epoch 322/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.0737 - accuracy: 0.6421\n",
            "Epoch 322: val_accuracy did not improve from 0.68822\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.0751 - accuracy: 0.6418 - val_loss: 1.5065 - val_accuracy: 0.5714\n",
            "Epoch 323/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.9573 - accuracy: 0.6756\n",
            "Epoch 323: val_accuracy did not improve from 0.68822\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.9588 - accuracy: 0.6752 - val_loss: 1.4098 - val_accuracy: 0.5845\n",
            "Epoch 324/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.9637 - accuracy: 0.6694\n",
            "Epoch 324: val_accuracy did not improve from 0.68822\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.9621 - accuracy: 0.6700 - val_loss: 1.1970 - val_accuracy: 0.6460\n",
            "Epoch 325/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.9486 - accuracy: 0.6715\n",
            "Epoch 325: val_accuracy did not improve from 0.68822\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.9490 - accuracy: 0.6713 - val_loss: 2.3880 - val_accuracy: 0.4235\n",
            "Epoch 326/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.0546 - accuracy: 0.6424\n",
            "Epoch 326: val_accuracy did not improve from 0.68822\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.0541 - accuracy: 0.6425 - val_loss: 1.2226 - val_accuracy: 0.6373\n",
            "Epoch 327/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.9532 - accuracy: 0.6699\n",
            "Epoch 327: val_accuracy did not improve from 0.68822\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.9532 - accuracy: 0.6699 - val_loss: 1.1880 - val_accuracy: 0.6418\n",
            "Epoch 328/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 1.0318 - accuracy: 0.6561\n",
            "Epoch 328: val_accuracy did not improve from 0.68822\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.0356 - accuracy: 0.6545 - val_loss: 1.5167 - val_accuracy: 0.5499\n",
            "Epoch 329/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.9083 - accuracy: 0.6823\n",
            "Epoch 329: val_accuracy did not improve from 0.68822\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.9082 - accuracy: 0.6824 - val_loss: 1.2026 - val_accuracy: 0.6421\n",
            "Epoch 330/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.0380 - accuracy: 0.6521\n",
            "Epoch 330: val_accuracy did not improve from 0.68822\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.0370 - accuracy: 0.6525 - val_loss: 1.2482 - val_accuracy: 0.6236\n",
            "Epoch 331/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9506 - accuracy: 0.6726\n",
            "Epoch 331: val_accuracy did not improve from 0.68822\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.9506 - accuracy: 0.6726 - val_loss: 1.0941 - val_accuracy: 0.6610\n",
            "Epoch 332/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.9585 - accuracy: 0.6719\n",
            "Epoch 332: val_accuracy did not improve from 0.68822\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.9604 - accuracy: 0.6715 - val_loss: 1.8352 - val_accuracy: 0.4974\n",
            "Epoch 333/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9821 - accuracy: 0.6653\n",
            "Epoch 333: val_accuracy did not improve from 0.68822\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.9821 - accuracy: 0.6653 - val_loss: 1.0947 - val_accuracy: 0.6677\n",
            "Epoch 334/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.9272 - accuracy: 0.6844\n",
            "Epoch 334: val_accuracy did not improve from 0.68822\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.9277 - accuracy: 0.6842 - val_loss: 1.6377 - val_accuracy: 0.5310\n",
            "Epoch 335/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.8988 - accuracy: 0.6869\n",
            "Epoch 335: val_accuracy did not improve from 0.68822\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.8995 - accuracy: 0.6861 - val_loss: 1.1411 - val_accuracy: 0.6472\n",
            "Epoch 336/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 1.0578 - accuracy: 0.6476\n",
            "Epoch 336: val_accuracy did not improve from 0.68822\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.0573 - accuracy: 0.6477 - val_loss: 1.1279 - val_accuracy: 0.6757\n",
            "Epoch 337/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.9026 - accuracy: 0.6849\n",
            "Epoch 337: val_accuracy did not improve from 0.68822\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.9025 - accuracy: 0.6849 - val_loss: 1.2758 - val_accuracy: 0.6300\n",
            "Epoch 338/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8829 - accuracy: 0.6937\n",
            "Epoch 338: val_accuracy did not improve from 0.68822\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.8829 - accuracy: 0.6937 - val_loss: 1.3174 - val_accuracy: 0.6207\n",
            "Epoch 339/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9556 - accuracy: 0.6746\n",
            "Epoch 339: val_accuracy did not improve from 0.68822\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.9556 - accuracy: 0.6746 - val_loss: 1.1093 - val_accuracy: 0.6658\n",
            "Epoch 340/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.9283 - accuracy: 0.6829\n",
            "Epoch 340: val_accuracy did not improve from 0.68822\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.9283 - accuracy: 0.6830 - val_loss: 1.6561 - val_accuracy: 0.5461\n",
            "Epoch 341/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.9585 - accuracy: 0.6707\n",
            "Epoch 341: val_accuracy did not improve from 0.68822\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.9572 - accuracy: 0.6712 - val_loss: 1.1524 - val_accuracy: 0.6620\n",
            "Epoch 342/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9475 - accuracy: 0.6728\n",
            "Epoch 342: val_accuracy did not improve from 0.68822\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.9475 - accuracy: 0.6728 - val_loss: 1.1646 - val_accuracy: 0.6530\n",
            "Epoch 343/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.9150 - accuracy: 0.6791\n",
            "Epoch 343: val_accuracy did not improve from 0.68822\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.9154 - accuracy: 0.6789 - val_loss: 1.3595 - val_accuracy: 0.6008\n",
            "Epoch 344/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.9587 - accuracy: 0.6768\n",
            "Epoch 344: val_accuracy did not improve from 0.68822\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.9583 - accuracy: 0.6769 - val_loss: 1.3194 - val_accuracy: 0.6152\n",
            "Epoch 345/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.0277 - accuracy: 0.6588\n",
            "Epoch 345: val_accuracy did not improve from 0.68822\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.0272 - accuracy: 0.6592 - val_loss: 1.0931 - val_accuracy: 0.6681\n",
            "Epoch 346/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.9262 - accuracy: 0.6824\n",
            "Epoch 346: val_accuracy did not improve from 0.68822\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.9263 - accuracy: 0.6821 - val_loss: 1.1758 - val_accuracy: 0.6437\n",
            "Epoch 347/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9512 - accuracy: 0.6712\n",
            "Epoch 347: val_accuracy did not improve from 0.68822\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.9512 - accuracy: 0.6712 - val_loss: 1.2923 - val_accuracy: 0.6200\n",
            "Epoch 348/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.9596 - accuracy: 0.6693\n",
            "Epoch 348: val_accuracy did not improve from 0.68822\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.9572 - accuracy: 0.6701 - val_loss: 1.0755 - val_accuracy: 0.6815\n",
            "Epoch 349/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.9815 - accuracy: 0.6683\n",
            "Epoch 349: val_accuracy did not improve from 0.68822\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.9818 - accuracy: 0.6679 - val_loss: 1.1544 - val_accuracy: 0.6658\n",
            "Epoch 350/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.8997 - accuracy: 0.6901\n",
            "Epoch 350: val_accuracy improved from 0.68822 to 0.70294, saving model to /content/asl/Adam2/cp-350-0.70.hdf5\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.8999 - accuracy: 0.6901 - val_loss: 1.0530 - val_accuracy: 0.7029\n",
            "Epoch 351/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.9731 - accuracy: 0.6739\n",
            "Epoch 351: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.9742 - accuracy: 0.6737 - val_loss: 1.1759 - val_accuracy: 0.6453\n",
            "Epoch 352/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.8637 - accuracy: 0.6933\n",
            "Epoch 352: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8639 - accuracy: 0.6932 - val_loss: 1.3280 - val_accuracy: 0.6101\n",
            "Epoch 353/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.9786 - accuracy: 0.6637\n",
            "Epoch 353: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.9811 - accuracy: 0.6627 - val_loss: 1.4714 - val_accuracy: 0.5656\n",
            "Epoch 354/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9681 - accuracy: 0.6647\n",
            "Epoch 354: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.9681 - accuracy: 0.6647 - val_loss: 1.4114 - val_accuracy: 0.5944\n",
            "Epoch 355/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9548 - accuracy: 0.6735\n",
            "Epoch 355: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.9548 - accuracy: 0.6735 - val_loss: 2.0334 - val_accuracy: 0.4741\n",
            "Epoch 356/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.9177 - accuracy: 0.6880\n",
            "Epoch 356: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.9177 - accuracy: 0.6876 - val_loss: 1.3446 - val_accuracy: 0.6076\n",
            "Epoch 357/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9489 - accuracy: 0.6785\n",
            "Epoch 357: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.9489 - accuracy: 0.6785 - val_loss: 1.1636 - val_accuracy: 0.6629\n",
            "Epoch 358/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.9537 - accuracy: 0.6708\n",
            "Epoch 358: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.9539 - accuracy: 0.6705 - val_loss: 1.0712 - val_accuracy: 0.6943\n",
            "Epoch 359/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.8530 - accuracy: 0.6985\n",
            "Epoch 359: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.8534 - accuracy: 0.6985 - val_loss: 1.0505 - val_accuracy: 0.6879\n",
            "Epoch 360/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 1.0242 - accuracy: 0.6506\n",
            "Epoch 360: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.0243 - accuracy: 0.6501 - val_loss: 1.1670 - val_accuracy: 0.6524\n",
            "Epoch 361/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.9689 - accuracy: 0.6764\n",
            "Epoch 361: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.9691 - accuracy: 0.6764 - val_loss: 1.1296 - val_accuracy: 0.6684\n",
            "Epoch 362/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.8793 - accuracy: 0.6935\n",
            "Epoch 362: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.8813 - accuracy: 0.6929 - val_loss: 1.2447 - val_accuracy: 0.6332\n",
            "Epoch 363/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.9587 - accuracy: 0.6733\n",
            "Epoch 363: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.9568 - accuracy: 0.6738 - val_loss: 1.1889 - val_accuracy: 0.6447\n",
            "Epoch 364/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.9605 - accuracy: 0.6712\n",
            "Epoch 364: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.9601 - accuracy: 0.6712 - val_loss: 1.0402 - val_accuracy: 0.6975\n",
            "Epoch 365/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.9667 - accuracy: 0.6718\n",
            "Epoch 365: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.9653 - accuracy: 0.6721 - val_loss: 1.1202 - val_accuracy: 0.6709\n",
            "Epoch 366/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.8738 - accuracy: 0.6959\n",
            "Epoch 366: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.8760 - accuracy: 0.6949 - val_loss: 1.6502 - val_accuracy: 0.5320\n",
            "Epoch 367/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.8576 - accuracy: 0.7011\n",
            "Epoch 367: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8580 - accuracy: 0.7010 - val_loss: 1.1357 - val_accuracy: 0.6693\n",
            "Epoch 368/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.9730 - accuracy: 0.6638\n",
            "Epoch 368: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.9744 - accuracy: 0.6641 - val_loss: 1.1301 - val_accuracy: 0.6751\n",
            "Epoch 369/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.9608 - accuracy: 0.6772\n",
            "Epoch 369: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.9679 - accuracy: 0.6762 - val_loss: 2.3977 - val_accuracy: 0.4107\n",
            "Epoch 370/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.9023 - accuracy: 0.6869\n",
            "Epoch 370: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.9009 - accuracy: 0.6874 - val_loss: 1.2834 - val_accuracy: 0.6194\n",
            "Epoch 371/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.9202 - accuracy: 0.6805\n",
            "Epoch 371: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.9204 - accuracy: 0.6802 - val_loss: 1.1799 - val_accuracy: 0.6543\n",
            "Epoch 372/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.9134 - accuracy: 0.6804\n",
            "Epoch 372: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.9146 - accuracy: 0.6799 - val_loss: 1.0660 - val_accuracy: 0.6831\n",
            "Epoch 373/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.8971 - accuracy: 0.6930\n",
            "Epoch 373: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.8963 - accuracy: 0.6936 - val_loss: 1.1013 - val_accuracy: 0.6761\n",
            "Epoch 374/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.8814 - accuracy: 0.6937\n",
            "Epoch 374: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8780 - accuracy: 0.6947 - val_loss: 1.1032 - val_accuracy: 0.6844\n",
            "Epoch 375/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.9045 - accuracy: 0.6930\n",
            "Epoch 375: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.9057 - accuracy: 0.6926 - val_loss: 1.2562 - val_accuracy: 0.6348\n",
            "Epoch 376/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9394 - accuracy: 0.6774\n",
            "Epoch 376: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.9394 - accuracy: 0.6774 - val_loss: 1.1412 - val_accuracy: 0.6748\n",
            "Epoch 377/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.8762 - accuracy: 0.6982\n",
            "Epoch 377: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8784 - accuracy: 0.6977 - val_loss: 1.4883 - val_accuracy: 0.5759\n",
            "Epoch 378/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.8787 - accuracy: 0.6964\n",
            "Epoch 378: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.8786 - accuracy: 0.6961 - val_loss: 1.1581 - val_accuracy: 0.6668\n",
            "Epoch 379/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8617 - accuracy: 0.7015\n",
            "Epoch 379: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.8617 - accuracy: 0.7015 - val_loss: 1.4439 - val_accuracy: 0.6085\n",
            "Epoch 380/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 1.0161 - accuracy: 0.6562\n",
            "Epoch 380: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.0157 - accuracy: 0.6564 - val_loss: 1.0978 - val_accuracy: 0.6658\n",
            "Epoch 381/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.9227 - accuracy: 0.6874\n",
            "Epoch 381: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.9228 - accuracy: 0.6872 - val_loss: 1.3446 - val_accuracy: 0.6040\n",
            "Epoch 382/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.8626 - accuracy: 0.7009\n",
            "Epoch 382: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.8625 - accuracy: 0.7009 - val_loss: 2.3644 - val_accuracy: 0.4395\n",
            "Epoch 383/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.9461 - accuracy: 0.6763\n",
            "Epoch 383: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.9456 - accuracy: 0.6766 - val_loss: 1.0637 - val_accuracy: 0.6863\n",
            "Epoch 384/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.9502 - accuracy: 0.6771\n",
            "Epoch 384: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.9479 - accuracy: 0.6783 - val_loss: 1.1639 - val_accuracy: 0.6623\n",
            "Epoch 385/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8220 - accuracy: 0.7117\n",
            "Epoch 385: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.8220 - accuracy: 0.7117 - val_loss: 1.1831 - val_accuracy: 0.6533\n",
            "Epoch 386/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 1.0273 - accuracy: 0.6601\n",
            "Epoch 386: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 1.0227 - accuracy: 0.6614 - val_loss: 1.0353 - val_accuracy: 0.6930\n",
            "Epoch 387/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.8270 - accuracy: 0.7095\n",
            "Epoch 387: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8270 - accuracy: 0.7097 - val_loss: 1.0934 - val_accuracy: 0.6783\n",
            "Epoch 388/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.8251 - accuracy: 0.7113\n",
            "Epoch 388: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.8255 - accuracy: 0.7112 - val_loss: 1.0400 - val_accuracy: 0.6994\n",
            "Epoch 389/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9270 - accuracy: 0.6789\n",
            "Epoch 389: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.9270 - accuracy: 0.6789 - val_loss: 1.3202 - val_accuracy: 0.6140\n",
            "Epoch 390/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.9116 - accuracy: 0.6824\n",
            "Epoch 390: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.9113 - accuracy: 0.6826 - val_loss: 1.6071 - val_accuracy: 0.5522\n",
            "Epoch 391/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8384 - accuracy: 0.7057\n",
            "Epoch 391: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.8384 - accuracy: 0.7057 - val_loss: 1.3918 - val_accuracy: 0.6060\n",
            "Epoch 392/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.8979 - accuracy: 0.6837\n",
            "Epoch 392: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.8958 - accuracy: 0.6843 - val_loss: 1.1282 - val_accuracy: 0.6716\n",
            "Epoch 393/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8815 - accuracy: 0.6921\n",
            "Epoch 393: val_accuracy did not improve from 0.70294\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8815 - accuracy: 0.6921 - val_loss: 1.1023 - val_accuracy: 0.6882\n",
            "Epoch 394/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.9167 - accuracy: 0.6888\n",
            "Epoch 394: val_accuracy improved from 0.70294 to 0.70391, saving model to /content/asl/Adam2/cp-394-0.70.hdf5\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.9164 - accuracy: 0.6889 - val_loss: 1.0409 - val_accuracy: 0.7039\n",
            "Epoch 395/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.8532 - accuracy: 0.7070\n",
            "Epoch 395: val_accuracy did not improve from 0.70391\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.8524 - accuracy: 0.7072 - val_loss: 1.0654 - val_accuracy: 0.6927\n",
            "Epoch 396/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.8937 - accuracy: 0.6899\n",
            "Epoch 396: val_accuracy did not improve from 0.70391\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8927 - accuracy: 0.6901 - val_loss: 1.2720 - val_accuracy: 0.6226\n",
            "Epoch 397/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.9091 - accuracy: 0.6871\n",
            "Epoch 397: val_accuracy did not improve from 0.70391\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.9079 - accuracy: 0.6872 - val_loss: 1.1044 - val_accuracy: 0.6860\n",
            "Epoch 398/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8977 - accuracy: 0.6877\n",
            "Epoch 398: val_accuracy did not improve from 0.70391\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.8977 - accuracy: 0.6877 - val_loss: 1.4326 - val_accuracy: 0.5835\n",
            "Epoch 399/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.8331 - accuracy: 0.7063\n",
            "Epoch 399: val_accuracy did not improve from 0.70391\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8330 - accuracy: 0.7063 - val_loss: 1.2023 - val_accuracy: 0.6645\n",
            "Epoch 400/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8289 - accuracy: 0.7069\n",
            "Epoch 400: val_accuracy did not improve from 0.70391\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.8289 - accuracy: 0.7069 - val_loss: 1.2003 - val_accuracy: 0.6629\n",
            "Epoch 401/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.9012 - accuracy: 0.6865\n",
            "Epoch 401: val_accuracy did not improve from 0.70391\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.9006 - accuracy: 0.6865 - val_loss: 1.0899 - val_accuracy: 0.6898\n",
            "Epoch 402/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.8658 - accuracy: 0.6960\n",
            "Epoch 402: val_accuracy did not improve from 0.70391\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8641 - accuracy: 0.6965 - val_loss: 1.0715 - val_accuracy: 0.6975\n",
            "Epoch 403/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.9071 - accuracy: 0.6864\n",
            "Epoch 403: val_accuracy did not improve from 0.70391\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.9068 - accuracy: 0.6865 - val_loss: 1.2415 - val_accuracy: 0.6428\n",
            "Epoch 404/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.8503 - accuracy: 0.7070\n",
            "Epoch 404: val_accuracy did not improve from 0.70391\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.8505 - accuracy: 0.7068 - val_loss: 1.1179 - val_accuracy: 0.6661\n",
            "Epoch 405/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8374 - accuracy: 0.7058\n",
            "Epoch 405: val_accuracy did not improve from 0.70391\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.8374 - accuracy: 0.7058 - val_loss: 1.0966 - val_accuracy: 0.6876\n",
            "Epoch 406/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.8767 - accuracy: 0.6966\n",
            "Epoch 406: val_accuracy improved from 0.70391 to 0.70743, saving model to /content/asl/Adam2/cp-406-0.71.hdf5\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.8753 - accuracy: 0.6972 - val_loss: 1.0395 - val_accuracy: 0.7074\n",
            "Epoch 407/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.8738 - accuracy: 0.6994\n",
            "Epoch 407: val_accuracy did not improve from 0.70743\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.8746 - accuracy: 0.6991 - val_loss: 1.8940 - val_accuracy: 0.4997\n",
            "Epoch 408/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.9183 - accuracy: 0.6860\n",
            "Epoch 408: val_accuracy did not improve from 0.70743\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.9165 - accuracy: 0.6864 - val_loss: 1.1288 - val_accuracy: 0.6674\n",
            "Epoch 409/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8227 - accuracy: 0.7137\n",
            "Epoch 409: val_accuracy did not improve from 0.70743\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8227 - accuracy: 0.7137 - val_loss: 1.3889 - val_accuracy: 0.6012\n",
            "Epoch 410/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.8673 - accuracy: 0.7031\n",
            "Epoch 410: val_accuracy did not improve from 0.70743\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.8652 - accuracy: 0.7035 - val_loss: 1.2619 - val_accuracy: 0.6386\n",
            "Epoch 411/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.8281 - accuracy: 0.7077\n",
            "Epoch 411: val_accuracy did not improve from 0.70743\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.8288 - accuracy: 0.7072 - val_loss: 1.1456 - val_accuracy: 0.6818\n",
            "Epoch 412/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.8608 - accuracy: 0.6989\n",
            "Epoch 412: val_accuracy did not improve from 0.70743\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8642 - accuracy: 0.6985 - val_loss: 1.4486 - val_accuracy: 0.5864\n",
            "Epoch 413/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.9035 - accuracy: 0.6893\n",
            "Epoch 413: val_accuracy did not improve from 0.70743\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.9067 - accuracy: 0.6884 - val_loss: 1.5703 - val_accuracy: 0.5416\n",
            "Epoch 414/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8884 - accuracy: 0.7015\n",
            "Epoch 414: val_accuracy did not improve from 0.70743\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.8884 - accuracy: 0.7015 - val_loss: 1.1253 - val_accuracy: 0.6796\n",
            "Epoch 415/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.9211 - accuracy: 0.6844\n",
            "Epoch 415: val_accuracy did not improve from 0.70743\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.9234 - accuracy: 0.6835 - val_loss: 1.5627 - val_accuracy: 0.5615\n",
            "Epoch 416/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.8444 - accuracy: 0.7037\n",
            "Epoch 416: val_accuracy did not improve from 0.70743\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8444 - accuracy: 0.7035 - val_loss: 1.0825 - val_accuracy: 0.6780\n",
            "Epoch 417/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.8286 - accuracy: 0.7104\n",
            "Epoch 417: val_accuracy did not improve from 0.70743\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.8291 - accuracy: 0.7101 - val_loss: 1.3146 - val_accuracy: 0.6223\n",
            "Epoch 418/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.8517 - accuracy: 0.7031\n",
            "Epoch 418: val_accuracy did not improve from 0.70743\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.8516 - accuracy: 0.7032 - val_loss: 1.0865 - val_accuracy: 0.6786\n",
            "Epoch 419/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.9085 - accuracy: 0.6845\n",
            "Epoch 419: val_accuracy did not improve from 0.70743\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.9082 - accuracy: 0.6845 - val_loss: 1.1459 - val_accuracy: 0.6780\n",
            "Epoch 420/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.8467 - accuracy: 0.7049\n",
            "Epoch 420: val_accuracy did not improve from 0.70743\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.8477 - accuracy: 0.7045 - val_loss: 1.0872 - val_accuracy: 0.6841\n",
            "Epoch 421/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.9910 - accuracy: 0.6803\n",
            "Epoch 421: val_accuracy did not improve from 0.70743\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.9917 - accuracy: 0.6798 - val_loss: 1.0639 - val_accuracy: 0.6853\n",
            "Epoch 422/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.8322 - accuracy: 0.7099\n",
            "Epoch 422: val_accuracy did not improve from 0.70743\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8324 - accuracy: 0.7101 - val_loss: 1.2872 - val_accuracy: 0.6264\n",
            "Epoch 423/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.7913 - accuracy: 0.7224\n",
            "Epoch 423: val_accuracy did not improve from 0.70743\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.7907 - accuracy: 0.7226 - val_loss: 1.1550 - val_accuracy: 0.6725\n",
            "Epoch 424/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.9054 - accuracy: 0.6875\n",
            "Epoch 424: val_accuracy did not improve from 0.70743\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.9056 - accuracy: 0.6874 - val_loss: 1.1987 - val_accuracy: 0.6466\n",
            "Epoch 425/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.8575 - accuracy: 0.7053\n",
            "Epoch 425: val_accuracy did not improve from 0.70743\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.8568 - accuracy: 0.7057 - val_loss: 1.2727 - val_accuracy: 0.6482\n",
            "Epoch 426/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.8258 - accuracy: 0.7115\n",
            "Epoch 426: val_accuracy did not improve from 0.70743\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.8314 - accuracy: 0.7103 - val_loss: 1.1937 - val_accuracy: 0.6649\n",
            "Epoch 427/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.9016 - accuracy: 0.6878\n",
            "Epoch 427: val_accuracy improved from 0.70743 to 0.71191, saving model to /content/asl/Adam2/cp-427-0.71.hdf5\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.8991 - accuracy: 0.6886 - val_loss: 1.0304 - val_accuracy: 0.7119\n",
            "Epoch 428/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.8175 - accuracy: 0.7092\n",
            "Epoch 428: val_accuracy did not improve from 0.71191\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8169 - accuracy: 0.7094 - val_loss: 1.1395 - val_accuracy: 0.6799\n",
            "Epoch 429/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.7907 - accuracy: 0.7218\n",
            "Epoch 429: val_accuracy did not improve from 0.71191\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.7906 - accuracy: 0.7217 - val_loss: 1.2150 - val_accuracy: 0.6642\n",
            "Epoch 430/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.9454 - accuracy: 0.6850\n",
            "Epoch 430: val_accuracy did not improve from 0.71191\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.9448 - accuracy: 0.6852 - val_loss: 1.0990 - val_accuracy: 0.6837\n",
            "Epoch 431/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.8202 - accuracy: 0.7143\n",
            "Epoch 431: val_accuracy did not improve from 0.71191\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8216 - accuracy: 0.7137 - val_loss: 1.6259 - val_accuracy: 0.5698\n",
            "Epoch 432/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.8419 - accuracy: 0.7094\n",
            "Epoch 432: val_accuracy did not improve from 0.71191\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8427 - accuracy: 0.7094 - val_loss: 1.4659 - val_accuracy: 0.5983\n",
            "Epoch 433/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.8446 - accuracy: 0.7083\n",
            "Epoch 433: val_accuracy did not improve from 0.71191\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.8424 - accuracy: 0.7091 - val_loss: 1.0497 - val_accuracy: 0.7097\n",
            "Epoch 434/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 1.4964 - accuracy: 0.5869\n",
            "Epoch 434: val_accuracy did not improve from 0.71191\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.4931 - accuracy: 0.5873 - val_loss: 1.4190 - val_accuracy: 0.5964\n",
            "Epoch 435/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.9679 - accuracy: 0.6731\n",
            "Epoch 435: val_accuracy did not improve from 0.71191\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.9682 - accuracy: 0.6729 - val_loss: 1.0771 - val_accuracy: 0.6821\n",
            "Epoch 436/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.8814 - accuracy: 0.6962\n",
            "Epoch 436: val_accuracy did not improve from 0.71191\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.8813 - accuracy: 0.6963 - val_loss: 1.1356 - val_accuracy: 0.6485\n",
            "Epoch 437/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.9527 - accuracy: 0.6783\n",
            "Epoch 437: val_accuracy did not improve from 0.71191\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.9519 - accuracy: 0.6785 - val_loss: 1.1671 - val_accuracy: 0.6575\n",
            "Epoch 438/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.8320 - accuracy: 0.7064\n",
            "Epoch 438: val_accuracy did not improve from 0.71191\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8337 - accuracy: 0.7057 - val_loss: 1.2861 - val_accuracy: 0.6261\n",
            "Epoch 439/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.8550 - accuracy: 0.7015\n",
            "Epoch 439: val_accuracy did not improve from 0.71191\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.8563 - accuracy: 0.7009 - val_loss: 1.4515 - val_accuracy: 0.5931\n",
            "Epoch 440/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.8855 - accuracy: 0.6934\n",
            "Epoch 440: val_accuracy did not improve from 0.71191\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.8873 - accuracy: 0.6927 - val_loss: 1.1122 - val_accuracy: 0.6841\n",
            "Epoch 441/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8635 - accuracy: 0.7081\n",
            "Epoch 441: val_accuracy did not improve from 0.71191\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8635 - accuracy: 0.7081 - val_loss: 1.0651 - val_accuracy: 0.6988\n",
            "Epoch 442/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.8368 - accuracy: 0.7103\n",
            "Epoch 442: val_accuracy did not improve from 0.71191\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.8372 - accuracy: 0.7100 - val_loss: 1.2263 - val_accuracy: 0.6431\n",
            "Epoch 443/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.8187 - accuracy: 0.7165\n",
            "Epoch 443: val_accuracy did not improve from 0.71191\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.8184 - accuracy: 0.7169 - val_loss: 1.2941 - val_accuracy: 0.6306\n",
            "Epoch 444/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.9122 - accuracy: 0.6866\n",
            "Epoch 444: val_accuracy did not improve from 0.71191\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.9118 - accuracy: 0.6868 - val_loss: 1.2065 - val_accuracy: 0.6456\n",
            "Epoch 445/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.7940 - accuracy: 0.7157\n",
            "Epoch 445: val_accuracy did not improve from 0.71191\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7940 - accuracy: 0.7157 - val_loss: 1.7636 - val_accuracy: 0.5333\n",
            "Epoch 446/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.9714 - accuracy: 0.6683\n",
            "Epoch 446: val_accuracy did not improve from 0.71191\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.9714 - accuracy: 0.6683 - val_loss: 1.1756 - val_accuracy: 0.6626\n",
            "Epoch 447/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.7439 - accuracy: 0.7383\n",
            "Epoch 447: val_accuracy did not improve from 0.71191\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.7520 - accuracy: 0.7371 - val_loss: 1.9277 - val_accuracy: 0.5288\n",
            "Epoch 448/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.8777 - accuracy: 0.6997\n",
            "Epoch 448: val_accuracy did not improve from 0.71191\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8780 - accuracy: 0.6998 - val_loss: 1.1167 - val_accuracy: 0.6780\n",
            "Epoch 449/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.9925 - accuracy: 0.6608\n",
            "Epoch 449: val_accuracy did not improve from 0.71191\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.9937 - accuracy: 0.6605 - val_loss: 1.4842 - val_accuracy: 0.5973\n",
            "Epoch 450/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.7882 - accuracy: 0.7268\n",
            "Epoch 450: val_accuracy did not improve from 0.71191\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.7894 - accuracy: 0.7260 - val_loss: 1.3959 - val_accuracy: 0.5980\n",
            "Epoch 451/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.7689 - accuracy: 0.7299\n",
            "Epoch 451: val_accuracy did not improve from 0.71191\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.7684 - accuracy: 0.7298 - val_loss: 1.1664 - val_accuracy: 0.6700\n",
            "Epoch 452/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.9228 - accuracy: 0.6878\n",
            "Epoch 452: val_accuracy did not improve from 0.71191\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.9202 - accuracy: 0.6888 - val_loss: 1.2980 - val_accuracy: 0.6325\n",
            "Epoch 453/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.8622 - accuracy: 0.6996\n",
            "Epoch 453: val_accuracy did not improve from 0.71191\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.8615 - accuracy: 0.7000 - val_loss: 1.0467 - val_accuracy: 0.6949\n",
            "Epoch 454/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.8901 - accuracy: 0.6913\n",
            "Epoch 454: val_accuracy did not improve from 0.71191\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8901 - accuracy: 0.6913 - val_loss: 1.3056 - val_accuracy: 0.6245\n",
            "Epoch 455/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.7842 - accuracy: 0.7245\n",
            "Epoch 455: val_accuracy improved from 0.71191 to 0.71607, saving model to /content/asl/Adam2/cp-455-0.72.hdf5\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7832 - accuracy: 0.7251 - val_loss: 1.0611 - val_accuracy: 0.7161\n",
            "Epoch 456/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.8236 - accuracy: 0.7105\n",
            "Epoch 456: val_accuracy did not improve from 0.71607\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.8237 - accuracy: 0.7105 - val_loss: 1.3313 - val_accuracy: 0.6255\n",
            "Epoch 457/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.8276 - accuracy: 0.7083\n",
            "Epoch 457: val_accuracy did not improve from 0.71607\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8277 - accuracy: 0.7081 - val_loss: 1.1304 - val_accuracy: 0.6690\n",
            "Epoch 458/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8281 - accuracy: 0.7087\n",
            "Epoch 458: val_accuracy did not improve from 0.71607\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.8281 - accuracy: 0.7087 - val_loss: 1.1522 - val_accuracy: 0.6786\n",
            "Epoch 459/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.8269 - accuracy: 0.7115\n",
            "Epoch 459: val_accuracy did not improve from 0.71607\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.8265 - accuracy: 0.7115 - val_loss: 1.0655 - val_accuracy: 0.6876\n",
            "Epoch 460/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.7910 - accuracy: 0.7228\n",
            "Epoch 460: val_accuracy did not improve from 0.71607\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.7928 - accuracy: 0.7222 - val_loss: 1.1251 - val_accuracy: 0.6889\n",
            "Epoch 461/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.7845 - accuracy: 0.7194\n",
            "Epoch 461: val_accuracy did not improve from 0.71607\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.7845 - accuracy: 0.7194 - val_loss: 1.1164 - val_accuracy: 0.6857\n",
            "Epoch 462/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.9225 - accuracy: 0.6901\n",
            "Epoch 462: val_accuracy did not improve from 0.71607\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.9230 - accuracy: 0.6899 - val_loss: 1.1210 - val_accuracy: 0.6684\n",
            "Epoch 463/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.8520 - accuracy: 0.7054\n",
            "Epoch 463: val_accuracy did not improve from 0.71607\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.8523 - accuracy: 0.7048 - val_loss: 2.1376 - val_accuracy: 0.4702\n",
            "Epoch 464/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8548 - accuracy: 0.7037\n",
            "Epoch 464: val_accuracy did not improve from 0.71607\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8548 - accuracy: 0.7037 - val_loss: 1.2826 - val_accuracy: 0.6232\n",
            "Epoch 465/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.8507 - accuracy: 0.7074\n",
            "Epoch 465: val_accuracy did not improve from 0.71607\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.8486 - accuracy: 0.7081 - val_loss: 1.6068 - val_accuracy: 0.5528\n",
            "Epoch 466/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.7978 - accuracy: 0.7189\n",
            "Epoch 466: val_accuracy did not improve from 0.71607\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7971 - accuracy: 0.7190 - val_loss: 1.1830 - val_accuracy: 0.6757\n",
            "Epoch 467/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.7927 - accuracy: 0.7218\n",
            "Epoch 467: val_accuracy did not improve from 0.71607\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.7934 - accuracy: 0.7219 - val_loss: 1.4847 - val_accuracy: 0.5791\n",
            "Epoch 468/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.9503 - accuracy: 0.6788\n",
            "Epoch 468: val_accuracy did not improve from 0.71607\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.9506 - accuracy: 0.6785 - val_loss: 1.4676 - val_accuracy: 0.5986\n",
            "Epoch 469/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.7653 - accuracy: 0.7312\n",
            "Epoch 469: val_accuracy did not improve from 0.71607\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.7653 - accuracy: 0.7311 - val_loss: 1.2857 - val_accuracy: 0.6520\n",
            "Epoch 470/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.9802 - accuracy: 0.6707\n",
            "Epoch 470: val_accuracy did not improve from 0.71607\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.9794 - accuracy: 0.6708 - val_loss: 1.2945 - val_accuracy: 0.6466\n",
            "Epoch 471/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.7815 - accuracy: 0.7300\n",
            "Epoch 471: val_accuracy did not improve from 0.71607\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7817 - accuracy: 0.7304 - val_loss: 1.0805 - val_accuracy: 0.7052\n",
            "Epoch 472/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.7830 - accuracy: 0.7269\n",
            "Epoch 472: val_accuracy did not improve from 0.71607\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.7832 - accuracy: 0.7266 - val_loss: 1.0348 - val_accuracy: 0.7103\n",
            "Epoch 473/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8456 - accuracy: 0.7081\n",
            "Epoch 473: val_accuracy did not improve from 0.71607\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8456 - accuracy: 0.7081 - val_loss: 1.3464 - val_accuracy: 0.6296\n",
            "Epoch 474/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.8412 - accuracy: 0.7069\n",
            "Epoch 474: val_accuracy did not improve from 0.71607\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8410 - accuracy: 0.7070 - val_loss: 1.1090 - val_accuracy: 0.6863\n",
            "Epoch 475/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.8131 - accuracy: 0.7132\n",
            "Epoch 475: val_accuracy did not improve from 0.71607\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.8123 - accuracy: 0.7139 - val_loss: 1.2764 - val_accuracy: 0.6623\n",
            "Epoch 476/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.8139 - accuracy: 0.7141\n",
            "Epoch 476: val_accuracy did not improve from 0.71607\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8151 - accuracy: 0.7136 - val_loss: 1.3936 - val_accuracy: 0.6060\n",
            "Epoch 477/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.8114 - accuracy: 0.7187\n",
            "Epoch 477: val_accuracy did not improve from 0.71607\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8114 - accuracy: 0.7186 - val_loss: 1.4120 - val_accuracy: 0.5899\n",
            "Epoch 478/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.9199 - accuracy: 0.6954\n",
            "Epoch 478: val_accuracy improved from 0.71607 to 0.71767, saving model to /content/asl/Adam2/cp-478-0.72.hdf5\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.9175 - accuracy: 0.6963 - val_loss: 1.0325 - val_accuracy: 0.7177\n",
            "Epoch 479/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.8192 - accuracy: 0.7110\n",
            "Epoch 479: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.8180 - accuracy: 0.7113 - val_loss: 1.2615 - val_accuracy: 0.6405\n",
            "Epoch 480/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.7958 - accuracy: 0.7199\n",
            "Epoch 480: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.7948 - accuracy: 0.7198 - val_loss: 1.1535 - val_accuracy: 0.6821\n",
            "Epoch 481/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.8195 - accuracy: 0.7130\n",
            "Epoch 481: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.8183 - accuracy: 0.7136 - val_loss: 1.3751 - val_accuracy: 0.6280\n",
            "Epoch 482/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.8001 - accuracy: 0.7182\n",
            "Epoch 482: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.7984 - accuracy: 0.7187 - val_loss: 1.1284 - val_accuracy: 0.6821\n",
            "Epoch 483/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.8325 - accuracy: 0.7113\n",
            "Epoch 483: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8321 - accuracy: 0.7114 - val_loss: 1.1603 - val_accuracy: 0.6841\n",
            "Epoch 484/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.8001 - accuracy: 0.7170\n",
            "Epoch 484: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.8005 - accuracy: 0.7169 - val_loss: 1.1064 - val_accuracy: 0.6975\n",
            "Epoch 485/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.7965 - accuracy: 0.7232\n",
            "Epoch 485: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.7962 - accuracy: 0.7231 - val_loss: 1.0972 - val_accuracy: 0.6946\n",
            "Epoch 486/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.7873 - accuracy: 0.7237\n",
            "Epoch 486: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7885 - accuracy: 0.7234 - val_loss: 1.1492 - val_accuracy: 0.6764\n",
            "Epoch 487/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.8804 - accuracy: 0.7028\n",
            "Epoch 487: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8823 - accuracy: 0.7019 - val_loss: 1.2391 - val_accuracy: 0.6524\n",
            "Epoch 488/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8471 - accuracy: 0.7109\n",
            "Epoch 488: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.8471 - accuracy: 0.7109 - val_loss: 1.0371 - val_accuracy: 0.7033\n",
            "Epoch 489/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.7569 - accuracy: 0.7322\n",
            "Epoch 489: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.7564 - accuracy: 0.7322 - val_loss: 1.2381 - val_accuracy: 0.6431\n",
            "Epoch 490/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.8217 - accuracy: 0.7104\n",
            "Epoch 490: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8213 - accuracy: 0.7103 - val_loss: 1.0445 - val_accuracy: 0.7109\n",
            "Epoch 491/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.7811 - accuracy: 0.7233\n",
            "Epoch 491: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.7812 - accuracy: 0.7231 - val_loss: 1.0595 - val_accuracy: 0.6962\n",
            "Epoch 492/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.7958 - accuracy: 0.7209\n",
            "Epoch 492: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7957 - accuracy: 0.7210 - val_loss: 1.1587 - val_accuracy: 0.6636\n",
            "Epoch 493/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.8378 - accuracy: 0.7109\n",
            "Epoch 493: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8362 - accuracy: 0.7116 - val_loss: 1.1718 - val_accuracy: 0.6729\n",
            "Epoch 494/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.7828 - accuracy: 0.7221\n",
            "Epoch 494: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7826 - accuracy: 0.7223 - val_loss: 1.0546 - val_accuracy: 0.7145\n",
            "Epoch 495/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.7945 - accuracy: 0.7183\n",
            "Epoch 495: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.7937 - accuracy: 0.7181 - val_loss: 1.1526 - val_accuracy: 0.6933\n",
            "Epoch 496/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.9082 - accuracy: 0.6949\n",
            "Epoch 496: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.9077 - accuracy: 0.6952 - val_loss: 1.2052 - val_accuracy: 0.6316\n",
            "Epoch 497/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.8175 - accuracy: 0.7188\n",
            "Epoch 497: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.8172 - accuracy: 0.7189 - val_loss: 1.1183 - val_accuracy: 0.6972\n",
            "Epoch 498/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.8087 - accuracy: 0.7224\n",
            "Epoch 498: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.8120 - accuracy: 0.7216 - val_loss: 2.0893 - val_accuracy: 0.4802\n",
            "Epoch 499/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8130 - accuracy: 0.7169\n",
            "Epoch 499: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8130 - accuracy: 0.7169 - val_loss: 1.1800 - val_accuracy: 0.6629\n",
            "Epoch 500/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.7643 - accuracy: 0.7268\n",
            "Epoch 500: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.7638 - accuracy: 0.7266 - val_loss: 1.1013 - val_accuracy: 0.6831\n",
            "Epoch 501/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.8358 - accuracy: 0.7078\n",
            "Epoch 501: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.8368 - accuracy: 0.7073 - val_loss: 1.4192 - val_accuracy: 0.6277\n",
            "Epoch 502/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.7665 - accuracy: 0.7249\n",
            "Epoch 502: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7653 - accuracy: 0.7250 - val_loss: 1.1350 - val_accuracy: 0.6876\n",
            "Epoch 503/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.8532 - accuracy: 0.7101\n",
            "Epoch 503: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8525 - accuracy: 0.7101 - val_loss: 1.1016 - val_accuracy: 0.7109\n",
            "Epoch 504/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.7557 - accuracy: 0.7349\n",
            "Epoch 504: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7567 - accuracy: 0.7346 - val_loss: 1.3133 - val_accuracy: 0.6402\n",
            "Epoch 505/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.8008 - accuracy: 0.7163\n",
            "Epoch 505: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7994 - accuracy: 0.7169 - val_loss: 1.1362 - val_accuracy: 0.6693\n",
            "Epoch 506/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.7494 - accuracy: 0.7377\n",
            "Epoch 506: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.7496 - accuracy: 0.7376 - val_loss: 1.3039 - val_accuracy: 0.6456\n",
            "Epoch 507/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.9920 - accuracy: 0.6843\n",
            "Epoch 507: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.9909 - accuracy: 0.6845 - val_loss: 1.4289 - val_accuracy: 0.5890\n",
            "Epoch 508/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.7592 - accuracy: 0.7319\n",
            "Epoch 508: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.7591 - accuracy: 0.7316 - val_loss: 1.0390 - val_accuracy: 0.7068\n",
            "Epoch 509/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.7674 - accuracy: 0.7337\n",
            "Epoch 509: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.7708 - accuracy: 0.7330 - val_loss: 1.3495 - val_accuracy: 0.6204\n",
            "Epoch 510/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.8367 - accuracy: 0.7144\n",
            "Epoch 510: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8342 - accuracy: 0.7149 - val_loss: 1.0269 - val_accuracy: 0.7113\n",
            "Epoch 511/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.7583 - accuracy: 0.7348\n",
            "Epoch 511: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.7583 - accuracy: 0.7347 - val_loss: 1.2652 - val_accuracy: 0.6533\n",
            "Epoch 512/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.8175 - accuracy: 0.7156\n",
            "Epoch 512: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8163 - accuracy: 0.7160 - val_loss: 1.1750 - val_accuracy: 0.6617\n",
            "Epoch 513/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.8154 - accuracy: 0.7132\n",
            "Epoch 513: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8138 - accuracy: 0.7137 - val_loss: 1.2475 - val_accuracy: 0.6729\n",
            "Epoch 514/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.8341 - accuracy: 0.7139\n",
            "Epoch 514: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.8323 - accuracy: 0.7144 - val_loss: 1.3306 - val_accuracy: 0.6316\n",
            "Epoch 515/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.7960 - accuracy: 0.7250\n",
            "Epoch 515: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.7955 - accuracy: 0.7251 - val_loss: 1.2305 - val_accuracy: 0.6533\n",
            "Epoch 516/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.7294 - accuracy: 0.7411\n",
            "Epoch 516: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7299 - accuracy: 0.7407 - val_loss: 1.2654 - val_accuracy: 0.6607\n",
            "Epoch 517/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.8602 - accuracy: 0.7043\n",
            "Epoch 517: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.8595 - accuracy: 0.7044 - val_loss: 1.3583 - val_accuracy: 0.6277\n",
            "Epoch 518/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.6954 - accuracy: 0.7529\n",
            "Epoch 518: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.6953 - accuracy: 0.7527 - val_loss: 1.2562 - val_accuracy: 0.6556\n",
            "Epoch 519/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.8342 - accuracy: 0.7131\n",
            "Epoch 519: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8338 - accuracy: 0.7133 - val_loss: 1.1199 - val_accuracy: 0.6837\n",
            "Epoch 520/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.7595 - accuracy: 0.7334\n",
            "Epoch 520: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.7627 - accuracy: 0.7320 - val_loss: 1.0998 - val_accuracy: 0.6892\n",
            "Epoch 521/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.7601 - accuracy: 0.7328\n",
            "Epoch 521: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.7635 - accuracy: 0.7318 - val_loss: 3.3630 - val_accuracy: 0.3550\n",
            "Epoch 522/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.7800 - accuracy: 0.7261\n",
            "Epoch 522: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7800 - accuracy: 0.7259 - val_loss: 1.0957 - val_accuracy: 0.7061\n",
            "Epoch 523/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.7748 - accuracy: 0.7320\n",
            "Epoch 523: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.7740 - accuracy: 0.7322 - val_loss: 1.2189 - val_accuracy: 0.6639\n",
            "Epoch 524/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.7490 - accuracy: 0.7367\n",
            "Epoch 524: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.7480 - accuracy: 0.7372 - val_loss: 1.3759 - val_accuracy: 0.6175\n",
            "Epoch 525/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.7254 - accuracy: 0.7421\n",
            "Epoch 525: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7309 - accuracy: 0.7406 - val_loss: 1.5210 - val_accuracy: 0.5919\n",
            "Epoch 526/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.8380 - accuracy: 0.7137\n",
            "Epoch 526: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8355 - accuracy: 0.7142 - val_loss: 1.0571 - val_accuracy: 0.7074\n",
            "Epoch 527/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.7797 - accuracy: 0.7269\n",
            "Epoch 527: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.7787 - accuracy: 0.7270 - val_loss: 1.1290 - val_accuracy: 0.6853\n",
            "Epoch 528/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.7288 - accuracy: 0.7439\n",
            "Epoch 528: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7288 - accuracy: 0.7439 - val_loss: 1.0351 - val_accuracy: 0.7148\n",
            "Epoch 529/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.8073 - accuracy: 0.7209\n",
            "Epoch 529: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.8069 - accuracy: 0.7207 - val_loss: 1.2393 - val_accuracy: 0.6424\n",
            "Epoch 530/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.7443 - accuracy: 0.7373\n",
            "Epoch 530: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.7445 - accuracy: 0.7370 - val_loss: 1.1103 - val_accuracy: 0.7020\n",
            "Epoch 531/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.7989 - accuracy: 0.7212\n",
            "Epoch 531: val_accuracy did not improve from 0.71767\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.7984 - accuracy: 0.7212 - val_loss: 1.0990 - val_accuracy: 0.7100\n",
            "Epoch 532/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.7347 - accuracy: 0.7417\n",
            "Epoch 532: val_accuracy improved from 0.71767 to 0.72343, saving model to /content/asl/Adam2/cp-532-0.72.hdf5\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.7342 - accuracy: 0.7419 - val_loss: 1.0324 - val_accuracy: 0.7234\n",
            "Epoch 533/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.8602 - accuracy: 0.7044\n",
            "Epoch 533: val_accuracy did not improve from 0.72343\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8602 - accuracy: 0.7043 - val_loss: 1.0774 - val_accuracy: 0.7001\n",
            "Epoch 534/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.7708 - accuracy: 0.7247\n",
            "Epoch 534: val_accuracy did not improve from 0.72343\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.7697 - accuracy: 0.7251 - val_loss: 1.0583 - val_accuracy: 0.7039\n",
            "Epoch 535/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.7368 - accuracy: 0.7435\n",
            "Epoch 535: val_accuracy improved from 0.72343 to 0.72439, saving model to /content/asl/Adam2/cp-535-0.72.hdf5\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7367 - accuracy: 0.7437 - val_loss: 1.0355 - val_accuracy: 0.7244\n",
            "Epoch 536/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.8187 - accuracy: 0.7238\n",
            "Epoch 536: val_accuracy did not improve from 0.72439\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8178 - accuracy: 0.7240 - val_loss: 1.0410 - val_accuracy: 0.7068\n",
            "Epoch 537/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.8013 - accuracy: 0.7149\n",
            "Epoch 537: val_accuracy did not improve from 0.72439\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.8014 - accuracy: 0.7148 - val_loss: 1.0354 - val_accuracy: 0.7196\n",
            "Epoch 538/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.6926 - accuracy: 0.7508\n",
            "Epoch 538: val_accuracy did not improve from 0.72439\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.6946 - accuracy: 0.7502 - val_loss: 1.3012 - val_accuracy: 0.6367\n",
            "Epoch 539/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.8528 - accuracy: 0.7090\n",
            "Epoch 539: val_accuracy did not improve from 0.72439\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8522 - accuracy: 0.7093 - val_loss: 1.2443 - val_accuracy: 0.6661\n",
            "Epoch 540/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.7608 - accuracy: 0.7331\n",
            "Epoch 540: val_accuracy did not improve from 0.72439\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7620 - accuracy: 0.7327 - val_loss: 1.2504 - val_accuracy: 0.6623\n",
            "Epoch 541/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.7913 - accuracy: 0.7292\n",
            "Epoch 541: val_accuracy did not improve from 0.72439\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.7917 - accuracy: 0.7289 - val_loss: 1.2216 - val_accuracy: 0.6716\n",
            "Epoch 542/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8374 - accuracy: 0.7105\n",
            "Epoch 542: val_accuracy did not improve from 0.72439\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8374 - accuracy: 0.7105 - val_loss: 1.1001 - val_accuracy: 0.6857\n",
            "Epoch 543/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.7037 - accuracy: 0.7504\n",
            "Epoch 543: val_accuracy did not improve from 0.72439\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7040 - accuracy: 0.7503 - val_loss: 1.2519 - val_accuracy: 0.6626\n",
            "Epoch 544/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.8420 - accuracy: 0.7151\n",
            "Epoch 544: val_accuracy did not improve from 0.72439\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.8429 - accuracy: 0.7150 - val_loss: 1.1632 - val_accuracy: 0.6828\n",
            "Epoch 545/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8364 - accuracy: 0.7120\n",
            "Epoch 545: val_accuracy did not improve from 0.72439\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.8364 - accuracy: 0.7120 - val_loss: 1.1250 - val_accuracy: 0.6821\n",
            "Epoch 546/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.7032 - accuracy: 0.7504\n",
            "Epoch 546: val_accuracy did not improve from 0.72439\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.7022 - accuracy: 0.7509 - val_loss: 1.0564 - val_accuracy: 0.7190\n",
            "Epoch 547/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.8371 - accuracy: 0.7228\n",
            "Epoch 547: val_accuracy did not improve from 0.72439\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.8363 - accuracy: 0.7229 - val_loss: 1.0704 - val_accuracy: 0.7068\n",
            "Epoch 548/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.7541 - accuracy: 0.7372\n",
            "Epoch 548: val_accuracy did not improve from 0.72439\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7562 - accuracy: 0.7364 - val_loss: 1.3610 - val_accuracy: 0.6450\n",
            "Epoch 549/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.7727 - accuracy: 0.7248\n",
            "Epoch 549: val_accuracy did not improve from 0.72439\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.7716 - accuracy: 0.7250 - val_loss: 1.2421 - val_accuracy: 0.6530\n",
            "Epoch 550/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.7397 - accuracy: 0.7379\n",
            "Epoch 550: val_accuracy did not improve from 0.72439\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.7395 - accuracy: 0.7378 - val_loss: 1.1470 - val_accuracy: 0.6738\n",
            "Epoch 551/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.7422 - accuracy: 0.7357\n",
            "Epoch 551: val_accuracy did not improve from 0.72439\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.7419 - accuracy: 0.7358 - val_loss: 1.0803 - val_accuracy: 0.7154\n",
            "Epoch 552/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.7501 - accuracy: 0.7322\n",
            "Epoch 552: val_accuracy did not improve from 0.72439\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7502 - accuracy: 0.7322 - val_loss: 1.1064 - val_accuracy: 0.6908\n",
            "Epoch 553/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.7335 - accuracy: 0.7431\n",
            "Epoch 553: val_accuracy did not improve from 0.72439\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7331 - accuracy: 0.7430 - val_loss: 1.2065 - val_accuracy: 0.6834\n",
            "Epoch 554/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.7456 - accuracy: 0.7326\n",
            "Epoch 554: val_accuracy did not improve from 0.72439\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.7456 - accuracy: 0.7326 - val_loss: 1.1340 - val_accuracy: 0.7129\n",
            "Epoch 555/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.8979 - accuracy: 0.7026\n",
            "Epoch 555: val_accuracy did not improve from 0.72439\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8971 - accuracy: 0.7029 - val_loss: 1.6077 - val_accuracy: 0.5835\n",
            "Epoch 556/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.7148 - accuracy: 0.7458\n",
            "Epoch 556: val_accuracy did not improve from 0.72439\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.7150 - accuracy: 0.7458 - val_loss: 1.2285 - val_accuracy: 0.6677\n",
            "Epoch 557/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.7772 - accuracy: 0.7308\n",
            "Epoch 557: val_accuracy did not improve from 0.72439\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.7768 - accuracy: 0.7310 - val_loss: 1.2286 - val_accuracy: 0.6745\n",
            "Epoch 558/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.6513 - accuracy: 0.7649\n",
            "Epoch 558: val_accuracy did not improve from 0.72439\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.6520 - accuracy: 0.7646 - val_loss: 1.0945 - val_accuracy: 0.7020\n",
            "Epoch 559/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.7386 - accuracy: 0.7379\n",
            "Epoch 559: val_accuracy did not improve from 0.72439\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.7392 - accuracy: 0.7374 - val_loss: 1.0718 - val_accuracy: 0.7122\n",
            "Epoch 560/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.8155 - accuracy: 0.7202\n",
            "Epoch 560: val_accuracy did not improve from 0.72439\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.8128 - accuracy: 0.7212 - val_loss: 1.2378 - val_accuracy: 0.6636\n",
            "Epoch 561/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.6991 - accuracy: 0.7458\n",
            "Epoch 561: val_accuracy did not improve from 0.72439\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7000 - accuracy: 0.7455 - val_loss: 1.2163 - val_accuracy: 0.6905\n",
            "Epoch 562/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.8457 - accuracy: 0.7098\n",
            "Epoch 562: val_accuracy did not improve from 0.72439\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.8451 - accuracy: 0.7099 - val_loss: 1.1555 - val_accuracy: 0.6751\n",
            "Epoch 563/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.7793 - accuracy: 0.7311\n",
            "Epoch 563: val_accuracy did not improve from 0.72439\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.7800 - accuracy: 0.7306 - val_loss: 1.3487 - val_accuracy: 0.6274\n",
            "Epoch 564/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.7387 - accuracy: 0.7377\n",
            "Epoch 564: val_accuracy did not improve from 0.72439\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.7387 - accuracy: 0.7377 - val_loss: 1.2131 - val_accuracy: 0.6613\n",
            "Epoch 565/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.7438 - accuracy: 0.7369\n",
            "Epoch 565: val_accuracy did not improve from 0.72439\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7438 - accuracy: 0.7369 - val_loss: 1.0860 - val_accuracy: 0.7135\n",
            "Epoch 566/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.7887 - accuracy: 0.7269\n",
            "Epoch 566: val_accuracy did not improve from 0.72439\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7869 - accuracy: 0.7274 - val_loss: 1.0777 - val_accuracy: 0.7138\n",
            "Epoch 567/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.7440 - accuracy: 0.7371\n",
            "Epoch 567: val_accuracy did not improve from 0.72439\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.7462 - accuracy: 0.7365 - val_loss: 1.0483 - val_accuracy: 0.7068\n",
            "Epoch 568/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.7891 - accuracy: 0.7270\n",
            "Epoch 568: val_accuracy did not improve from 0.72439\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.7892 - accuracy: 0.7269 - val_loss: 1.1466 - val_accuracy: 0.6908\n",
            "Epoch 569/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.6886 - accuracy: 0.7513\n",
            "Epoch 569: val_accuracy did not improve from 0.72439\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.6890 - accuracy: 0.7508 - val_loss: 1.1369 - val_accuracy: 0.6828\n",
            "Epoch 570/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.9317 - accuracy: 0.7026\n",
            "Epoch 570: val_accuracy did not improve from 0.72439\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 0.9301 - accuracy: 0.7031 - val_loss: 1.0654 - val_accuracy: 0.7109\n",
            "Epoch 571/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.6282 - accuracy: 0.7761\n",
            "Epoch 571: val_accuracy improved from 0.72439 to 0.72759, saving model to /content/asl/Adam2/cp-571-0.73.hdf5\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.6298 - accuracy: 0.7755 - val_loss: 1.0310 - val_accuracy: 0.7276\n",
            "Epoch 572/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.7490 - accuracy: 0.7375\n",
            "Epoch 572: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7490 - accuracy: 0.7375 - val_loss: 1.0704 - val_accuracy: 0.7055\n",
            "Epoch 573/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.8445 - accuracy: 0.7146\n",
            "Epoch 573: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 0.8490 - accuracy: 0.7136 - val_loss: 1.7150 - val_accuracy: 0.5378\n",
            "Epoch 574/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.7996 - accuracy: 0.7260\n",
            "Epoch 574: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7986 - accuracy: 0.7262 - val_loss: 1.1589 - val_accuracy: 0.6853\n",
            "Epoch 575/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.7454 - accuracy: 0.7385\n",
            "Epoch 575: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7454 - accuracy: 0.7385 - val_loss: 1.2130 - val_accuracy: 0.6885\n",
            "Epoch 576/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.7203 - accuracy: 0.7434\n",
            "Epoch 576: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.7197 - accuracy: 0.7436 - val_loss: 1.2312 - val_accuracy: 0.6805\n",
            "Epoch 577/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.9024 - accuracy: 0.7037\n",
            "Epoch 577: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.9040 - accuracy: 0.7033 - val_loss: 1.1804 - val_accuracy: 0.6767\n",
            "Epoch 578/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.6734 - accuracy: 0.7591\n",
            "Epoch 578: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.6725 - accuracy: 0.7594 - val_loss: 1.0260 - val_accuracy: 0.7257\n",
            "Epoch 579/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.7483 - accuracy: 0.7349\n",
            "Epoch 579: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.7518 - accuracy: 0.7343 - val_loss: 1.3039 - val_accuracy: 0.6472\n",
            "Epoch 580/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.9647 - accuracy: 0.6959\n",
            "Epoch 580: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.9640 - accuracy: 0.6958 - val_loss: 1.4260 - val_accuracy: 0.6108\n",
            "Epoch 581/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.6725 - accuracy: 0.7615\n",
            "Epoch 581: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.6733 - accuracy: 0.7615 - val_loss: 1.0074 - val_accuracy: 0.7263\n",
            "Epoch 582/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.8475 - accuracy: 0.7168\n",
            "Epoch 582: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.8475 - accuracy: 0.7168 - val_loss: 1.1639 - val_accuracy: 0.6754\n",
            "Epoch 583/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.8512 - accuracy: 0.7112\n",
            "Epoch 583: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.8518 - accuracy: 0.7113 - val_loss: 1.3887 - val_accuracy: 0.6085\n",
            "Epoch 584/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.7386 - accuracy: 0.7363\n",
            "Epoch 584: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7397 - accuracy: 0.7359 - val_loss: 1.4379 - val_accuracy: 0.6072\n",
            "Epoch 585/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.7271 - accuracy: 0.7438\n",
            "Epoch 585: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.7273 - accuracy: 0.7438 - val_loss: 1.1311 - val_accuracy: 0.6812\n",
            "Epoch 586/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.7258 - accuracy: 0.7453\n",
            "Epoch 586: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 0.7291 - accuracy: 0.7444 - val_loss: 1.4036 - val_accuracy: 0.6168\n",
            "Epoch 587/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.7657 - accuracy: 0.7323\n",
            "Epoch 587: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7666 - accuracy: 0.7320 - val_loss: 1.1415 - val_accuracy: 0.6988\n",
            "Epoch 588/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.7515 - accuracy: 0.7346\n",
            "Epoch 588: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7515 - accuracy: 0.7346 - val_loss: 2.1265 - val_accuracy: 0.4818\n",
            "Epoch 589/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.7943 - accuracy: 0.7214\n",
            "Epoch 589: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 0.7943 - accuracy: 0.7214 - val_loss: 1.0876 - val_accuracy: 0.7049\n",
            "Epoch 590/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.6936 - accuracy: 0.7531\n",
            "Epoch 590: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.6949 - accuracy: 0.7528 - val_loss: 1.8030 - val_accuracy: 0.5573\n",
            "Epoch 591/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.8196 - accuracy: 0.7249\n",
            "Epoch 591: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.8200 - accuracy: 0.7249 - val_loss: 1.1717 - val_accuracy: 0.6767\n",
            "Epoch 592/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.7051 - accuracy: 0.7502\n",
            "Epoch 592: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 0.7051 - accuracy: 0.7502 - val_loss: 1.4014 - val_accuracy: 0.6325\n",
            "Epoch 593/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.6993 - accuracy: 0.7488\n",
            "Epoch 593: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.6968 - accuracy: 0.7495 - val_loss: 1.0653 - val_accuracy: 0.7260\n",
            "Epoch 594/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.7273 - accuracy: 0.7437\n",
            "Epoch 594: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7273 - accuracy: 0.7437 - val_loss: 1.3797 - val_accuracy: 0.6351\n",
            "Epoch 595/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.7600 - accuracy: 0.7331\n",
            "Epoch 595: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.7594 - accuracy: 0.7330 - val_loss: 1.1329 - val_accuracy: 0.6988\n",
            "Epoch 596/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.8044 - accuracy: 0.7248\n",
            "Epoch 596: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.8042 - accuracy: 0.7252 - val_loss: 1.1936 - val_accuracy: 0.6940\n",
            "Epoch 597/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.7102 - accuracy: 0.7466\n",
            "Epoch 597: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7102 - accuracy: 0.7466 - val_loss: 1.3701 - val_accuracy: 0.6325\n",
            "Epoch 598/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.8266 - accuracy: 0.7202\n",
            "Epoch 598: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.8285 - accuracy: 0.7197 - val_loss: 1.2158 - val_accuracy: 0.6517\n",
            "Epoch 599/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.7233 - accuracy: 0.7449\n",
            "Epoch 599: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.7230 - accuracy: 0.7450 - val_loss: 1.1217 - val_accuracy: 0.6937\n",
            "Epoch 600/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.6707 - accuracy: 0.7621\n",
            "Epoch 600: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.6704 - accuracy: 0.7624 - val_loss: 1.1742 - val_accuracy: 0.6997\n",
            "Epoch 601/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.7330 - accuracy: 0.7418\n",
            "Epoch 601: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.7327 - accuracy: 0.7418 - val_loss: 1.2834 - val_accuracy: 0.6520\n",
            "Epoch 602/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.6971 - accuracy: 0.7506\n",
            "Epoch 602: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.6970 - accuracy: 0.7506 - val_loss: 1.4117 - val_accuracy: 0.6127\n",
            "Epoch 603/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.7238 - accuracy: 0.7389\n",
            "Epoch 603: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7238 - accuracy: 0.7389 - val_loss: 1.2243 - val_accuracy: 0.6821\n",
            "Epoch 604/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.7796 - accuracy: 0.7316\n",
            "Epoch 604: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7790 - accuracy: 0.7318 - val_loss: 1.6282 - val_accuracy: 0.5647\n",
            "Epoch 605/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.7721 - accuracy: 0.7355\n",
            "Epoch 605: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.7717 - accuracy: 0.7357 - val_loss: 1.1641 - val_accuracy: 0.6898\n",
            "Epoch 606/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.7655 - accuracy: 0.7298\n",
            "Epoch 606: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7652 - accuracy: 0.7297 - val_loss: 1.1223 - val_accuracy: 0.6978\n",
            "Epoch 607/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.7142 - accuracy: 0.7476\n",
            "Epoch 607: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7137 - accuracy: 0.7476 - val_loss: 1.3120 - val_accuracy: 0.6501\n",
            "Epoch 608/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.6717 - accuracy: 0.7600\n",
            "Epoch 608: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.6728 - accuracy: 0.7601 - val_loss: 1.5948 - val_accuracy: 0.5816\n",
            "Epoch 609/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.8004 - accuracy: 0.7347\n",
            "Epoch 609: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7994 - accuracy: 0.7347 - val_loss: 1.1566 - val_accuracy: 0.6927\n",
            "Epoch 610/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.7530\n",
            "Epoch 610: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.6949 - accuracy: 0.7526 - val_loss: 1.8855 - val_accuracy: 0.5343\n",
            "Epoch 611/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8474 - accuracy: 0.7149\n",
            "Epoch 611: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.8474 - accuracy: 0.7149 - val_loss: 1.1338 - val_accuracy: 0.6988\n",
            "Epoch 612/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.6401 - accuracy: 0.7726\n",
            "Epoch 612: val_accuracy did not improve from 0.72759\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.6427 - accuracy: 0.7719 - val_loss: 1.1910 - val_accuracy: 0.6857\n",
            "Epoch 613/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.7533 - accuracy: 0.7416\n",
            "Epoch 613: val_accuracy improved from 0.72759 to 0.73175, saving model to /content/asl/Adam2/cp-613-0.73.hdf5\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7538 - accuracy: 0.7417 - val_loss: 1.0458 - val_accuracy: 0.7318\n",
            "Epoch 614/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.6760 - accuracy: 0.7573\n",
            "Epoch 614: val_accuracy did not improve from 0.73175\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.6757 - accuracy: 0.7578 - val_loss: 1.1128 - val_accuracy: 0.6937\n",
            "Epoch 615/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.7834 - accuracy: 0.7309\n",
            "Epoch 615: val_accuracy did not improve from 0.73175\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.7842 - accuracy: 0.7308 - val_loss: 1.4462 - val_accuracy: 0.6156\n",
            "Epoch 616/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.6528 - accuracy: 0.7656\n",
            "Epoch 616: val_accuracy did not improve from 0.73175\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.6520 - accuracy: 0.7658 - val_loss: 1.1329 - val_accuracy: 0.7212\n",
            "Epoch 617/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.8297 - accuracy: 0.7166\n",
            "Epoch 617: val_accuracy did not improve from 0.73175\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.8305 - accuracy: 0.7162 - val_loss: 1.2189 - val_accuracy: 0.6626\n",
            "Epoch 618/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.7109 - accuracy: 0.7501\n",
            "Epoch 618: val_accuracy did not improve from 0.73175\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.7109 - accuracy: 0.7501 - val_loss: 1.4164 - val_accuracy: 0.6213\n",
            "Epoch 619/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.7613 - accuracy: 0.7312\n",
            "Epoch 619: val_accuracy did not improve from 0.73175\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7610 - accuracy: 0.7311 - val_loss: 1.1340 - val_accuracy: 0.6927\n",
            "Epoch 620/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.6913 - accuracy: 0.7547\n",
            "Epoch 620: val_accuracy did not improve from 0.73175\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.6911 - accuracy: 0.7545 - val_loss: 1.1738 - val_accuracy: 0.7049\n",
            "Epoch 621/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.9013 - accuracy: 0.6995\n",
            "Epoch 621: val_accuracy did not improve from 0.73175\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.9007 - accuracy: 0.6997 - val_loss: 1.0490 - val_accuracy: 0.7113\n",
            "Epoch 622/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.6635 - accuracy: 0.7632\n",
            "Epoch 622: val_accuracy did not improve from 0.73175\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.6630 - accuracy: 0.7629 - val_loss: 1.0677 - val_accuracy: 0.7212\n",
            "Epoch 623/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.7369 - accuracy: 0.7423\n",
            "Epoch 623: val_accuracy did not improve from 0.73175\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.7410 - accuracy: 0.7411 - val_loss: 1.3869 - val_accuracy: 0.6191\n",
            "Epoch 624/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.7592 - accuracy: 0.7311\n",
            "Epoch 624: val_accuracy did not improve from 0.73175\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 0.7589 - accuracy: 0.7311 - val_loss: 1.2398 - val_accuracy: 0.6668\n",
            "Epoch 625/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.7103 - accuracy: 0.7458\n",
            "Epoch 625: val_accuracy did not improve from 0.73175\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7103 - accuracy: 0.7458 - val_loss: 1.9599 - val_accuracy: 0.5221\n",
            "Epoch 626/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.7463 - accuracy: 0.7409\n",
            "Epoch 626: val_accuracy did not improve from 0.73175\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7465 - accuracy: 0.7408 - val_loss: 1.2344 - val_accuracy: 0.6821\n",
            "Epoch 627/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.7427 - accuracy: 0.7394\n",
            "Epoch 627: val_accuracy did not improve from 0.73175\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 0.7418 - accuracy: 0.7397 - val_loss: 1.1458 - val_accuracy: 0.7068\n",
            "Epoch 628/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.6901 - accuracy: 0.7527\n",
            "Epoch 628: val_accuracy did not improve from 0.73175\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.6914 - accuracy: 0.7526 - val_loss: 1.3290 - val_accuracy: 0.6562\n",
            "Epoch 629/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.7856 - accuracy: 0.7296\n",
            "Epoch 629: val_accuracy did not improve from 0.73175\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7856 - accuracy: 0.7296 - val_loss: 1.2877 - val_accuracy: 0.6658\n",
            "Epoch 630/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.7138 - accuracy: 0.7490\n",
            "Epoch 630: val_accuracy did not improve from 0.73175\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 0.7138 - accuracy: 0.7490 - val_loss: 1.3671 - val_accuracy: 0.6415\n",
            "Epoch 631/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.7393 - accuracy: 0.7424\n",
            "Epoch 631: val_accuracy did not improve from 0.73175\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.7393 - accuracy: 0.7424 - val_loss: 1.2056 - val_accuracy: 0.6863\n",
            "Epoch 632/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.6867 - accuracy: 0.7580\n",
            "Epoch 632: val_accuracy improved from 0.73175 to 0.73271, saving model to /content/asl/Adam2/cp-632-0.73.hdf5\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.6865 - accuracy: 0.7580 - val_loss: 1.0205 - val_accuracy: 0.7327\n",
            "Epoch 633/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.7117 - accuracy: 0.7514\n",
            "Epoch 633: val_accuracy did not improve from 0.73271\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.7120 - accuracy: 0.7513 - val_loss: 1.3023 - val_accuracy: 0.6559\n",
            "Epoch 634/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.6802 - accuracy: 0.7576\n",
            "Epoch 634: val_accuracy did not improve from 0.73271\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.6796 - accuracy: 0.7578 - val_loss: 1.1135 - val_accuracy: 0.6898\n",
            "Epoch 635/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.8112 - accuracy: 0.7206\n",
            "Epoch 635: val_accuracy did not improve from 0.73271\n",
            "391/391 [==============================] - 11s 27ms/step - loss: 0.8112 - accuracy: 0.7206 - val_loss: 1.0436 - val_accuracy: 0.7170\n",
            "Epoch 636/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.7188 - accuracy: 0.7449\n",
            "Epoch 636: val_accuracy did not improve from 0.73271\n",
            "391/391 [==============================] - 9s 22ms/step - loss: 0.7190 - accuracy: 0.7448 - val_loss: 1.3496 - val_accuracy: 0.6306\n",
            "Epoch 637/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.6670 - accuracy: 0.7590\n",
            "Epoch 637: val_accuracy did not improve from 0.73271\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.6671 - accuracy: 0.7590 - val_loss: 1.3117 - val_accuracy: 0.6633\n",
            "Epoch 638/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.7378 - accuracy: 0.7390\n",
            "Epoch 638: val_accuracy did not improve from 0.73271\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.7377 - accuracy: 0.7393 - val_loss: 1.2155 - val_accuracy: 0.6741\n",
            "Epoch 639/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.6555 - accuracy: 0.7638\n",
            "Epoch 639: val_accuracy did not improve from 0.73271\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.6555 - accuracy: 0.7638 - val_loss: 1.0678 - val_accuracy: 0.7154\n",
            "Epoch 640/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.6830 - accuracy: 0.7580\n",
            "Epoch 640: val_accuracy did not improve from 0.73271\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.6816 - accuracy: 0.7584 - val_loss: 1.3150 - val_accuracy: 0.6479\n",
            "Epoch 641/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.8291 - accuracy: 0.7240\n",
            "Epoch 641: val_accuracy did not improve from 0.73271\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.8289 - accuracy: 0.7242 - val_loss: 1.4143 - val_accuracy: 0.6242\n",
            "Epoch 642/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.6347 - accuracy: 0.7695\n",
            "Epoch 642: val_accuracy did not improve from 0.73271\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 0.6346 - accuracy: 0.7694 - val_loss: 1.2046 - val_accuracy: 0.6911\n",
            "Epoch 643/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.8946 - accuracy: 0.7176\n",
            "Epoch 643: val_accuracy did not improve from 0.73271\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.8925 - accuracy: 0.7182 - val_loss: 1.1139 - val_accuracy: 0.7068\n",
            "Epoch 644/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.6519 - accuracy: 0.7691\n",
            "Epoch 644: val_accuracy did not improve from 0.73271\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.6511 - accuracy: 0.7693 - val_loss: 1.0579 - val_accuracy: 0.7183\n",
            "Epoch 645/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.8094 - accuracy: 0.7271\n",
            "Epoch 645: val_accuracy did not improve from 0.73271\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.8105 - accuracy: 0.7267 - val_loss: 1.6506 - val_accuracy: 0.5627\n",
            "Epoch 646/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.6959 - accuracy: 0.7537\n",
            "Epoch 646: val_accuracy did not improve from 0.73271\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.6966 - accuracy: 0.7534 - val_loss: 1.0992 - val_accuracy: 0.7141\n",
            "Epoch 647/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.7668 - accuracy: 0.7357\n",
            "Epoch 647: val_accuracy did not improve from 0.73271\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7660 - accuracy: 0.7358 - val_loss: 1.1132 - val_accuracy: 0.7017\n",
            "Epoch 648/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.7018 - accuracy: 0.7510\n",
            "Epoch 648: val_accuracy did not improve from 0.73271\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.7009 - accuracy: 0.7514 - val_loss: 1.5970 - val_accuracy: 0.5851\n",
            "Epoch 649/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.6333 - accuracy: 0.7705\n",
            "Epoch 649: val_accuracy did not improve from 0.73271\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.6336 - accuracy: 0.7705 - val_loss: 1.0648 - val_accuracy: 0.7257\n",
            "Epoch 650/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.7068 - accuracy: 0.7486\n",
            "Epoch 650: val_accuracy did not improve from 0.73271\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7090 - accuracy: 0.7478 - val_loss: 1.1555 - val_accuracy: 0.6905\n",
            "Epoch 651/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.7170 - accuracy: 0.7514\n",
            "Epoch 651: val_accuracy did not improve from 0.73271\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.7161 - accuracy: 0.7517 - val_loss: 1.0682 - val_accuracy: 0.7228\n",
            "Epoch 652/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.6634 - accuracy: 0.7609\n",
            "Epoch 652: val_accuracy did not improve from 0.73271\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.6642 - accuracy: 0.7610 - val_loss: 1.1713 - val_accuracy: 0.7023\n",
            "Epoch 653/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.7633 - accuracy: 0.7342\n",
            "Epoch 653: val_accuracy did not improve from 0.73271\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7633 - accuracy: 0.7342 - val_loss: 1.7306 - val_accuracy: 0.5842\n",
            "Epoch 654/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.6528 - accuracy: 0.7656\n",
            "Epoch 654: val_accuracy did not improve from 0.73271\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.6530 - accuracy: 0.7654 - val_loss: 1.2793 - val_accuracy: 0.6601\n",
            "Epoch 655/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.7037 - accuracy: 0.7502\n",
            "Epoch 655: val_accuracy did not improve from 0.73271\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.7037 - accuracy: 0.7502 - val_loss: 1.1565 - val_accuracy: 0.6962\n",
            "Epoch 656/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.7816 - accuracy: 0.7292\n",
            "Epoch 656: val_accuracy did not improve from 0.73271\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7810 - accuracy: 0.7294 - val_loss: 1.1168 - val_accuracy: 0.7007\n",
            "Epoch 657/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.7052 - accuracy: 0.7509\n",
            "Epoch 657: val_accuracy did not improve from 0.73271\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.7048 - accuracy: 0.7510 - val_loss: 1.3870 - val_accuracy: 0.6261\n",
            "Epoch 658/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.6867 - accuracy: 0.7539\n",
            "Epoch 658: val_accuracy did not improve from 0.73271\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.6879 - accuracy: 0.7536 - val_loss: 1.2996 - val_accuracy: 0.6585\n",
            "Epoch 659/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.7163 - accuracy: 0.7479\n",
            "Epoch 659: val_accuracy improved from 0.73271 to 0.73303, saving model to /content/asl/Adam2/cp-659-0.73.hdf5\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7163 - accuracy: 0.7478 - val_loss: 1.0252 - val_accuracy: 0.7330\n",
            "Epoch 660/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.7154 - accuracy: 0.7485\n",
            "Epoch 660: val_accuracy did not improve from 0.73303\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.7151 - accuracy: 0.7485 - val_loss: 1.3847 - val_accuracy: 0.6428\n",
            "Epoch 661/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.6737 - accuracy: 0.7625\n",
            "Epoch 661: val_accuracy did not improve from 0.73303\n",
            "391/391 [==============================] - 6s 15ms/step - loss: 0.6736 - accuracy: 0.7624 - val_loss: 1.0635 - val_accuracy: 0.7302\n",
            "Epoch 662/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.7463 - accuracy: 0.7470\n",
            "Epoch 662: val_accuracy did not improve from 0.73303\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.7454 - accuracy: 0.7472 - val_loss: 1.1643 - val_accuracy: 0.7087\n",
            "Epoch 663/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.7040 - accuracy: 0.7461\n",
            "Epoch 663: val_accuracy did not improve from 0.73303\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 0.7032 - accuracy: 0.7465 - val_loss: 1.0825 - val_accuracy: 0.7090\n",
            "Epoch 664/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.7073 - accuracy: 0.7526\n",
            "Epoch 664: val_accuracy did not improve from 0.73303\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7080 - accuracy: 0.7520 - val_loss: 1.1517 - val_accuracy: 0.7010\n",
            "Epoch 665/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.6700 - accuracy: 0.7642\n",
            "Epoch 665: val_accuracy did not improve from 0.73303\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.6736 - accuracy: 0.7626 - val_loss: 2.1095 - val_accuracy: 0.5157\n",
            "Epoch 666/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.7053 - accuracy: 0.7535\n",
            "Epoch 666: val_accuracy did not improve from 0.73303\n",
            "391/391 [==============================] - 6s 15ms/step - loss: 0.7092 - accuracy: 0.7525 - val_loss: 2.4485 - val_accuracy: 0.4840\n",
            "Epoch 667/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.7988 - accuracy: 0.7288\n",
            "Epoch 667: val_accuracy did not improve from 0.73303\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7962 - accuracy: 0.7298 - val_loss: 1.3657 - val_accuracy: 0.6498\n",
            "Epoch 668/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.7002 - accuracy: 0.7555\n",
            "Epoch 668: val_accuracy did not improve from 0.73303\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.6989 - accuracy: 0.7563 - val_loss: 1.1307 - val_accuracy: 0.7001\n",
            "Epoch 669/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.6600 - accuracy: 0.7655\n",
            "Epoch 669: val_accuracy did not improve from 0.73303\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.6599 - accuracy: 0.7657 - val_loss: 1.2784 - val_accuracy: 0.6754\n",
            "Epoch 670/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.7025 - accuracy: 0.7557\n",
            "Epoch 670: val_accuracy did not improve from 0.73303\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7053 - accuracy: 0.7553 - val_loss: 1.9550 - val_accuracy: 0.5349\n",
            "Epoch 671/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.6818 - accuracy: 0.7640\n",
            "Epoch 671: val_accuracy did not improve from 0.73303\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.6810 - accuracy: 0.7642 - val_loss: 1.0886 - val_accuracy: 0.7270\n",
            "Epoch 672/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 1.0197 - accuracy: 0.7014\n",
            "Epoch 672: val_accuracy did not improve from 0.73303\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.0197 - accuracy: 0.7014 - val_loss: 1.1752 - val_accuracy: 0.6655\n",
            "Epoch 673/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.6350 - accuracy: 0.7702\n",
            "Epoch 673: val_accuracy did not improve from 0.73303\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.6350 - accuracy: 0.7701 - val_loss: 1.0344 - val_accuracy: 0.7314\n",
            "Epoch 674/700\n",
            "386/391 [============================>.] - ETA: 0s - loss: 0.7278 - accuracy: 0.7466\n",
            "Epoch 674: val_accuracy did not improve from 0.73303\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7258 - accuracy: 0.7472 - val_loss: 1.1236 - val_accuracy: 0.7039\n",
            "Epoch 675/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.6870 - accuracy: 0.7579\n",
            "Epoch 675: val_accuracy did not improve from 0.73303\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.6857 - accuracy: 0.7583 - val_loss: 1.0658 - val_accuracy: 0.7129\n",
            "Epoch 676/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.6429 - accuracy: 0.7637\n",
            "Epoch 676: val_accuracy did not improve from 0.73303\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 0.6428 - accuracy: 0.7638 - val_loss: 1.1260 - val_accuracy: 0.7055\n",
            "Epoch 677/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.7355 - accuracy: 0.7466\n",
            "Epoch 677: val_accuracy did not improve from 0.73303\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7365 - accuracy: 0.7464 - val_loss: 2.2916 - val_accuracy: 0.4750\n",
            "Epoch 678/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.6509 - accuracy: 0.7690\n",
            "Epoch 678: val_accuracy did not improve from 0.73303\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.6506 - accuracy: 0.7691 - val_loss: 1.0492 - val_accuracy: 0.7292\n",
            "Epoch 679/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.7302 - accuracy: 0.7465\n",
            "Epoch 679: val_accuracy did not improve from 0.73303\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.7298 - accuracy: 0.7465 - val_loss: 1.3160 - val_accuracy: 0.6559\n",
            "Epoch 680/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.7251 - accuracy: 0.7461\n",
            "Epoch 680: val_accuracy did not improve from 0.73303\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.7255 - accuracy: 0.7458 - val_loss: 1.3855 - val_accuracy: 0.6418\n",
            "Epoch 681/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.6994 - accuracy: 0.7527\n",
            "Epoch 681: val_accuracy did not improve from 0.73303\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.6981 - accuracy: 0.7533 - val_loss: 1.0720 - val_accuracy: 0.6975\n",
            "Epoch 682/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.6826 - accuracy: 0.7640\n",
            "Epoch 682: val_accuracy did not improve from 0.73303\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 0.6831 - accuracy: 0.7636 - val_loss: 1.0405 - val_accuracy: 0.7286\n",
            "Epoch 683/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.6876 - accuracy: 0.7561\n",
            "Epoch 683: val_accuracy did not improve from 0.73303\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.6870 - accuracy: 0.7561 - val_loss: 1.2756 - val_accuracy: 0.6812\n",
            "Epoch 684/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.6639 - accuracy: 0.7665\n",
            "Epoch 684: val_accuracy did not improve from 0.73303\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.6641 - accuracy: 0.7665 - val_loss: 1.0413 - val_accuracy: 0.7324\n",
            "Epoch 685/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.7033 - accuracy: 0.7529\n",
            "Epoch 685: val_accuracy did not improve from 0.73303\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.7037 - accuracy: 0.7530 - val_loss: 2.5943 - val_accuracy: 0.4584\n",
            "Epoch 686/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.8451 - accuracy: 0.7284\n",
            "Epoch 686: val_accuracy did not improve from 0.73303\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.8451 - accuracy: 0.7282 - val_loss: 1.2140 - val_accuracy: 0.6889\n",
            "Epoch 687/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.6942 - accuracy: 0.7523\n",
            "Epoch 687: val_accuracy did not improve from 0.73303\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.6925 - accuracy: 0.7531 - val_loss: 1.1000 - val_accuracy: 0.7132\n",
            "Epoch 688/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.6546 - accuracy: 0.7675\n",
            "Epoch 688: val_accuracy improved from 0.73303 to 0.73624, saving model to /content/asl/Adam2/cp-688-0.74.hdf5\n",
            "391/391 [==============================] - 6s 15ms/step - loss: 0.6539 - accuracy: 0.7678 - val_loss: 1.0296 - val_accuracy: 0.7362\n",
            "Epoch 689/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.6272 - accuracy: 0.7738\n",
            "Epoch 689: val_accuracy did not improve from 0.73624\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.6272 - accuracy: 0.7738 - val_loss: 1.1711 - val_accuracy: 0.6927\n",
            "Epoch 690/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.6538 - accuracy: 0.7638\n",
            "Epoch 690: val_accuracy did not improve from 0.73624\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.6548 - accuracy: 0.7637 - val_loss: 1.1372 - val_accuracy: 0.7055\n",
            "Epoch 691/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.6505 - accuracy: 0.7660\n",
            "Epoch 691: val_accuracy did not improve from 0.73624\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.6505 - accuracy: 0.7660 - val_loss: 1.1535 - val_accuracy: 0.7087\n",
            "Epoch 692/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.6956 - accuracy: 0.7535\n",
            "Epoch 692: val_accuracy did not improve from 0.73624\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.6956 - accuracy: 0.7535 - val_loss: 1.1911 - val_accuracy: 0.6969\n",
            "Epoch 693/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.6803 - accuracy: 0.7622\n",
            "Epoch 693: val_accuracy did not improve from 0.73624\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.6803 - accuracy: 0.7622 - val_loss: 1.1634 - val_accuracy: 0.6969\n",
            "Epoch 694/700\n",
            "389/391 [============================>.] - ETA: 0s - loss: 0.7371 - accuracy: 0.7424\n",
            "Epoch 694: val_accuracy did not improve from 0.73624\n",
            "391/391 [==============================] - 6s 15ms/step - loss: 0.7379 - accuracy: 0.7423 - val_loss: 1.0671 - val_accuracy: 0.7276\n",
            "Epoch 695/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.7158 - accuracy: 0.7538\n",
            "Epoch 695: val_accuracy did not improve from 0.73624\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.7159 - accuracy: 0.7538 - val_loss: 1.1738 - val_accuracy: 0.6908\n",
            "Epoch 696/700\n",
            "390/391 [============================>.] - ETA: 0s - loss: 0.6852 - accuracy: 0.7534\n",
            "Epoch 696: val_accuracy did not improve from 0.73624\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.6850 - accuracy: 0.7535 - val_loss: 1.1117 - val_accuracy: 0.7100\n",
            "Epoch 697/700\n",
            "387/391 [============================>.] - ETA: 0s - loss: 0.6252 - accuracy: 0.7761\n",
            "Epoch 697: val_accuracy did not improve from 0.73624\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.6253 - accuracy: 0.7758 - val_loss: 1.1384 - val_accuracy: 0.7212\n",
            "Epoch 698/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.6110 - accuracy: 0.7817\n",
            "Epoch 698: val_accuracy did not improve from 0.73624\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 0.6110 - accuracy: 0.7817 - val_loss: 1.1644 - val_accuracy: 0.6943\n",
            "Epoch 699/700\n",
            "388/391 [============================>.] - ETA: 0s - loss: 0.6936 - accuracy: 0.7610\n",
            "Epoch 699: val_accuracy did not improve from 0.73624\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.6933 - accuracy: 0.7606 - val_loss: 1.0849 - val_accuracy: 0.7295\n",
            "Epoch 700/700\n",
            "391/391 [==============================] - ETA: 0s - loss: 0.6842 - accuracy: 0.7598\n",
            "Epoch 700: val_accuracy did not improve from 0.73624\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 0.6842 - accuracy: 0.7598 - val_loss: 1.6433 - val_accuracy: 0.5999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try another model"
      ],
      "metadata": {
        "id": "IVb-p4b_hGHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 174\n",
        "\n",
        "model = Sequential()\n",
        "model.add(GRU(256, return_sequences=True, input_shape=(1, 543)))\n",
        "model.add(GRU(128 ))\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "filepath       = \"/content/asl/Adam3/cp-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint     = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history2 = model.fit(X_train, y_train_encoded, validation_data=(X_test, y_test_encoded), epochs=700, batch_size=128,callbacks=callbacks_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cL37dLqOlCKn",
        "outputId": "168b1840-3ee0-4e8c-b736-9214ca7ae39c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_10 (GRU)                (None, 1, 256)            615168    \n",
            "                                                                 \n",
            " gru_11 (GRU)                (None, 128)               148224    \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 174)               44718     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 841134 (3.21 MB)\n",
            "Trainable params: 841134 (3.21 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 5.0900 - accuracy: 0.0139\n",
            "Epoch 1: val_accuracy improved from -inf to 0.01953, saving model to /content/asl/Adam3/cp-01-0.02.hdf5\n",
            "98/98 [==============================] - 7s 14ms/step - loss: 5.0813 - accuracy: 0.0142 - val_loss: 4.9022 - val_accuracy: 0.0195\n",
            "Epoch 2/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 4.8297 - accuracy: 0.0225\n",
            "Epoch 2: val_accuracy improved from 0.01953 to 0.03169, saving model to /content/asl/Adam3/cp-02-0.03.hdf5\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 4.8257 - accuracy: 0.0236 - val_loss: 4.7401 - val_accuracy: 0.0317\n",
            "Epoch 3/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 4.6547 - accuracy: 0.0380\n",
            "Epoch 3: val_accuracy improved from 0.03169 to 0.04353, saving model to /content/asl/Adam3/cp-03-0.04.hdf5\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 4.6412 - accuracy: 0.0396 - val_loss: 4.5294 - val_accuracy: 0.0435\n",
            "Epoch 4/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 4.2663 - accuracy: 0.0721\n",
            "Epoch 4: val_accuracy improved from 0.04353 to 0.11908, saving model to /content/asl/Adam3/cp-04-0.12.hdf5\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 4.2574 - accuracy: 0.0735 - val_loss: 3.8756 - val_accuracy: 0.1191\n",
            "Epoch 5/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 3.8003 - accuracy: 0.1067\n",
            "Epoch 5: val_accuracy improved from 0.11908 to 0.13220, saving model to /content/asl/Adam3/cp-05-0.13.hdf5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 3.7986 - accuracy: 0.1070 - val_loss: 3.5926 - val_accuracy: 0.1322\n",
            "Epoch 6/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 3.4946 - accuracy: 0.1500\n",
            "Epoch 6: val_accuracy improved from 0.13220 to 0.19590, saving model to /content/asl/Adam3/cp-06-0.20.hdf5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 3.4911 - accuracy: 0.1505 - val_loss: 3.2486 - val_accuracy: 0.1959\n",
            "Epoch 7/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 3.2823 - accuracy: 0.1724\n",
            "Epoch 7: val_accuracy improved from 0.19590 to 0.22119, saving model to /content/asl/Adam3/cp-07-0.22.hdf5\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 3.2837 - accuracy: 0.1722 - val_loss: 3.0239 - val_accuracy: 0.2212\n",
            "Epoch 8/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 3.0536 - accuracy: 0.2086\n",
            "Epoch 8: val_accuracy improved from 0.22119 to 0.27977, saving model to /content/asl/Adam3/cp-08-0.28.hdf5\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 3.0497 - accuracy: 0.2101 - val_loss: 2.8159 - val_accuracy: 0.2798\n",
            "Epoch 9/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 2.8438 - accuracy: 0.2509\n",
            "Epoch 9: val_accuracy did not improve from 0.27977\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 2.8414 - accuracy: 0.2512 - val_loss: 2.7508 - val_accuracy: 0.2561\n",
            "Epoch 10/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 2.7010 - accuracy: 0.2705\n",
            "Epoch 10: val_accuracy did not improve from 0.27977\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 2.7014 - accuracy: 0.2705 - val_loss: 2.8296 - val_accuracy: 0.2129\n",
            "Epoch 11/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 2.5605 - accuracy: 0.3068\n",
            "Epoch 11: val_accuracy did not improve from 0.27977\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 2.5605 - accuracy: 0.3068 - val_loss: 2.5959 - val_accuracy: 0.2778\n",
            "Epoch 12/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 2.4653 - accuracy: 0.3229\n",
            "Epoch 12: val_accuracy improved from 0.27977 to 0.36780, saving model to /content/asl/Adam3/cp-12-0.37.hdf5\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 2.4653 - accuracy: 0.3229 - val_loss: 2.3279 - val_accuracy: 0.3678\n",
            "Epoch 13/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 2.3917 - accuracy: 0.3345\n",
            "Epoch 13: val_accuracy did not improve from 0.36780\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 2.3933 - accuracy: 0.3341 - val_loss: 2.5837 - val_accuracy: 0.2689\n",
            "Epoch 14/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 2.4223 - accuracy: 0.3290\n",
            "Epoch 14: val_accuracy improved from 0.36780 to 0.38412, saving model to /content/asl/Adam3/cp-14-0.38.hdf5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 2.4157 - accuracy: 0.3302 - val_loss: 2.2084 - val_accuracy: 0.3841\n",
            "Epoch 15/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 2.2640 - accuracy: 0.3599\n",
            "Epoch 15: val_accuracy did not improve from 0.38412\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 2.2698 - accuracy: 0.3577 - val_loss: 2.4288 - val_accuracy: 0.3143\n",
            "Epoch 16/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 2.2855 - accuracy: 0.3516\n",
            "Epoch 16: val_accuracy did not improve from 0.38412\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 2.2855 - accuracy: 0.3516 - val_loss: 2.1955 - val_accuracy: 0.3771\n",
            "Epoch 17/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 2.2433 - accuracy: 0.3594\n",
            "Epoch 17: val_accuracy did not improve from 0.38412\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 2.2376 - accuracy: 0.3604 - val_loss: 2.1672 - val_accuracy: 0.3700\n",
            "Epoch 18/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 2.0880 - accuracy: 0.3962\n",
            "Epoch 18: val_accuracy improved from 0.38412 to 0.41357, saving model to /content/asl/Adam3/cp-18-0.41.hdf5\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 2.0865 - accuracy: 0.3970 - val_loss: 2.0645 - val_accuracy: 0.4136\n",
            "Epoch 19/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 2.1560 - accuracy: 0.3793\n",
            "Epoch 19: val_accuracy improved from 0.41357 to 0.42734, saving model to /content/asl/Adam3/cp-19-0.43.hdf5\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 2.1646 - accuracy: 0.3774 - val_loss: 2.0148 - val_accuracy: 0.4273\n",
            "Epoch 20/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 2.1050 - accuracy: 0.3891\n",
            "Epoch 20: val_accuracy improved from 0.42734 to 0.42990, saving model to /content/asl/Adam3/cp-20-0.43.hdf5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 2.1025 - accuracy: 0.3891 - val_loss: 1.9885 - val_accuracy: 0.4299\n",
            "Epoch 21/700\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 2.0521 - accuracy: 0.4044\n",
            "Epoch 21: val_accuracy improved from 0.42990 to 0.43118, saving model to /content/asl/Adam3/cp-21-0.43.hdf5\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 2.0439 - accuracy: 0.4069 - val_loss: 1.9683 - val_accuracy: 0.4312\n",
            "Epoch 22/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 1.9534 - accuracy: 0.4265\n",
            "Epoch 22: val_accuracy did not improve from 0.43118\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.9533 - accuracy: 0.4272 - val_loss: 2.0167 - val_accuracy: 0.4110\n",
            "Epoch 23/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 1.9971 - accuracy: 0.4148\n",
            "Epoch 23: val_accuracy improved from 0.43118 to 0.44590, saving model to /content/asl/Adam3/cp-23-0.45.hdf5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.9942 - accuracy: 0.4152 - val_loss: 1.8704 - val_accuracy: 0.4459\n",
            "Epoch 24/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.9229 - accuracy: 0.4365\n",
            "Epoch 24: val_accuracy improved from 0.44590 to 0.46063, saving model to /content/asl/Adam3/cp-24-0.46.hdf5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.9229 - accuracy: 0.4365 - val_loss: 1.8545 - val_accuracy: 0.4606\n",
            "Epoch 25/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 1.9163 - accuracy: 0.4352\n",
            "Epoch 25: val_accuracy did not improve from 0.46063\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.9167 - accuracy: 0.4348 - val_loss: 1.9336 - val_accuracy: 0.4273\n",
            "Epoch 26/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 1.8274 - accuracy: 0.4563\n",
            "Epoch 26: val_accuracy improved from 0.46063 to 0.46991, saving model to /content/asl/Adam3/cp-26-0.47.hdf5\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.8293 - accuracy: 0.4559 - val_loss: 1.8040 - val_accuracy: 0.4699\n",
            "Epoch 27/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 1.8002 - accuracy: 0.4648\n",
            "Epoch 27: val_accuracy improved from 0.46991 to 0.48592, saving model to /content/asl/Adam3/cp-27-0.49.hdf5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.7994 - accuracy: 0.4646 - val_loss: 1.7542 - val_accuracy: 0.4859\n",
            "Epoch 28/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 1.9228 - accuracy: 0.4256\n",
            "Epoch 28: val_accuracy improved from 0.48592 to 0.49232, saving model to /content/asl/Adam3/cp-28-0.49.hdf5\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1.9055 - accuracy: 0.4310 - val_loss: 1.7334 - val_accuracy: 0.4923\n",
            "Epoch 29/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.7507 - accuracy: 0.4798\n",
            "Epoch 29: val_accuracy did not improve from 0.49232\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1.7507 - accuracy: 0.4798 - val_loss: 1.8003 - val_accuracy: 0.4571\n",
            "Epoch 30/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 1.8316 - accuracy: 0.4516\n",
            "Epoch 30: val_accuracy did not improve from 0.49232\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1.8383 - accuracy: 0.4509 - val_loss: 1.7594 - val_accuracy: 0.4824\n",
            "Epoch 31/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 1.8710 - accuracy: 0.4486\n",
            "Epoch 31: val_accuracy did not improve from 0.49232\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.8693 - accuracy: 0.4487 - val_loss: 1.9079 - val_accuracy: 0.4401\n",
            "Epoch 32/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 1.7536 - accuracy: 0.4794\n",
            "Epoch 32: val_accuracy improved from 0.49232 to 0.51697, saving model to /content/asl/Adam3/cp-32-0.52.hdf5\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.7514 - accuracy: 0.4795 - val_loss: 1.6370 - val_accuracy: 0.5170\n",
            "Epoch 33/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 1.6855 - accuracy: 0.4926\n",
            "Epoch 33: val_accuracy improved from 0.51697 to 0.52209, saving model to /content/asl/Adam3/cp-33-0.52.hdf5\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.6855 - accuracy: 0.4926 - val_loss: 1.6493 - val_accuracy: 0.5221\n",
            "Epoch 34/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 1.6722 - accuracy: 0.4985\n",
            "Epoch 34: val_accuracy did not improve from 0.52209\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.6711 - accuracy: 0.4988 - val_loss: 1.6341 - val_accuracy: 0.5163\n",
            "Epoch 35/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 1.6924 - accuracy: 0.4907\n",
            "Epoch 35: val_accuracy did not improve from 0.52209\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.6919 - accuracy: 0.4913 - val_loss: 1.8611 - val_accuracy: 0.4443\n",
            "Epoch 36/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 1.6595 - accuracy: 0.4981\n",
            "Epoch 36: val_accuracy did not improve from 0.52209\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.6649 - accuracy: 0.4978 - val_loss: 1.6548 - val_accuracy: 0.5147\n",
            "Epoch 37/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.6081 - accuracy: 0.5123\n",
            "Epoch 37: val_accuracy did not improve from 0.52209\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 1.6081 - accuracy: 0.5123 - val_loss: 1.7805 - val_accuracy: 0.4571\n",
            "Epoch 38/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.6452 - accuracy: 0.5017\n",
            "Epoch 38: val_accuracy improved from 0.52209 to 0.53073, saving model to /content/asl/Adam3/cp-38-0.53.hdf5\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.6452 - accuracy: 0.5017 - val_loss: 1.5577 - val_accuracy: 0.5307\n",
            "Epoch 39/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 1.5519 - accuracy: 0.5291\n",
            "Epoch 39: val_accuracy did not improve from 0.53073\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.5518 - accuracy: 0.5289 - val_loss: 1.7417 - val_accuracy: 0.4725\n",
            "Epoch 40/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 1.5912 - accuracy: 0.5121\n",
            "Epoch 40: val_accuracy did not improve from 0.53073\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.5939 - accuracy: 0.5118 - val_loss: 1.6460 - val_accuracy: 0.5109\n",
            "Epoch 41/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 1.5832 - accuracy: 0.5145\n",
            "Epoch 41: val_accuracy did not improve from 0.53073\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.5956 - accuracy: 0.5117 - val_loss: 1.7443 - val_accuracy: 0.4712\n",
            "Epoch 42/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.5461 - accuracy: 0.5280\n",
            "Epoch 42: val_accuracy did not improve from 0.53073\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 1.5461 - accuracy: 0.5280 - val_loss: 1.7651 - val_accuracy: 0.4808\n",
            "Epoch 43/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 1.6577 - accuracy: 0.4902\n",
            "Epoch 43: val_accuracy did not improve from 0.53073\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.6563 - accuracy: 0.4906 - val_loss: 1.6558 - val_accuracy: 0.4930\n",
            "Epoch 44/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.5452 - accuracy: 0.5205\n",
            "Epoch 44: val_accuracy improved from 0.53073 to 0.54001, saving model to /content/asl/Adam3/cp-44-0.54.hdf5\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.5452 - accuracy: 0.5205 - val_loss: 1.5334 - val_accuracy: 0.5400\n",
            "Epoch 45/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 1.5040 - accuracy: 0.5362\n",
            "Epoch 45: val_accuracy did not improve from 0.54001\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.5061 - accuracy: 0.5351 - val_loss: 1.7130 - val_accuracy: 0.4968\n",
            "Epoch 46/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 1.4939 - accuracy: 0.5398\n",
            "Epoch 46: val_accuracy did not improve from 0.54001\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1.4968 - accuracy: 0.5396 - val_loss: 1.6231 - val_accuracy: 0.5144\n",
            "Epoch 47/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 1.5095 - accuracy: 0.5306\n",
            "Epoch 47: val_accuracy did not improve from 0.54001\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.5075 - accuracy: 0.5316 - val_loss: 1.7605 - val_accuracy: 0.4629\n",
            "Epoch 48/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 1.4556 - accuracy: 0.5523\n",
            "Epoch 48: val_accuracy did not improve from 0.54001\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.4590 - accuracy: 0.5507 - val_loss: 1.8340 - val_accuracy: 0.4600\n",
            "Epoch 49/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 1.5139 - accuracy: 0.5283\n",
            "Epoch 49: val_accuracy did not improve from 0.54001\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.5159 - accuracy: 0.5280 - val_loss: 1.6643 - val_accuracy: 0.4978\n",
            "Epoch 50/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 1.4490 - accuracy: 0.5495\n",
            "Epoch 50: val_accuracy did not improve from 0.54001\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.4471 - accuracy: 0.5500 - val_loss: 1.5932 - val_accuracy: 0.5307\n",
            "Epoch 51/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 1.4206 - accuracy: 0.5582\n",
            "Epoch 51: val_accuracy improved from 0.54001 to 0.55730, saving model to /content/asl/Adam3/cp-51-0.56.hdf5\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.4175 - accuracy: 0.5597 - val_loss: 1.4493 - val_accuracy: 0.5573\n",
            "Epoch 52/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 1.5046 - accuracy: 0.5271\n",
            "Epoch 52: val_accuracy did not improve from 0.55730\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.5174 - accuracy: 0.5236 - val_loss: 1.8898 - val_accuracy: 0.4379\n",
            "Epoch 53/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 1.3980 - accuracy: 0.5669\n",
            "Epoch 53: val_accuracy improved from 0.55730 to 0.57907, saving model to /content/asl/Adam3/cp-53-0.58.hdf5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.3904 - accuracy: 0.5687 - val_loss: 1.3970 - val_accuracy: 0.5791\n",
            "Epoch 54/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.4433 - accuracy: 0.5440\n",
            "Epoch 54: val_accuracy did not improve from 0.57907\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.4433 - accuracy: 0.5440 - val_loss: 1.5941 - val_accuracy: 0.5157\n",
            "Epoch 55/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.4229 - accuracy: 0.5569\n",
            "Epoch 55: val_accuracy improved from 0.57907 to 0.58643, saving model to /content/asl/Adam3/cp-55-0.59.hdf5\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.4229 - accuracy: 0.5569 - val_loss: 1.4000 - val_accuracy: 0.5864\n",
            "Epoch 56/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 1.4034 - accuracy: 0.5591\n",
            "Epoch 56: val_accuracy did not improve from 0.58643\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.4045 - accuracy: 0.5588 - val_loss: 1.5255 - val_accuracy: 0.5423\n",
            "Epoch 57/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 1.3798 - accuracy: 0.5688\n",
            "Epoch 57: val_accuracy did not improve from 0.58643\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.3798 - accuracy: 0.5687 - val_loss: 1.4001 - val_accuracy: 0.5832\n",
            "Epoch 58/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 1.3688 - accuracy: 0.5675\n",
            "Epoch 58: val_accuracy did not improve from 0.58643\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.3613 - accuracy: 0.5700 - val_loss: 1.4168 - val_accuracy: 0.5749\n",
            "Epoch 59/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 1.3235 - accuracy: 0.5842\n",
            "Epoch 59: val_accuracy did not improve from 0.58643\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.3399 - accuracy: 0.5807 - val_loss: 1.9230 - val_accuracy: 0.4571\n",
            "Epoch 60/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 1.4366 - accuracy: 0.5426\n",
            "Epoch 60: val_accuracy did not improve from 0.58643\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.4369 - accuracy: 0.5429 - val_loss: 1.5876 - val_accuracy: 0.5128\n",
            "Epoch 61/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 1.3010 - accuracy: 0.5902\n",
            "Epoch 61: val_accuracy did not improve from 0.58643\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.2962 - accuracy: 0.5913 - val_loss: 1.3822 - val_accuracy: 0.5733\n",
            "Epoch 62/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 1.3734 - accuracy: 0.5673\n",
            "Epoch 62: val_accuracy did not improve from 0.58643\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.3733 - accuracy: 0.5673 - val_loss: 1.5586 - val_accuracy: 0.5262\n",
            "Epoch 63/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 1.3107 - accuracy: 0.5881\n",
            "Epoch 63: val_accuracy did not improve from 0.58643\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.3145 - accuracy: 0.5864 - val_loss: 1.4798 - val_accuracy: 0.5429\n",
            "Epoch 64/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 1.4382 - accuracy: 0.5504\n",
            "Epoch 64: val_accuracy did not improve from 0.58643\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.4332 - accuracy: 0.5527 - val_loss: 1.4061 - val_accuracy: 0.5835\n",
            "Epoch 65/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 1.2516 - accuracy: 0.6028\n",
            "Epoch 65: val_accuracy improved from 0.58643 to 0.59283, saving model to /content/asl/Adam3/cp-65-0.59.hdf5\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.2471 - accuracy: 0.6045 - val_loss: 1.3379 - val_accuracy: 0.5928\n",
            "Epoch 66/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 1.3040 - accuracy: 0.5909\n",
            "Epoch 66: val_accuracy did not improve from 0.59283\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.3019 - accuracy: 0.5911 - val_loss: 1.3835 - val_accuracy: 0.5896\n",
            "Epoch 67/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 1.3010 - accuracy: 0.5879\n",
            "Epoch 67: val_accuracy improved from 0.59283 to 0.59763, saving model to /content/asl/Adam3/cp-67-0.60.hdf5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.3008 - accuracy: 0.5879 - val_loss: 1.3243 - val_accuracy: 0.5976\n",
            "Epoch 68/700\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 1.2656 - accuracy: 0.5945\n",
            "Epoch 68: val_accuracy did not improve from 0.59763\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.2590 - accuracy: 0.5984 - val_loss: 1.3994 - val_accuracy: 0.5797\n",
            "Epoch 69/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 1.3107 - accuracy: 0.5773\n",
            "Epoch 69: val_accuracy improved from 0.59763 to 0.60371, saving model to /content/asl/Adam3/cp-69-0.60.hdf5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.3101 - accuracy: 0.5782 - val_loss: 1.3300 - val_accuracy: 0.6037\n",
            "Epoch 70/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 1.2385 - accuracy: 0.6030\n",
            "Epoch 70: val_accuracy did not improve from 0.60371\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.2356 - accuracy: 0.6041 - val_loss: 1.3342 - val_accuracy: 0.5976\n",
            "Epoch 71/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 1.2125 - accuracy: 0.6125\n",
            "Epoch 71: val_accuracy did not improve from 0.60371\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.2133 - accuracy: 0.6132 - val_loss: 1.3536 - val_accuracy: 0.5855\n",
            "Epoch 72/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.2136 - accuracy: 0.6092\n",
            "Epoch 72: val_accuracy did not improve from 0.60371\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.2136 - accuracy: 0.6092 - val_loss: 1.3544 - val_accuracy: 0.5864\n",
            "Epoch 73/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 1.2207 - accuracy: 0.6076\n",
            "Epoch 73: val_accuracy improved from 0.60371 to 0.61428, saving model to /content/asl/Adam3/cp-73-0.61.hdf5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.2202 - accuracy: 0.6085 - val_loss: 1.2828 - val_accuracy: 0.6143\n",
            "Epoch 74/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.2321 - accuracy: 0.6033\n",
            "Epoch 74: val_accuracy did not improve from 0.61428\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.2321 - accuracy: 0.6033 - val_loss: 1.5048 - val_accuracy: 0.5538\n",
            "Epoch 75/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 1.1689 - accuracy: 0.6257\n",
            "Epoch 75: val_accuracy improved from 0.61428 to 0.63636, saving model to /content/asl/Adam3/cp-75-0.64.hdf5\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.1722 - accuracy: 0.6248 - val_loss: 1.2283 - val_accuracy: 0.6364\n",
            "Epoch 76/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 1.3122 - accuracy: 0.5810\n",
            "Epoch 76: val_accuracy did not improve from 0.63636\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.3101 - accuracy: 0.5802 - val_loss: 1.3824 - val_accuracy: 0.5867\n",
            "Epoch 77/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 1.2236 - accuracy: 0.6074\n",
            "Epoch 77: val_accuracy did not improve from 0.63636\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.2247 - accuracy: 0.6072 - val_loss: 1.5389 - val_accuracy: 0.5278\n",
            "Epoch 78/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 1.1679 - accuracy: 0.6253\n",
            "Epoch 78: val_accuracy did not improve from 0.63636\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.1693 - accuracy: 0.6247 - val_loss: 1.5018 - val_accuracy: 0.5503\n",
            "Epoch 79/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.2664 - accuracy: 0.5968\n",
            "Epoch 79: val_accuracy did not improve from 0.63636\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.2664 - accuracy: 0.5968 - val_loss: 1.4594 - val_accuracy: 0.5640\n",
            "Epoch 80/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 1.1520 - accuracy: 0.6263\n",
            "Epoch 80: val_accuracy did not improve from 0.63636\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.1520 - accuracy: 0.6262 - val_loss: 1.3208 - val_accuracy: 0.5896\n",
            "Epoch 81/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 1.1740 - accuracy: 0.6201\n",
            "Epoch 81: val_accuracy did not improve from 0.63636\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.1727 - accuracy: 0.6203 - val_loss: 1.4038 - val_accuracy: 0.5749\n",
            "Epoch 82/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 1.1219 - accuracy: 0.6358\n",
            "Epoch 82: val_accuracy did not improve from 0.63636\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.1221 - accuracy: 0.6364 - val_loss: 1.3006 - val_accuracy: 0.6111\n",
            "Epoch 83/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 1.1756 - accuracy: 0.6218\n",
            "Epoch 83: val_accuracy did not improve from 0.63636\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.1774 - accuracy: 0.6209 - val_loss: 1.3809 - val_accuracy: 0.5746\n",
            "Epoch 84/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 1.1003 - accuracy: 0.6447\n",
            "Epoch 84: val_accuracy did not improve from 0.63636\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.0998 - accuracy: 0.6445 - val_loss: 1.3024 - val_accuracy: 0.5948\n",
            "Epoch 85/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 1.1238 - accuracy: 0.6326\n",
            "Epoch 85: val_accuracy did not improve from 0.63636\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.1241 - accuracy: 0.6329 - val_loss: 1.3504 - val_accuracy: 0.5877\n",
            "Epoch 86/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 1.1524 - accuracy: 0.6274\n",
            "Epoch 86: val_accuracy did not improve from 0.63636\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.1521 - accuracy: 0.6275 - val_loss: 1.3039 - val_accuracy: 0.6050\n",
            "Epoch 87/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 1.0522 - accuracy: 0.6597\n",
            "Epoch 87: val_accuracy did not improve from 0.63636\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.0532 - accuracy: 0.6597 - val_loss: 1.2490 - val_accuracy: 0.6312\n",
            "Epoch 88/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 1.1560 - accuracy: 0.6288\n",
            "Epoch 88: val_accuracy did not improve from 0.63636\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.1614 - accuracy: 0.6261 - val_loss: 1.2466 - val_accuracy: 0.6264\n",
            "Epoch 89/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 1.1244 - accuracy: 0.6316\n",
            "Epoch 89: val_accuracy did not improve from 0.63636\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.1308 - accuracy: 0.6304 - val_loss: 1.3240 - val_accuracy: 0.6028\n",
            "Epoch 90/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.1311 - accuracy: 0.6288\n",
            "Epoch 90: val_accuracy did not improve from 0.63636\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.1311 - accuracy: 0.6288 - val_loss: 1.2740 - val_accuracy: 0.6111\n",
            "Epoch 91/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 1.1702 - accuracy: 0.6158\n",
            "Epoch 91: val_accuracy did not improve from 0.63636\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.1710 - accuracy: 0.6156 - val_loss: 1.3478 - val_accuracy: 0.5899\n",
            "Epoch 92/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 1.0517 - accuracy: 0.6567\n",
            "Epoch 92: val_accuracy did not improve from 0.63636\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.0510 - accuracy: 0.6565 - val_loss: 1.3373 - val_accuracy: 0.5986\n",
            "Epoch 93/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 1.0848 - accuracy: 0.6478\n",
            "Epoch 93: val_accuracy did not improve from 0.63636\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.0877 - accuracy: 0.6472 - val_loss: 1.4246 - val_accuracy: 0.5730\n",
            "Epoch 94/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 1.0701 - accuracy: 0.6513\n",
            "Epoch 94: val_accuracy did not improve from 0.63636\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.0679 - accuracy: 0.6513 - val_loss: 1.2738 - val_accuracy: 0.6130\n",
            "Epoch 95/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.0492 - accuracy: 0.6520\n",
            "Epoch 95: val_accuracy improved from 0.63636 to 0.64565, saving model to /content/asl/Adam3/cp-95-0.65.hdf5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.0492 - accuracy: 0.6520 - val_loss: 1.2056 - val_accuracy: 0.6456\n",
            "Epoch 96/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 1.0421 - accuracy: 0.6599\n",
            "Epoch 96: val_accuracy did not improve from 0.64565\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.0384 - accuracy: 0.6607 - val_loss: 1.2099 - val_accuracy: 0.6373\n",
            "Epoch 97/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 1.0046 - accuracy: 0.6745\n",
            "Epoch 97: val_accuracy did not improve from 0.64565\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.0114 - accuracy: 0.6721 - val_loss: 1.2117 - val_accuracy: 0.6338\n",
            "Epoch 98/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 1.0558 - accuracy: 0.6513\n",
            "Epoch 98: val_accuracy did not improve from 0.64565\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.0567 - accuracy: 0.6510 - val_loss: 1.2171 - val_accuracy: 0.6332\n",
            "Epoch 99/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.9709 - accuracy: 0.6811\n",
            "Epoch 99: val_accuracy improved from 0.64565 to 0.65397, saving model to /content/asl/Adam3/cp-99-0.65.hdf5\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.9709 - accuracy: 0.6811 - val_loss: 1.1753 - val_accuracy: 0.6540\n",
            "Epoch 100/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 1.0696 - accuracy: 0.6508\n",
            "Epoch 100: val_accuracy did not improve from 0.65397\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.0665 - accuracy: 0.6512 - val_loss: 1.3084 - val_accuracy: 0.5919\n",
            "Epoch 101/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.0180 - accuracy: 0.6675\n",
            "Epoch 101: val_accuracy did not improve from 0.65397\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.0180 - accuracy: 0.6675 - val_loss: 1.2242 - val_accuracy: 0.6316\n",
            "Epoch 102/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 1.0291 - accuracy: 0.6626\n",
            "Epoch 102: val_accuracy did not improve from 0.65397\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 1.0320 - accuracy: 0.6621 - val_loss: 1.7730 - val_accuracy: 0.5192\n",
            "Epoch 103/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 1.0227 - accuracy: 0.6626\n",
            "Epoch 103: val_accuracy did not improve from 0.65397\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.0366 - accuracy: 0.6584 - val_loss: 1.6835 - val_accuracy: 0.5080\n",
            "Epoch 104/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 1.0993 - accuracy: 0.6407\n",
            "Epoch 104: val_accuracy did not improve from 0.65397\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.0980 - accuracy: 0.6408 - val_loss: 1.1664 - val_accuracy: 0.6511\n",
            "Epoch 105/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.9706 - accuracy: 0.6771\n",
            "Epoch 105: val_accuracy improved from 0.65397 to 0.66805, saving model to /content/asl/Adam3/cp-105-0.67.hdf5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.9689 - accuracy: 0.6779 - val_loss: 1.1195 - val_accuracy: 0.6681\n",
            "Epoch 106/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.9481 - accuracy: 0.6852\n",
            "Epoch 106: val_accuracy did not improve from 0.66805\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.9481 - accuracy: 0.6852 - val_loss: 1.4696 - val_accuracy: 0.5503\n",
            "Epoch 107/700\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.9877 - accuracy: 0.6789\n",
            "Epoch 107: val_accuracy did not improve from 0.66805\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.9850 - accuracy: 0.6795 - val_loss: 1.1624 - val_accuracy: 0.6565\n",
            "Epoch 108/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.9471 - accuracy: 0.6878\n",
            "Epoch 108: val_accuracy did not improve from 0.66805\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.9452 - accuracy: 0.6878 - val_loss: 1.1538 - val_accuracy: 0.6492\n",
            "Epoch 109/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 1.1304 - accuracy: 0.6276\n",
            "Epoch 109: val_accuracy did not improve from 0.66805\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.1366 - accuracy: 0.6263 - val_loss: 1.4537 - val_accuracy: 0.5512\n",
            "Epoch 110/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.9479 - accuracy: 0.6872\n",
            "Epoch 110: val_accuracy did not improve from 0.66805\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.9508 - accuracy: 0.6869 - val_loss: 1.3513 - val_accuracy: 0.5848\n",
            "Epoch 111/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.9585 - accuracy: 0.6788\n",
            "Epoch 111: val_accuracy did not improve from 0.66805\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.9577 - accuracy: 0.6797 - val_loss: 1.1398 - val_accuracy: 0.6597\n",
            "Epoch 112/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.8910 - accuracy: 0.7075\n",
            "Epoch 112: val_accuracy did not improve from 0.66805\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.8978 - accuracy: 0.7052 - val_loss: 1.1636 - val_accuracy: 0.6501\n",
            "Epoch 113/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.9691 - accuracy: 0.6783\n",
            "Epoch 113: val_accuracy improved from 0.66805 to 0.66997, saving model to /content/asl/Adam3/cp-113-0.67.hdf5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.9613 - accuracy: 0.6801 - val_loss: 1.1156 - val_accuracy: 0.6700\n",
            "Epoch 114/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 1.0210 - accuracy: 0.6611\n",
            "Epoch 114: val_accuracy did not improve from 0.66997\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.0219 - accuracy: 0.6609 - val_loss: 1.3811 - val_accuracy: 0.6044\n",
            "Epoch 115/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.9662 - accuracy: 0.6823\n",
            "Epoch 115: val_accuracy did not improve from 0.66997\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.9728 - accuracy: 0.6806 - val_loss: 1.6530 - val_accuracy: 0.5323\n",
            "Epoch 116/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.9354 - accuracy: 0.6856\n",
            "Epoch 116: val_accuracy did not improve from 0.66997\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.9354 - accuracy: 0.6856 - val_loss: 1.2488 - val_accuracy: 0.6236\n",
            "Epoch 117/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.9607 - accuracy: 0.6832\n",
            "Epoch 117: val_accuracy did not improve from 0.66997\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.9601 - accuracy: 0.6833 - val_loss: 1.1303 - val_accuracy: 0.6610\n",
            "Epoch 118/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.9226 - accuracy: 0.6940\n",
            "Epoch 118: val_accuracy did not improve from 0.66997\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.9235 - accuracy: 0.6929 - val_loss: 1.1849 - val_accuracy: 0.6472\n",
            "Epoch 119/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.9509 - accuracy: 0.6872\n",
            "Epoch 119: val_accuracy improved from 0.66997 to 0.67990, saving model to /content/asl/Adam3/cp-119-0.68.hdf5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.9475 - accuracy: 0.6883 - val_loss: 1.1070 - val_accuracy: 0.6799\n",
            "Epoch 120/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.9371 - accuracy: 0.6921\n",
            "Epoch 120: val_accuracy did not improve from 0.67990\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.9455 - accuracy: 0.6881 - val_loss: 1.1940 - val_accuracy: 0.6440\n",
            "Epoch 121/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.8987 - accuracy: 0.6979\n",
            "Epoch 121: val_accuracy did not improve from 0.67990\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.8982 - accuracy: 0.6979 - val_loss: 1.1593 - val_accuracy: 0.6511\n",
            "Epoch 122/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.8547 - accuracy: 0.7146\n",
            "Epoch 122: val_accuracy improved from 0.67990 to 0.69526, saving model to /content/asl/Adam3/cp-122-0.70.hdf5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.8540 - accuracy: 0.7156 - val_loss: 1.0514 - val_accuracy: 0.6953\n",
            "Epoch 123/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.8369 - accuracy: 0.7252\n",
            "Epoch 123: val_accuracy did not improve from 0.69526\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.8355 - accuracy: 0.7249 - val_loss: 1.1038 - val_accuracy: 0.6748\n",
            "Epoch 124/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.9026 - accuracy: 0.7011\n",
            "Epoch 124: val_accuracy did not improve from 0.69526\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.9026 - accuracy: 0.7011 - val_loss: 1.1124 - val_accuracy: 0.6674\n",
            "Epoch 125/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.9766 - accuracy: 0.6779\n",
            "Epoch 125: val_accuracy did not improve from 0.69526\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.9730 - accuracy: 0.6789 - val_loss: 1.1112 - val_accuracy: 0.6770\n",
            "Epoch 126/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.8176 - accuracy: 0.7281\n",
            "Epoch 126: val_accuracy improved from 0.69526 to 0.71799, saving model to /content/asl/Adam3/cp-126-0.72.hdf5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.8130 - accuracy: 0.7291 - val_loss: 0.9780 - val_accuracy: 0.7180\n",
            "Epoch 127/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.9392 - accuracy: 0.6858\n",
            "Epoch 127: val_accuracy did not improve from 0.71799\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.9415 - accuracy: 0.6855 - val_loss: 1.3216 - val_accuracy: 0.6127\n",
            "Epoch 128/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.8940 - accuracy: 0.7046\n",
            "Epoch 128: val_accuracy did not improve from 0.71799\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.8941 - accuracy: 0.7046 - val_loss: 1.1639 - val_accuracy: 0.6498\n",
            "Epoch 129/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.9739 - accuracy: 0.6824\n",
            "Epoch 129: val_accuracy did not improve from 0.71799\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.9612 - accuracy: 0.6861 - val_loss: 1.1046 - val_accuracy: 0.6732\n",
            "Epoch 130/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.8280 - accuracy: 0.7261\n",
            "Epoch 130: val_accuracy did not improve from 0.71799\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.8246 - accuracy: 0.7270 - val_loss: 1.0009 - val_accuracy: 0.7058\n",
            "Epoch 131/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.8484 - accuracy: 0.7165\n",
            "Epoch 131: val_accuracy did not improve from 0.71799\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.8484 - accuracy: 0.7165 - val_loss: 1.1626 - val_accuracy: 0.6562\n",
            "Epoch 132/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.8599 - accuracy: 0.7137\n",
            "Epoch 132: val_accuracy did not improve from 0.71799\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.8624 - accuracy: 0.7127 - val_loss: 1.0884 - val_accuracy: 0.6780\n",
            "Epoch 133/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.9720 - accuracy: 0.6861\n",
            "Epoch 133: val_accuracy did not improve from 0.71799\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.9759 - accuracy: 0.6843 - val_loss: 1.7287 - val_accuracy: 0.5477\n",
            "Epoch 134/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.8497 - accuracy: 0.7184\n",
            "Epoch 134: val_accuracy did not improve from 0.71799\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.8416 - accuracy: 0.7204 - val_loss: 1.1065 - val_accuracy: 0.6716\n",
            "Epoch 135/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.8053 - accuracy: 0.7292\n",
            "Epoch 135: val_accuracy did not improve from 0.71799\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.8050 - accuracy: 0.7298 - val_loss: 1.0298 - val_accuracy: 0.6940\n",
            "Epoch 136/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.7827 - accuracy: 0.7402\n",
            "Epoch 136: val_accuracy did not improve from 0.71799\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.7872 - accuracy: 0.7377 - val_loss: 1.2731 - val_accuracy: 0.6156\n",
            "Epoch 137/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.8363 - accuracy: 0.7195\n",
            "Epoch 137: val_accuracy did not improve from 0.71799\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.8490 - accuracy: 0.7161 - val_loss: 1.4371 - val_accuracy: 0.5560\n",
            "Epoch 138/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.8183 - accuracy: 0.7266\n",
            "Epoch 138: val_accuracy did not improve from 0.71799\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.8183 - accuracy: 0.7266 - val_loss: 1.5519 - val_accuracy: 0.5563\n",
            "Epoch 139/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.7910 - accuracy: 0.7339\n",
            "Epoch 139: val_accuracy did not improve from 0.71799\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.7899 - accuracy: 0.7342 - val_loss: 1.0838 - val_accuracy: 0.6796\n",
            "Epoch 140/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.8467 - accuracy: 0.7147\n",
            "Epoch 140: val_accuracy did not improve from 0.71799\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.8497 - accuracy: 0.7137 - val_loss: 1.3013 - val_accuracy: 0.6360\n",
            "Epoch 141/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.8202 - accuracy: 0.7214\n",
            "Epoch 141: val_accuracy did not improve from 0.71799\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.8185 - accuracy: 0.7222 - val_loss: 1.1561 - val_accuracy: 0.6681\n",
            "Epoch 142/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.8531 - accuracy: 0.7137\n",
            "Epoch 142: val_accuracy did not improve from 0.71799\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.8531 - accuracy: 0.7138 - val_loss: 1.1252 - val_accuracy: 0.6732\n",
            "Epoch 143/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.8109 - accuracy: 0.7271\n",
            "Epoch 143: val_accuracy did not improve from 0.71799\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.8124 - accuracy: 0.7263 - val_loss: 1.3352 - val_accuracy: 0.6018\n",
            "Epoch 144/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.7959 - accuracy: 0.7306\n",
            "Epoch 144: val_accuracy did not improve from 0.71799\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.7943 - accuracy: 0.7302 - val_loss: 1.0393 - val_accuracy: 0.6828\n",
            "Epoch 145/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.7283 - accuracy: 0.7593\n",
            "Epoch 145: val_accuracy improved from 0.71799 to 0.72375, saving model to /content/asl/Adam3/cp-145-0.72.hdf5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.7326 - accuracy: 0.7578 - val_loss: 0.9543 - val_accuracy: 0.7238\n",
            "Epoch 146/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.8196 - accuracy: 0.7222\n",
            "Epoch 146: val_accuracy did not improve from 0.72375\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.8225 - accuracy: 0.7214 - val_loss: 1.1942 - val_accuracy: 0.6508\n",
            "Epoch 147/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.7335 - accuracy: 0.7505\n",
            "Epoch 147: val_accuracy did not improve from 0.72375\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.7313 - accuracy: 0.7520 - val_loss: 1.0253 - val_accuracy: 0.6997\n",
            "Epoch 148/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.8735 - accuracy: 0.7085\n",
            "Epoch 148: val_accuracy did not improve from 0.72375\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.8735 - accuracy: 0.7085 - val_loss: 1.1475 - val_accuracy: 0.6610\n",
            "Epoch 149/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.7046 - accuracy: 0.7594\n",
            "Epoch 149: val_accuracy improved from 0.72375 to 0.72439, saving model to /content/asl/Adam3/cp-149-0.72.hdf5\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.7050 - accuracy: 0.7590 - val_loss: 0.9542 - val_accuracy: 0.7244\n",
            "Epoch 150/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.6971 - accuracy: 0.7646\n",
            "Epoch 150: val_accuracy did not improve from 0.72439\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.6968 - accuracy: 0.7653 - val_loss: 1.0065 - val_accuracy: 0.7017\n",
            "Epoch 151/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.7851 - accuracy: 0.7296\n",
            "Epoch 151: val_accuracy did not improve from 0.72439\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.7841 - accuracy: 0.7296 - val_loss: 1.0064 - val_accuracy: 0.7148\n",
            "Epoch 152/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.7896 - accuracy: 0.7336\n",
            "Epoch 152: val_accuracy did not improve from 0.72439\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.7861 - accuracy: 0.7352 - val_loss: 1.1804 - val_accuracy: 0.6597\n",
            "Epoch 153/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.8216 - accuracy: 0.7227\n",
            "Epoch 153: val_accuracy did not improve from 0.72439\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.8186 - accuracy: 0.7238 - val_loss: 0.9507 - val_accuracy: 0.7225\n",
            "Epoch 154/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.6813 - accuracy: 0.7698\n",
            "Epoch 154: val_accuracy did not improve from 0.72439\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.6813 - accuracy: 0.7698 - val_loss: 0.9689 - val_accuracy: 0.7177\n",
            "Epoch 155/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.7295 - accuracy: 0.7503\n",
            "Epoch 155: val_accuracy did not improve from 0.72439\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.7228 - accuracy: 0.7543 - val_loss: 1.0274 - val_accuracy: 0.6969\n",
            "Epoch 156/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.8393 - accuracy: 0.7264\n",
            "Epoch 156: val_accuracy did not improve from 0.72439\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.8305 - accuracy: 0.7287 - val_loss: 1.4722 - val_accuracy: 0.5826\n",
            "Epoch 157/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.6876 - accuracy: 0.7702\n",
            "Epoch 157: val_accuracy did not improve from 0.72439\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.6924 - accuracy: 0.7674 - val_loss: 1.1360 - val_accuracy: 0.6780\n",
            "Epoch 158/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.8421 - accuracy: 0.7233\n",
            "Epoch 158: val_accuracy did not improve from 0.72439\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.8386 - accuracy: 0.7234 - val_loss: 0.9783 - val_accuracy: 0.7090\n",
            "Epoch 159/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.7335 - accuracy: 0.7522\n",
            "Epoch 159: val_accuracy did not improve from 0.72439\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.7301 - accuracy: 0.7533 - val_loss: 1.0563 - val_accuracy: 0.6885\n",
            "Epoch 160/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.8289 - accuracy: 0.7192\n",
            "Epoch 160: val_accuracy did not improve from 0.72439\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.8222 - accuracy: 0.7219 - val_loss: 1.1451 - val_accuracy: 0.6793\n",
            "Epoch 161/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.6607 - accuracy: 0.7770\n",
            "Epoch 161: val_accuracy improved from 0.72439 to 0.72855, saving model to /content/asl/Adam3/cp-161-0.73.hdf5\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.6582 - accuracy: 0.7784 - val_loss: 0.9541 - val_accuracy: 0.7286\n",
            "Epoch 162/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.7026 - accuracy: 0.7618\n",
            "Epoch 162: val_accuracy did not improve from 0.72855\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.7026 - accuracy: 0.7618 - val_loss: 1.3517 - val_accuracy: 0.6248\n",
            "Epoch 163/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.7748 - accuracy: 0.7399\n",
            "Epoch 163: val_accuracy did not improve from 0.72855\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.7732 - accuracy: 0.7403 - val_loss: 0.9578 - val_accuracy: 0.7177\n",
            "Epoch 164/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.6956 - accuracy: 0.7650\n",
            "Epoch 164: val_accuracy did not improve from 0.72855\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.6935 - accuracy: 0.7660 - val_loss: 1.0846 - val_accuracy: 0.6847\n",
            "Epoch 165/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.6794 - accuracy: 0.7701\n",
            "Epoch 165: val_accuracy did not improve from 0.72855\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.6796 - accuracy: 0.7701 - val_loss: 1.0438 - val_accuracy: 0.6940\n",
            "Epoch 166/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.6783 - accuracy: 0.7690\n",
            "Epoch 166: val_accuracy did not improve from 0.72855\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.6776 - accuracy: 0.7694 - val_loss: 0.9951 - val_accuracy: 0.7222\n",
            "Epoch 167/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.6651 - accuracy: 0.7753\n",
            "Epoch 167: val_accuracy did not improve from 0.72855\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.6617 - accuracy: 0.7762 - val_loss: 0.9883 - val_accuracy: 0.7065\n",
            "Epoch 168/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.6806 - accuracy: 0.7689\n",
            "Epoch 168: val_accuracy did not improve from 0.72855\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.6810 - accuracy: 0.7690 - val_loss: 0.9633 - val_accuracy: 0.7151\n",
            "Epoch 169/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.7530 - accuracy: 0.7428\n",
            "Epoch 169: val_accuracy did not improve from 0.72855\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.7570 - accuracy: 0.7414 - val_loss: 1.0858 - val_accuracy: 0.6965\n",
            "Epoch 170/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.7001 - accuracy: 0.7655\n",
            "Epoch 170: val_accuracy did not improve from 0.72855\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.7007 - accuracy: 0.7645 - val_loss: 1.0507 - val_accuracy: 0.6933\n",
            "Epoch 171/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 1.0399 - accuracy: 0.6821\n",
            "Epoch 171: val_accuracy did not improve from 0.72855\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.0390 - accuracy: 0.6822 - val_loss: 1.0197 - val_accuracy: 0.7113\n",
            "Epoch 172/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.6483 - accuracy: 0.7859\n",
            "Epoch 172: val_accuracy improved from 0.72855 to 0.74936, saving model to /content/asl/Adam3/cp-172-0.75.hdf5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.6457 - accuracy: 0.7862 - val_loss: 0.8904 - val_accuracy: 0.7494\n",
            "Epoch 173/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.6349 - accuracy: 0.7855\n",
            "Epoch 173: val_accuracy did not improve from 0.74936\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.6478 - accuracy: 0.7810 - val_loss: 1.0325 - val_accuracy: 0.7042\n",
            "Epoch 174/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.6585 - accuracy: 0.7781\n",
            "Epoch 174: val_accuracy did not improve from 0.74936\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.6665 - accuracy: 0.7750 - val_loss: 1.4897 - val_accuracy: 0.5931\n",
            "Epoch 175/700\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.8829 - accuracy: 0.7152\n",
            "Epoch 175: val_accuracy did not improve from 0.74936\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.8695 - accuracy: 0.7172 - val_loss: 0.9796 - val_accuracy: 0.7081\n",
            "Epoch 176/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.6655 - accuracy: 0.7730\n",
            "Epoch 176: val_accuracy did not improve from 0.74936\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.6699 - accuracy: 0.7718 - val_loss: 1.1752 - val_accuracy: 0.6569\n",
            "Epoch 177/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.6796 - accuracy: 0.7689\n",
            "Epoch 177: val_accuracy did not improve from 0.74936\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.6804 - accuracy: 0.7686 - val_loss: 0.9390 - val_accuracy: 0.7250\n",
            "Epoch 178/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.7252 - accuracy: 0.7570\n",
            "Epoch 178: val_accuracy did not improve from 0.74936\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.7202 - accuracy: 0.7587 - val_loss: 0.9300 - val_accuracy: 0.7481\n",
            "Epoch 179/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.6100 - accuracy: 0.7865\n",
            "Epoch 179: val_accuracy did not improve from 0.74936\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.6090 - accuracy: 0.7867 - val_loss: 1.2187 - val_accuracy: 0.6549\n",
            "Epoch 180/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.6899 - accuracy: 0.7693\n",
            "Epoch 180: val_accuracy did not improve from 0.74936\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.6846 - accuracy: 0.7711 - val_loss: 0.9494 - val_accuracy: 0.7266\n",
            "Epoch 181/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.6792 - accuracy: 0.7674\n",
            "Epoch 181: val_accuracy did not improve from 0.74936\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.6813 - accuracy: 0.7666 - val_loss: 0.8975 - val_accuracy: 0.7430\n",
            "Epoch 182/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.6141 - accuracy: 0.7896\n",
            "Epoch 182: val_accuracy did not improve from 0.74936\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.6166 - accuracy: 0.7887 - val_loss: 0.9022 - val_accuracy: 0.7436\n",
            "Epoch 183/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.7634 - accuracy: 0.7391\n",
            "Epoch 183: val_accuracy did not improve from 0.74936\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.7593 - accuracy: 0.7410 - val_loss: 0.9789 - val_accuracy: 0.7154\n",
            "Epoch 184/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.5963 - accuracy: 0.7958\n",
            "Epoch 184: val_accuracy did not improve from 0.74936\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.6044 - accuracy: 0.7935 - val_loss: 1.2291 - val_accuracy: 0.6501\n",
            "Epoch 185/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.6787 - accuracy: 0.7660\n",
            "Epoch 185: val_accuracy did not improve from 0.74936\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.6790 - accuracy: 0.7658 - val_loss: 1.0033 - val_accuracy: 0.7138\n",
            "Epoch 186/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.8023 - accuracy: 0.7329\n",
            "Epoch 186: val_accuracy did not improve from 0.74936\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.8005 - accuracy: 0.7335 - val_loss: 0.9512 - val_accuracy: 0.7286\n",
            "Epoch 187/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.6010 - accuracy: 0.7909\n",
            "Epoch 187: val_accuracy did not improve from 0.74936\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.6025 - accuracy: 0.7913 - val_loss: 0.9728 - val_accuracy: 0.7263\n",
            "Epoch 188/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.6117 - accuracy: 0.7869\n",
            "Epoch 188: val_accuracy did not improve from 0.74936\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.6116 - accuracy: 0.7862 - val_loss: 1.0639 - val_accuracy: 0.6956\n",
            "Epoch 189/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.6153 - accuracy: 0.7867\n",
            "Epoch 189: val_accuracy did not improve from 0.74936\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.6145 - accuracy: 0.7868 - val_loss: 1.0774 - val_accuracy: 0.6975\n",
            "Epoch 190/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.6869 - accuracy: 0.7677\n",
            "Epoch 190: val_accuracy did not improve from 0.74936\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.6822 - accuracy: 0.7691 - val_loss: 0.9254 - val_accuracy: 0.7420\n",
            "Epoch 191/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.6047 - accuracy: 0.7894\n",
            "Epoch 191: val_accuracy did not improve from 0.74936\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.6043 - accuracy: 0.7899 - val_loss: 1.1456 - val_accuracy: 0.6767\n",
            "Epoch 192/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 1.0857 - accuracy: 0.6681\n",
            "Epoch 192: val_accuracy did not improve from 0.74936\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.0839 - accuracy: 0.6685 - val_loss: 0.9346 - val_accuracy: 0.7334\n",
            "Epoch 193/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.6113 - accuracy: 0.7893\n",
            "Epoch 193: val_accuracy did not improve from 0.74936\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.6128 - accuracy: 0.7887 - val_loss: 1.0792 - val_accuracy: 0.7026\n",
            "Epoch 194/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.5525 - accuracy: 0.8127\n",
            "Epoch 194: val_accuracy did not improve from 0.74936\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.5525 - accuracy: 0.8127 - val_loss: 0.9727 - val_accuracy: 0.7225\n",
            "Epoch 195/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.5598 - accuracy: 0.8099\n",
            "Epoch 195: val_accuracy improved from 0.74936 to 0.76857, saving model to /content/asl/Adam3/cp-195-0.77.hdf5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.5555 - accuracy: 0.8119 - val_loss: 0.8254 - val_accuracy: 0.7686\n",
            "Epoch 196/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.6155 - accuracy: 0.7957\n",
            "Epoch 196: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.6214 - accuracy: 0.7930 - val_loss: 1.0599 - val_accuracy: 0.6969\n",
            "Epoch 197/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.5937 - accuracy: 0.7961\n",
            "Epoch 197: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.5931 - accuracy: 0.7964 - val_loss: 0.9041 - val_accuracy: 0.7362\n",
            "Epoch 198/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.6018 - accuracy: 0.7953\n",
            "Epoch 198: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.6010 - accuracy: 0.7955 - val_loss: 1.0103 - val_accuracy: 0.7119\n",
            "Epoch 199/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.5478 - accuracy: 0.8087\n",
            "Epoch 199: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.5474 - accuracy: 0.8092 - val_loss: 0.9155 - val_accuracy: 0.7455\n",
            "Epoch 200/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.5864 - accuracy: 0.8000\n",
            "Epoch 200: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.5814 - accuracy: 0.8016 - val_loss: 0.9961 - val_accuracy: 0.7109\n",
            "Epoch 201/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.6482 - accuracy: 0.7792\n",
            "Epoch 201: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.6502 - accuracy: 0.7782 - val_loss: 1.0627 - val_accuracy: 0.6962\n",
            "Epoch 202/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.6394 - accuracy: 0.7794\n",
            "Epoch 202: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.6356 - accuracy: 0.7806 - val_loss: 0.9778 - val_accuracy: 0.7228\n",
            "Epoch 203/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.5826 - accuracy: 0.7960\n",
            "Epoch 203: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.5861 - accuracy: 0.7954 - val_loss: 0.9239 - val_accuracy: 0.7398\n",
            "Epoch 204/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.8350 - accuracy: 0.7255\n",
            "Epoch 204: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.8337 - accuracy: 0.7259 - val_loss: 0.9762 - val_accuracy: 0.7234\n",
            "Epoch 205/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.5602 - accuracy: 0.8060\n",
            "Epoch 205: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.5597 - accuracy: 0.8059 - val_loss: 0.9372 - val_accuracy: 0.7359\n",
            "Epoch 206/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.5285 - accuracy: 0.8193\n",
            "Epoch 206: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.5355 - accuracy: 0.8167 - val_loss: 0.9186 - val_accuracy: 0.7494\n",
            "Epoch 207/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.6750 - accuracy: 0.7673\n",
            "Epoch 207: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.6842 - accuracy: 0.7651 - val_loss: 1.2598 - val_accuracy: 0.6460\n",
            "Epoch 208/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 1.0141 - accuracy: 0.6830\n",
            "Epoch 208: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.0030 - accuracy: 0.6838 - val_loss: 1.2220 - val_accuracy: 0.6543\n",
            "Epoch 209/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.6490 - accuracy: 0.7725\n",
            "Epoch 209: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.6461 - accuracy: 0.7737 - val_loss: 1.2556 - val_accuracy: 0.6569\n",
            "Epoch 210/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.5804 - accuracy: 0.7975\n",
            "Epoch 210: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.5804 - accuracy: 0.7975 - val_loss: 0.9595 - val_accuracy: 0.7311\n",
            "Epoch 211/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.5944 - accuracy: 0.7970\n",
            "Epoch 211: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.5987 - accuracy: 0.7949 - val_loss: 1.1006 - val_accuracy: 0.6892\n",
            "Epoch 212/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.5387 - accuracy: 0.8113\n",
            "Epoch 212: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.5418 - accuracy: 0.8108 - val_loss: 0.8865 - val_accuracy: 0.7487\n",
            "Epoch 213/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.6262 - accuracy: 0.7860\n",
            "Epoch 213: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.6302 - accuracy: 0.7833 - val_loss: 1.0107 - val_accuracy: 0.7154\n",
            "Epoch 214/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.6374 - accuracy: 0.7790\n",
            "Epoch 214: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.6397 - accuracy: 0.7782 - val_loss: 1.0013 - val_accuracy: 0.7186\n",
            "Epoch 215/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.5236 - accuracy: 0.8202\n",
            "Epoch 215: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.5244 - accuracy: 0.8197 - val_loss: 0.9086 - val_accuracy: 0.7423\n",
            "Epoch 216/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.5480 - accuracy: 0.8156\n",
            "Epoch 216: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.5514 - accuracy: 0.8137 - val_loss: 0.9768 - val_accuracy: 0.7302\n",
            "Epoch 217/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.5764 - accuracy: 0.7995\n",
            "Epoch 217: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.5747 - accuracy: 0.8005 - val_loss: 0.8827 - val_accuracy: 0.7628\n",
            "Epoch 218/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.6034 - accuracy: 0.7941\n",
            "Epoch 218: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.6081 - accuracy: 0.7924 - val_loss: 1.4920 - val_accuracy: 0.6136\n",
            "Epoch 219/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.7015 - accuracy: 0.7646\n",
            "Epoch 219: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.6951 - accuracy: 0.7669 - val_loss: 0.9220 - val_accuracy: 0.7394\n",
            "Epoch 220/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.5733 - accuracy: 0.8022\n",
            "Epoch 220: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.5869 - accuracy: 0.7982 - val_loss: 1.1499 - val_accuracy: 0.6748\n",
            "Epoch 221/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.5643 - accuracy: 0.8019\n",
            "Epoch 221: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.5612 - accuracy: 0.8030 - val_loss: 0.8745 - val_accuracy: 0.7580\n",
            "Epoch 222/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.5735 - accuracy: 0.8013\n",
            "Epoch 222: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.5691 - accuracy: 0.8023 - val_loss: 0.8930 - val_accuracy: 0.7487\n",
            "Epoch 223/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.5024 - accuracy: 0.8273\n",
            "Epoch 223: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.5075 - accuracy: 0.8253 - val_loss: 1.3538 - val_accuracy: 0.6396\n",
            "Epoch 224/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.7971 - accuracy: 0.7359\n",
            "Epoch 224: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.7932 - accuracy: 0.7360 - val_loss: 0.8745 - val_accuracy: 0.7570\n",
            "Epoch 225/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.5611 - accuracy: 0.8065\n",
            "Epoch 225: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.5572 - accuracy: 0.8086 - val_loss: 0.8878 - val_accuracy: 0.7519\n",
            "Epoch 226/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.5234 - accuracy: 0.8169\n",
            "Epoch 226: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.5234 - accuracy: 0.8169 - val_loss: 0.9684 - val_accuracy: 0.7212\n",
            "Epoch 227/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.4911 - accuracy: 0.8283\n",
            "Epoch 227: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4911 - accuracy: 0.8283 - val_loss: 0.9151 - val_accuracy: 0.7478\n",
            "Epoch 228/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.5563 - accuracy: 0.8062\n",
            "Epoch 228: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.5525 - accuracy: 0.8071 - val_loss: 0.9268 - val_accuracy: 0.7353\n",
            "Epoch 229/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.6370 - accuracy: 0.7786\n",
            "Epoch 229: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.6356 - accuracy: 0.7791 - val_loss: 0.9809 - val_accuracy: 0.7177\n",
            "Epoch 230/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.6678 - accuracy: 0.7681\n",
            "Epoch 230: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.6674 - accuracy: 0.7683 - val_loss: 1.1237 - val_accuracy: 0.6834\n",
            "Epoch 231/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.6045 - accuracy: 0.7934\n",
            "Epoch 231: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.6018 - accuracy: 0.7939 - val_loss: 0.8383 - val_accuracy: 0.7666\n",
            "Epoch 232/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.4591 - accuracy: 0.8427\n",
            "Epoch 232: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4711 - accuracy: 0.8385 - val_loss: 0.8949 - val_accuracy: 0.7481\n",
            "Epoch 233/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 1.1023 - accuracy: 0.6837\n",
            "Epoch 233: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.0801 - accuracy: 0.6887 - val_loss: 1.1239 - val_accuracy: 0.6802\n",
            "Epoch 234/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.5543 - accuracy: 0.8076\n",
            "Epoch 234: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.5535 - accuracy: 0.8074 - val_loss: 0.8864 - val_accuracy: 0.7484\n",
            "Epoch 235/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.4709 - accuracy: 0.8402\n",
            "Epoch 235: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.4709 - accuracy: 0.8402 - val_loss: 0.9030 - val_accuracy: 0.7558\n",
            "Epoch 236/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.5283 - accuracy: 0.8151\n",
            "Epoch 236: val_accuracy did not improve from 0.76857\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.5283 - accuracy: 0.8151 - val_loss: 1.0769 - val_accuracy: 0.7013\n",
            "Epoch 237/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.5539 - accuracy: 0.8087\n",
            "Epoch 237: val_accuracy improved from 0.76857 to 0.78265, saving model to /content/asl/Adam3/cp-237-0.78.hdf5\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.5528 - accuracy: 0.8091 - val_loss: 0.8092 - val_accuracy: 0.7827\n",
            "Epoch 238/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.5330 - accuracy: 0.8179\n",
            "Epoch 238: val_accuracy did not improve from 0.78265\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.5359 - accuracy: 0.8173 - val_loss: 1.0782 - val_accuracy: 0.6988\n",
            "Epoch 239/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.5612 - accuracy: 0.8061\n",
            "Epoch 239: val_accuracy did not improve from 0.78265\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.5563 - accuracy: 0.8074 - val_loss: 0.8324 - val_accuracy: 0.7743\n",
            "Epoch 240/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.6895 - accuracy: 0.7701\n",
            "Epoch 240: val_accuracy did not improve from 0.78265\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.6875 - accuracy: 0.7694 - val_loss: 1.0808 - val_accuracy: 0.6988\n",
            "Epoch 241/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.6465 - accuracy: 0.7770\n",
            "Epoch 241: val_accuracy did not improve from 0.78265\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.6387 - accuracy: 0.7798 - val_loss: 1.0819 - val_accuracy: 0.7116\n",
            "Epoch 242/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.4956 - accuracy: 0.8252\n",
            "Epoch 242: val_accuracy did not improve from 0.78265\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4937 - accuracy: 0.8264 - val_loss: 0.8322 - val_accuracy: 0.7762\n",
            "Epoch 243/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.4790 - accuracy: 0.8349\n",
            "Epoch 243: val_accuracy did not improve from 0.78265\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4795 - accuracy: 0.8347 - val_loss: 0.8396 - val_accuracy: 0.7711\n",
            "Epoch 244/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.4867 - accuracy: 0.8285\n",
            "Epoch 244: val_accuracy did not improve from 0.78265\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4886 - accuracy: 0.8269 - val_loss: 1.0028 - val_accuracy: 0.7244\n",
            "Epoch 245/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.7373 - accuracy: 0.7587\n",
            "Epoch 245: val_accuracy did not improve from 0.78265\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.7384 - accuracy: 0.7585 - val_loss: 1.9068 - val_accuracy: 0.5461\n",
            "Epoch 246/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.6706 - accuracy: 0.7662\n",
            "Epoch 246: val_accuracy did not improve from 0.78265\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.6663 - accuracy: 0.7662 - val_loss: 0.8873 - val_accuracy: 0.7628\n",
            "Epoch 247/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.4796 - accuracy: 0.8309\n",
            "Epoch 247: val_accuracy did not improve from 0.78265\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4801 - accuracy: 0.8307 - val_loss: 0.8261 - val_accuracy: 0.7782\n",
            "Epoch 248/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.4691 - accuracy: 0.8366\n",
            "Epoch 248: val_accuracy did not improve from 0.78265\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4691 - accuracy: 0.8366 - val_loss: 0.9326 - val_accuracy: 0.7404\n",
            "Epoch 249/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.5097 - accuracy: 0.8239\n",
            "Epoch 249: val_accuracy did not improve from 0.78265\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.5097 - accuracy: 0.8239 - val_loss: 0.9172 - val_accuracy: 0.7500\n",
            "Epoch 250/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.6675 - accuracy: 0.7715\n",
            "Epoch 250: val_accuracy did not improve from 0.78265\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.6632 - accuracy: 0.7733 - val_loss: 1.1477 - val_accuracy: 0.6853\n",
            "Epoch 251/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.5319 - accuracy: 0.8138\n",
            "Epoch 251: val_accuracy did not improve from 0.78265\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.5323 - accuracy: 0.8135 - val_loss: 0.8845 - val_accuracy: 0.7606\n",
            "Epoch 252/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.5487 - accuracy: 0.8117\n",
            "Epoch 252: val_accuracy did not improve from 0.78265\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.5588 - accuracy: 0.8086 - val_loss: 1.0252 - val_accuracy: 0.7215\n",
            "Epoch 253/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.8374 - accuracy: 0.7253\n",
            "Epoch 253: val_accuracy did not improve from 0.78265\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.8402 - accuracy: 0.7257 - val_loss: 1.8872 - val_accuracy: 0.5615\n",
            "Epoch 254/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.6633 - accuracy: 0.7817\n",
            "Epoch 254: val_accuracy did not improve from 0.78265\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.6561 - accuracy: 0.7838 - val_loss: 0.8406 - val_accuracy: 0.7644\n",
            "Epoch 255/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.4733 - accuracy: 0.8340\n",
            "Epoch 255: val_accuracy did not improve from 0.78265\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4751 - accuracy: 0.8338 - val_loss: 0.8756 - val_accuracy: 0.7510\n",
            "Epoch 256/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.4443 - accuracy: 0.8431\n",
            "Epoch 256: val_accuracy did not improve from 0.78265\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4449 - accuracy: 0.8427 - val_loss: 0.8192 - val_accuracy: 0.7785\n",
            "Epoch 257/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.4423 - accuracy: 0.8470\n",
            "Epoch 257: val_accuracy did not improve from 0.78265\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4576 - accuracy: 0.8414 - val_loss: 0.8562 - val_accuracy: 0.7666\n",
            "Epoch 258/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.4788 - accuracy: 0.8317\n",
            "Epoch 258: val_accuracy did not improve from 0.78265\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4788 - accuracy: 0.8317 - val_loss: 1.0213 - val_accuracy: 0.7212\n",
            "Epoch 259/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.4648 - accuracy: 0.8374\n",
            "Epoch 259: val_accuracy did not improve from 0.78265\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4627 - accuracy: 0.8379 - val_loss: 0.9166 - val_accuracy: 0.7478\n",
            "Epoch 260/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.4401 - accuracy: 0.8403\n",
            "Epoch 260: val_accuracy did not improve from 0.78265\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4396 - accuracy: 0.8410 - val_loss: 1.1352 - val_accuracy: 0.6908\n",
            "Epoch 261/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.6492 - accuracy: 0.7791\n",
            "Epoch 261: val_accuracy did not improve from 0.78265\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.6500 - accuracy: 0.7784 - val_loss: 1.0574 - val_accuracy: 0.7065\n",
            "Epoch 262/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.5349 - accuracy: 0.8139\n",
            "Epoch 262: val_accuracy did not improve from 0.78265\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.5606 - accuracy: 0.8080 - val_loss: 0.9918 - val_accuracy: 0.7318\n",
            "Epoch 263/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.6292 - accuracy: 0.7914\n",
            "Epoch 263: val_accuracy did not improve from 0.78265\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.6179 - accuracy: 0.7945 - val_loss: 0.8453 - val_accuracy: 0.7689\n",
            "Epoch 264/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.4505 - accuracy: 0.8409\n",
            "Epoch 264: val_accuracy did not improve from 0.78265\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4488 - accuracy: 0.8407 - val_loss: 0.8314 - val_accuracy: 0.7801\n",
            "Epoch 265/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.9568 - accuracy: 0.7170\n",
            "Epoch 265: val_accuracy did not improve from 0.78265\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.9558 - accuracy: 0.7169 - val_loss: 0.9307 - val_accuracy: 0.7484\n",
            "Epoch 266/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.4942 - accuracy: 0.8288\n",
            "Epoch 266: val_accuracy did not improve from 0.78265\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4906 - accuracy: 0.8299 - val_loss: 0.8284 - val_accuracy: 0.7762\n",
            "Epoch 267/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.4578 - accuracy: 0.8428\n",
            "Epoch 267: val_accuracy did not improve from 0.78265\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4598 - accuracy: 0.8423 - val_loss: 0.8514 - val_accuracy: 0.7657\n",
            "Epoch 268/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.4441 - accuracy: 0.8438\n",
            "Epoch 268: val_accuracy improved from 0.78265 to 0.79065, saving model to /content/asl/Adam3/cp-268-0.79.hdf5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4420 - accuracy: 0.8448 - val_loss: 0.7872 - val_accuracy: 0.7907\n",
            "Epoch 269/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.4051 - accuracy: 0.8587\n",
            "Epoch 269: val_accuracy improved from 0.79065 to 0.79706, saving model to /content/asl/Adam3/cp-269-0.80.hdf5\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.4051 - accuracy: 0.8587 - val_loss: 0.7803 - val_accuracy: 0.7971\n",
            "Epoch 270/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.4806 - accuracy: 0.8321\n",
            "Epoch 270: val_accuracy did not improve from 0.79706\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.4834 - accuracy: 0.8315 - val_loss: 1.1643 - val_accuracy: 0.6956\n",
            "Epoch 271/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.0856 - accuracy: 0.6834\n",
            "Epoch 271: val_accuracy did not improve from 0.79706\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 1.0856 - accuracy: 0.6834 - val_loss: 1.4493 - val_accuracy: 0.6069\n",
            "Epoch 272/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.5447 - accuracy: 0.8148\n",
            "Epoch 272: val_accuracy did not improve from 0.79706\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.5416 - accuracy: 0.8161 - val_loss: 0.9146 - val_accuracy: 0.7478\n",
            "Epoch 273/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.4223 - accuracy: 0.8532\n",
            "Epoch 273: val_accuracy did not improve from 0.79706\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4203 - accuracy: 0.8544 - val_loss: 0.8464 - val_accuracy: 0.7641\n",
            "Epoch 274/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.5381 - accuracy: 0.8207\n",
            "Epoch 274: val_accuracy did not improve from 0.79706\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.5381 - accuracy: 0.8207 - val_loss: 1.7153 - val_accuracy: 0.5797\n",
            "Epoch 275/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.6008 - accuracy: 0.7965\n",
            "Epoch 275: val_accuracy did not improve from 0.79706\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.5969 - accuracy: 0.7977 - val_loss: 0.8169 - val_accuracy: 0.7887\n",
            "Epoch 276/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.4201 - accuracy: 0.8516\n",
            "Epoch 276: val_accuracy did not improve from 0.79706\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4191 - accuracy: 0.8520 - val_loss: 0.8006 - val_accuracy: 0.7839\n",
            "Epoch 277/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.5234 - accuracy: 0.8203\n",
            "Epoch 277: val_accuracy did not improve from 0.79706\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.5228 - accuracy: 0.8203 - val_loss: 0.8021 - val_accuracy: 0.7817\n",
            "Epoch 278/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.5120 - accuracy: 0.8239\n",
            "Epoch 278: val_accuracy did not improve from 0.79706\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.5048 - accuracy: 0.8268 - val_loss: 0.8284 - val_accuracy: 0.7862\n",
            "Epoch 279/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.4298 - accuracy: 0.8495\n",
            "Epoch 279: val_accuracy did not improve from 0.79706\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4303 - accuracy: 0.8496 - val_loss: 0.8683 - val_accuracy: 0.7625\n",
            "Epoch 280/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.9643 - accuracy: 0.7251\n",
            "Epoch 280: val_accuracy did not improve from 0.79706\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.9512 - accuracy: 0.7274 - val_loss: 0.8948 - val_accuracy: 0.7542\n",
            "Epoch 281/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.4844 - accuracy: 0.8300\n",
            "Epoch 281: val_accuracy did not improve from 0.79706\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4816 - accuracy: 0.8306 - val_loss: 0.8925 - val_accuracy: 0.7596\n",
            "Epoch 282/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.4887 - accuracy: 0.8272\n",
            "Epoch 282: val_accuracy did not improve from 0.79706\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4834 - accuracy: 0.8288 - val_loss: 0.7950 - val_accuracy: 0.7919\n",
            "Epoch 283/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.4446 - accuracy: 0.8456\n",
            "Epoch 283: val_accuracy did not improve from 0.79706\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4458 - accuracy: 0.8451 - val_loss: 0.9983 - val_accuracy: 0.7436\n",
            "Epoch 284/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.4867 - accuracy: 0.8238\n",
            "Epoch 284: val_accuracy did not improve from 0.79706\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4810 - accuracy: 0.8251 - val_loss: 0.7855 - val_accuracy: 0.7891\n",
            "Epoch 285/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.4522 - accuracy: 0.8465\n",
            "Epoch 285: val_accuracy did not improve from 0.79706\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4576 - accuracy: 0.8444 - val_loss: 1.0882 - val_accuracy: 0.7103\n",
            "Epoch 286/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.6278 - accuracy: 0.7852\n",
            "Epoch 286: val_accuracy did not improve from 0.79706\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.6203 - accuracy: 0.7872 - val_loss: 0.9459 - val_accuracy: 0.7548\n",
            "Epoch 287/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.5242 - accuracy: 0.8192\n",
            "Epoch 287: val_accuracy did not improve from 0.79706\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.5239 - accuracy: 0.8192 - val_loss: 0.8921 - val_accuracy: 0.7682\n",
            "Epoch 288/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.4059 - accuracy: 0.8607\n",
            "Epoch 288: val_accuracy improved from 0.79706 to 0.79738, saving model to /content/asl/Adam3/cp-288-0.80.hdf5\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.4062 - accuracy: 0.8604 - val_loss: 0.7792 - val_accuracy: 0.7974\n",
            "Epoch 289/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.4268 - accuracy: 0.8516\n",
            "Epoch 289: val_accuracy did not improve from 0.79738\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.4256 - accuracy: 0.8516 - val_loss: 0.8874 - val_accuracy: 0.7670\n",
            "Epoch 290/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.6420 - accuracy: 0.7806\n",
            "Epoch 290: val_accuracy did not improve from 0.79738\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.6440 - accuracy: 0.7795 - val_loss: 1.0398 - val_accuracy: 0.7170\n",
            "Epoch 291/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.4495 - accuracy: 0.8413\n",
            "Epoch 291: val_accuracy improved from 0.79738 to 0.79962, saving model to /content/asl/Adam3/cp-291-0.80.hdf5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4486 - accuracy: 0.8418 - val_loss: 0.7574 - val_accuracy: 0.7996\n",
            "Epoch 292/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.4283 - accuracy: 0.8512\n",
            "Epoch 292: val_accuracy did not improve from 0.79962\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4283 - accuracy: 0.8512 - val_loss: 0.8554 - val_accuracy: 0.7670\n",
            "Epoch 293/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.5260 - accuracy: 0.8167\n",
            "Epoch 293: val_accuracy did not improve from 0.79962\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.5250 - accuracy: 0.8169 - val_loss: 1.0690 - val_accuracy: 0.7266\n",
            "Epoch 294/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.8343 - accuracy: 0.7342\n",
            "Epoch 294: val_accuracy did not improve from 0.79962\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.8343 - accuracy: 0.7342 - val_loss: 0.9677 - val_accuracy: 0.7266\n",
            "Epoch 295/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.4718 - accuracy: 0.8325\n",
            "Epoch 295: val_accuracy did not improve from 0.79962\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4805 - accuracy: 0.8289 - val_loss: 0.9481 - val_accuracy: 0.7436\n",
            "Epoch 296/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.4541 - accuracy: 0.8390\n",
            "Epoch 296: val_accuracy did not improve from 0.79962\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4586 - accuracy: 0.8372 - val_loss: 0.7885 - val_accuracy: 0.7926\n",
            "Epoch 297/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.5263 - accuracy: 0.8155\n",
            "Epoch 297: val_accuracy did not improve from 0.79962\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.5257 - accuracy: 0.8163 - val_loss: 0.8320 - val_accuracy: 0.7740\n",
            "Epoch 298/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.4022 - accuracy: 0.8590\n",
            "Epoch 298: val_accuracy did not improve from 0.79962\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4004 - accuracy: 0.8596 - val_loss: 0.9212 - val_accuracy: 0.7506\n",
            "Epoch 299/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.5559 - accuracy: 0.8051\n",
            "Epoch 299: val_accuracy did not improve from 0.79962\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.5508 - accuracy: 0.8062 - val_loss: 0.8893 - val_accuracy: 0.7564\n",
            "Epoch 300/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.4295 - accuracy: 0.8471\n",
            "Epoch 300: val_accuracy did not improve from 0.79962\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4334 - accuracy: 0.8448 - val_loss: 0.8746 - val_accuracy: 0.7670\n",
            "Epoch 301/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.4561 - accuracy: 0.8413\n",
            "Epoch 301: val_accuracy did not improve from 0.79962\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4486 - accuracy: 0.8440 - val_loss: 0.8285 - val_accuracy: 0.7868\n",
            "Epoch 302/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.4122 - accuracy: 0.8553\n",
            "Epoch 302: val_accuracy did not improve from 0.79962\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4214 - accuracy: 0.8529 - val_loss: 0.8089 - val_accuracy: 0.7891\n",
            "Epoch 303/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.5985 - accuracy: 0.7947\n",
            "Epoch 303: val_accuracy did not improve from 0.79962\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.6086 - accuracy: 0.7917 - val_loss: 1.2915 - val_accuracy: 0.6668\n",
            "Epoch 304/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.5883 - accuracy: 0.7971\n",
            "Epoch 304: val_accuracy did not improve from 0.79962\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.5883 - accuracy: 0.7971 - val_loss: 0.8936 - val_accuracy: 0.7638\n",
            "Epoch 305/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.4349 - accuracy: 0.8486\n",
            "Epoch 305: val_accuracy did not improve from 0.79962\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.4386 - accuracy: 0.8483 - val_loss: 0.9258 - val_accuracy: 0.7500\n",
            "Epoch 306/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.6155 - accuracy: 0.7996\n",
            "Epoch 306: val_accuracy did not improve from 0.79962\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.6073 - accuracy: 0.8023 - val_loss: 0.8462 - val_accuracy: 0.7698\n",
            "Epoch 307/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3940 - accuracy: 0.8593\n",
            "Epoch 307: val_accuracy did not improve from 0.79962\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4014 - accuracy: 0.8568 - val_loss: 1.0697 - val_accuracy: 0.7260\n",
            "Epoch 308/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.4414 - accuracy: 0.8421\n",
            "Epoch 308: val_accuracy did not improve from 0.79962\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4388 - accuracy: 0.8433 - val_loss: 0.9423 - val_accuracy: 0.7446\n",
            "Epoch 309/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.4133 - accuracy: 0.8575\n",
            "Epoch 309: val_accuracy did not improve from 0.79962\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4138 - accuracy: 0.8556 - val_loss: 0.8709 - val_accuracy: 0.7641\n",
            "Epoch 310/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.4426 - accuracy: 0.8462\n",
            "Epoch 310: val_accuracy did not improve from 0.79962\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4442 - accuracy: 0.8457 - val_loss: 0.8975 - val_accuracy: 0.7606\n",
            "Epoch 311/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.4480 - accuracy: 0.8407\n",
            "Epoch 311: val_accuracy improved from 0.79962 to 0.80506, saving model to /content/asl/Adam3/cp-311-0.81.hdf5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4474 - accuracy: 0.8411 - val_loss: 0.7854 - val_accuracy: 0.8051\n",
            "Epoch 312/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8632\n",
            "Epoch 312: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3846 - accuracy: 0.8640 - val_loss: 0.7835 - val_accuracy: 0.7999\n",
            "Epoch 313/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.4967 - accuracy: 0.8301\n",
            "Epoch 313: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4961 - accuracy: 0.8298 - val_loss: 0.9159 - val_accuracy: 0.7641\n",
            "Epoch 314/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3792 - accuracy: 0.8624\n",
            "Epoch 314: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3791 - accuracy: 0.8632 - val_loss: 0.8545 - val_accuracy: 0.7791\n",
            "Epoch 315/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.7485 - accuracy: 0.7636\n",
            "Epoch 315: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.7772 - accuracy: 0.7584 - val_loss: 3.7597 - val_accuracy: 0.3800\n",
            "Epoch 316/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 1.0481 - accuracy: 0.7234\n",
            "Epoch 316: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.0336 - accuracy: 0.7262 - val_loss: 0.8810 - val_accuracy: 0.7634\n",
            "Epoch 317/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8641\n",
            "Epoch 317: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3883 - accuracy: 0.8639 - val_loss: 0.8680 - val_accuracy: 0.7730\n",
            "Epoch 318/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.4034 - accuracy: 0.8566\n",
            "Epoch 318: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4031 - accuracy: 0.8565 - val_loss: 0.8688 - val_accuracy: 0.7679\n",
            "Epoch 319/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3943 - accuracy: 0.8621\n",
            "Epoch 319: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3949 - accuracy: 0.8612 - val_loss: 0.8794 - val_accuracy: 0.7622\n",
            "Epoch 320/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.4284 - accuracy: 0.8516\n",
            "Epoch 320: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.4284 - accuracy: 0.8518 - val_loss: 1.2538 - val_accuracy: 0.6828\n",
            "Epoch 321/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.4577 - accuracy: 0.8355\n",
            "Epoch 321: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.4578 - accuracy: 0.8355 - val_loss: 0.8942 - val_accuracy: 0.7692\n",
            "Epoch 322/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.5144 - accuracy: 0.8236\n",
            "Epoch 322: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.5134 - accuracy: 0.8240 - val_loss: 0.9509 - val_accuracy: 0.7497\n",
            "Epoch 323/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.4614 - accuracy: 0.8408\n",
            "Epoch 323: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.4614 - accuracy: 0.8408 - val_loss: 0.8537 - val_accuracy: 0.7766\n",
            "Epoch 324/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.4013 - accuracy: 0.8591\n",
            "Epoch 324: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3995 - accuracy: 0.8600 - val_loss: 0.8958 - val_accuracy: 0.7846\n",
            "Epoch 325/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.4463 - accuracy: 0.8427\n",
            "Epoch 325: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4463 - accuracy: 0.8427 - val_loss: 1.1650 - val_accuracy: 0.7007\n",
            "Epoch 326/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.4673 - accuracy: 0.8328\n",
            "Epoch 326: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4664 - accuracy: 0.8330 - val_loss: 1.0576 - val_accuracy: 0.7247\n",
            "Epoch 327/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.4456 - accuracy: 0.8464\n",
            "Epoch 327: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4662 - accuracy: 0.8394 - val_loss: 1.0478 - val_accuracy: 0.7180\n",
            "Epoch 328/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.4293 - accuracy: 0.8458\n",
            "Epoch 328: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4294 - accuracy: 0.8458 - val_loss: 0.9779 - val_accuracy: 0.7462\n",
            "Epoch 329/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.4399 - accuracy: 0.8422\n",
            "Epoch 329: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4406 - accuracy: 0.8416 - val_loss: 1.0909 - val_accuracy: 0.7196\n",
            "Epoch 330/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.4248 - accuracy: 0.8471\n",
            "Epoch 330: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4470 - accuracy: 0.8408 - val_loss: 0.8859 - val_accuracy: 0.7673\n",
            "Epoch 331/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.6465 - accuracy: 0.7908\n",
            "Epoch 331: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.6396 - accuracy: 0.7930 - val_loss: 0.8859 - val_accuracy: 0.7618\n",
            "Epoch 332/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3555 - accuracy: 0.8742\n",
            "Epoch 332: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3583 - accuracy: 0.8734 - val_loss: 0.8214 - val_accuracy: 0.7833\n",
            "Epoch 333/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.6766 - accuracy: 0.7833\n",
            "Epoch 333: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.6726 - accuracy: 0.7844 - val_loss: 0.8077 - val_accuracy: 0.7935\n",
            "Epoch 334/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3873 - accuracy: 0.8636\n",
            "Epoch 334: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3863 - accuracy: 0.8636 - val_loss: 0.8159 - val_accuracy: 0.7903\n",
            "Epoch 335/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3802 - accuracy: 0.8663\n",
            "Epoch 335: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3802 - accuracy: 0.8663 - val_loss: 1.3055 - val_accuracy: 0.6847\n",
            "Epoch 336/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.4220 - accuracy: 0.8485\n",
            "Epoch 336: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.4230 - accuracy: 0.8478 - val_loss: 0.8888 - val_accuracy: 0.7670\n",
            "Epoch 337/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3930 - accuracy: 0.8587\n",
            "Epoch 337: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.3926 - accuracy: 0.8590 - val_loss: 0.9035 - val_accuracy: 0.7679\n",
            "Epoch 338/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3925 - accuracy: 0.8595\n",
            "Epoch 338: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3941 - accuracy: 0.8587 - val_loss: 0.8474 - val_accuracy: 0.7762\n",
            "Epoch 339/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.5966 - accuracy: 0.8064\n",
            "Epoch 339: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.5914 - accuracy: 0.8081 - val_loss: 0.8402 - val_accuracy: 0.7772\n",
            "Epoch 340/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.4916 - accuracy: 0.8297\n",
            "Epoch 340: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4982 - accuracy: 0.8282 - val_loss: 0.9757 - val_accuracy: 0.7369\n",
            "Epoch 341/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.4448 - accuracy: 0.8433\n",
            "Epoch 341: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4448 - accuracy: 0.8433 - val_loss: 0.8357 - val_accuracy: 0.7839\n",
            "Epoch 342/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.4183 - accuracy: 0.8499\n",
            "Epoch 342: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4184 - accuracy: 0.8499 - val_loss: 0.9644 - val_accuracy: 0.7401\n",
            "Epoch 343/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.3880 - accuracy: 0.8631\n",
            "Epoch 343: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3859 - accuracy: 0.8636 - val_loss: 0.9302 - val_accuracy: 0.7602\n",
            "Epoch 344/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.6047 - accuracy: 0.8015\n",
            "Epoch 344: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.6063 - accuracy: 0.8007 - val_loss: 1.2299 - val_accuracy: 0.6898\n",
            "Epoch 345/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.4390 - accuracy: 0.8438\n",
            "Epoch 345: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4367 - accuracy: 0.8447 - val_loss: 0.8342 - val_accuracy: 0.7708\n",
            "Epoch 346/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.4625 - accuracy: 0.8411\n",
            "Epoch 346: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4603 - accuracy: 0.8419 - val_loss: 0.8474 - val_accuracy: 0.7791\n",
            "Epoch 347/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.4499 - accuracy: 0.8433\n",
            "Epoch 347: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4467 - accuracy: 0.8446 - val_loss: 0.8129 - val_accuracy: 0.7913\n",
            "Epoch 348/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.4615 - accuracy: 0.8314\n",
            "Epoch 348: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4634 - accuracy: 0.8303 - val_loss: 0.8942 - val_accuracy: 0.7638\n",
            "Epoch 349/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3858 - accuracy: 0.8592\n",
            "Epoch 349: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3858 - accuracy: 0.8592 - val_loss: 0.9115 - val_accuracy: 0.7593\n",
            "Epoch 350/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.5196 - accuracy: 0.8308\n",
            "Epoch 350: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.5306 - accuracy: 0.8276 - val_loss: 1.7523 - val_accuracy: 0.6088\n",
            "Epoch 351/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.7125 - accuracy: 0.7653\n",
            "Epoch 351: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.6933 - accuracy: 0.7713 - val_loss: 0.8804 - val_accuracy: 0.7721\n",
            "Epoch 352/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.4306 - accuracy: 0.8500\n",
            "Epoch 352: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4255 - accuracy: 0.8519 - val_loss: 0.8316 - val_accuracy: 0.7836\n",
            "Epoch 353/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3329 - accuracy: 0.8818\n",
            "Epoch 353: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3323 - accuracy: 0.8821 - val_loss: 0.7667 - val_accuracy: 0.8041\n",
            "Epoch 354/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3600 - accuracy: 0.8713\n",
            "Epoch 354: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.3638 - accuracy: 0.8698 - val_loss: 0.9456 - val_accuracy: 0.7602\n",
            "Epoch 355/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.6829 - accuracy: 0.8173\n",
            "Epoch 355: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.8269 - accuracy: 0.7975 - val_loss: 3.7627 - val_accuracy: 0.3825\n",
            "Epoch 356/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.8506 - accuracy: 0.7377\n",
            "Epoch 356: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.8328 - accuracy: 0.7424 - val_loss: 0.8835 - val_accuracy: 0.7625\n",
            "Epoch 357/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3921 - accuracy: 0.8629\n",
            "Epoch 357: val_accuracy did not improve from 0.80506\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3902 - accuracy: 0.8636 - val_loss: 0.8230 - val_accuracy: 0.7788\n",
            "Epoch 358/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3521 - accuracy: 0.8773\n",
            "Epoch 358: val_accuracy improved from 0.80506 to 0.80634, saving model to /content/asl/Adam3/cp-358-0.81.hdf5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3530 - accuracy: 0.8765 - val_loss: 0.7673 - val_accuracy: 0.8063\n",
            "Epoch 359/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3973 - accuracy: 0.8604\n",
            "Epoch 359: val_accuracy did not improve from 0.80634\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4008 - accuracy: 0.8592 - val_loss: 1.0935 - val_accuracy: 0.7135\n",
            "Epoch 360/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3546 - accuracy: 0.8739\n",
            "Epoch 360: val_accuracy improved from 0.80634 to 0.81530, saving model to /content/asl/Adam3/cp-360-0.82.hdf5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3544 - accuracy: 0.8738 - val_loss: 0.7536 - val_accuracy: 0.8153\n",
            "Epoch 361/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3059 - accuracy: 0.8934\n",
            "Epoch 361: val_accuracy did not improve from 0.81530\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3119 - accuracy: 0.8911 - val_loss: 0.9878 - val_accuracy: 0.7458\n",
            "Epoch 362/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.4413 - accuracy: 0.8453\n",
            "Epoch 362: val_accuracy did not improve from 0.81530\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4413 - accuracy: 0.8453 - val_loss: 1.0399 - val_accuracy: 0.7366\n",
            "Epoch 363/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.5925 - accuracy: 0.7977\n",
            "Epoch 363: val_accuracy did not improve from 0.81530\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.5852 - accuracy: 0.7999 - val_loss: 0.8762 - val_accuracy: 0.7679\n",
            "Epoch 364/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.5493 - accuracy: 0.8117\n",
            "Epoch 364: val_accuracy did not improve from 0.81530\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.5426 - accuracy: 0.8136 - val_loss: 0.8785 - val_accuracy: 0.7804\n",
            "Epoch 365/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3718 - accuracy: 0.8692\n",
            "Epoch 365: val_accuracy did not improve from 0.81530\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3705 - accuracy: 0.8699 - val_loss: 0.8036 - val_accuracy: 0.7980\n",
            "Epoch 366/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3520 - accuracy: 0.8750\n",
            "Epoch 366: val_accuracy did not improve from 0.81530\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3546 - accuracy: 0.8742 - val_loss: 1.0354 - val_accuracy: 0.7318\n",
            "Epoch 367/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3728 - accuracy: 0.8677\n",
            "Epoch 367: val_accuracy did not improve from 0.81530\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3770 - accuracy: 0.8662 - val_loss: 1.2377 - val_accuracy: 0.6978\n",
            "Epoch 368/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.4560 - accuracy: 0.8381\n",
            "Epoch 368: val_accuracy did not improve from 0.81530\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4514 - accuracy: 0.8395 - val_loss: 0.9044 - val_accuracy: 0.7654\n",
            "Epoch 369/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3995 - accuracy: 0.8571\n",
            "Epoch 369: val_accuracy did not improve from 0.81530\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3986 - accuracy: 0.8571 - val_loss: 0.8821 - val_accuracy: 0.7804\n",
            "Epoch 370/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.4103 - accuracy: 0.8541\n",
            "Epoch 370: val_accuracy did not improve from 0.81530\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4088 - accuracy: 0.8545 - val_loss: 0.8108 - val_accuracy: 0.7817\n",
            "Epoch 371/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3583 - accuracy: 0.8718\n",
            "Epoch 371: val_accuracy did not improve from 0.81530\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.3565 - accuracy: 0.8725 - val_loss: 0.7898 - val_accuracy: 0.8022\n",
            "Epoch 372/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.4010 - accuracy: 0.8650\n",
            "Epoch 372: val_accuracy did not improve from 0.81530\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.4010 - accuracy: 0.8650 - val_loss: 1.2283 - val_accuracy: 0.7109\n",
            "Epoch 373/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.6655 - accuracy: 0.7812\n",
            "Epoch 373: val_accuracy did not improve from 0.81530\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.6602 - accuracy: 0.7823 - val_loss: 1.0417 - val_accuracy: 0.7318\n",
            "Epoch 374/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3989 - accuracy: 0.8574\n",
            "Epoch 374: val_accuracy did not improve from 0.81530\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3941 - accuracy: 0.8591 - val_loss: 0.7938 - val_accuracy: 0.8108\n",
            "Epoch 375/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3448 - accuracy: 0.8780\n",
            "Epoch 375: val_accuracy improved from 0.81530 to 0.81562, saving model to /content/asl/Adam3/cp-375-0.82.hdf5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3472 - accuracy: 0.8768 - val_loss: 0.7941 - val_accuracy: 0.8156\n",
            "Epoch 376/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3998 - accuracy: 0.8546\n",
            "Epoch 376: val_accuracy improved from 0.81562 to 0.81786, saving model to /content/asl/Adam3/cp-376-0.82.hdf5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3972 - accuracy: 0.8550 - val_loss: 0.7581 - val_accuracy: 0.8179\n",
            "Epoch 377/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.5712 - accuracy: 0.8094\n",
            "Epoch 377: val_accuracy did not improve from 0.81786\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.5659 - accuracy: 0.8104 - val_loss: 0.8734 - val_accuracy: 0.7798\n",
            "Epoch 378/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.4074 - accuracy: 0.8526\n",
            "Epoch 378: val_accuracy did not improve from 0.81786\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4074 - accuracy: 0.8526 - val_loss: 2.0451 - val_accuracy: 0.5739\n",
            "Epoch 379/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.4175 - accuracy: 0.8567\n",
            "Epoch 379: val_accuracy did not improve from 0.81786\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4154 - accuracy: 0.8570 - val_loss: 0.8775 - val_accuracy: 0.7785\n",
            "Epoch 380/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.5066 - accuracy: 0.8271\n",
            "Epoch 380: val_accuracy did not improve from 0.81786\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.5043 - accuracy: 0.8283 - val_loss: 0.8309 - val_accuracy: 0.7900\n",
            "Epoch 381/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3324 - accuracy: 0.8813\n",
            "Epoch 381: val_accuracy did not improve from 0.81786\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3331 - accuracy: 0.8812 - val_loss: 0.8461 - val_accuracy: 0.7849\n",
            "Epoch 382/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.4447 - accuracy: 0.8417\n",
            "Epoch 382: val_accuracy did not improve from 0.81786\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4361 - accuracy: 0.8451 - val_loss: 0.7821 - val_accuracy: 0.8035\n",
            "Epoch 383/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3246 - accuracy: 0.8876\n",
            "Epoch 383: val_accuracy did not improve from 0.81786\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3252 - accuracy: 0.8873 - val_loss: 0.8356 - val_accuracy: 0.7903\n",
            "Epoch 384/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3864 - accuracy: 0.8640\n",
            "Epoch 384: val_accuracy did not improve from 0.81786\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3901 - accuracy: 0.8624 - val_loss: 0.8716 - val_accuracy: 0.7794\n",
            "Epoch 385/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 1.2123 - accuracy: 0.6951\n",
            "Epoch 385: val_accuracy did not improve from 0.81786\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.2127 - accuracy: 0.6942 - val_loss: 1.3660 - val_accuracy: 0.6399\n",
            "Epoch 386/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.5046 - accuracy: 0.8269\n",
            "Epoch 386: val_accuracy did not improve from 0.81786\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.5032 - accuracy: 0.8267 - val_loss: 0.9897 - val_accuracy: 0.7346\n",
            "Epoch 387/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3187 - accuracy: 0.8881\n",
            "Epoch 387: val_accuracy did not improve from 0.81786\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3185 - accuracy: 0.8883 - val_loss: 0.7804 - val_accuracy: 0.7935\n",
            "Epoch 388/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3494 - accuracy: 0.8778\n",
            "Epoch 388: val_accuracy did not improve from 0.81786\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.3453 - accuracy: 0.8792 - val_loss: 0.7748 - val_accuracy: 0.8089\n",
            "Epoch 389/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2881 - accuracy: 0.8997\n",
            "Epoch 389: val_accuracy did not improve from 0.81786\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.2862 - accuracy: 0.9006 - val_loss: 0.9351 - val_accuracy: 0.7660\n",
            "Epoch 390/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.4228 - accuracy: 0.8581\n",
            "Epoch 390: val_accuracy did not improve from 0.81786\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.4391 - accuracy: 0.8534 - val_loss: 1.2796 - val_accuracy: 0.6901\n",
            "Epoch 391/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.3860 - accuracy: 0.8630\n",
            "Epoch 391: val_accuracy did not improve from 0.81786\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3750 - accuracy: 0.8670 - val_loss: 0.7650 - val_accuracy: 0.8105\n",
            "Epoch 392/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.4167 - accuracy: 0.8542\n",
            "Epoch 392: val_accuracy did not improve from 0.81786\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4108 - accuracy: 0.8567 - val_loss: 0.7497 - val_accuracy: 0.8147\n",
            "Epoch 393/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.3008 - accuracy: 0.8944\n",
            "Epoch 393: val_accuracy did not improve from 0.81786\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3081 - accuracy: 0.8912 - val_loss: 0.8609 - val_accuracy: 0.7814\n",
            "Epoch 394/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.5341 - accuracy: 0.8188\n",
            "Epoch 394: val_accuracy did not improve from 0.81786\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.5476 - accuracy: 0.8154 - val_loss: 0.9595 - val_accuracy: 0.7516\n",
            "Epoch 395/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3769 - accuracy: 0.8675\n",
            "Epoch 395: val_accuracy did not improve from 0.81786\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3737 - accuracy: 0.8683 - val_loss: 0.7844 - val_accuracy: 0.8111\n",
            "Epoch 396/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.3417 - accuracy: 0.8759\n",
            "Epoch 396: val_accuracy did not improve from 0.81786\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3408 - accuracy: 0.8759 - val_loss: 0.7759 - val_accuracy: 0.8083\n",
            "Epoch 397/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.3733 - accuracy: 0.8635\n",
            "Epoch 397: val_accuracy did not improve from 0.81786\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3712 - accuracy: 0.8646 - val_loss: 0.8061 - val_accuracy: 0.8025\n",
            "Epoch 398/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.4242 - accuracy: 0.8515\n",
            "Epoch 398: val_accuracy did not improve from 0.81786\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4234 - accuracy: 0.8514 - val_loss: 0.8758 - val_accuracy: 0.7759\n",
            "Epoch 399/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.4249 - accuracy: 0.8491\n",
            "Epoch 399: val_accuracy did not improve from 0.81786\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4216 - accuracy: 0.8507 - val_loss: 0.7620 - val_accuracy: 0.8089\n",
            "Epoch 400/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.4642 - accuracy: 0.8494\n",
            "Epoch 400: val_accuracy did not improve from 0.81786\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4659 - accuracy: 0.8477 - val_loss: 1.0492 - val_accuracy: 0.7372\n",
            "Epoch 401/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.4917 - accuracy: 0.8298\n",
            "Epoch 401: val_accuracy did not improve from 0.81786\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4991 - accuracy: 0.8269 - val_loss: 1.1226 - val_accuracy: 0.7244\n",
            "Epoch 402/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.4851 - accuracy: 0.8330\n",
            "Epoch 402: val_accuracy did not improve from 0.81786\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4827 - accuracy: 0.8337 - val_loss: 0.8681 - val_accuracy: 0.7798\n",
            "Epoch 403/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3877 - accuracy: 0.8654\n",
            "Epoch 403: val_accuracy did not improve from 0.81786\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3868 - accuracy: 0.8659 - val_loss: 0.7957 - val_accuracy: 0.8073\n",
            "Epoch 404/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3716 - accuracy: 0.8701\n",
            "Epoch 404: val_accuracy did not improve from 0.81786\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3716 - accuracy: 0.8701 - val_loss: 1.9117 - val_accuracy: 0.5986\n",
            "Epoch 405/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.5070 - accuracy: 0.8264\n",
            "Epoch 405: val_accuracy did not improve from 0.81786\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.4975 - accuracy: 0.8295 - val_loss: 0.8771 - val_accuracy: 0.7766\n",
            "Epoch 406/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3338 - accuracy: 0.8799\n",
            "Epoch 406: val_accuracy did not improve from 0.81786\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.3361 - accuracy: 0.8793 - val_loss: 0.8413 - val_accuracy: 0.7849\n",
            "Epoch 407/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3355 - accuracy: 0.8856\n",
            "Epoch 407: val_accuracy did not improve from 0.81786\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.3544 - accuracy: 0.8803 - val_loss: 1.2245 - val_accuracy: 0.6965\n",
            "Epoch 408/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.5363 - accuracy: 0.8177\n",
            "Epoch 408: val_accuracy did not improve from 0.81786\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.5354 - accuracy: 0.8176 - val_loss: 0.8455 - val_accuracy: 0.7903\n",
            "Epoch 409/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3436 - accuracy: 0.8768\n",
            "Epoch 409: val_accuracy did not improve from 0.81786\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3420 - accuracy: 0.8776 - val_loss: 0.9444 - val_accuracy: 0.7542\n",
            "Epoch 410/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3300 - accuracy: 0.8804\n",
            "Epoch 410: val_accuracy did not improve from 0.81786\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3298 - accuracy: 0.8806 - val_loss: 0.7524 - val_accuracy: 0.8127\n",
            "Epoch 411/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3515 - accuracy: 0.8751\n",
            "Epoch 411: val_accuracy did not improve from 0.81786\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3521 - accuracy: 0.8748 - val_loss: 1.1936 - val_accuracy: 0.7081\n",
            "Epoch 412/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3884 - accuracy: 0.8644\n",
            "Epoch 412: val_accuracy improved from 0.81786 to 0.82907, saving model to /content/asl/Adam3/cp-412-0.83.hdf5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3823 - accuracy: 0.8666 - val_loss: 0.7525 - val_accuracy: 0.8291\n",
            "Epoch 413/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3799 - accuracy: 0.8627\n",
            "Epoch 413: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3853 - accuracy: 0.8604 - val_loss: 1.1830 - val_accuracy: 0.7260\n",
            "Epoch 414/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3995 - accuracy: 0.8589\n",
            "Epoch 414: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3944 - accuracy: 0.8608 - val_loss: 0.8346 - val_accuracy: 0.7875\n",
            "Epoch 415/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2977 - accuracy: 0.8944\n",
            "Epoch 415: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3010 - accuracy: 0.8932 - val_loss: 1.0765 - val_accuracy: 0.7433\n",
            "Epoch 416/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.5731 - accuracy: 0.8022\n",
            "Epoch 416: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.5724 - accuracy: 0.8027 - val_loss: 0.9157 - val_accuracy: 0.7718\n",
            "Epoch 417/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.4593 - accuracy: 0.8421\n",
            "Epoch 417: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4573 - accuracy: 0.8429 - val_loss: 0.7939 - val_accuracy: 0.8028\n",
            "Epoch 418/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3584 - accuracy: 0.8696\n",
            "Epoch 418: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3584 - accuracy: 0.8696 - val_loss: 0.9813 - val_accuracy: 0.7430\n",
            "Epoch 419/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.4431 - accuracy: 0.8396\n",
            "Epoch 419: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4426 - accuracy: 0.8395 - val_loss: 1.4937 - val_accuracy: 0.6504\n",
            "Epoch 420/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.4549 - accuracy: 0.8478\n",
            "Epoch 420: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4497 - accuracy: 0.8491 - val_loss: 0.8557 - val_accuracy: 0.7759\n",
            "Epoch 421/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3527 - accuracy: 0.8735\n",
            "Epoch 421: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.3527 - accuracy: 0.8741 - val_loss: 0.8932 - val_accuracy: 0.7862\n",
            "Epoch 422/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3723 - accuracy: 0.8706\n",
            "Epoch 422: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.3954 - accuracy: 0.8648 - val_loss: 2.0051 - val_accuracy: 0.6069\n",
            "Epoch 423/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.8291 - accuracy: 0.7591\n",
            "Epoch 423: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.8202 - accuracy: 0.7610 - val_loss: 0.7959 - val_accuracy: 0.7993\n",
            "Epoch 424/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2867 - accuracy: 0.8995\n",
            "Epoch 424: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.2865 - accuracy: 0.8993 - val_loss: 0.8011 - val_accuracy: 0.8015\n",
            "Epoch 425/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3402 - accuracy: 0.8767\n",
            "Epoch 425: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3429 - accuracy: 0.8759 - val_loss: 0.8964 - val_accuracy: 0.7814\n",
            "Epoch 426/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3173 - accuracy: 0.8863\n",
            "Epoch 426: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3159 - accuracy: 0.8865 - val_loss: 0.8098 - val_accuracy: 0.7948\n",
            "Epoch 427/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2984 - accuracy: 0.8938\n",
            "Epoch 427: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3012 - accuracy: 0.8925 - val_loss: 0.7762 - val_accuracy: 0.8092\n",
            "Epoch 428/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3213 - accuracy: 0.8824\n",
            "Epoch 428: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3206 - accuracy: 0.8830 - val_loss: 0.8376 - val_accuracy: 0.7945\n",
            "Epoch 429/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.6318 - accuracy: 0.7975\n",
            "Epoch 429: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.6274 - accuracy: 0.7984 - val_loss: 1.1916 - val_accuracy: 0.7061\n",
            "Epoch 430/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3844 - accuracy: 0.8623\n",
            "Epoch 430: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4082 - accuracy: 0.8568 - val_loss: 1.5215 - val_accuracy: 0.6703\n",
            "Epoch 431/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.4505 - accuracy: 0.8409\n",
            "Epoch 431: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4496 - accuracy: 0.8410 - val_loss: 0.9185 - val_accuracy: 0.7641\n",
            "Epoch 432/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3113 - accuracy: 0.8890\n",
            "Epoch 432: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3108 - accuracy: 0.8891 - val_loss: 0.8066 - val_accuracy: 0.8019\n",
            "Epoch 433/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2868 - accuracy: 0.8990\n",
            "Epoch 433: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2941 - accuracy: 0.8959 - val_loss: 0.8511 - val_accuracy: 0.7980\n",
            "Epoch 434/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2966 - accuracy: 0.8937\n",
            "Epoch 434: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2978 - accuracy: 0.8931 - val_loss: 0.9606 - val_accuracy: 0.7673\n",
            "Epoch 435/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.4926 - accuracy: 0.8279\n",
            "Epoch 435: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4835 - accuracy: 0.8312 - val_loss: 0.9491 - val_accuracy: 0.7702\n",
            "Epoch 436/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.4635 - accuracy: 0.8406\n",
            "Epoch 436: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4634 - accuracy: 0.8407 - val_loss: 1.1311 - val_accuracy: 0.7215\n",
            "Epoch 437/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.4123 - accuracy: 0.8489\n",
            "Epoch 437: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4088 - accuracy: 0.8492 - val_loss: 0.9455 - val_accuracy: 0.7609\n",
            "Epoch 438/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3420 - accuracy: 0.8784\n",
            "Epoch 438: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.3420 - accuracy: 0.8784 - val_loss: 0.8762 - val_accuracy: 0.7951\n",
            "Epoch 439/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2841 - accuracy: 0.8987\n",
            "Epoch 439: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.2858 - accuracy: 0.8979 - val_loss: 0.8764 - val_accuracy: 0.7836\n",
            "Epoch 440/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.6102 - accuracy: 0.7960\n",
            "Epoch 440: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.6082 - accuracy: 0.7967 - val_loss: 1.0875 - val_accuracy: 0.7266\n",
            "Epoch 441/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.3990 - accuracy: 0.6876\n",
            "Epoch 441: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 1.3990 - accuracy: 0.6876 - val_loss: 0.8318 - val_accuracy: 0.7875\n",
            "Epoch 442/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3184 - accuracy: 0.8910\n",
            "Epoch 442: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3175 - accuracy: 0.8912 - val_loss: 0.7770 - val_accuracy: 0.8003\n",
            "Epoch 443/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3407 - accuracy: 0.8799\n",
            "Epoch 443: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3420 - accuracy: 0.8796 - val_loss: 0.7697 - val_accuracy: 0.8118\n",
            "Epoch 444/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3078 - accuracy: 0.8930\n",
            "Epoch 444: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3079 - accuracy: 0.8928 - val_loss: 0.9744 - val_accuracy: 0.7583\n",
            "Epoch 445/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2700 - accuracy: 0.9049\n",
            "Epoch 445: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2682 - accuracy: 0.9051 - val_loss: 0.7906 - val_accuracy: 0.8022\n",
            "Epoch 446/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3031 - accuracy: 0.8915\n",
            "Epoch 446: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3033 - accuracy: 0.8916 - val_loss: 0.7551 - val_accuracy: 0.8198\n",
            "Epoch 447/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3254 - accuracy: 0.8848\n",
            "Epoch 447: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3254 - accuracy: 0.8848 - val_loss: 0.8176 - val_accuracy: 0.7903\n",
            "Epoch 448/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3169 - accuracy: 0.8879\n",
            "Epoch 448: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3204 - accuracy: 0.8862 - val_loss: 0.8471 - val_accuracy: 0.7817\n",
            "Epoch 449/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3613 - accuracy: 0.8684\n",
            "Epoch 449: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3718 - accuracy: 0.8657 - val_loss: 1.5487 - val_accuracy: 0.6559\n",
            "Epoch 450/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.7365 - accuracy: 0.7721\n",
            "Epoch 450: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.7252 - accuracy: 0.7746 - val_loss: 0.8340 - val_accuracy: 0.7967\n",
            "Epoch 451/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3064 - accuracy: 0.8910\n",
            "Epoch 451: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3078 - accuracy: 0.8900 - val_loss: 0.9209 - val_accuracy: 0.7730\n",
            "Epoch 452/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.4346 - accuracy: 0.8469\n",
            "Epoch 452: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4342 - accuracy: 0.8468 - val_loss: 0.8148 - val_accuracy: 0.8031\n",
            "Epoch 453/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2864 - accuracy: 0.8961\n",
            "Epoch 453: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2874 - accuracy: 0.8957 - val_loss: 0.9174 - val_accuracy: 0.7740\n",
            "Epoch 454/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3192 - accuracy: 0.8847\n",
            "Epoch 454: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3175 - accuracy: 0.8854 - val_loss: 0.8066 - val_accuracy: 0.8092\n",
            "Epoch 455/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2696 - accuracy: 0.9014\n",
            "Epoch 455: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.2694 - accuracy: 0.9016 - val_loss: 0.7806 - val_accuracy: 0.8019\n",
            "Epoch 456/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.4412 - accuracy: 0.8488\n",
            "Epoch 456: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.4412 - accuracy: 0.8488 - val_loss: 1.1080 - val_accuracy: 0.7442\n",
            "Epoch 457/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3365 - accuracy: 0.8770\n",
            "Epoch 457: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.3335 - accuracy: 0.8781 - val_loss: 0.7674 - val_accuracy: 0.8143\n",
            "Epoch 458/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2887 - accuracy: 0.8976\n",
            "Epoch 458: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.2894 - accuracy: 0.8967 - val_loss: 0.7704 - val_accuracy: 0.8102\n",
            "Epoch 459/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.4360 - accuracy: 0.8538\n",
            "Epoch 459: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4580 - accuracy: 0.8469 - val_loss: 2.2064 - val_accuracy: 0.5976\n",
            "Epoch 460/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3967 - accuracy: 0.8586\n",
            "Epoch 460: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3924 - accuracy: 0.8604 - val_loss: 0.8543 - val_accuracy: 0.7833\n",
            "Epoch 461/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3127 - accuracy: 0.8858\n",
            "Epoch 461: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.3092 - accuracy: 0.8872 - val_loss: 0.7919 - val_accuracy: 0.8067\n",
            "Epoch 462/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.4001 - accuracy: 0.8566\n",
            "Epoch 462: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 0.3994 - accuracy: 0.8569 - val_loss: 0.7542 - val_accuracy: 0.8131\n",
            "Epoch 463/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3494 - accuracy: 0.8743\n",
            "Epoch 463: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 12ms/step - loss: 0.3494 - accuracy: 0.8743 - val_loss: 1.3181 - val_accuracy: 0.6863\n",
            "Epoch 464/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.4811 - accuracy: 0.8345\n",
            "Epoch 464: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 0.4793 - accuracy: 0.8352 - val_loss: 1.0952 - val_accuracy: 0.7407\n",
            "Epoch 465/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3010 - accuracy: 0.8899\n",
            "Epoch 465: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 13ms/step - loss: 0.2985 - accuracy: 0.8913 - val_loss: 0.7828 - val_accuracy: 0.8191\n",
            "Epoch 466/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2927 - accuracy: 0.8924\n",
            "Epoch 466: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 13ms/step - loss: 0.2920 - accuracy: 0.8928 - val_loss: 0.7464 - val_accuracy: 0.8198\n",
            "Epoch 467/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.4710 - accuracy: 0.8425\n",
            "Epoch 467: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 0.4906 - accuracy: 0.8382 - val_loss: 2.4196 - val_accuracy: 0.5675\n",
            "Epoch 468/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 1.0870 - accuracy: 0.7291\n",
            "Epoch 468: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 1.0814 - accuracy: 0.7303 - val_loss: 0.8327 - val_accuracy: 0.7945\n",
            "Epoch 469/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3029 - accuracy: 0.8930\n",
            "Epoch 469: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.3056 - accuracy: 0.8920 - val_loss: 0.8106 - val_accuracy: 0.8028\n",
            "Epoch 470/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2948 - accuracy: 0.8941\n",
            "Epoch 470: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 0.2948 - accuracy: 0.8941 - val_loss: 0.8366 - val_accuracy: 0.7983\n",
            "Epoch 471/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2982 - accuracy: 0.8940\n",
            "Epoch 471: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 0.2988 - accuracy: 0.8934 - val_loss: 0.8436 - val_accuracy: 0.7887\n",
            "Epoch 472/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3817 - accuracy: 0.8673\n",
            "Epoch 472: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.3789 - accuracy: 0.8676 - val_loss: 0.9966 - val_accuracy: 0.7561\n",
            "Epoch 473/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.4316 - accuracy: 0.8496\n",
            "Epoch 473: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 12ms/step - loss: 0.4322 - accuracy: 0.8491 - val_loss: 0.7985 - val_accuracy: 0.8169\n",
            "Epoch 474/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3381 - accuracy: 0.8789\n",
            "Epoch 474: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 12ms/step - loss: 0.3396 - accuracy: 0.8785 - val_loss: 0.8588 - val_accuracy: 0.7987\n",
            "Epoch 475/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3413 - accuracy: 0.8758\n",
            "Epoch 475: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.3369 - accuracy: 0.8774 - val_loss: 0.7707 - val_accuracy: 0.8198\n",
            "Epoch 476/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.4781 - accuracy: 0.8500\n",
            "Epoch 476: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 0.4779 - accuracy: 0.8498 - val_loss: 1.3897 - val_accuracy: 0.6633\n",
            "Epoch 477/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3553 - accuracy: 0.8718\n",
            "Epoch 477: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 13ms/step - loss: 0.3564 - accuracy: 0.8712 - val_loss: 0.8054 - val_accuracy: 0.8083\n",
            "Epoch 478/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2911 - accuracy: 0.8968\n",
            "Epoch 478: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.2910 - accuracy: 0.8967 - val_loss: 0.7682 - val_accuracy: 0.8102\n",
            "Epoch 479/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2839 - accuracy: 0.8979\n",
            "Epoch 479: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 2s 19ms/step - loss: 0.2878 - accuracy: 0.8964 - val_loss: 1.0361 - val_accuracy: 0.7494\n",
            "Epoch 480/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3628 - accuracy: 0.8668\n",
            "Epoch 480: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.3628 - accuracy: 0.8668 - val_loss: 0.7508 - val_accuracy: 0.8284\n",
            "Epoch 481/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3097 - accuracy: 0.8907\n",
            "Epoch 481: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.3168 - accuracy: 0.8888 - val_loss: 1.1061 - val_accuracy: 0.7321\n",
            "Epoch 482/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.4400 - accuracy: 0.8439\n",
            "Epoch 482: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.4346 - accuracy: 0.8455 - val_loss: 0.8994 - val_accuracy: 0.7801\n",
            "Epoch 483/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2953 - accuracy: 0.8875\n",
            "Epoch 483: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2977 - accuracy: 0.8870 - val_loss: 0.9377 - val_accuracy: 0.7740\n",
            "Epoch 484/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.5989 - accuracy: 0.8146\n",
            "Epoch 484: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.5974 - accuracy: 0.8152 - val_loss: 0.9181 - val_accuracy: 0.7849\n",
            "Epoch 485/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.3274 - accuracy: 0.8805\n",
            "Epoch 485: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3244 - accuracy: 0.8816 - val_loss: 0.8667 - val_accuracy: 0.7967\n",
            "Epoch 486/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2654 - accuracy: 0.9036\n",
            "Epoch 486: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2656 - accuracy: 0.9032 - val_loss: 0.8047 - val_accuracy: 0.8204\n",
            "Epoch 487/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2558 - accuracy: 0.9079\n",
            "Epoch 487: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2644 - accuracy: 0.9052 - val_loss: 1.1619 - val_accuracy: 0.7282\n",
            "Epoch 488/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.6739 - accuracy: 0.7879\n",
            "Epoch 488: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.6739 - accuracy: 0.7879 - val_loss: 0.9286 - val_accuracy: 0.7762\n",
            "Epoch 489/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3394 - accuracy: 0.8771\n",
            "Epoch 489: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3383 - accuracy: 0.8774 - val_loss: 0.8552 - val_accuracy: 0.7910\n",
            "Epoch 490/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3627 - accuracy: 0.8724\n",
            "Epoch 490: val_accuracy did not improve from 0.82907\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3647 - accuracy: 0.8716 - val_loss: 0.8794 - val_accuracy: 0.7775\n",
            "Epoch 491/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2923 - accuracy: 0.8955\n",
            "Epoch 491: val_accuracy improved from 0.82907 to 0.83099, saving model to /content/asl/Adam3/cp-491-0.83.hdf5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2904 - accuracy: 0.8960 - val_loss: 0.7350 - val_accuracy: 0.8310\n",
            "Epoch 492/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2647 - accuracy: 0.9056\n",
            "Epoch 492: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2664 - accuracy: 0.9044 - val_loss: 0.9281 - val_accuracy: 0.7727\n",
            "Epoch 493/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3551 - accuracy: 0.8672\n",
            "Epoch 493: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3505 - accuracy: 0.8691 - val_loss: 0.8217 - val_accuracy: 0.8067\n",
            "Epoch 494/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3183 - accuracy: 0.8857\n",
            "Epoch 494: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3193 - accuracy: 0.8856 - val_loss: 0.8960 - val_accuracy: 0.7836\n",
            "Epoch 495/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3314 - accuracy: 0.8821\n",
            "Epoch 495: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.3314 - accuracy: 0.8821 - val_loss: 0.8026 - val_accuracy: 0.8246\n",
            "Epoch 496/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3450 - accuracy: 0.8734\n",
            "Epoch 496: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.3450 - accuracy: 0.8734 - val_loss: 1.0424 - val_accuracy: 0.7570\n",
            "Epoch 497/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3436 - accuracy: 0.8771\n",
            "Epoch 497: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 12ms/step - loss: 0.3436 - accuracy: 0.8771 - val_loss: 0.7813 - val_accuracy: 0.8249\n",
            "Epoch 498/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3496 - accuracy: 0.8755\n",
            "Epoch 498: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.3552 - accuracy: 0.8748 - val_loss: 0.8925 - val_accuracy: 0.7900\n",
            "Epoch 499/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2724 - accuracy: 0.9010\n",
            "Epoch 499: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2761 - accuracy: 0.8997 - val_loss: 0.9555 - val_accuracy: 0.7702\n",
            "Epoch 500/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.6124 - accuracy: 0.8002\n",
            "Epoch 500: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.6094 - accuracy: 0.8006 - val_loss: 1.0927 - val_accuracy: 0.7350\n",
            "Epoch 501/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3391 - accuracy: 0.8770\n",
            "Epoch 501: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3395 - accuracy: 0.8765 - val_loss: 0.8435 - val_accuracy: 0.8054\n",
            "Epoch 502/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2344 - accuracy: 0.9164\n",
            "Epoch 502: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2413 - accuracy: 0.9138 - val_loss: 0.8062 - val_accuracy: 0.8076\n",
            "Epoch 503/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3119 - accuracy: 0.8828\n",
            "Epoch 503: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3130 - accuracy: 0.8824 - val_loss: 0.9579 - val_accuracy: 0.7673\n",
            "Epoch 504/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3988 - accuracy: 0.8548\n",
            "Epoch 504: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3988 - accuracy: 0.8548 - val_loss: 0.8821 - val_accuracy: 0.7865\n",
            "Epoch 505/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2720 - accuracy: 0.8987\n",
            "Epoch 505: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2720 - accuracy: 0.8987 - val_loss: 0.8093 - val_accuracy: 0.8121\n",
            "Epoch 506/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2619 - accuracy: 0.9062\n",
            "Epoch 506: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2627 - accuracy: 0.9058 - val_loss: 0.8016 - val_accuracy: 0.8127\n",
            "Epoch 507/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2839 - accuracy: 0.8963\n",
            "Epoch 507: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2839 - accuracy: 0.8963 - val_loss: 0.7917 - val_accuracy: 0.8207\n",
            "Epoch 508/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3730 - accuracy: 0.8664\n",
            "Epoch 508: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3700 - accuracy: 0.8670 - val_loss: 0.8036 - val_accuracy: 0.8038\n",
            "Epoch 509/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.4583 - accuracy: 0.8423\n",
            "Epoch 509: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4566 - accuracy: 0.8423 - val_loss: 0.9187 - val_accuracy: 0.7859\n",
            "Epoch 510/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2651 - accuracy: 0.9045\n",
            "Epoch 510: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2651 - accuracy: 0.9045 - val_loss: 0.9521 - val_accuracy: 0.7727\n",
            "Epoch 511/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2976 - accuracy: 0.8947\n",
            "Epoch 511: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2990 - accuracy: 0.8944 - val_loss: 0.9500 - val_accuracy: 0.7682\n",
            "Epoch 512/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3226 - accuracy: 0.8812\n",
            "Epoch 512: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3226 - accuracy: 0.8812 - val_loss: 0.8495 - val_accuracy: 0.7942\n",
            "Epoch 513/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2662 - accuracy: 0.9028\n",
            "Epoch 513: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.2662 - accuracy: 0.9026 - val_loss: 0.9994 - val_accuracy: 0.7583\n",
            "Epoch 514/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3257 - accuracy: 0.8840\n",
            "Epoch 514: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.3290 - accuracy: 0.8829 - val_loss: 1.2612 - val_accuracy: 0.7132\n",
            "Epoch 515/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.8008 - accuracy: 0.7696\n",
            "Epoch 515: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.7984 - accuracy: 0.7694 - val_loss: 1.1579 - val_accuracy: 0.7173\n",
            "Epoch 516/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3738 - accuracy: 0.8691\n",
            "Epoch 516: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3709 - accuracy: 0.8704 - val_loss: 0.8064 - val_accuracy: 0.7999\n",
            "Epoch 517/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2973 - accuracy: 0.8893\n",
            "Epoch 517: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2967 - accuracy: 0.8896 - val_loss: 0.9610 - val_accuracy: 0.7762\n",
            "Epoch 518/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2759 - accuracy: 0.8983\n",
            "Epoch 518: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2753 - accuracy: 0.8980 - val_loss: 0.8508 - val_accuracy: 0.7964\n",
            "Epoch 519/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2503 - accuracy: 0.9077\n",
            "Epoch 519: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2488 - accuracy: 0.9082 - val_loss: 0.7711 - val_accuracy: 0.8243\n",
            "Epoch 520/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.4579 - accuracy: 0.8448\n",
            "Epoch 520: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4579 - accuracy: 0.8448 - val_loss: 0.8838 - val_accuracy: 0.7804\n",
            "Epoch 521/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3106 - accuracy: 0.8877\n",
            "Epoch 521: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3060 - accuracy: 0.8886 - val_loss: 0.8051 - val_accuracy: 0.8134\n",
            "Epoch 522/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3304 - accuracy: 0.8822\n",
            "Epoch 522: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3272 - accuracy: 0.8838 - val_loss: 0.8479 - val_accuracy: 0.8060\n",
            "Epoch 523/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2519 - accuracy: 0.9086\n",
            "Epoch 523: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2528 - accuracy: 0.9081 - val_loss: 0.7969 - val_accuracy: 0.8265\n",
            "Epoch 524/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2869 - accuracy: 0.8965\n",
            "Epoch 524: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2912 - accuracy: 0.8944 - val_loss: 1.0909 - val_accuracy: 0.7481\n",
            "Epoch 525/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8623\n",
            "Epoch 525: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3850 - accuracy: 0.8626 - val_loss: 0.9885 - val_accuracy: 0.7462\n",
            "Epoch 526/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.5068 - accuracy: 0.8298\n",
            "Epoch 526: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.5058 - accuracy: 0.8296 - val_loss: 1.0292 - val_accuracy: 0.7494\n",
            "Epoch 527/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2977 - accuracy: 0.8941\n",
            "Epoch 527: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2985 - accuracy: 0.8928 - val_loss: 1.1663 - val_accuracy: 0.7298\n",
            "Epoch 528/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.4956 - accuracy: 0.8446\n",
            "Epoch 528: val_accuracy did not improve from 0.83099\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4996 - accuracy: 0.8426 - val_loss: 1.0179 - val_accuracy: 0.7382\n",
            "Epoch 529/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3657 - accuracy: 0.8711\n",
            "Epoch 529: val_accuracy improved from 0.83099 to 0.83803, saving model to /content/asl/Adam3/cp-529-0.84.hdf5\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.3597 - accuracy: 0.8732 - val_loss: 0.7640 - val_accuracy: 0.8380\n",
            "Epoch 530/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2246 - accuracy: 0.9216\n",
            "Epoch 530: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.2246 - accuracy: 0.9216 - val_loss: 0.9570 - val_accuracy: 0.7743\n",
            "Epoch 531/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2782 - accuracy: 0.8949\n",
            "Epoch 531: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.2811 - accuracy: 0.8939 - val_loss: 0.7740 - val_accuracy: 0.8182\n",
            "Epoch 532/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2675 - accuracy: 0.8999\n",
            "Epoch 532: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.2680 - accuracy: 0.8996 - val_loss: 0.8642 - val_accuracy: 0.8035\n",
            "Epoch 533/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2965 - accuracy: 0.8905\n",
            "Epoch 533: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2972 - accuracy: 0.8896 - val_loss: 0.8114 - val_accuracy: 0.8201\n",
            "Epoch 534/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2759 - accuracy: 0.9009\n",
            "Epoch 534: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2766 - accuracy: 0.9008 - val_loss: 0.7911 - val_accuracy: 0.8255\n",
            "Epoch 535/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2823 - accuracy: 0.8996\n",
            "Epoch 535: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2836 - accuracy: 0.8985 - val_loss: 0.8953 - val_accuracy: 0.7999\n",
            "Epoch 536/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2805 - accuracy: 0.8976\n",
            "Epoch 536: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2763 - accuracy: 0.8986 - val_loss: 0.8509 - val_accuracy: 0.8089\n",
            "Epoch 537/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2500 - accuracy: 0.9073\n",
            "Epoch 537: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2519 - accuracy: 0.9069 - val_loss: 0.7863 - val_accuracy: 0.8281\n",
            "Epoch 538/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.4844 - accuracy: 0.8381\n",
            "Epoch 538: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4902 - accuracy: 0.8366 - val_loss: 1.1217 - val_accuracy: 0.7289\n",
            "Epoch 539/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.4760 - accuracy: 0.8383\n",
            "Epoch 539: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4760 - accuracy: 0.8383 - val_loss: 0.8850 - val_accuracy: 0.8019\n",
            "Epoch 540/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 1.1245 - accuracy: 0.7238\n",
            "Epoch 540: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.0910 - accuracy: 0.7302 - val_loss: 0.9702 - val_accuracy: 0.7622\n",
            "Epoch 541/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3134 - accuracy: 0.8901\n",
            "Epoch 541: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3156 - accuracy: 0.8885 - val_loss: 1.0471 - val_accuracy: 0.7673\n",
            "Epoch 542/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2761 - accuracy: 0.9001\n",
            "Epoch 542: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2730 - accuracy: 0.9008 - val_loss: 0.8404 - val_accuracy: 0.8105\n",
            "Epoch 543/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2681 - accuracy: 0.9008\n",
            "Epoch 543: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2787 - accuracy: 0.8979 - val_loss: 1.0221 - val_accuracy: 0.7670\n",
            "Epoch 544/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.4326 - accuracy: 0.8596\n",
            "Epoch 544: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4326 - accuracy: 0.8596 - val_loss: 0.8601 - val_accuracy: 0.8127\n",
            "Epoch 545/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2180 - accuracy: 0.9197\n",
            "Epoch 545: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2192 - accuracy: 0.9195 - val_loss: 0.8285 - val_accuracy: 0.8169\n",
            "Epoch 546/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2013 - accuracy: 0.9290\n",
            "Epoch 546: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2000 - accuracy: 0.9295 - val_loss: 0.7806 - val_accuracy: 0.8297\n",
            "Epoch 547/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2044 - accuracy: 0.9242\n",
            "Epoch 547: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.2046 - accuracy: 0.9241 - val_loss: 0.7744 - val_accuracy: 0.8230\n",
            "Epoch 548/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2842 - accuracy: 0.8966\n",
            "Epoch 548: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 12ms/step - loss: 0.2834 - accuracy: 0.8969 - val_loss: 0.8236 - val_accuracy: 0.8083\n",
            "Epoch 549/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2746 - accuracy: 0.9007\n",
            "Epoch 549: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.2752 - accuracy: 0.9004 - val_loss: 0.8650 - val_accuracy: 0.7945\n",
            "Epoch 550/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3201 - accuracy: 0.8817\n",
            "Epoch 550: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3196 - accuracy: 0.8817 - val_loss: 1.5729 - val_accuracy: 0.6741\n",
            "Epoch 551/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.4064 - accuracy: 0.8568\n",
            "Epoch 551: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4049 - accuracy: 0.8573 - val_loss: 0.9059 - val_accuracy: 0.7884\n",
            "Epoch 552/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.4135 - accuracy: 0.8588\n",
            "Epoch 552: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4135 - accuracy: 0.8588 - val_loss: 1.2701 - val_accuracy: 0.7122\n",
            "Epoch 553/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3650 - accuracy: 0.8663\n",
            "Epoch 553: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3649 - accuracy: 0.8667 - val_loss: 0.8450 - val_accuracy: 0.8089\n",
            "Epoch 554/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2373 - accuracy: 0.9124\n",
            "Epoch 554: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2373 - accuracy: 0.9124 - val_loss: 0.7666 - val_accuracy: 0.8191\n",
            "Epoch 555/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2146 - accuracy: 0.9231\n",
            "Epoch 555: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2156 - accuracy: 0.9226 - val_loss: 0.9703 - val_accuracy: 0.7891\n",
            "Epoch 556/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.4202 - accuracy: 0.8635\n",
            "Epoch 556: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4146 - accuracy: 0.8652 - val_loss: 0.7954 - val_accuracy: 0.8185\n",
            "Epoch 557/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.6249 - accuracy: 0.8182\n",
            "Epoch 557: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.6249 - accuracy: 0.8182 - val_loss: 0.9049 - val_accuracy: 0.7942\n",
            "Epoch 558/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2944 - accuracy: 0.8904\n",
            "Epoch 558: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2934 - accuracy: 0.8910 - val_loss: 0.7957 - val_accuracy: 0.8124\n",
            "Epoch 559/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3688 - accuracy: 0.8769\n",
            "Epoch 559: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3850 - accuracy: 0.8718 - val_loss: 1.0158 - val_accuracy: 0.7583\n",
            "Epoch 560/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3198 - accuracy: 0.8849\n",
            "Epoch 560: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3174 - accuracy: 0.8858 - val_loss: 0.8140 - val_accuracy: 0.8163\n",
            "Epoch 561/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2488 - accuracy: 0.9104\n",
            "Epoch 561: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2534 - accuracy: 0.9085 - val_loss: 1.0198 - val_accuracy: 0.7702\n",
            "Epoch 562/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3415 - accuracy: 0.8756\n",
            "Epoch 562: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3415 - accuracy: 0.8756 - val_loss: 0.7723 - val_accuracy: 0.8313\n",
            "Epoch 563/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2238 - accuracy: 0.9169\n",
            "Epoch 563: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.2232 - accuracy: 0.9173 - val_loss: 0.8202 - val_accuracy: 0.8211\n",
            "Epoch 564/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2416 - accuracy: 0.9115\n",
            "Epoch 564: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.2416 - accuracy: 0.9115 - val_loss: 0.8139 - val_accuracy: 0.8092\n",
            "Epoch 565/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.6057 - accuracy: 0.8296\n",
            "Epoch 565: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 12ms/step - loss: 0.6507 - accuracy: 0.8221 - val_loss: 3.2895 - val_accuracy: 0.4962\n",
            "Epoch 566/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.5705 - accuracy: 0.8260\n",
            "Epoch 566: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.5685 - accuracy: 0.8266 - val_loss: 0.8057 - val_accuracy: 0.8265\n",
            "Epoch 567/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2709 - accuracy: 0.9029\n",
            "Epoch 567: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2671 - accuracy: 0.9044 - val_loss: 0.8175 - val_accuracy: 0.8131\n",
            "Epoch 568/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2303 - accuracy: 0.9190\n",
            "Epoch 568: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2330 - accuracy: 0.9176 - val_loss: 1.2135 - val_accuracy: 0.7289\n",
            "Epoch 569/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2748 - accuracy: 0.9004\n",
            "Epoch 569: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2729 - accuracy: 0.9016 - val_loss: 0.7929 - val_accuracy: 0.8195\n",
            "Epoch 570/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3429 - accuracy: 0.8808\n",
            "Epoch 570: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3519 - accuracy: 0.8778 - val_loss: 1.2224 - val_accuracy: 0.7346\n",
            "Epoch 571/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.4107 - accuracy: 0.8569\n",
            "Epoch 571: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4061 - accuracy: 0.8581 - val_loss: 0.9898 - val_accuracy: 0.7948\n",
            "Epoch 572/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3625 - accuracy: 0.8690\n",
            "Epoch 572: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3622 - accuracy: 0.8690 - val_loss: 0.9020 - val_accuracy: 0.7987\n",
            "Epoch 573/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3449 - accuracy: 0.8758\n",
            "Epoch 573: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3441 - accuracy: 0.8766 - val_loss: 0.8761 - val_accuracy: 0.8019\n",
            "Epoch 574/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2291 - accuracy: 0.9159\n",
            "Epoch 574: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2285 - accuracy: 0.9163 - val_loss: 0.7900 - val_accuracy: 0.8236\n",
            "Epoch 575/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.8122 - accuracy: 0.7814\n",
            "Epoch 575: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.7792 - accuracy: 0.7879 - val_loss: 0.9715 - val_accuracy: 0.7670\n",
            "Epoch 576/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2334 - accuracy: 0.9159\n",
            "Epoch 576: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2330 - accuracy: 0.9161 - val_loss: 0.7535 - val_accuracy: 0.8233\n",
            "Epoch 577/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2221 - accuracy: 0.9190\n",
            "Epoch 577: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2220 - accuracy: 0.9189 - val_loss: 0.8271 - val_accuracy: 0.8115\n",
            "Epoch 578/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2214 - accuracy: 0.9183\n",
            "Epoch 578: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2233 - accuracy: 0.9177 - val_loss: 0.8781 - val_accuracy: 0.7939\n",
            "Epoch 579/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3918 - accuracy: 0.8622\n",
            "Epoch 579: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3890 - accuracy: 0.8630 - val_loss: 1.2828 - val_accuracy: 0.7113\n",
            "Epoch 580/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2728 - accuracy: 0.9015\n",
            "Epoch 580: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.2717 - accuracy: 0.9016 - val_loss: 0.8370 - val_accuracy: 0.8236\n",
            "Epoch 581/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2176 - accuracy: 0.9208\n",
            "Epoch 581: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.2249 - accuracy: 0.9182 - val_loss: 1.3369 - val_accuracy: 0.7273\n",
            "Epoch 582/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.4543 - accuracy: 0.8463\n",
            "Epoch 582: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 12ms/step - loss: 0.4452 - accuracy: 0.8492 - val_loss: 0.8574 - val_accuracy: 0.8054\n",
            "Epoch 583/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2105 - accuracy: 0.9274\n",
            "Epoch 583: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.2109 - accuracy: 0.9271 - val_loss: 0.7611 - val_accuracy: 0.8348\n",
            "Epoch 584/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2909 - accuracy: 0.8977\n",
            "Epoch 584: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2923 - accuracy: 0.8971 - val_loss: 0.9870 - val_accuracy: 0.7711\n",
            "Epoch 585/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.3745 - accuracy: 0.8688\n",
            "Epoch 585: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3656 - accuracy: 0.8710 - val_loss: 0.8114 - val_accuracy: 0.8179\n",
            "Epoch 586/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2328 - accuracy: 0.9147\n",
            "Epoch 586: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2328 - accuracy: 0.9147 - val_loss: 1.0811 - val_accuracy: 0.7519\n",
            "Epoch 587/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2335 - accuracy: 0.9159\n",
            "Epoch 587: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2380 - accuracy: 0.9141 - val_loss: 0.7836 - val_accuracy: 0.8195\n",
            "Epoch 588/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2477 - accuracy: 0.9076\n",
            "Epoch 588: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2481 - accuracy: 0.9076 - val_loss: 0.8996 - val_accuracy: 0.7907\n",
            "Epoch 589/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3610 - accuracy: 0.8799\n",
            "Epoch 589: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3773 - accuracy: 0.8752 - val_loss: 1.2282 - val_accuracy: 0.7298\n",
            "Epoch 590/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.4019 - accuracy: 0.8642\n",
            "Epoch 590: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3985 - accuracy: 0.8652 - val_loss: 0.8216 - val_accuracy: 0.8262\n",
            "Epoch 591/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.4354 - accuracy: 0.8483\n",
            "Epoch 591: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4323 - accuracy: 0.8495 - val_loss: 0.9030 - val_accuracy: 0.7878\n",
            "Epoch 592/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3773 - accuracy: 0.8657\n",
            "Epoch 592: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4012 - accuracy: 0.8603 - val_loss: 1.0110 - val_accuracy: 0.7558\n",
            "Epoch 593/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3567 - accuracy: 0.8794\n",
            "Epoch 593: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3561 - accuracy: 0.8796 - val_loss: 0.8812 - val_accuracy: 0.8003\n",
            "Epoch 594/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.5735 - accuracy: 0.8382\n",
            "Epoch 594: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.5751 - accuracy: 0.8364 - val_loss: 1.1130 - val_accuracy: 0.7314\n",
            "Epoch 595/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3548 - accuracy: 0.8723\n",
            "Epoch 595: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3547 - accuracy: 0.8723 - val_loss: 0.8285 - val_accuracy: 0.8172\n",
            "Epoch 596/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2186 - accuracy: 0.9231\n",
            "Epoch 596: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2191 - accuracy: 0.9229 - val_loss: 0.8093 - val_accuracy: 0.8150\n",
            "Epoch 597/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2959 - accuracy: 0.8934\n",
            "Epoch 597: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.2956 - accuracy: 0.8936 - val_loss: 0.8173 - val_accuracy: 0.8201\n",
            "Epoch 598/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2011 - accuracy: 0.9289\n",
            "Epoch 598: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.2011 - accuracy: 0.9289 - val_loss: 0.7696 - val_accuracy: 0.8291\n",
            "Epoch 599/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2554 - accuracy: 0.9057\n",
            "Epoch 599: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.2544 - accuracy: 0.9059 - val_loss: 0.8312 - val_accuracy: 0.8143\n",
            "Epoch 600/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2602 - accuracy: 0.9062\n",
            "Epoch 600: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.2597 - accuracy: 0.9062 - val_loss: 0.7930 - val_accuracy: 0.8233\n",
            "Epoch 601/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2359 - accuracy: 0.9123\n",
            "Epoch 601: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2380 - accuracy: 0.9117 - val_loss: 1.0319 - val_accuracy: 0.7660\n",
            "Epoch 602/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.4814 - accuracy: 0.8334\n",
            "Epoch 602: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4738 - accuracy: 0.8353 - val_loss: 0.9417 - val_accuracy: 0.7862\n",
            "Epoch 603/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3132 - accuracy: 0.8860\n",
            "Epoch 603: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3136 - accuracy: 0.8858 - val_loss: 0.9600 - val_accuracy: 0.8012\n",
            "Epoch 604/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2902 - accuracy: 0.8934\n",
            "Epoch 604: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2895 - accuracy: 0.8936 - val_loss: 0.8357 - val_accuracy: 0.8147\n",
            "Epoch 605/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3337 - accuracy: 0.8786\n",
            "Epoch 605: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3301 - accuracy: 0.8796 - val_loss: 0.8276 - val_accuracy: 0.8195\n",
            "Epoch 606/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2251 - accuracy: 0.9176\n",
            "Epoch 606: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2290 - accuracy: 0.9162 - val_loss: 0.8484 - val_accuracy: 0.8070\n",
            "Epoch 607/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2501 - accuracy: 0.9048\n",
            "Epoch 607: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2506 - accuracy: 0.9047 - val_loss: 0.8029 - val_accuracy: 0.8252\n",
            "Epoch 608/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3475 - accuracy: 0.8779\n",
            "Epoch 608: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3464 - accuracy: 0.8785 - val_loss: 0.9817 - val_accuracy: 0.7628\n",
            "Epoch 609/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3527 - accuracy: 0.8729\n",
            "Epoch 609: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3531 - accuracy: 0.8728 - val_loss: 0.8503 - val_accuracy: 0.8092\n",
            "Epoch 610/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2377 - accuracy: 0.9108\n",
            "Epoch 610: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2378 - accuracy: 0.9106 - val_loss: 0.8592 - val_accuracy: 0.8051\n",
            "Epoch 611/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3338 - accuracy: 0.8865\n",
            "Epoch 611: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3264 - accuracy: 0.8891 - val_loss: 0.7875 - val_accuracy: 0.8223\n",
            "Epoch 612/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3962 - accuracy: 0.8690\n",
            "Epoch 612: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3943 - accuracy: 0.8696 - val_loss: 0.8201 - val_accuracy: 0.8195\n",
            "Epoch 613/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2170 - accuracy: 0.9196\n",
            "Epoch 613: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2172 - accuracy: 0.9196 - val_loss: 0.8195 - val_accuracy: 0.8262\n",
            "Epoch 614/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2146 - accuracy: 0.9210\n",
            "Epoch 614: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.2135 - accuracy: 0.9210 - val_loss: 0.7816 - val_accuracy: 0.8281\n",
            "Epoch 615/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2100 - accuracy: 0.9228\n",
            "Epoch 615: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.2111 - accuracy: 0.9221 - val_loss: 0.9066 - val_accuracy: 0.7987\n",
            "Epoch 616/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.5894 - accuracy: 0.8079\n",
            "Epoch 616: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.5878 - accuracy: 0.8075 - val_loss: 1.1040 - val_accuracy: 0.7471\n",
            "Epoch 617/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2690 - accuracy: 0.9008\n",
            "Epoch 617: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.2681 - accuracy: 0.9011 - val_loss: 0.7968 - val_accuracy: 0.8188\n",
            "Epoch 618/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3485 - accuracy: 0.8791\n",
            "Epoch 618: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3489 - accuracy: 0.8790 - val_loss: 0.9627 - val_accuracy: 0.7766\n",
            "Epoch 619/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2793 - accuracy: 0.8988\n",
            "Epoch 619: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2793 - accuracy: 0.8988 - val_loss: 1.4232 - val_accuracy: 0.7029\n",
            "Epoch 620/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.5564 - accuracy: 0.8189\n",
            "Epoch 620: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.5471 - accuracy: 0.8221 - val_loss: 1.0626 - val_accuracy: 0.7513\n",
            "Epoch 621/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2201 - accuracy: 0.9180\n",
            "Epoch 621: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2203 - accuracy: 0.9179 - val_loss: 0.8564 - val_accuracy: 0.8022\n",
            "Epoch 622/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2745 - accuracy: 0.9000\n",
            "Epoch 622: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2745 - accuracy: 0.9000 - val_loss: 0.8995 - val_accuracy: 0.7996\n",
            "Epoch 623/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2251 - accuracy: 0.9199\n",
            "Epoch 623: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2275 - accuracy: 0.9185 - val_loss: 0.8432 - val_accuracy: 0.8169\n",
            "Epoch 624/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2252 - accuracy: 0.9159\n",
            "Epoch 624: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2252 - accuracy: 0.9160 - val_loss: 0.9033 - val_accuracy: 0.7945\n",
            "Epoch 625/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2321 - accuracy: 0.9154\n",
            "Epoch 625: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2320 - accuracy: 0.9155 - val_loss: 0.7771 - val_accuracy: 0.8335\n",
            "Epoch 626/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3235 - accuracy: 0.8882\n",
            "Epoch 626: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3378 - accuracy: 0.8852 - val_loss: 1.3803 - val_accuracy: 0.6991\n",
            "Epoch 627/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3236 - accuracy: 0.8841\n",
            "Epoch 627: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3188 - accuracy: 0.8856 - val_loss: 0.8684 - val_accuracy: 0.8207\n",
            "Epoch 628/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2893 - accuracy: 0.8926\n",
            "Epoch 628: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2893 - accuracy: 0.8926 - val_loss: 0.9027 - val_accuracy: 0.7980\n",
            "Epoch 629/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2553 - accuracy: 0.9072\n",
            "Epoch 629: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2547 - accuracy: 0.9080 - val_loss: 0.8816 - val_accuracy: 0.8086\n",
            "Epoch 630/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3368 - accuracy: 0.8826\n",
            "Epoch 630: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3344 - accuracy: 0.8836 - val_loss: 0.8449 - val_accuracy: 0.8207\n",
            "Epoch 631/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2165 - accuracy: 0.9199\n",
            "Epoch 631: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.2166 - accuracy: 0.9194 - val_loss: 0.9768 - val_accuracy: 0.7807\n",
            "Epoch 632/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2479 - accuracy: 0.9094\n",
            "Epoch 632: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.2487 - accuracy: 0.9089 - val_loss: 0.9298 - val_accuracy: 0.7929\n",
            "Epoch 633/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.5877 - accuracy: 0.8160\n",
            "Epoch 633: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.6182 - accuracy: 0.8103 - val_loss: 1.5370 - val_accuracy: 0.6674\n",
            "Epoch 634/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3879 - accuracy: 0.8610\n",
            "Epoch 634: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.3788 - accuracy: 0.8647 - val_loss: 0.8088 - val_accuracy: 0.8265\n",
            "Epoch 635/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2521 - accuracy: 0.9085\n",
            "Epoch 635: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2521 - accuracy: 0.9085 - val_loss: 0.8553 - val_accuracy: 0.8070\n",
            "Epoch 636/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2631 - accuracy: 0.9046\n",
            "Epoch 636: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2659 - accuracy: 0.9038 - val_loss: 0.9297 - val_accuracy: 0.7875\n",
            "Epoch 637/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3329 - accuracy: 0.8799\n",
            "Epoch 637: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3293 - accuracy: 0.8812 - val_loss: 0.8188 - val_accuracy: 0.8220\n",
            "Epoch 638/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2333 - accuracy: 0.9164\n",
            "Epoch 638: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2352 - accuracy: 0.9157 - val_loss: 0.8783 - val_accuracy: 0.8223\n",
            "Epoch 639/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2457 - accuracy: 0.9068\n",
            "Epoch 639: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2456 - accuracy: 0.9069 - val_loss: 0.8150 - val_accuracy: 0.8233\n",
            "Epoch 640/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.4283 - accuracy: 0.8657\n",
            "Epoch 640: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4294 - accuracy: 0.8645 - val_loss: 1.0173 - val_accuracy: 0.7647\n",
            "Epoch 641/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3102 - accuracy: 0.8884\n",
            "Epoch 641: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3118 - accuracy: 0.8875 - val_loss: 0.9553 - val_accuracy: 0.7810\n",
            "Epoch 642/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2953 - accuracy: 0.8925\n",
            "Epoch 642: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2952 - accuracy: 0.8920 - val_loss: 0.7935 - val_accuracy: 0.8284\n",
            "Epoch 643/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.6341 - accuracy: 0.8272\n",
            "Epoch 643: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.6479 - accuracy: 0.8211 - val_loss: 1.3685 - val_accuracy: 0.6924\n",
            "Epoch 644/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.3792 - accuracy: 0.8645\n",
            "Epoch 644: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3700 - accuracy: 0.8669 - val_loss: 0.9272 - val_accuracy: 0.7868\n",
            "Epoch 645/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.6062 - accuracy: 0.8374\n",
            "Epoch 645: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.6112 - accuracy: 0.8355 - val_loss: 1.2077 - val_accuracy: 0.7241\n",
            "Epoch 646/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8636\n",
            "Epoch 646: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3849 - accuracy: 0.8638 - val_loss: 0.8134 - val_accuracy: 0.8191\n",
            "Epoch 647/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2082 - accuracy: 0.9244\n",
            "Epoch 647: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2080 - accuracy: 0.9245 - val_loss: 0.8003 - val_accuracy: 0.8223\n",
            "Epoch 648/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1803 - accuracy: 0.9356\n",
            "Epoch 648: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.1794 - accuracy: 0.9358 - val_loss: 0.7740 - val_accuracy: 0.8339\n",
            "Epoch 649/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1818 - accuracy: 0.9359\n",
            "Epoch 649: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.1825 - accuracy: 0.9357 - val_loss: 0.8603 - val_accuracy: 0.8179\n",
            "Epoch 650/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2198 - accuracy: 0.9164\n",
            "Epoch 650: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.2252 - accuracy: 0.9144 - val_loss: 0.9636 - val_accuracy: 0.7891\n",
            "Epoch 651/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.7294 - accuracy: 0.7870\n",
            "Epoch 651: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.7262 - accuracy: 0.7879 - val_loss: 0.8965 - val_accuracy: 0.7945\n",
            "Epoch 652/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2196 - accuracy: 0.9202\n",
            "Epoch 652: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2199 - accuracy: 0.9201 - val_loss: 0.8797 - val_accuracy: 0.8131\n",
            "Epoch 653/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2145 - accuracy: 0.9211\n",
            "Epoch 653: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2115 - accuracy: 0.9229 - val_loss: 0.8101 - val_accuracy: 0.8211\n",
            "Epoch 654/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2013 - accuracy: 0.9260\n",
            "Epoch 654: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2008 - accuracy: 0.9261 - val_loss: 0.9896 - val_accuracy: 0.7801\n",
            "Epoch 655/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2251 - accuracy: 0.9139\n",
            "Epoch 655: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2249 - accuracy: 0.9141 - val_loss: 0.8314 - val_accuracy: 0.8188\n",
            "Epoch 656/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2277 - accuracy: 0.9166\n",
            "Epoch 656: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2293 - accuracy: 0.9157 - val_loss: 0.9727 - val_accuracy: 0.7913\n",
            "Epoch 657/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.4858 - accuracy: 0.8651\n",
            "Epoch 657: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4938 - accuracy: 0.8623 - val_loss: 1.2062 - val_accuracy: 0.7138\n",
            "Epoch 658/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.4183 - accuracy: 0.8566\n",
            "Epoch 658: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.4179 - accuracy: 0.8568 - val_loss: 1.1669 - val_accuracy: 0.7286\n",
            "Epoch 659/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3454 - accuracy: 0.8718\n",
            "Epoch 659: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3442 - accuracy: 0.8724 - val_loss: 0.9243 - val_accuracy: 0.7932\n",
            "Epoch 660/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2979 - accuracy: 0.8920\n",
            "Epoch 660: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2954 - accuracy: 0.8927 - val_loss: 0.8220 - val_accuracy: 0.8207\n",
            "Epoch 661/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2820 - accuracy: 0.8964\n",
            "Epoch 661: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2808 - accuracy: 0.8968 - val_loss: 0.8532 - val_accuracy: 0.8108\n",
            "Epoch 662/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3565 - accuracy: 0.8729\n",
            "Epoch 662: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3462 - accuracy: 0.8765 - val_loss: 0.8585 - val_accuracy: 0.8057\n",
            "Epoch 663/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2306 - accuracy: 0.9162\n",
            "Epoch 663: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2307 - accuracy: 0.9161 - val_loss: 0.8249 - val_accuracy: 0.8223\n",
            "Epoch 664/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1916 - accuracy: 0.9307\n",
            "Epoch 664: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1928 - accuracy: 0.9301 - val_loss: 0.7731 - val_accuracy: 0.8303\n",
            "Epoch 665/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2974 - accuracy: 0.8915\n",
            "Epoch 665: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.2952 - accuracy: 0.8923 - val_loss: 0.8182 - val_accuracy: 0.8198\n",
            "Epoch 666/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2076 - accuracy: 0.9212\n",
            "Epoch 666: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.2081 - accuracy: 0.9209 - val_loss: 0.8443 - val_accuracy: 0.8147\n",
            "Epoch 667/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2389 - accuracy: 0.9068\n",
            "Epoch 667: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.2419 - accuracy: 0.9060 - val_loss: 1.0403 - val_accuracy: 0.7801\n",
            "Epoch 668/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2989 - accuracy: 0.8908\n",
            "Epoch 668: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.2997 - accuracy: 0.8904 - val_loss: 0.9958 - val_accuracy: 0.7756\n",
            "Epoch 669/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3200 - accuracy: 0.8852\n",
            "Epoch 669: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3286 - accuracy: 0.8820 - val_loss: 0.9610 - val_accuracy: 0.7942\n",
            "Epoch 670/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2601 - accuracy: 0.9052\n",
            "Epoch 670: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2589 - accuracy: 0.9053 - val_loss: 0.8270 - val_accuracy: 0.8214\n",
            "Epoch 671/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2082 - accuracy: 0.9248\n",
            "Epoch 671: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2084 - accuracy: 0.9245 - val_loss: 0.8965 - val_accuracy: 0.8019\n",
            "Epoch 672/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2170 - accuracy: 0.9199\n",
            "Epoch 672: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2175 - accuracy: 0.9198 - val_loss: 0.9178 - val_accuracy: 0.8006\n",
            "Epoch 673/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.7225 - accuracy: 0.7950\n",
            "Epoch 673: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.7096 - accuracy: 0.7976 - val_loss: 1.0924 - val_accuracy: 0.7631\n",
            "Epoch 674/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2783 - accuracy: 0.9016\n",
            "Epoch 674: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2731 - accuracy: 0.9028 - val_loss: 0.9671 - val_accuracy: 0.7884\n",
            "Epoch 675/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1779 - accuracy: 0.9360\n",
            "Epoch 675: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1772 - accuracy: 0.9364 - val_loss: 0.8227 - val_accuracy: 0.8268\n",
            "Epoch 676/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2871 - accuracy: 0.8962\n",
            "Epoch 676: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2871 - accuracy: 0.8962 - val_loss: 0.9847 - val_accuracy: 0.7766\n",
            "Epoch 677/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.4820 - accuracy: 0.8412\n",
            "Epoch 677: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.4845 - accuracy: 0.8400 - val_loss: 1.0609 - val_accuracy: 0.7564\n",
            "Epoch 678/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2413 - accuracy: 0.9110\n",
            "Epoch 678: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2435 - accuracy: 0.9096 - val_loss: 0.8913 - val_accuracy: 0.8015\n",
            "Epoch 679/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3170 - accuracy: 0.8877\n",
            "Epoch 679: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3319 - accuracy: 0.8835 - val_loss: 0.8514 - val_accuracy: 0.8134\n",
            "Epoch 680/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3085 - accuracy: 0.8886\n",
            "Epoch 680: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2992 - accuracy: 0.8921 - val_loss: 0.7873 - val_accuracy: 0.8355\n",
            "Epoch 681/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1895 - accuracy: 0.9296\n",
            "Epoch 681: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.1917 - accuracy: 0.9288 - val_loss: 0.8818 - val_accuracy: 0.8233\n",
            "Epoch 682/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2421 - accuracy: 0.9102\n",
            "Epoch 682: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.2421 - accuracy: 0.9101 - val_loss: 0.9439 - val_accuracy: 0.7999\n",
            "Epoch 683/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2666 - accuracy: 0.9105\n",
            "Epoch 683: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.3140 - accuracy: 0.9035 - val_loss: 1.4224 - val_accuracy: 0.7033\n",
            "Epoch 684/700\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.4053 - accuracy: 0.8673\n",
            "Epoch 684: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.4035 - accuracy: 0.8679 - val_loss: 0.8550 - val_accuracy: 0.8025\n",
            "Epoch 685/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1745 - accuracy: 0.9381\n",
            "Epoch 685: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.1771 - accuracy: 0.9368 - val_loss: 0.8237 - val_accuracy: 0.8259\n",
            "Epoch 686/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3439 - accuracy: 0.8838\n",
            "Epoch 686: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3387 - accuracy: 0.8857 - val_loss: 0.8733 - val_accuracy: 0.8067\n",
            "Epoch 687/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1983 - accuracy: 0.9259\n",
            "Epoch 687: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1967 - accuracy: 0.9268 - val_loss: 0.8194 - val_accuracy: 0.8252\n",
            "Epoch 688/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1605 - accuracy: 0.9420\n",
            "Epoch 688: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1631 - accuracy: 0.9411 - val_loss: 0.8605 - val_accuracy: 0.8127\n",
            "Epoch 689/700\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2239 - accuracy: 0.9166\n",
            "Epoch 689: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2226 - accuracy: 0.9169 - val_loss: 0.8493 - val_accuracy: 0.8169\n",
            "Epoch 690/700\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3798 - accuracy: 0.8702\n",
            "Epoch 690: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3798 - accuracy: 0.8702 - val_loss: 0.8025 - val_accuracy: 0.8307\n",
            "Epoch 691/700\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2408 - accuracy: 0.9081\n",
            "Epoch 691: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2368 - accuracy: 0.9100 - val_loss: 0.9176 - val_accuracy: 0.7999\n",
            "Epoch 692/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2438 - accuracy: 0.9104\n",
            "Epoch 692: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2437 - accuracy: 0.9107 - val_loss: 1.1209 - val_accuracy: 0.7570\n",
            "Epoch 693/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.4326 - accuracy: 0.8526\n",
            "Epoch 693: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4388 - accuracy: 0.8512 - val_loss: 1.0322 - val_accuracy: 0.7609\n",
            "Epoch 694/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3226 - accuracy: 0.8869\n",
            "Epoch 694: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3241 - accuracy: 0.8873 - val_loss: 1.0966 - val_accuracy: 0.7574\n",
            "Epoch 695/700\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2897 - accuracy: 0.8930\n",
            "Epoch 695: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2873 - accuracy: 0.8944 - val_loss: 0.8214 - val_accuracy: 0.8243\n",
            "Epoch 696/700\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2461 - accuracy: 0.9083\n",
            "Epoch 696: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2503 - accuracy: 0.9077 - val_loss: 0.8385 - val_accuracy: 0.8239\n",
            "Epoch 697/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2056 - accuracy: 0.9249\n",
            "Epoch 697: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2046 - accuracy: 0.9253 - val_loss: 0.8982 - val_accuracy: 0.8060\n",
            "Epoch 698/700\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2172 - accuracy: 0.9175\n",
            "Epoch 698: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2150 - accuracy: 0.9182 - val_loss: 0.8589 - val_accuracy: 0.8239\n",
            "Epoch 699/700\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2154 - accuracy: 0.9178\n",
            "Epoch 699: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.2189 - accuracy: 0.9165 - val_loss: 1.0025 - val_accuracy: 0.7862\n",
            "Epoch 700/700\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2986 - accuracy: 0.8942\n",
            "Epoch 700: val_accuracy did not improve from 0.83803\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.2976 - accuracy: 0.8944 - val_loss: 0.9544 - val_accuracy: 0.7935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# try another model with difrent unit numbers 33"
      ],
      "metadata": {
        "id": "_50zlCQuhMIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 174\n",
        "\n",
        "model = Sequential()\n",
        "model.add(GRU(33, input_shape=(1, 543)))\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "filepath       = \"/content/asl1/Adam4/cp-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint     = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history2 = model.fit(X_train, y_train_encoded, validation_data=(X_test, y_test_encoded), epochs=2000, batch_size=128,callbacks=callbacks_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jX0YFffn5zg",
        "outputId": "0914beef-415b-4981-e937-085deab45815"
      },
      "execution_count": 44,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_12 (GRU)                (None, 33)                57222     \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 256)               8704      \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 174)               44718     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 110644 (432.20 KB)\n",
            "Trainable params: 110644 (432.20 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 5.0900 - accuracy: 0.0130\n",
            "Epoch 1: val_accuracy improved from -inf to 0.02241, saving model to /content/asl1/Adam4/cp-01-0.02.hdf5\n",
            "98/98 [==============================] - 3s 10ms/step - loss: 5.0828 - accuracy: 0.0135 - val_loss: 4.9268 - val_accuracy: 0.0224\n",
            "Epoch 2/2000\n",
            "33/98 [=========>....................] - ETA: 0s - loss: 4.8929 - accuracy: 0.0199"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 751/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.3733 - accuracy: 0.8688\n",
            "Epoch 751: val_accuracy did not improve from 0.82843\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3707 - accuracy: 0.8700 - val_loss: 0.7777 - val_accuracy: 0.8236\n",
            "Epoch 752/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3143 - accuracy: 0.8941\n",
            "Epoch 752: val_accuracy did not improve from 0.82843\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3143 - accuracy: 0.8940 - val_loss: 0.8679 - val_accuracy: 0.7910\n",
            "Epoch 753/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3459 - accuracy: 0.8792\n",
            "Epoch 753: val_accuracy did not improve from 0.82843\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3438 - accuracy: 0.8801 - val_loss: 0.8087 - val_accuracy: 0.8063\n",
            "Epoch 754/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3139 - accuracy: 0.8892\n",
            "Epoch 754: val_accuracy did not improve from 0.82843\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3142 - accuracy: 0.8892 - val_loss: 0.8618 - val_accuracy: 0.8015\n",
            "Epoch 755/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2952 - accuracy: 0.8948\n",
            "Epoch 755: val_accuracy did not improve from 0.82843\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2969 - accuracy: 0.8943 - val_loss: 0.8409 - val_accuracy: 0.8070\n",
            "Epoch 756/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.3077 - accuracy: 0.8918\n",
            "Epoch 756: val_accuracy did not improve from 0.82843\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3124 - accuracy: 0.8900 - val_loss: 0.8703 - val_accuracy: 0.8060\n",
            "Epoch 757/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2921 - accuracy: 0.8991\n",
            "Epoch 757: val_accuracy did not improve from 0.82843\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2918 - accuracy: 0.8992 - val_loss: 0.8275 - val_accuracy: 0.8124\n",
            "Epoch 758/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.3138 - accuracy: 0.8875\n",
            "Epoch 758: val_accuracy did not improve from 0.82843\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3151 - accuracy: 0.8874 - val_loss: 0.7901 - val_accuracy: 0.8211\n",
            "Epoch 759/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3176 - accuracy: 0.8881\n",
            "Epoch 759: val_accuracy did not improve from 0.82843\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3177 - accuracy: 0.8876 - val_loss: 0.9110 - val_accuracy: 0.7859\n",
            "Epoch 760/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3427 - accuracy: 0.8765\n",
            "Epoch 760: val_accuracy did not improve from 0.82843\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3427 - accuracy: 0.8768 - val_loss: 0.9789 - val_accuracy: 0.7734\n",
            "Epoch 761/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3316 - accuracy: 0.8831\n",
            "Epoch 761: val_accuracy did not improve from 0.82843\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3329 - accuracy: 0.8826 - val_loss: 0.9334 - val_accuracy: 0.7836\n",
            "Epoch 762/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.3744 - accuracy: 0.8683\n",
            "Epoch 762: val_accuracy did not improve from 0.82843\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3681 - accuracy: 0.8705 - val_loss: 0.8239 - val_accuracy: 0.8147\n",
            "Epoch 763/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2856 - accuracy: 0.9014\n",
            "Epoch 763: val_accuracy did not improve from 0.82843\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2853 - accuracy: 0.9014 - val_loss: 0.9039 - val_accuracy: 0.7894\n",
            "Epoch 764/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.6818 - accuracy: 0.8040\n",
            "Epoch 764: val_accuracy did not improve from 0.82843\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.6897 - accuracy: 0.8021 - val_loss: 1.3603 - val_accuracy: 0.7125\n",
            "Epoch 765/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.4521 - accuracy: 0.8468\n",
            "Epoch 765: val_accuracy did not improve from 0.82843\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.4469 - accuracy: 0.8485 - val_loss: 0.8198 - val_accuracy: 0.8131\n",
            "Epoch 766/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2712 - accuracy: 0.9084\n",
            "Epoch 766: val_accuracy did not improve from 0.82843\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2704 - accuracy: 0.9087 - val_loss: 0.7874 - val_accuracy: 0.8204\n",
            "Epoch 767/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2785 - accuracy: 0.9068\n",
            "Epoch 767: val_accuracy did not improve from 0.82843\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2805 - accuracy: 0.9060 - val_loss: 0.8795 - val_accuracy: 0.7967\n",
            "Epoch 768/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3079 - accuracy: 0.8932\n",
            "Epoch 768: val_accuracy did not improve from 0.82843\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3079 - accuracy: 0.8932 - val_loss: 0.8301 - val_accuracy: 0.8121\n",
            "Epoch 769/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2914 - accuracy: 0.9003\n",
            "Epoch 769: val_accuracy did not improve from 0.82843\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2877 - accuracy: 0.9014 - val_loss: 0.8174 - val_accuracy: 0.8172\n",
            "Epoch 770/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2665 - accuracy: 0.9100\n",
            "Epoch 770: val_accuracy did not improve from 0.82843\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2660 - accuracy: 0.9097 - val_loss: 0.8529 - val_accuracy: 0.8124\n",
            "Epoch 771/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2814 - accuracy: 0.9037\n",
            "Epoch 771: val_accuracy did not improve from 0.82843\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2825 - accuracy: 0.9040 - val_loss: 0.8818 - val_accuracy: 0.7996\n",
            "Epoch 772/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3140 - accuracy: 0.8924\n",
            "Epoch 772: val_accuracy improved from 0.82843 to 0.83227, saving model to /content/asl1/Adam4/cp-772-0.83.hdf5\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3140 - accuracy: 0.8924 - val_loss: 0.7900 - val_accuracy: 0.8323\n",
            "Epoch 773/2000\n",
            "88/98 [=========================>....] - ETA: 0s - loss: 0.3400 - accuracy: 0.8810\n",
            "Epoch 773: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3462 - accuracy: 0.8784 - val_loss: 1.1835 - val_accuracy: 0.7346\n",
            "Epoch 774/2000\n",
            "88/98 [=========================>....] - ETA: 0s - loss: 0.3229 - accuracy: 0.8886\n",
            "Epoch 774: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3215 - accuracy: 0.8900 - val_loss: 0.8292 - val_accuracy: 0.8153\n",
            "Epoch 775/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3594 - accuracy: 0.8737\n",
            "Epoch 775: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3628 - accuracy: 0.8725 - val_loss: 0.9303 - val_accuracy: 0.7929\n",
            "Epoch 776/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3094 - accuracy: 0.8916\n",
            "Epoch 776: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3139 - accuracy: 0.8902 - val_loss: 0.9850 - val_accuracy: 0.7666\n",
            "Epoch 777/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3767 - accuracy: 0.8708\n",
            "Epoch 777: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3763 - accuracy: 0.8712 - val_loss: 0.8261 - val_accuracy: 0.8124\n",
            "Epoch 778/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.6067 - accuracy: 0.8177\n",
            "Epoch 778: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.6045 - accuracy: 0.8182 - val_loss: 0.8326 - val_accuracy: 0.8147\n",
            "Epoch 779/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2775 - accuracy: 0.9085\n",
            "Epoch 779: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2760 - accuracy: 0.9093 - val_loss: 0.8467 - val_accuracy: 0.8127\n",
            "Epoch 780/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2833 - accuracy: 0.9028\n",
            "Epoch 780: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2830 - accuracy: 0.9028 - val_loss: 0.7823 - val_accuracy: 0.8268\n",
            "Epoch 781/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2785 - accuracy: 0.9039\n",
            "Epoch 781: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2806 - accuracy: 0.9029 - val_loss: 0.8609 - val_accuracy: 0.8089\n",
            "Epoch 782/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3656 - accuracy: 0.8714\n",
            "Epoch 782: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3614 - accuracy: 0.8724 - val_loss: 0.9298 - val_accuracy: 0.7836\n",
            "Epoch 783/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3049 - accuracy: 0.8935\n",
            "Epoch 783: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3054 - accuracy: 0.8932 - val_loss: 0.9807 - val_accuracy: 0.7746\n",
            "Epoch 784/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.5567 - accuracy: 0.8204\n",
            "Epoch 784: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.5481 - accuracy: 0.8231 - val_loss: 0.9345 - val_accuracy: 0.7814\n",
            "Epoch 785/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3088 - accuracy: 0.8912\n",
            "Epoch 785: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3088 - accuracy: 0.8912 - val_loss: 0.8667 - val_accuracy: 0.7980\n",
            "Epoch 786/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3058 - accuracy: 0.8968\n",
            "Epoch 786: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3058 - accuracy: 0.8968 - val_loss: 0.9783 - val_accuracy: 0.7746\n",
            "Epoch 787/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2919 - accuracy: 0.8999\n",
            "Epoch 787: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2921 - accuracy: 0.9000 - val_loss: 0.9422 - val_accuracy: 0.7862\n",
            "Epoch 788/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2776 - accuracy: 0.9034\n",
            "Epoch 788: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2770 - accuracy: 0.9038 - val_loss: 0.8189 - val_accuracy: 0.8268\n",
            "Epoch 789/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2841 - accuracy: 0.9029\n",
            "Epoch 789: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2861 - accuracy: 0.9024 - val_loss: 0.9739 - val_accuracy: 0.7810\n",
            "Epoch 790/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3224 - accuracy: 0.8882\n",
            "Epoch 790: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3222 - accuracy: 0.8881 - val_loss: 0.8530 - val_accuracy: 0.8089\n",
            "Epoch 791/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.4086 - accuracy: 0.8616\n",
            "Epoch 791: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.4093 - accuracy: 0.8612 - val_loss: 0.9156 - val_accuracy: 0.7958\n",
            "Epoch 792/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2780 - accuracy: 0.9057\n",
            "Epoch 792: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2778 - accuracy: 0.9059 - val_loss: 0.8036 - val_accuracy: 0.8239\n",
            "Epoch 793/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2795 - accuracy: 0.9033\n",
            "Epoch 793: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2792 - accuracy: 0.9033 - val_loss: 0.9073 - val_accuracy: 0.7961\n",
            "Epoch 794/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3046 - accuracy: 0.8913\n",
            "Epoch 794: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3052 - accuracy: 0.8908 - val_loss: 0.8507 - val_accuracy: 0.8092\n",
            "Epoch 795/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.4127 - accuracy: 0.8571\n",
            "Epoch 795: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4161 - accuracy: 0.8561 - val_loss: 1.1670 - val_accuracy: 0.7353\n",
            "Epoch 796/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.4673 - accuracy: 0.8414\n",
            "Epoch 796: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4649 - accuracy: 0.8419 - val_loss: 0.8578 - val_accuracy: 0.8118\n",
            "Epoch 797/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.2653 - accuracy: 0.9088\n",
            "Epoch 797: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2669 - accuracy: 0.9086 - val_loss: 0.9627 - val_accuracy: 0.7740\n",
            "Epoch 798/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.2922 - accuracy: 0.9009\n",
            "Epoch 798: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2938 - accuracy: 0.9003 - val_loss: 0.7981 - val_accuracy: 0.8259\n",
            "Epoch 799/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2692 - accuracy: 0.9068\n",
            "Epoch 799: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2698 - accuracy: 0.9069 - val_loss: 0.8839 - val_accuracy: 0.8009\n",
            "Epoch 800/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.5028 - accuracy: 0.8389\n",
            "Epoch 800: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.5084 - accuracy: 0.8379 - val_loss: 1.0491 - val_accuracy: 0.7538\n",
            "Epoch 801/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.3970 - accuracy: 0.8641\n",
            "Epoch 801: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3870 - accuracy: 0.8672 - val_loss: 0.8548 - val_accuracy: 0.8019\n",
            "Epoch 802/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2722 - accuracy: 0.9039\n",
            "Epoch 802: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2729 - accuracy: 0.9039 - val_loss: 0.8084 - val_accuracy: 0.8239\n",
            "Epoch 803/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2769 - accuracy: 0.9032\n",
            "Epoch 803: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2784 - accuracy: 0.9029 - val_loss: 0.8265 - val_accuracy: 0.8137\n",
            "Epoch 804/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3113 - accuracy: 0.8904\n",
            "Epoch 804: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3134 - accuracy: 0.8898 - val_loss: 0.8822 - val_accuracy: 0.8063\n",
            "Epoch 805/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2982 - accuracy: 0.8975\n",
            "Epoch 805: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2967 - accuracy: 0.8976 - val_loss: 0.8245 - val_accuracy: 0.8092\n",
            "Epoch 806/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2658 - accuracy: 0.9091\n",
            "Epoch 806: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2660 - accuracy: 0.9089 - val_loss: 0.8919 - val_accuracy: 0.7951\n",
            "Epoch 807/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2855 - accuracy: 0.9027\n",
            "Epoch 807: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2838 - accuracy: 0.9028 - val_loss: 0.9307 - val_accuracy: 0.7875\n",
            "Epoch 808/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.4938 - accuracy: 0.8347\n",
            "Epoch 808: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.4938 - accuracy: 0.8347 - val_loss: 0.9250 - val_accuracy: 0.7868\n",
            "Epoch 809/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3050 - accuracy: 0.8951\n",
            "Epoch 809: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3046 - accuracy: 0.8952 - val_loss: 0.8925 - val_accuracy: 0.8025\n",
            "Epoch 810/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2892 - accuracy: 0.8993\n",
            "Epoch 810: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2890 - accuracy: 0.8997 - val_loss: 0.8124 - val_accuracy: 0.8169\n",
            "Epoch 811/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3089 - accuracy: 0.8920\n",
            "Epoch 811: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3089 - accuracy: 0.8920 - val_loss: 0.8139 - val_accuracy: 0.8140\n",
            "Epoch 812/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3345 - accuracy: 0.8826\n",
            "Epoch 812: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3384 - accuracy: 0.8811 - val_loss: 1.0741 - val_accuracy: 0.7561\n",
            "Epoch 813/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.5226 - accuracy: 0.8273\n",
            "Epoch 813: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.5745 - accuracy: 0.8190 - val_loss: 1.2838 - val_accuracy: 0.7369\n",
            "Epoch 814/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.5194 - accuracy: 0.8460\n",
            "Epoch 814: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.5100 - accuracy: 0.8480 - val_loss: 0.8307 - val_accuracy: 0.8095\n",
            "Epoch 815/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2580 - accuracy: 0.9127\n",
            "Epoch 815: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2580 - accuracy: 0.9127 - val_loss: 0.8291 - val_accuracy: 0.8169\n",
            "Epoch 816/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.2610 - accuracy: 0.9115\n",
            "Epoch 816: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2633 - accuracy: 0.9112 - val_loss: 0.8574 - val_accuracy: 0.7999\n",
            "Epoch 817/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2631 - accuracy: 0.9095\n",
            "Epoch 817: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2627 - accuracy: 0.9095 - val_loss: 0.8834 - val_accuracy: 0.7999\n",
            "Epoch 818/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2745 - accuracy: 0.9032\n",
            "Epoch 818: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2743 - accuracy: 0.9036 - val_loss: 0.8033 - val_accuracy: 0.8230\n",
            "Epoch 819/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2728 - accuracy: 0.9051\n",
            "Epoch 819: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2727 - accuracy: 0.9050 - val_loss: 0.8254 - val_accuracy: 0.8195\n",
            "Epoch 820/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2772 - accuracy: 0.9046\n",
            "Epoch 820: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2774 - accuracy: 0.9047 - val_loss: 0.9262 - val_accuracy: 0.7955\n",
            "Epoch 821/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3073 - accuracy: 0.8913\n",
            "Epoch 821: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3049 - accuracy: 0.8924 - val_loss: 0.9210 - val_accuracy: 0.7958\n",
            "Epoch 822/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.4344 - accuracy: 0.8583\n",
            "Epoch 822: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.4326 - accuracy: 0.8591 - val_loss: 0.8217 - val_accuracy: 0.8227\n",
            "Epoch 823/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2819 - accuracy: 0.9034\n",
            "Epoch 823: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2854 - accuracy: 0.9028 - val_loss: 0.8999 - val_accuracy: 0.7878\n",
            "Epoch 824/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2936 - accuracy: 0.8990\n",
            "Epoch 824: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2928 - accuracy: 0.8992 - val_loss: 0.8153 - val_accuracy: 0.8246\n",
            "Epoch 825/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2867 - accuracy: 0.9018\n",
            "Epoch 825: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2880 - accuracy: 0.9006 - val_loss: 0.9523 - val_accuracy: 0.7923\n",
            "Epoch 826/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2947 - accuracy: 0.8970\n",
            "Epoch 826: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2962 - accuracy: 0.8965 - val_loss: 0.9118 - val_accuracy: 0.7919\n",
            "Epoch 827/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3649 - accuracy: 0.8740\n",
            "Epoch 827: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3656 - accuracy: 0.8738 - val_loss: 0.9701 - val_accuracy: 0.7871\n",
            "Epoch 828/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3179 - accuracy: 0.8905\n",
            "Epoch 828: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3232 - accuracy: 0.8883 - val_loss: 0.8477 - val_accuracy: 0.8073\n",
            "Epoch 829/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3287 - accuracy: 0.8852\n",
            "Epoch 829: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3228 - accuracy: 0.8876 - val_loss: 0.7941 - val_accuracy: 0.8281\n",
            "Epoch 830/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3013 - accuracy: 0.8956\n",
            "Epoch 830: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3002 - accuracy: 0.8961 - val_loss: 0.8184 - val_accuracy: 0.8271\n",
            "Epoch 831/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3218 - accuracy: 0.8871\n",
            "Epoch 831: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3296 - accuracy: 0.8848 - val_loss: 1.0011 - val_accuracy: 0.7827\n",
            "Epoch 832/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3736 - accuracy: 0.8725\n",
            "Epoch 832: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3652 - accuracy: 0.8757 - val_loss: 0.8469 - val_accuracy: 0.8127\n",
            "Epoch 833/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.3461 - accuracy: 0.8766\n",
            "Epoch 833: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3507 - accuracy: 0.8741 - val_loss: 1.0014 - val_accuracy: 0.7743\n",
            "Epoch 834/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2919 - accuracy: 0.9007\n",
            "Epoch 834: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2898 - accuracy: 0.9012 - val_loss: 0.8282 - val_accuracy: 0.8118\n",
            "Epoch 835/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2705 - accuracy: 0.9057\n",
            "Epoch 835: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2705 - accuracy: 0.9057 - val_loss: 1.0571 - val_accuracy: 0.7567\n",
            "Epoch 836/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3019 - accuracy: 0.8920\n",
            "Epoch 836: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3057 - accuracy: 0.8909 - val_loss: 0.9054 - val_accuracy: 0.7974\n",
            "Epoch 837/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2726 - accuracy: 0.9051\n",
            "Epoch 837: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2718 - accuracy: 0.9057 - val_loss: 0.8035 - val_accuracy: 0.8271\n",
            "Epoch 838/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3890 - accuracy: 0.8673\n",
            "Epoch 838: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3823 - accuracy: 0.8692 - val_loss: 0.8502 - val_accuracy: 0.8121\n",
            "Epoch 839/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2879 - accuracy: 0.8980\n",
            "Epoch 839: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2860 - accuracy: 0.8986 - val_loss: 0.8177 - val_accuracy: 0.8220\n",
            "Epoch 840/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3882 - accuracy: 0.8639\n",
            "Epoch 840: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3888 - accuracy: 0.8641 - val_loss: 0.9261 - val_accuracy: 0.7894\n",
            "Epoch 841/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2809 - accuracy: 0.9032\n",
            "Epoch 841: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2816 - accuracy: 0.9028 - val_loss: 0.8863 - val_accuracy: 0.8083\n",
            "Epoch 842/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2739 - accuracy: 0.9051\n",
            "Epoch 842: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2739 - accuracy: 0.9053 - val_loss: 0.8834 - val_accuracy: 0.8015\n",
            "Epoch 843/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3254 - accuracy: 0.8835\n",
            "Epoch 843: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3252 - accuracy: 0.8835 - val_loss: 1.0719 - val_accuracy: 0.7673\n",
            "Epoch 844/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2850 - accuracy: 0.8992\n",
            "Epoch 844: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2849 - accuracy: 0.8992 - val_loss: 0.8994 - val_accuracy: 0.8019\n",
            "Epoch 845/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3258 - accuracy: 0.8860\n",
            "Epoch 845: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3229 - accuracy: 0.8875 - val_loss: 0.8604 - val_accuracy: 0.8073\n",
            "Epoch 846/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2772 - accuracy: 0.9046\n",
            "Epoch 846: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2763 - accuracy: 0.9048 - val_loss: 0.8177 - val_accuracy: 0.8220\n",
            "Epoch 847/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2773 - accuracy: 0.9012\n",
            "Epoch 847: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2765 - accuracy: 0.9014 - val_loss: 0.8654 - val_accuracy: 0.8092\n",
            "Epoch 848/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2707 - accuracy: 0.9085\n",
            "Epoch 848: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2707 - accuracy: 0.9085 - val_loss: 1.2624 - val_accuracy: 0.7337\n",
            "Epoch 849/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 1.0372 - accuracy: 0.7663\n",
            "Epoch 849: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.0026 - accuracy: 0.7709 - val_loss: 0.9701 - val_accuracy: 0.7881\n",
            "Epoch 850/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3031 - accuracy: 0.8935\n",
            "Epoch 850: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3031 - accuracy: 0.8935 - val_loss: 0.8151 - val_accuracy: 0.8169\n",
            "Epoch 851/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2454 - accuracy: 0.9190\n",
            "Epoch 851: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2458 - accuracy: 0.9186 - val_loss: 0.8406 - val_accuracy: 0.8121\n",
            "Epoch 852/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2499 - accuracy: 0.9156\n",
            "Epoch 852: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2484 - accuracy: 0.9165 - val_loss: 0.8080 - val_accuracy: 0.8297\n",
            "Epoch 853/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2628 - accuracy: 0.9100\n",
            "Epoch 853: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2675 - accuracy: 0.9082 - val_loss: 0.8555 - val_accuracy: 0.8031\n",
            "Epoch 854/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2714 - accuracy: 0.9044\n",
            "Epoch 854: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2702 - accuracy: 0.9048 - val_loss: 0.8992 - val_accuracy: 0.7990\n",
            "Epoch 855/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2745 - accuracy: 0.9028\n",
            "Epoch 855: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2737 - accuracy: 0.9030 - val_loss: 0.9384 - val_accuracy: 0.7878\n",
            "Epoch 856/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2835 - accuracy: 0.8991\n",
            "Epoch 856: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2834 - accuracy: 0.8990 - val_loss: 0.8502 - val_accuracy: 0.8108\n",
            "Epoch 857/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2665 - accuracy: 0.9066\n",
            "Epoch 857: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2657 - accuracy: 0.9067 - val_loss: 0.8248 - val_accuracy: 0.8239\n",
            "Epoch 858/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2798 - accuracy: 0.9030\n",
            "Epoch 858: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2828 - accuracy: 0.9017 - val_loss: 0.9783 - val_accuracy: 0.7798\n",
            "Epoch 859/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.4139 - accuracy: 0.8601\n",
            "Epoch 859: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4163 - accuracy: 0.8596 - val_loss: 1.0916 - val_accuracy: 0.7506\n",
            "Epoch 860/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3181 - accuracy: 0.8869\n",
            "Epoch 860: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3168 - accuracy: 0.8872 - val_loss: 0.8159 - val_accuracy: 0.8233\n",
            "Epoch 861/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2749 - accuracy: 0.9056\n",
            "Epoch 861: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2749 - accuracy: 0.9056 - val_loss: 0.8322 - val_accuracy: 0.8198\n",
            "Epoch 862/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2711 - accuracy: 0.9021\n",
            "Epoch 862: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2700 - accuracy: 0.9027 - val_loss: 1.0966 - val_accuracy: 0.7580\n",
            "Epoch 863/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3061 - accuracy: 0.8917\n",
            "Epoch 863: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3052 - accuracy: 0.8920 - val_loss: 0.9852 - val_accuracy: 0.7871\n",
            "Epoch 864/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2993 - accuracy: 0.8945\n",
            "Epoch 864: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3022 - accuracy: 0.8935 - val_loss: 0.8368 - val_accuracy: 0.8076\n",
            "Epoch 865/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3293 - accuracy: 0.8821\n",
            "Epoch 865: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3333 - accuracy: 0.8814 - val_loss: 1.4038 - val_accuracy: 0.7090\n",
            "Epoch 866/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3461 - accuracy: 0.8777\n",
            "Epoch 866: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3427 - accuracy: 0.8788 - val_loss: 0.8791 - val_accuracy: 0.8028\n",
            "Epoch 867/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3225 - accuracy: 0.8863\n",
            "Epoch 867: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3181 - accuracy: 0.8876 - val_loss: 0.9108 - val_accuracy: 0.7983\n",
            "Epoch 868/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2738 - accuracy: 0.9040\n",
            "Epoch 868: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2707 - accuracy: 0.9052 - val_loss: 0.8915 - val_accuracy: 0.7980\n",
            "Epoch 869/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3120 - accuracy: 0.8894\n",
            "Epoch 869: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3119 - accuracy: 0.8896 - val_loss: 0.9283 - val_accuracy: 0.7932\n",
            "Epoch 870/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2672 - accuracy: 0.9099\n",
            "Epoch 870: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2773 - accuracy: 0.9065 - val_loss: 1.5628 - val_accuracy: 0.6764\n",
            "Epoch 871/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8657\n",
            "Epoch 871: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3848 - accuracy: 0.8659 - val_loss: 0.9063 - val_accuracy: 0.7942\n",
            "Epoch 872/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2938 - accuracy: 0.8963\n",
            "Epoch 872: val_accuracy did not improve from 0.83227\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2947 - accuracy: 0.8956 - val_loss: 0.9073 - val_accuracy: 0.7999\n",
            "Epoch 873/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2560 - accuracy: 0.9116\n",
            "Epoch 873: val_accuracy improved from 0.83227 to 0.83323, saving model to /content/asl1/Adam4/cp-873-0.83.hdf5\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.2560 - accuracy: 0.9116 - val_loss: 0.8193 - val_accuracy: 0.8332\n",
            "Epoch 874/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3300 - accuracy: 0.8857\n",
            "Epoch 874: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3312 - accuracy: 0.8847 - val_loss: 1.3883 - val_accuracy: 0.7026\n",
            "Epoch 875/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3001 - accuracy: 0.8961\n",
            "Epoch 875: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2964 - accuracy: 0.8973 - val_loss: 0.8204 - val_accuracy: 0.8303\n",
            "Epoch 876/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2612 - accuracy: 0.9091\n",
            "Epoch 876: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2605 - accuracy: 0.9095 - val_loss: 0.8452 - val_accuracy: 0.8195\n",
            "Epoch 877/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2962 - accuracy: 0.8949\n",
            "Epoch 877: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2951 - accuracy: 0.8949 - val_loss: 0.8744 - val_accuracy: 0.8041\n",
            "Epoch 878/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2708 - accuracy: 0.9054\n",
            "Epoch 878: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2704 - accuracy: 0.9056 - val_loss: 0.8538 - val_accuracy: 0.8243\n",
            "Epoch 879/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3038 - accuracy: 0.8911\n",
            "Epoch 879: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3079 - accuracy: 0.8897 - val_loss: 0.9138 - val_accuracy: 0.7961\n",
            "Epoch 880/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3772 - accuracy: 0.8752\n",
            "Epoch 880: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3760 - accuracy: 0.8752 - val_loss: 0.8313 - val_accuracy: 0.8204\n",
            "Epoch 881/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3438 - accuracy: 0.8764\n",
            "Epoch 881: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3443 - accuracy: 0.8762 - val_loss: 0.8915 - val_accuracy: 0.8137\n",
            "Epoch 882/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.2771 - accuracy: 0.9027\n",
            "Epoch 882: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2747 - accuracy: 0.9033 - val_loss: 0.8516 - val_accuracy: 0.8153\n",
            "Epoch 883/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2595 - accuracy: 0.9095\n",
            "Epoch 883: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2596 - accuracy: 0.9097 - val_loss: 0.8852 - val_accuracy: 0.8073\n",
            "Epoch 884/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2944 - accuracy: 0.8937\n",
            "Epoch 884: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2944 - accuracy: 0.8936 - val_loss: 0.9676 - val_accuracy: 0.7868\n",
            "Epoch 885/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3163 - accuracy: 0.8875\n",
            "Epoch 885: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3151 - accuracy: 0.8882 - val_loss: 0.8011 - val_accuracy: 0.8284\n",
            "Epoch 886/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2528 - accuracy: 0.9120\n",
            "Epoch 886: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2533 - accuracy: 0.9121 - val_loss: 0.8894 - val_accuracy: 0.8035\n",
            "Epoch 887/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3198 - accuracy: 0.8860\n",
            "Epoch 887: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3209 - accuracy: 0.8856 - val_loss: 1.0342 - val_accuracy: 0.7615\n",
            "Epoch 888/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3538 - accuracy: 0.8757\n",
            "Epoch 888: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3538 - accuracy: 0.8757 - val_loss: 0.8486 - val_accuracy: 0.8140\n",
            "Epoch 889/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2916 - accuracy: 0.8942\n",
            "Epoch 889: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2976 - accuracy: 0.8928 - val_loss: 0.9690 - val_accuracy: 0.7791\n",
            "Epoch 890/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2987 - accuracy: 0.8897\n",
            "Epoch 890: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2975 - accuracy: 0.8900 - val_loss: 0.9330 - val_accuracy: 0.7878\n",
            "Epoch 891/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2959 - accuracy: 0.8971\n",
            "Epoch 891: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2969 - accuracy: 0.8964 - val_loss: 0.8562 - val_accuracy: 0.8137\n",
            "Epoch 892/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2806 - accuracy: 0.9024\n",
            "Epoch 892: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2767 - accuracy: 0.9036 - val_loss: 0.9330 - val_accuracy: 0.7974\n",
            "Epoch 893/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2828 - accuracy: 0.9000\n",
            "Epoch 893: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2846 - accuracy: 0.8983 - val_loss: 0.8486 - val_accuracy: 0.8166\n",
            "Epoch 894/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3469 - accuracy: 0.8781\n",
            "Epoch 894: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3460 - accuracy: 0.8786 - val_loss: 1.0289 - val_accuracy: 0.7711\n",
            "Epoch 895/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3119 - accuracy: 0.8919\n",
            "Epoch 895: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3116 - accuracy: 0.8920 - val_loss: 1.0047 - val_accuracy: 0.7791\n",
            "Epoch 896/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2934 - accuracy: 0.8945\n",
            "Epoch 896: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2945 - accuracy: 0.8940 - val_loss: 0.8328 - val_accuracy: 0.8255\n",
            "Epoch 897/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2658 - accuracy: 0.9073\n",
            "Epoch 897: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2657 - accuracy: 0.9072 - val_loss: 0.8273 - val_accuracy: 0.8217\n",
            "Epoch 898/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2824 - accuracy: 0.9020\n",
            "Epoch 898: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2805 - accuracy: 0.9023 - val_loss: 0.8267 - val_accuracy: 0.8217\n",
            "Epoch 899/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3296 - accuracy: 0.8848\n",
            "Epoch 899: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3251 - accuracy: 0.8862 - val_loss: 0.8431 - val_accuracy: 0.8185\n",
            "Epoch 900/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2689 - accuracy: 0.9059\n",
            "Epoch 900: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2698 - accuracy: 0.9052 - val_loss: 0.8572 - val_accuracy: 0.8185\n",
            "Epoch 901/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2998 - accuracy: 0.8935\n",
            "Epoch 901: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2991 - accuracy: 0.8937 - val_loss: 0.8751 - val_accuracy: 0.8137\n",
            "Epoch 902/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2556 - accuracy: 0.9100\n",
            "Epoch 902: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2548 - accuracy: 0.9101 - val_loss: 0.8677 - val_accuracy: 0.8175\n",
            "Epoch 903/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2691 - accuracy: 0.9073\n",
            "Epoch 903: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2796 - accuracy: 0.9031 - val_loss: 0.8547 - val_accuracy: 0.8127\n",
            "Epoch 904/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3058 - accuracy: 0.8900\n",
            "Epoch 904: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3055 - accuracy: 0.8904 - val_loss: 0.9249 - val_accuracy: 0.7939\n",
            "Epoch 905/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.4990 - accuracy: 0.8478\n",
            "Epoch 905: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.4997 - accuracy: 0.8466 - val_loss: 1.0459 - val_accuracy: 0.7705\n",
            "Epoch 906/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.4125 - accuracy: 0.8606\n",
            "Epoch 906: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4126 - accuracy: 0.8605 - val_loss: 0.9007 - val_accuracy: 0.7996\n",
            "Epoch 907/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2986 - accuracy: 0.8944\n",
            "Epoch 907: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2982 - accuracy: 0.8946 - val_loss: 0.9656 - val_accuracy: 0.7862\n",
            "Epoch 908/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3389 - accuracy: 0.8806\n",
            "Epoch 908: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3323 - accuracy: 0.8834 - val_loss: 0.8487 - val_accuracy: 0.8207\n",
            "Epoch 909/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2645 - accuracy: 0.9062\n",
            "Epoch 909: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2632 - accuracy: 0.9066 - val_loss: 0.9011 - val_accuracy: 0.8070\n",
            "Epoch 910/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2469 - accuracy: 0.9148\n",
            "Epoch 910: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2498 - accuracy: 0.9142 - val_loss: 0.9067 - val_accuracy: 0.7983\n",
            "Epoch 911/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2518 - accuracy: 0.9115\n",
            "Epoch 911: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2541 - accuracy: 0.9105 - val_loss: 0.8732 - val_accuracy: 0.8115\n",
            "Epoch 912/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2909 - accuracy: 0.8970\n",
            "Epoch 912: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2909 - accuracy: 0.8970 - val_loss: 0.9378 - val_accuracy: 0.7974\n",
            "Epoch 913/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.3096 - accuracy: 0.8889\n",
            "Epoch 913: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3049 - accuracy: 0.8906 - val_loss: 0.8455 - val_accuracy: 0.8124\n",
            "Epoch 914/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3046 - accuracy: 0.8890\n",
            "Epoch 914: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3045 - accuracy: 0.8889 - val_loss: 0.8739 - val_accuracy: 0.8070\n",
            "Epoch 915/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2750 - accuracy: 0.9021\n",
            "Epoch 915: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2773 - accuracy: 0.9008 - val_loss: 0.9428 - val_accuracy: 0.7967\n",
            "Epoch 916/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.4326 - accuracy: 0.8541\n",
            "Epoch 916: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4293 - accuracy: 0.8551 - val_loss: 0.9222 - val_accuracy: 0.8057\n",
            "Epoch 917/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2626 - accuracy: 0.9093\n",
            "Epoch 917: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2626 - accuracy: 0.9093 - val_loss: 0.8426 - val_accuracy: 0.8153\n",
            "Epoch 918/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2550 - accuracy: 0.9120\n",
            "Epoch 918: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2538 - accuracy: 0.9121 - val_loss: 0.8413 - val_accuracy: 0.8230\n",
            "Epoch 919/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2465 - accuracy: 0.9153\n",
            "Epoch 919: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2483 - accuracy: 0.9150 - val_loss: 0.8497 - val_accuracy: 0.8153\n",
            "Epoch 920/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2989 - accuracy: 0.8949\n",
            "Epoch 920: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2999 - accuracy: 0.8940 - val_loss: 0.9915 - val_accuracy: 0.7823\n",
            "Epoch 921/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3004 - accuracy: 0.8930\n",
            "Epoch 921: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3005 - accuracy: 0.8932 - val_loss: 0.8404 - val_accuracy: 0.8249\n",
            "Epoch 922/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3310 - accuracy: 0.8802\n",
            "Epoch 922: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3307 - accuracy: 0.8807 - val_loss: 1.1067 - val_accuracy: 0.7506\n",
            "Epoch 923/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2730 - accuracy: 0.9051\n",
            "Epoch 923: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2719 - accuracy: 0.9055 - val_loss: 0.8813 - val_accuracy: 0.8076\n",
            "Epoch 924/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3254 - accuracy: 0.8865\n",
            "Epoch 924: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3264 - accuracy: 0.8856 - val_loss: 1.0566 - val_accuracy: 0.7602\n",
            "Epoch 925/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3055 - accuracy: 0.8898\n",
            "Epoch 925: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3065 - accuracy: 0.8894 - val_loss: 1.1607 - val_accuracy: 0.7401\n",
            "Epoch 926/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.4147 - accuracy: 0.8561\n",
            "Epoch 926: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4132 - accuracy: 0.8563 - val_loss: 0.9649 - val_accuracy: 0.7939\n",
            "Epoch 927/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2904 - accuracy: 0.8984\n",
            "Epoch 927: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2893 - accuracy: 0.8983 - val_loss: 0.8410 - val_accuracy: 0.8108\n",
            "Epoch 928/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2431 - accuracy: 0.9159\n",
            "Epoch 928: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2443 - accuracy: 0.9161 - val_loss: 0.8139 - val_accuracy: 0.8201\n",
            "Epoch 929/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2390 - accuracy: 0.9156\n",
            "Epoch 929: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2408 - accuracy: 0.9149 - val_loss: 0.8445 - val_accuracy: 0.8214\n",
            "Epoch 930/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2646 - accuracy: 0.9056\n",
            "Epoch 930: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2665 - accuracy: 0.9052 - val_loss: 0.8744 - val_accuracy: 0.8121\n",
            "Epoch 931/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2526 - accuracy: 0.9099\n",
            "Epoch 931: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2527 - accuracy: 0.9100 - val_loss: 0.8864 - val_accuracy: 0.8012\n",
            "Epoch 932/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2848 - accuracy: 0.8972\n",
            "Epoch 932: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2848 - accuracy: 0.8972 - val_loss: 0.8694 - val_accuracy: 0.8031\n",
            "Epoch 933/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3763 - accuracy: 0.8650\n",
            "Epoch 933: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3764 - accuracy: 0.8649 - val_loss: 0.9474 - val_accuracy: 0.7859\n",
            "Epoch 934/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3599 - accuracy: 0.8723\n",
            "Epoch 934: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3597 - accuracy: 0.8727 - val_loss: 1.0153 - val_accuracy: 0.7762\n",
            "Epoch 935/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2867 - accuracy: 0.9005\n",
            "Epoch 935: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2825 - accuracy: 0.9021 - val_loss: 0.8242 - val_accuracy: 0.8249\n",
            "Epoch 936/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.3006 - accuracy: 0.8933\n",
            "Epoch 936: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2958 - accuracy: 0.8953 - val_loss: 1.0135 - val_accuracy: 0.7804\n",
            "Epoch 937/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3613 - accuracy: 0.8743\n",
            "Epoch 937: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3569 - accuracy: 0.8760 - val_loss: 0.8678 - val_accuracy: 0.8121\n",
            "Epoch 938/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.2610 - accuracy: 0.9076\n",
            "Epoch 938: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2618 - accuracy: 0.9069 - val_loss: 0.8933 - val_accuracy: 0.8095\n",
            "Epoch 939/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2493 - accuracy: 0.9118\n",
            "Epoch 939: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2475 - accuracy: 0.9127 - val_loss: 0.8583 - val_accuracy: 0.8169\n",
            "Epoch 940/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2308 - accuracy: 0.9197\n",
            "Epoch 940: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2308 - accuracy: 0.9197 - val_loss: 0.8316 - val_accuracy: 0.8332\n",
            "Epoch 941/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.2739 - accuracy: 0.9062\n",
            "Epoch 941: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3304 - accuracy: 0.8923 - val_loss: 1.6057 - val_accuracy: 0.6738\n",
            "Epoch 942/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.4619 - accuracy: 0.8448\n",
            "Epoch 942: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4619 - accuracy: 0.8448 - val_loss: 1.0357 - val_accuracy: 0.7692\n",
            "Epoch 943/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2765 - accuracy: 0.9073\n",
            "Epoch 943: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2761 - accuracy: 0.9077 - val_loss: 0.8150 - val_accuracy: 0.8230\n",
            "Epoch 944/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2502 - accuracy: 0.9126\n",
            "Epoch 944: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2509 - accuracy: 0.9120 - val_loss: 0.8429 - val_accuracy: 0.8214\n",
            "Epoch 945/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2529 - accuracy: 0.9120\n",
            "Epoch 945: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2565 - accuracy: 0.9105 - val_loss: 0.8839 - val_accuracy: 0.8057\n",
            "Epoch 946/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2782 - accuracy: 0.9022\n",
            "Epoch 946: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2776 - accuracy: 0.9021 - val_loss: 1.0311 - val_accuracy: 0.7817\n",
            "Epoch 947/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2885 - accuracy: 0.8964\n",
            "Epoch 947: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2890 - accuracy: 0.8960 - val_loss: 1.0715 - val_accuracy: 0.7618\n",
            "Epoch 948/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.4436 - accuracy: 0.8482\n",
            "Epoch 948: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.4431 - accuracy: 0.8484 - val_loss: 0.9153 - val_accuracy: 0.8012\n",
            "Epoch 949/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3453 - accuracy: 0.8800\n",
            "Epoch 949: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3401 - accuracy: 0.8815 - val_loss: 0.8955 - val_accuracy: 0.8108\n",
            "Epoch 950/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2329 - accuracy: 0.9199\n",
            "Epoch 950: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2298 - accuracy: 0.9209 - val_loss: 0.8333 - val_accuracy: 0.8201\n",
            "Epoch 951/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2339 - accuracy: 0.9189\n",
            "Epoch 951: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2368 - accuracy: 0.9178 - val_loss: 0.8683 - val_accuracy: 0.8099\n",
            "Epoch 952/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2368 - accuracy: 0.9196\n",
            "Epoch 952: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2368 - accuracy: 0.9197 - val_loss: 0.9166 - val_accuracy: 0.8057\n",
            "Epoch 953/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2409 - accuracy: 0.9166\n",
            "Epoch 953: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2406 - accuracy: 0.9165 - val_loss: 0.8575 - val_accuracy: 0.8124\n",
            "Epoch 954/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2869 - accuracy: 0.8994\n",
            "Epoch 954: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2928 - accuracy: 0.8970 - val_loss: 0.9703 - val_accuracy: 0.7967\n",
            "Epoch 955/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3041 - accuracy: 0.8899\n",
            "Epoch 955: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3050 - accuracy: 0.8898 - val_loss: 0.9939 - val_accuracy: 0.7862\n",
            "Epoch 956/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2544 - accuracy: 0.9096\n",
            "Epoch 956: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2567 - accuracy: 0.9089 - val_loss: 0.8117 - val_accuracy: 0.8303\n",
            "Epoch 957/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3308 - accuracy: 0.8821\n",
            "Epoch 957: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3276 - accuracy: 0.8837 - val_loss: 0.8231 - val_accuracy: 0.8278\n",
            "Epoch 958/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3572 - accuracy: 0.8800\n",
            "Epoch 958: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3536 - accuracy: 0.8809 - val_loss: 0.8711 - val_accuracy: 0.8172\n",
            "Epoch 959/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3792 - accuracy: 0.8734\n",
            "Epoch 959: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3744 - accuracy: 0.8745 - val_loss: 0.8603 - val_accuracy: 0.8102\n",
            "Epoch 960/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2423 - accuracy: 0.9134\n",
            "Epoch 960: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2438 - accuracy: 0.9123 - val_loss: 0.8467 - val_accuracy: 0.8175\n",
            "Epoch 961/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2392 - accuracy: 0.9171\n",
            "Epoch 961: val_accuracy did not improve from 0.83323\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2407 - accuracy: 0.9166 - val_loss: 0.8461 - val_accuracy: 0.8255\n",
            "Epoch 962/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2619 - accuracy: 0.9085\n",
            "Epoch 962: val_accuracy improved from 0.83323 to 0.84091, saving model to /content/asl1/Adam4/cp-962-0.84.hdf5\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2582 - accuracy: 0.9104 - val_loss: 0.8043 - val_accuracy: 0.8409\n",
            "Epoch 963/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2399 - accuracy: 0.9179\n",
            "Epoch 963: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2520 - accuracy: 0.9138 - val_loss: 1.1188 - val_accuracy: 0.7625\n",
            "Epoch 964/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2896 - accuracy: 0.8947\n",
            "Epoch 964: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2892 - accuracy: 0.8949 - val_loss: 0.8345 - val_accuracy: 0.8271\n",
            "Epoch 965/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.2766 - accuracy: 0.8988\n",
            "Epoch 965: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2792 - accuracy: 0.8986 - val_loss: 1.0355 - val_accuracy: 0.7711\n",
            "Epoch 966/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2745 - accuracy: 0.9011\n",
            "Epoch 966: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2712 - accuracy: 0.9025 - val_loss: 0.9228 - val_accuracy: 0.7996\n",
            "Epoch 967/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.4355 - accuracy: 0.8567\n",
            "Epoch 967: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.4324 - accuracy: 0.8572 - val_loss: 0.9574 - val_accuracy: 0.7948\n",
            "Epoch 968/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2716 - accuracy: 0.9025\n",
            "Epoch 968: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2715 - accuracy: 0.9024 - val_loss: 0.8698 - val_accuracy: 0.8131\n",
            "Epoch 969/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2846 - accuracy: 0.8989\n",
            "Epoch 969: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2826 - accuracy: 0.9000 - val_loss: 0.8597 - val_accuracy: 0.8204\n",
            "Epoch 970/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2709 - accuracy: 0.9042\n",
            "Epoch 970: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2708 - accuracy: 0.9043 - val_loss: 0.9273 - val_accuracy: 0.8054\n",
            "Epoch 971/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2488 - accuracy: 0.9123\n",
            "Epoch 971: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2512 - accuracy: 0.9109 - val_loss: 0.8242 - val_accuracy: 0.8262\n",
            "Epoch 972/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2579 - accuracy: 0.9110\n",
            "Epoch 972: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2558 - accuracy: 0.9125 - val_loss: 0.8762 - val_accuracy: 0.8182\n",
            "Epoch 973/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2344 - accuracy: 0.9176\n",
            "Epoch 973: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2328 - accuracy: 0.9185 - val_loss: 0.8631 - val_accuracy: 0.8156\n",
            "Epoch 974/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3003 - accuracy: 0.8936\n",
            "Epoch 974: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3028 - accuracy: 0.8933 - val_loss: 1.1610 - val_accuracy: 0.7644\n",
            "Epoch 975/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3942 - accuracy: 0.8608\n",
            "Epoch 975: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3986 - accuracy: 0.8597 - val_loss: 1.0976 - val_accuracy: 0.7548\n",
            "Epoch 976/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2814 - accuracy: 0.8999\n",
            "Epoch 976: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2809 - accuracy: 0.9001 - val_loss: 0.8634 - val_accuracy: 0.8153\n",
            "Epoch 977/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2352 - accuracy: 0.9171\n",
            "Epoch 977: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2366 - accuracy: 0.9168 - val_loss: 0.8257 - val_accuracy: 0.8284\n",
            "Epoch 978/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2635 - accuracy: 0.9057\n",
            "Epoch 978: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2616 - accuracy: 0.9062 - val_loss: 0.8607 - val_accuracy: 0.8191\n",
            "Epoch 979/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2278 - accuracy: 0.9183\n",
            "Epoch 979: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2280 - accuracy: 0.9185 - val_loss: 0.8419 - val_accuracy: 0.8255\n",
            "Epoch 980/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2863 - accuracy: 0.8968\n",
            "Epoch 980: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2874 - accuracy: 0.8963 - val_loss: 0.9243 - val_accuracy: 0.8035\n",
            "Epoch 981/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2791 - accuracy: 0.8978\n",
            "Epoch 981: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2799 - accuracy: 0.8980 - val_loss: 1.0190 - val_accuracy: 0.7785\n",
            "Epoch 982/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3681 - accuracy: 0.8679\n",
            "Epoch 982: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3684 - accuracy: 0.8677 - val_loss: 0.9994 - val_accuracy: 0.7769\n",
            "Epoch 983/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2669 - accuracy: 0.9075\n",
            "Epoch 983: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2656 - accuracy: 0.9077 - val_loss: 0.8080 - val_accuracy: 0.8348\n",
            "Epoch 984/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3464 - accuracy: 0.8844\n",
            "Epoch 984: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3598 - accuracy: 0.8800 - val_loss: 1.0749 - val_accuracy: 0.7689\n",
            "Epoch 985/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3454 - accuracy: 0.8784\n",
            "Epoch 985: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3444 - accuracy: 0.8788 - val_loss: 0.9108 - val_accuracy: 0.8092\n",
            "Epoch 986/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2446 - accuracy: 0.9155\n",
            "Epoch 986: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2446 - accuracy: 0.9153 - val_loss: 0.8796 - val_accuracy: 0.8134\n",
            "Epoch 987/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2630 - accuracy: 0.9065\n",
            "Epoch 987: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2638 - accuracy: 0.9063 - val_loss: 0.9172 - val_accuracy: 0.8012\n",
            "Epoch 988/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2874 - accuracy: 0.9004\n",
            "Epoch 988: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2936 - accuracy: 0.8984 - val_loss: 1.1690 - val_accuracy: 0.7433\n",
            "Epoch 989/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3934 - accuracy: 0.8684\n",
            "Epoch 989: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3934 - accuracy: 0.8684 - val_loss: 0.8636 - val_accuracy: 0.8175\n",
            "Epoch 990/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2424 - accuracy: 0.9152\n",
            "Epoch 990: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2424 - accuracy: 0.9152 - val_loss: 0.8388 - val_accuracy: 0.8287\n",
            "Epoch 991/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2467 - accuracy: 0.9161\n",
            "Epoch 991: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2481 - accuracy: 0.9149 - val_loss: 0.9812 - val_accuracy: 0.7830\n",
            "Epoch 992/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2640 - accuracy: 0.9080\n",
            "Epoch 992: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2635 - accuracy: 0.9081 - val_loss: 1.1878 - val_accuracy: 0.7474\n",
            "Epoch 993/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2445 - accuracy: 0.9159\n",
            "Epoch 993: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2443 - accuracy: 0.9161 - val_loss: 0.8664 - val_accuracy: 0.8252\n",
            "Epoch 994/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2469 - accuracy: 0.9117\n",
            "Epoch 994: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2463 - accuracy: 0.9121 - val_loss: 0.9247 - val_accuracy: 0.8009\n",
            "Epoch 995/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2716 - accuracy: 0.9015\n",
            "Epoch 995: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2696 - accuracy: 0.9023 - val_loss: 0.9028 - val_accuracy: 0.8073\n",
            "Epoch 996/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3105 - accuracy: 0.8892\n",
            "Epoch 996: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3089 - accuracy: 0.8900 - val_loss: 0.9270 - val_accuracy: 0.8025\n",
            "Epoch 997/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2936 - accuracy: 0.8967\n",
            "Epoch 997: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2949 - accuracy: 0.8963 - val_loss: 0.9769 - val_accuracy: 0.7932\n",
            "Epoch 998/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.3371 - accuracy: 0.8825\n",
            "Epoch 998: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3384 - accuracy: 0.8808 - val_loss: 0.9867 - val_accuracy: 0.7910\n",
            "Epoch 999/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2486 - accuracy: 0.9130\n",
            "Epoch 999: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2544 - accuracy: 0.9108 - val_loss: 1.0454 - val_accuracy: 0.7794\n",
            "Epoch 1000/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2990 - accuracy: 0.8917\n",
            "Epoch 1000: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2994 - accuracy: 0.8910 - val_loss: 0.8987 - val_accuracy: 0.8121\n",
            "Epoch 1001/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2731 - accuracy: 0.9049\n",
            "Epoch 1001: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2731 - accuracy: 0.9049 - val_loss: 0.8851 - val_accuracy: 0.8172\n",
            "Epoch 1002/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2453 - accuracy: 0.9132\n",
            "Epoch 1002: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2470 - accuracy: 0.9129 - val_loss: 1.0244 - val_accuracy: 0.7830\n",
            "Epoch 1003/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2745 - accuracy: 0.9023\n",
            "Epoch 1003: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2732 - accuracy: 0.9024 - val_loss: 0.8520 - val_accuracy: 0.8198\n",
            "Epoch 1004/2000\n",
            "88/98 [=========================>....] - ETA: 0s - loss: 0.4187 - accuracy: 0.8579\n",
            "Epoch 1004: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4074 - accuracy: 0.8604 - val_loss: 1.0256 - val_accuracy: 0.7766\n",
            "Epoch 1005/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2476 - accuracy: 0.9126\n",
            "Epoch 1005: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2476 - accuracy: 0.9128 - val_loss: 0.8603 - val_accuracy: 0.8303\n",
            "Epoch 1006/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2421 - accuracy: 0.9146\n",
            "Epoch 1006: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2425 - accuracy: 0.9144 - val_loss: 1.0224 - val_accuracy: 0.7762\n",
            "Epoch 1007/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2422 - accuracy: 0.9141\n",
            "Epoch 1007: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2433 - accuracy: 0.9137 - val_loss: 0.8143 - val_accuracy: 0.8307\n",
            "Epoch 1008/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2882 - accuracy: 0.8969\n",
            "Epoch 1008: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2873 - accuracy: 0.8976 - val_loss: 0.9368 - val_accuracy: 0.7993\n",
            "Epoch 1009/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3626 - accuracy: 0.8739\n",
            "Epoch 1009: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3613 - accuracy: 0.8742 - val_loss: 1.0734 - val_accuracy: 0.7711\n",
            "Epoch 1010/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3996 - accuracy: 0.8618\n",
            "Epoch 1010: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3889 - accuracy: 0.8659 - val_loss: 0.9620 - val_accuracy: 0.7974\n",
            "Epoch 1011/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2248 - accuracy: 0.9201\n",
            "Epoch 1011: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2259 - accuracy: 0.9198 - val_loss: 0.8432 - val_accuracy: 0.8319\n",
            "Epoch 1012/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2635 - accuracy: 0.9062\n",
            "Epoch 1012: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2633 - accuracy: 0.9062 - val_loss: 0.9130 - val_accuracy: 0.8089\n",
            "Epoch 1013/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2453 - accuracy: 0.9153\n",
            "Epoch 1013: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2453 - accuracy: 0.9153 - val_loss: 0.8873 - val_accuracy: 0.8175\n",
            "Epoch 1014/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2112 - accuracy: 0.9254\n",
            "Epoch 1014: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2128 - accuracy: 0.9250 - val_loss: 0.8790 - val_accuracy: 0.8220\n",
            "Epoch 1015/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2611 - accuracy: 0.9089\n",
            "Epoch 1015: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2610 - accuracy: 0.9089 - val_loss: 0.9329 - val_accuracy: 0.8063\n",
            "Epoch 1016/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.3300 - accuracy: 0.8876\n",
            "Epoch 1016: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3235 - accuracy: 0.8893 - val_loss: 0.9902 - val_accuracy: 0.7926\n",
            "Epoch 1017/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.2697 - accuracy: 0.9037\n",
            "Epoch 1017: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2747 - accuracy: 0.9016 - val_loss: 0.9135 - val_accuracy: 0.8022\n",
            "Epoch 1018/2000\n",
            "88/98 [=========================>....] - ETA: 0s - loss: 0.3217 - accuracy: 0.8872\n",
            "Epoch 1018: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3382 - accuracy: 0.8830 - val_loss: 0.9668 - val_accuracy: 0.8006\n",
            "Epoch 1019/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3223 - accuracy: 0.8830\n",
            "Epoch 1019: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3212 - accuracy: 0.8836 - val_loss: 0.9133 - val_accuracy: 0.8022\n",
            "Epoch 1020/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.2405 - accuracy: 0.9159\n",
            "Epoch 1020: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2472 - accuracy: 0.9136 - val_loss: 0.8218 - val_accuracy: 0.8291\n",
            "Epoch 1021/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2462 - accuracy: 0.9111\n",
            "Epoch 1021: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2453 - accuracy: 0.9119 - val_loss: 0.9158 - val_accuracy: 0.8031\n",
            "Epoch 1022/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2651 - accuracy: 0.9058\n",
            "Epoch 1022: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2674 - accuracy: 0.9044 - val_loss: 0.8598 - val_accuracy: 0.8236\n",
            "Epoch 1023/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.2241 - accuracy: 0.9199\n",
            "Epoch 1023: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2246 - accuracy: 0.9194 - val_loss: 0.8568 - val_accuracy: 0.8175\n",
            "Epoch 1024/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2866 - accuracy: 0.8965\n",
            "Epoch 1024: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2869 - accuracy: 0.8964 - val_loss: 1.1086 - val_accuracy: 0.7743\n",
            "Epoch 1025/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3905 - accuracy: 0.8664\n",
            "Epoch 1025: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3905 - accuracy: 0.8664 - val_loss: 0.8980 - val_accuracy: 0.8147\n",
            "Epoch 1026/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2472 - accuracy: 0.9130\n",
            "Epoch 1026: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2432 - accuracy: 0.9147 - val_loss: 0.8138 - val_accuracy: 0.8339\n",
            "Epoch 1027/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2279 - accuracy: 0.9229\n",
            "Epoch 1027: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2274 - accuracy: 0.9231 - val_loss: 0.8502 - val_accuracy: 0.8339\n",
            "Epoch 1028/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2362 - accuracy: 0.9140\n",
            "Epoch 1028: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2366 - accuracy: 0.9138 - val_loss: 0.9429 - val_accuracy: 0.8035\n",
            "Epoch 1029/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3280 - accuracy: 0.8899\n",
            "Epoch 1029: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3227 - accuracy: 0.8910 - val_loss: 0.8598 - val_accuracy: 0.8217\n",
            "Epoch 1030/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2301 - accuracy: 0.9203\n",
            "Epoch 1030: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2302 - accuracy: 0.9200 - val_loss: 0.8265 - val_accuracy: 0.8329\n",
            "Epoch 1031/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2869 - accuracy: 0.8984\n",
            "Epoch 1031: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2869 - accuracy: 0.8984 - val_loss: 1.0166 - val_accuracy: 0.7913\n",
            "Epoch 1032/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3520 - accuracy: 0.8812\n",
            "Epoch 1032: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3616 - accuracy: 0.8784 - val_loss: 0.8903 - val_accuracy: 0.8102\n",
            "Epoch 1033/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2845 - accuracy: 0.9006\n",
            "Epoch 1033: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2845 - accuracy: 0.9006 - val_loss: 0.8259 - val_accuracy: 0.8339\n",
            "Epoch 1034/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2284 - accuracy: 0.9179\n",
            "Epoch 1034: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2310 - accuracy: 0.9167 - val_loss: 0.9578 - val_accuracy: 0.7974\n",
            "Epoch 1035/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2282 - accuracy: 0.9220\n",
            "Epoch 1035: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2264 - accuracy: 0.9216 - val_loss: 0.9367 - val_accuracy: 0.8054\n",
            "Epoch 1036/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3298 - accuracy: 0.8840\n",
            "Epoch 1036: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3295 - accuracy: 0.8840 - val_loss: 0.9804 - val_accuracy: 0.7945\n",
            "Epoch 1037/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2646 - accuracy: 0.9057\n",
            "Epoch 1037: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2636 - accuracy: 0.9060 - val_loss: 0.9154 - val_accuracy: 0.7996\n",
            "Epoch 1038/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2561 - accuracy: 0.9089\n",
            "Epoch 1038: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2561 - accuracy: 0.9089 - val_loss: 1.0283 - val_accuracy: 0.7891\n",
            "Epoch 1039/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.4251 - accuracy: 0.8637\n",
            "Epoch 1039: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4374 - accuracy: 0.8608 - val_loss: 1.3210 - val_accuracy: 0.7375\n",
            "Epoch 1040/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3549 - accuracy: 0.8821\n",
            "Epoch 1040: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3528 - accuracy: 0.8826 - val_loss: 0.8675 - val_accuracy: 0.8233\n",
            "Epoch 1041/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2248 - accuracy: 0.9205\n",
            "Epoch 1041: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2223 - accuracy: 0.9219 - val_loss: 0.8248 - val_accuracy: 0.8262\n",
            "Epoch 1042/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2683 - accuracy: 0.9058\n",
            "Epoch 1042: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2681 - accuracy: 0.9060 - val_loss: 0.9713 - val_accuracy: 0.8038\n",
            "Epoch 1043/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2662 - accuracy: 0.9064\n",
            "Epoch 1043: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2739 - accuracy: 0.9038 - val_loss: 0.9443 - val_accuracy: 0.7958\n",
            "Epoch 1044/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2969 - accuracy: 0.8941\n",
            "Epoch 1044: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3007 - accuracy: 0.8932 - val_loss: 1.2675 - val_accuracy: 0.7500\n",
            "Epoch 1045/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2466 - accuracy: 0.9133\n",
            "Epoch 1045: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2469 - accuracy: 0.9129 - val_loss: 0.8349 - val_accuracy: 0.8307\n",
            "Epoch 1046/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2048 - accuracy: 0.9288\n",
            "Epoch 1046: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2051 - accuracy: 0.9288 - val_loss: 0.8582 - val_accuracy: 0.8198\n",
            "Epoch 1047/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2716 - accuracy: 0.9041\n",
            "Epoch 1047: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2724 - accuracy: 0.9038 - val_loss: 0.9348 - val_accuracy: 0.8060\n",
            "Epoch 1048/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2872 - accuracy: 0.8956\n",
            "Epoch 1048: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2854 - accuracy: 0.8965 - val_loss: 0.8448 - val_accuracy: 0.8214\n",
            "Epoch 1049/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2296 - accuracy: 0.9189\n",
            "Epoch 1049: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2345 - accuracy: 0.9176 - val_loss: 1.0709 - val_accuracy: 0.7794\n",
            "Epoch 1050/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3098 - accuracy: 0.8857\n",
            "Epoch 1050: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3101 - accuracy: 0.8856 - val_loss: 1.0118 - val_accuracy: 0.7814\n",
            "Epoch 1051/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2858 - accuracy: 0.8989\n",
            "Epoch 1051: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2898 - accuracy: 0.8968 - val_loss: 0.9433 - val_accuracy: 0.8035\n",
            "Epoch 1052/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3247 - accuracy: 0.8822\n",
            "Epoch 1052: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3237 - accuracy: 0.8828 - val_loss: 0.9218 - val_accuracy: 0.8057\n",
            "Epoch 1053/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2503 - accuracy: 0.9118\n",
            "Epoch 1053: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2493 - accuracy: 0.9125 - val_loss: 0.9023 - val_accuracy: 0.8150\n",
            "Epoch 1054/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2132 - accuracy: 0.9248\n",
            "Epoch 1054: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2138 - accuracy: 0.9244 - val_loss: 0.8503 - val_accuracy: 0.8233\n",
            "Epoch 1055/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2400 - accuracy: 0.9137\n",
            "Epoch 1055: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2401 - accuracy: 0.9136 - val_loss: 0.9831 - val_accuracy: 0.7900\n",
            "Epoch 1056/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2520 - accuracy: 0.9097\n",
            "Epoch 1056: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2530 - accuracy: 0.9095 - val_loss: 0.8581 - val_accuracy: 0.8278\n",
            "Epoch 1057/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2138 - accuracy: 0.9255\n",
            "Epoch 1057: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2138 - accuracy: 0.9257 - val_loss: 0.9809 - val_accuracy: 0.7967\n",
            "Epoch 1058/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2926 - accuracy: 0.8949\n",
            "Epoch 1058: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3019 - accuracy: 0.8918 - val_loss: 1.1103 - val_accuracy: 0.7727\n",
            "Epoch 1059/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3028 - accuracy: 0.8883\n",
            "Epoch 1059: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3025 - accuracy: 0.8882 - val_loss: 0.9328 - val_accuracy: 0.8060\n",
            "Epoch 1060/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2671 - accuracy: 0.9064\n",
            "Epoch 1060: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2671 - accuracy: 0.9064 - val_loss: 0.9869 - val_accuracy: 0.7916\n",
            "Epoch 1061/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.4099 - accuracy: 0.8641\n",
            "Epoch 1061: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.4099 - accuracy: 0.8641 - val_loss: 0.9807 - val_accuracy: 0.7948\n",
            "Epoch 1062/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2538 - accuracy: 0.9097\n",
            "Epoch 1062: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2531 - accuracy: 0.9103 - val_loss: 0.8968 - val_accuracy: 0.8150\n",
            "Epoch 1063/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2331 - accuracy: 0.9183\n",
            "Epoch 1063: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2334 - accuracy: 0.9181 - val_loss: 0.8178 - val_accuracy: 0.8367\n",
            "Epoch 1064/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2508 - accuracy: 0.9111\n",
            "Epoch 1064: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2513 - accuracy: 0.9107 - val_loss: 0.8982 - val_accuracy: 0.8169\n",
            "Epoch 1065/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2089 - accuracy: 0.9287\n",
            "Epoch 1065: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2097 - accuracy: 0.9285 - val_loss: 0.9736 - val_accuracy: 0.7990\n",
            "Epoch 1066/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2333 - accuracy: 0.9179\n",
            "Epoch 1066: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2331 - accuracy: 0.9177 - val_loss: 0.8384 - val_accuracy: 0.8223\n",
            "Epoch 1067/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2223 - accuracy: 0.9202\n",
            "Epoch 1067: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2219 - accuracy: 0.9202 - val_loss: 0.8887 - val_accuracy: 0.8188\n",
            "Epoch 1068/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2305 - accuracy: 0.9191\n",
            "Epoch 1068: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2325 - accuracy: 0.9182 - val_loss: 0.9385 - val_accuracy: 0.8143\n",
            "Epoch 1069/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2991 - accuracy: 0.8939\n",
            "Epoch 1069: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2953 - accuracy: 0.8956 - val_loss: 1.1289 - val_accuracy: 0.7705\n",
            "Epoch 1070/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3146 - accuracy: 0.8877\n",
            "Epoch 1070: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3146 - accuracy: 0.8876 - val_loss: 0.9140 - val_accuracy: 0.8211\n",
            "Epoch 1071/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2266 - accuracy: 0.9194\n",
            "Epoch 1071: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2266 - accuracy: 0.9194 - val_loss: 0.8432 - val_accuracy: 0.8291\n",
            "Epoch 1072/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2553 - accuracy: 0.9104\n",
            "Epoch 1072: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2553 - accuracy: 0.9104 - val_loss: 0.9990 - val_accuracy: 0.7910\n",
            "Epoch 1073/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3737 - accuracy: 0.8768\n",
            "Epoch 1073: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3737 - accuracy: 0.8770 - val_loss: 1.1496 - val_accuracy: 0.7522\n",
            "Epoch 1074/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.3176 - accuracy: 0.8890\n",
            "Epoch 1074: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3529 - accuracy: 0.8811 - val_loss: 1.1033 - val_accuracy: 0.7625\n",
            "Epoch 1075/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2816 - accuracy: 0.8977\n",
            "Epoch 1075: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2882 - accuracy: 0.8964 - val_loss: 1.0284 - val_accuracy: 0.7913\n",
            "Epoch 1076/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3158 - accuracy: 0.8887\n",
            "Epoch 1076: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3113 - accuracy: 0.8904 - val_loss: 0.9127 - val_accuracy: 0.8086\n",
            "Epoch 1077/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.2402 - accuracy: 0.9147\n",
            "Epoch 1077: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2490 - accuracy: 0.9125 - val_loss: 1.0499 - val_accuracy: 0.7718\n",
            "Epoch 1078/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2834 - accuracy: 0.8991\n",
            "Epoch 1078: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2831 - accuracy: 0.8986 - val_loss: 0.9763 - val_accuracy: 0.8089\n",
            "Epoch 1079/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2317 - accuracy: 0.9185\n",
            "Epoch 1079: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2321 - accuracy: 0.9184 - val_loss: 0.8766 - val_accuracy: 0.8198\n",
            "Epoch 1080/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2273 - accuracy: 0.9186\n",
            "Epoch 1080: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2276 - accuracy: 0.9185 - val_loss: 0.9649 - val_accuracy: 0.7961\n",
            "Epoch 1081/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2842 - accuracy: 0.9004\n",
            "Epoch 1081: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2869 - accuracy: 0.8995 - val_loss: 0.9733 - val_accuracy: 0.7980\n",
            "Epoch 1082/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3121 - accuracy: 0.8893\n",
            "Epoch 1082: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3120 - accuracy: 0.8895 - val_loss: 0.9218 - val_accuracy: 0.8121\n",
            "Epoch 1083/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2030 - accuracy: 0.9271\n",
            "Epoch 1083: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2030 - accuracy: 0.9271 - val_loss: 0.8396 - val_accuracy: 0.8355\n",
            "Epoch 1084/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2424 - accuracy: 0.9129\n",
            "Epoch 1084: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2430 - accuracy: 0.9128 - val_loss: 0.9818 - val_accuracy: 0.7894\n",
            "Epoch 1085/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.8534 - accuracy: 0.8046\n",
            "Epoch 1085: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.8138 - accuracy: 0.8114 - val_loss: 0.8825 - val_accuracy: 0.8182\n",
            "Epoch 1086/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2176 - accuracy: 0.9250\n",
            "Epoch 1086: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2172 - accuracy: 0.9249 - val_loss: 0.8843 - val_accuracy: 0.8099\n",
            "Epoch 1087/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2182 - accuracy: 0.9242\n",
            "Epoch 1087: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2158 - accuracy: 0.9251 - val_loss: 0.8562 - val_accuracy: 0.8227\n",
            "Epoch 1088/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2031 - accuracy: 0.9293\n",
            "Epoch 1088: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2023 - accuracy: 0.9297 - val_loss: 0.8337 - val_accuracy: 0.8287\n",
            "Epoch 1089/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2149 - accuracy: 0.9253\n",
            "Epoch 1089: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2149 - accuracy: 0.9253 - val_loss: 0.8241 - val_accuracy: 0.8380\n",
            "Epoch 1090/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1973 - accuracy: 0.9312\n",
            "Epoch 1090: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1972 - accuracy: 0.9313 - val_loss: 0.9396 - val_accuracy: 0.8063\n",
            "Epoch 1091/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2671 - accuracy: 0.9058\n",
            "Epoch 1091: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2690 - accuracy: 0.9047 - val_loss: 1.0759 - val_accuracy: 0.7666\n",
            "Epoch 1092/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2532 - accuracy: 0.9108\n",
            "Epoch 1092: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2527 - accuracy: 0.9112 - val_loss: 0.8511 - val_accuracy: 0.8326\n",
            "Epoch 1093/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2058 - accuracy: 0.9285\n",
            "Epoch 1093: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2066 - accuracy: 0.9279 - val_loss: 0.9035 - val_accuracy: 0.8169\n",
            "Epoch 1094/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2309 - accuracy: 0.9207\n",
            "Epoch 1094: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2306 - accuracy: 0.9206 - val_loss: 0.8532 - val_accuracy: 0.8255\n",
            "Epoch 1095/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3861 - accuracy: 0.8703\n",
            "Epoch 1095: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4064 - accuracy: 0.8648 - val_loss: 1.8548 - val_accuracy: 0.6501\n",
            "Epoch 1096/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2911 - accuracy: 0.8976\n",
            "Epoch 1096: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2896 - accuracy: 0.8983 - val_loss: 0.9111 - val_accuracy: 0.8153\n",
            "Epoch 1097/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2251 - accuracy: 0.9210\n",
            "Epoch 1097: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2244 - accuracy: 0.9213 - val_loss: 0.9029 - val_accuracy: 0.8182\n",
            "Epoch 1098/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2166 - accuracy: 0.9223\n",
            "Epoch 1098: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2199 - accuracy: 0.9207 - val_loss: 0.9663 - val_accuracy: 0.7974\n",
            "Epoch 1099/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2824 - accuracy: 0.8972\n",
            "Epoch 1099: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2824 - accuracy: 0.8972 - val_loss: 0.9399 - val_accuracy: 0.8038\n",
            "Epoch 1100/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2060 - accuracy: 0.9268\n",
            "Epoch 1100: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2060 - accuracy: 0.9268 - val_loss: 0.9065 - val_accuracy: 0.8147\n",
            "Epoch 1101/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2322 - accuracy: 0.9184\n",
            "Epoch 1101: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2326 - accuracy: 0.9181 - val_loss: 0.9942 - val_accuracy: 0.7971\n",
            "Epoch 1102/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2301 - accuracy: 0.9195\n",
            "Epoch 1102: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2307 - accuracy: 0.9192 - val_loss: 0.8931 - val_accuracy: 0.8220\n",
            "Epoch 1103/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2597 - accuracy: 0.9061\n",
            "Epoch 1103: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2604 - accuracy: 0.9056 - val_loss: 0.9858 - val_accuracy: 0.7974\n",
            "Epoch 1104/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3046 - accuracy: 0.8947\n",
            "Epoch 1104: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3049 - accuracy: 0.8945 - val_loss: 0.9826 - val_accuracy: 0.7964\n",
            "Epoch 1105/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2421 - accuracy: 0.9134\n",
            "Epoch 1105: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2428 - accuracy: 0.9126 - val_loss: 0.9441 - val_accuracy: 0.8015\n",
            "Epoch 1106/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2705 - accuracy: 0.9027\n",
            "Epoch 1106: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2711 - accuracy: 0.9028 - val_loss: 1.0223 - val_accuracy: 0.7999\n",
            "Epoch 1107/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2435 - accuracy: 0.9135\n",
            "Epoch 1107: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2433 - accuracy: 0.9135 - val_loss: 0.9598 - val_accuracy: 0.8060\n",
            "Epoch 1108/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2131 - accuracy: 0.9255\n",
            "Epoch 1108: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2117 - accuracy: 0.9260 - val_loss: 0.8541 - val_accuracy: 0.8252\n",
            "Epoch 1109/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2237 - accuracy: 0.9208\n",
            "Epoch 1109: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2273 - accuracy: 0.9195 - val_loss: 1.0398 - val_accuracy: 0.7836\n",
            "Epoch 1110/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2695 - accuracy: 0.9024\n",
            "Epoch 1110: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2731 - accuracy: 0.9007 - val_loss: 0.9139 - val_accuracy: 0.8188\n",
            "Epoch 1111/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2514 - accuracy: 0.9098\n",
            "Epoch 1111: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2515 - accuracy: 0.9097 - val_loss: 1.3789 - val_accuracy: 0.7266\n",
            "Epoch 1112/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.4423 - accuracy: 0.8538\n",
            "Epoch 1112: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.4331 - accuracy: 0.8572 - val_loss: 0.9088 - val_accuracy: 0.8195\n",
            "Epoch 1113/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1994 - accuracy: 0.9296\n",
            "Epoch 1113: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2000 - accuracy: 0.9297 - val_loss: 0.8980 - val_accuracy: 0.8147\n",
            "Epoch 1114/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2107 - accuracy: 0.9262\n",
            "Epoch 1114: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2118 - accuracy: 0.9249 - val_loss: 0.8773 - val_accuracy: 0.8271\n",
            "Epoch 1115/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2503 - accuracy: 0.9085\n",
            "Epoch 1115: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2505 - accuracy: 0.9084 - val_loss: 0.8674 - val_accuracy: 0.8236\n",
            "Epoch 1116/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2321 - accuracy: 0.9166\n",
            "Epoch 1116: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2321 - accuracy: 0.9166 - val_loss: 0.8951 - val_accuracy: 0.8233\n",
            "Epoch 1117/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2062 - accuracy: 0.9277\n",
            "Epoch 1117: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2062 - accuracy: 0.9277 - val_loss: 0.8965 - val_accuracy: 0.8118\n",
            "Epoch 1118/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2394 - accuracy: 0.9133\n",
            "Epoch 1118: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2372 - accuracy: 0.9136 - val_loss: 0.9086 - val_accuracy: 0.8153\n",
            "Epoch 1119/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2535 - accuracy: 0.9085\n",
            "Epoch 1119: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2535 - accuracy: 0.9085 - val_loss: 0.8959 - val_accuracy: 0.8207\n",
            "Epoch 1120/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2587 - accuracy: 0.9053\n",
            "Epoch 1120: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2581 - accuracy: 0.9055 - val_loss: 0.9056 - val_accuracy: 0.8089\n",
            "Epoch 1121/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2744 - accuracy: 0.8990\n",
            "Epoch 1121: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2811 - accuracy: 0.8972 - val_loss: 1.1099 - val_accuracy: 0.7657\n",
            "Epoch 1122/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2443 - accuracy: 0.9150\n",
            "Epoch 1122: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2443 - accuracy: 0.9149 - val_loss: 0.9134 - val_accuracy: 0.8172\n",
            "Epoch 1123/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2804 - accuracy: 0.8987\n",
            "Epoch 1123: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2806 - accuracy: 0.8990 - val_loss: 0.9243 - val_accuracy: 0.8067\n",
            "Epoch 1124/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2228 - accuracy: 0.9201\n",
            "Epoch 1124: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2236 - accuracy: 0.9201 - val_loss: 1.1055 - val_accuracy: 0.7673\n",
            "Epoch 1125/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2319 - accuracy: 0.9170\n",
            "Epoch 1125: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2302 - accuracy: 0.9173 - val_loss: 0.9435 - val_accuracy: 0.7999\n",
            "Epoch 1126/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2210 - accuracy: 0.9231\n",
            "Epoch 1126: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2210 - accuracy: 0.9231 - val_loss: 1.0742 - val_accuracy: 0.7705\n",
            "Epoch 1127/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2347 - accuracy: 0.9155\n",
            "Epoch 1127: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2351 - accuracy: 0.9154 - val_loss: 1.0733 - val_accuracy: 0.7740\n",
            "Epoch 1128/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2364 - accuracy: 0.9106\n",
            "Epoch 1128: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2362 - accuracy: 0.9108 - val_loss: 0.9335 - val_accuracy: 0.8137\n",
            "Epoch 1129/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2416 - accuracy: 0.9145\n",
            "Epoch 1129: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2415 - accuracy: 0.9146 - val_loss: 0.9031 - val_accuracy: 0.8246\n",
            "Epoch 1130/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2359 - accuracy: 0.9157\n",
            "Epoch 1130: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2359 - accuracy: 0.9157 - val_loss: 1.0522 - val_accuracy: 0.7814\n",
            "Epoch 1131/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2447 - accuracy: 0.9137\n",
            "Epoch 1131: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2444 - accuracy: 0.9140 - val_loss: 0.9275 - val_accuracy: 0.8156\n",
            "Epoch 1132/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3297 - accuracy: 0.8845\n",
            "Epoch 1132: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3297 - accuracy: 0.8845 - val_loss: 0.8746 - val_accuracy: 0.8236\n",
            "Epoch 1133/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2809 - accuracy: 0.8976\n",
            "Epoch 1133: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2785 - accuracy: 0.8987 - val_loss: 0.8672 - val_accuracy: 0.8271\n",
            "Epoch 1134/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2440 - accuracy: 0.9108\n",
            "Epoch 1134: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2493 - accuracy: 0.9096 - val_loss: 0.9044 - val_accuracy: 0.8201\n",
            "Epoch 1135/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.4343 - accuracy: 0.8625\n",
            "Epoch 1135: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4370 - accuracy: 0.8618 - val_loss: 1.7360 - val_accuracy: 0.6757\n",
            "Epoch 1136/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3309 - accuracy: 0.8844\n",
            "Epoch 1136: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3303 - accuracy: 0.8843 - val_loss: 0.8428 - val_accuracy: 0.8348\n",
            "Epoch 1137/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2127 - accuracy: 0.9236\n",
            "Epoch 1137: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2126 - accuracy: 0.9237 - val_loss: 0.9028 - val_accuracy: 0.8188\n",
            "Epoch 1138/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2530 - accuracy: 0.9100\n",
            "Epoch 1138: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2527 - accuracy: 0.9100 - val_loss: 0.8948 - val_accuracy: 0.8249\n",
            "Epoch 1139/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2512 - accuracy: 0.9100\n",
            "Epoch 1139: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2558 - accuracy: 0.9077 - val_loss: 1.0363 - val_accuracy: 0.7948\n",
            "Epoch 1140/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2648 - accuracy: 0.9048\n",
            "Epoch 1140: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2663 - accuracy: 0.9039 - val_loss: 1.0400 - val_accuracy: 0.7801\n",
            "Epoch 1141/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2341 - accuracy: 0.9177\n",
            "Epoch 1141: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2338 - accuracy: 0.9178 - val_loss: 1.0406 - val_accuracy: 0.7919\n",
            "Epoch 1142/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3338 - accuracy: 0.8859\n",
            "Epoch 1142: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3279 - accuracy: 0.8876 - val_loss: 0.8437 - val_accuracy: 0.8355\n",
            "Epoch 1143/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2440 - accuracy: 0.9123\n",
            "Epoch 1143: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2436 - accuracy: 0.9125 - val_loss: 0.9225 - val_accuracy: 0.8108\n",
            "Epoch 1144/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2066 - accuracy: 0.9259\n",
            "Epoch 1144: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2061 - accuracy: 0.9262 - val_loss: 0.9454 - val_accuracy: 0.8057\n",
            "Epoch 1145/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1958 - accuracy: 0.9331\n",
            "Epoch 1145: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1956 - accuracy: 0.9332 - val_loss: 0.8240 - val_accuracy: 0.8374\n",
            "Epoch 1146/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2105 - accuracy: 0.9251\n",
            "Epoch 1146: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2102 - accuracy: 0.9253 - val_loss: 0.9010 - val_accuracy: 0.8175\n",
            "Epoch 1147/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2162 - accuracy: 0.9219\n",
            "Epoch 1147: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2211 - accuracy: 0.9202 - val_loss: 1.0263 - val_accuracy: 0.7932\n",
            "Epoch 1148/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.4134 - accuracy: 0.8617\n",
            "Epoch 1148: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.4140 - accuracy: 0.8613 - val_loss: 1.0012 - val_accuracy: 0.7990\n",
            "Epoch 1149/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2259 - accuracy: 0.9231\n",
            "Epoch 1149: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2255 - accuracy: 0.9232 - val_loss: 0.9103 - val_accuracy: 0.8214\n",
            "Epoch 1150/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1874 - accuracy: 0.9344\n",
            "Epoch 1150: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1881 - accuracy: 0.9341 - val_loss: 0.8344 - val_accuracy: 0.8396\n",
            "Epoch 1151/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1982 - accuracy: 0.9288\n",
            "Epoch 1151: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1984 - accuracy: 0.9289 - val_loss: 0.9902 - val_accuracy: 0.8051\n",
            "Epoch 1152/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2094 - accuracy: 0.9262\n",
            "Epoch 1152: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2091 - accuracy: 0.9259 - val_loss: 0.8565 - val_accuracy: 0.8249\n",
            "Epoch 1153/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.2376 - accuracy: 0.9153\n",
            "Epoch 1153: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2375 - accuracy: 0.9154 - val_loss: 1.0033 - val_accuracy: 0.7967\n",
            "Epoch 1154/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3497 - accuracy: 0.8779\n",
            "Epoch 1154: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3457 - accuracy: 0.8782 - val_loss: 0.9843 - val_accuracy: 0.7903\n",
            "Epoch 1155/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2173 - accuracy: 0.9211\n",
            "Epoch 1155: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2182 - accuracy: 0.9206 - val_loss: 0.9347 - val_accuracy: 0.8153\n",
            "Epoch 1156/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2370 - accuracy: 0.9159\n",
            "Epoch 1156: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2405 - accuracy: 0.9137 - val_loss: 1.0002 - val_accuracy: 0.7923\n",
            "Epoch 1157/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3066 - accuracy: 0.8879\n",
            "Epoch 1157: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3066 - accuracy: 0.8879 - val_loss: 1.1175 - val_accuracy: 0.7641\n",
            "Epoch 1158/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3865 - accuracy: 0.8738\n",
            "Epoch 1158: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3765 - accuracy: 0.8768 - val_loss: 0.8750 - val_accuracy: 0.8255\n",
            "Epoch 1159/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2051 - accuracy: 0.9267\n",
            "Epoch 1159: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2043 - accuracy: 0.9269 - val_loss: 0.8549 - val_accuracy: 0.8310\n",
            "Epoch 1160/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1989 - accuracy: 0.9298\n",
            "Epoch 1160: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2004 - accuracy: 0.9292 - val_loss: 0.9726 - val_accuracy: 0.8086\n",
            "Epoch 1161/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1884 - accuracy: 0.9323\n",
            "Epoch 1161: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1889 - accuracy: 0.9326 - val_loss: 0.8677 - val_accuracy: 0.8377\n",
            "Epoch 1162/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2059 - accuracy: 0.9277\n",
            "Epoch 1162: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2073 - accuracy: 0.9274 - val_loss: 1.1291 - val_accuracy: 0.7714\n",
            "Epoch 1163/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2811 - accuracy: 0.8978\n",
            "Epoch 1163: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2789 - accuracy: 0.8986 - val_loss: 1.1389 - val_accuracy: 0.7622\n",
            "Epoch 1164/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2677 - accuracy: 0.9063\n",
            "Epoch 1164: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2664 - accuracy: 0.9071 - val_loss: 0.9918 - val_accuracy: 0.7967\n",
            "Epoch 1165/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3722 - accuracy: 0.8736\n",
            "Epoch 1165: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3691 - accuracy: 0.8741 - val_loss: 0.9399 - val_accuracy: 0.8172\n",
            "Epoch 1166/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2461 - accuracy: 0.9137\n",
            "Epoch 1166: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2461 - accuracy: 0.9137 - val_loss: 0.8973 - val_accuracy: 0.8255\n",
            "Epoch 1167/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2564 - accuracy: 0.9070\n",
            "Epoch 1167: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2559 - accuracy: 0.9073 - val_loss: 0.9003 - val_accuracy: 0.8214\n",
            "Epoch 1168/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2482 - accuracy: 0.9079\n",
            "Epoch 1168: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2492 - accuracy: 0.9077 - val_loss: 0.9744 - val_accuracy: 0.8031\n",
            "Epoch 1169/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2153 - accuracy: 0.9243\n",
            "Epoch 1169: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2153 - accuracy: 0.9242 - val_loss: 0.9017 - val_accuracy: 0.8271\n",
            "Epoch 1170/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2435 - accuracy: 0.9113\n",
            "Epoch 1170: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2420 - accuracy: 0.9118 - val_loss: 0.8319 - val_accuracy: 0.8403\n",
            "Epoch 1171/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2112 - accuracy: 0.9259\n",
            "Epoch 1171: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2112 - accuracy: 0.9259 - val_loss: 0.8475 - val_accuracy: 0.8361\n",
            "Epoch 1172/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2030 - accuracy: 0.9260\n",
            "Epoch 1172: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2088 - accuracy: 0.9239 - val_loss: 0.8864 - val_accuracy: 0.8198\n",
            "Epoch 1173/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2419 - accuracy: 0.9130\n",
            "Epoch 1173: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2407 - accuracy: 0.9139 - val_loss: 0.8990 - val_accuracy: 0.8230\n",
            "Epoch 1174/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2159 - accuracy: 0.9216\n",
            "Epoch 1174: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2180 - accuracy: 0.9210 - val_loss: 1.0712 - val_accuracy: 0.7919\n",
            "Epoch 1175/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3892 - accuracy: 0.8642\n",
            "Epoch 1175: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3837 - accuracy: 0.8662 - val_loss: 0.9755 - val_accuracy: 0.8038\n",
            "Epoch 1176/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2357 - accuracy: 0.9152\n",
            "Epoch 1176: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2356 - accuracy: 0.9150 - val_loss: 0.8500 - val_accuracy: 0.8342\n",
            "Epoch 1177/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1862 - accuracy: 0.9351\n",
            "Epoch 1177: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1869 - accuracy: 0.9350 - val_loss: 0.9308 - val_accuracy: 0.8108\n",
            "Epoch 1178/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2295 - accuracy: 0.9182\n",
            "Epoch 1178: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2296 - accuracy: 0.9180 - val_loss: 1.0672 - val_accuracy: 0.7830\n",
            "Epoch 1179/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.4685 - accuracy: 0.8749\n",
            "Epoch 1179: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.5115 - accuracy: 0.8648 - val_loss: 1.5377 - val_accuracy: 0.7074\n",
            "Epoch 1180/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3339 - accuracy: 0.8810\n",
            "Epoch 1180: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3341 - accuracy: 0.8808 - val_loss: 0.9339 - val_accuracy: 0.8054\n",
            "Epoch 1181/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2470 - accuracy: 0.9102\n",
            "Epoch 1181: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2459 - accuracy: 0.9109 - val_loss: 0.8478 - val_accuracy: 0.8358\n",
            "Epoch 1182/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2071 - accuracy: 0.9258\n",
            "Epoch 1182: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2071 - accuracy: 0.9258 - val_loss: 1.1336 - val_accuracy: 0.7660\n",
            "Epoch 1183/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2000 - accuracy: 0.9299\n",
            "Epoch 1183: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1984 - accuracy: 0.9301 - val_loss: 0.8614 - val_accuracy: 0.8303\n",
            "Epoch 1184/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1841 - accuracy: 0.9348\n",
            "Epoch 1184: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1887 - accuracy: 0.9333 - val_loss: 0.9256 - val_accuracy: 0.8207\n",
            "Epoch 1185/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2136 - accuracy: 0.9223\n",
            "Epoch 1185: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2107 - accuracy: 0.9236 - val_loss: 0.9361 - val_accuracy: 0.8134\n",
            "Epoch 1186/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2216 - accuracy: 0.9214\n",
            "Epoch 1186: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2213 - accuracy: 0.9217 - val_loss: 0.8467 - val_accuracy: 0.8332\n",
            "Epoch 1187/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2036 - accuracy: 0.9291\n",
            "Epoch 1187: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2031 - accuracy: 0.9293 - val_loss: 0.9160 - val_accuracy: 0.8179\n",
            "Epoch 1188/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1880 - accuracy: 0.9343\n",
            "Epoch 1188: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1890 - accuracy: 0.9337 - val_loss: 0.8669 - val_accuracy: 0.8300\n",
            "Epoch 1189/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2380 - accuracy: 0.9143\n",
            "Epoch 1189: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2390 - accuracy: 0.9140 - val_loss: 0.9428 - val_accuracy: 0.8057\n",
            "Epoch 1190/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3167 - accuracy: 0.8896\n",
            "Epoch 1190: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3155 - accuracy: 0.8896 - val_loss: 0.9637 - val_accuracy: 0.8079\n",
            "Epoch 1191/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2982 - accuracy: 0.8948\n",
            "Epoch 1191: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2964 - accuracy: 0.8952 - val_loss: 0.8772 - val_accuracy: 0.8236\n",
            "Epoch 1192/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1868 - accuracy: 0.9369\n",
            "Epoch 1192: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1885 - accuracy: 0.9363 - val_loss: 0.9013 - val_accuracy: 0.8211\n",
            "Epoch 1193/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2408 - accuracy: 0.9136\n",
            "Epoch 1193: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2399 - accuracy: 0.9136 - val_loss: 1.0798 - val_accuracy: 0.7705\n",
            "Epoch 1194/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3588 - accuracy: 0.8755\n",
            "Epoch 1194: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3572 - accuracy: 0.8759 - val_loss: 0.9543 - val_accuracy: 0.8127\n",
            "Epoch 1195/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2130 - accuracy: 0.9244\n",
            "Epoch 1195: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2125 - accuracy: 0.9246 - val_loss: 0.9218 - val_accuracy: 0.8175\n",
            "Epoch 1196/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2347 - accuracy: 0.9171\n",
            "Epoch 1196: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2401 - accuracy: 0.9156 - val_loss: 1.0733 - val_accuracy: 0.7801\n",
            "Epoch 1197/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3500 - accuracy: 0.8851\n",
            "Epoch 1197: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3452 - accuracy: 0.8864 - val_loss: 0.8844 - val_accuracy: 0.8297\n",
            "Epoch 1198/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1795 - accuracy: 0.9408\n",
            "Epoch 1198: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1810 - accuracy: 0.9401 - val_loss: 0.8484 - val_accuracy: 0.8335\n",
            "Epoch 1199/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2098 - accuracy: 0.9245\n",
            "Epoch 1199: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2092 - accuracy: 0.9249 - val_loss: 0.8617 - val_accuracy: 0.8291\n",
            "Epoch 1200/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1906 - accuracy: 0.9326\n",
            "Epoch 1200: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1933 - accuracy: 0.9311 - val_loss: 0.8776 - val_accuracy: 0.8291\n",
            "Epoch 1201/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2755 - accuracy: 0.9052\n",
            "Epoch 1201: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2781 - accuracy: 0.9047 - val_loss: 1.2683 - val_accuracy: 0.7513\n",
            "Epoch 1202/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3179 - accuracy: 0.8881\n",
            "Epoch 1202: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3172 - accuracy: 0.8884 - val_loss: 1.0167 - val_accuracy: 0.7884\n",
            "Epoch 1203/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2319 - accuracy: 0.9162\n",
            "Epoch 1203: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2322 - accuracy: 0.9159 - val_loss: 0.9545 - val_accuracy: 0.8131\n",
            "Epoch 1204/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2322 - accuracy: 0.9173\n",
            "Epoch 1204: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2322 - accuracy: 0.9173 - val_loss: 0.9105 - val_accuracy: 0.8249\n",
            "Epoch 1205/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1801 - accuracy: 0.9385\n",
            "Epoch 1205: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1806 - accuracy: 0.9381 - val_loss: 0.9317 - val_accuracy: 0.8236\n",
            "Epoch 1206/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2145 - accuracy: 0.9229\n",
            "Epoch 1206: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2233 - accuracy: 0.9201 - val_loss: 1.0144 - val_accuracy: 0.7862\n",
            "Epoch 1207/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2594 - accuracy: 0.9072\n",
            "Epoch 1207: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2609 - accuracy: 0.9069 - val_loss: 1.0431 - val_accuracy: 0.7865\n",
            "Epoch 1208/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2600 - accuracy: 0.9049\n",
            "Epoch 1208: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2600 - accuracy: 0.9049 - val_loss: 0.8893 - val_accuracy: 0.8342\n",
            "Epoch 1209/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2544 - accuracy: 0.9077\n",
            "Epoch 1209: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2533 - accuracy: 0.9081 - val_loss: 0.9888 - val_accuracy: 0.8067\n",
            "Epoch 1210/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2223 - accuracy: 0.9216\n",
            "Epoch 1210: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2231 - accuracy: 0.9215 - val_loss: 0.9439 - val_accuracy: 0.8214\n",
            "Epoch 1211/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2716 - accuracy: 0.9046\n",
            "Epoch 1211: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2707 - accuracy: 0.9049 - val_loss: 0.9525 - val_accuracy: 0.8230\n",
            "Epoch 1212/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3016 - accuracy: 0.8927\n",
            "Epoch 1212: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2974 - accuracy: 0.8940 - val_loss: 0.8957 - val_accuracy: 0.8223\n",
            "Epoch 1213/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.6125 - accuracy: 0.8322\n",
            "Epoch 1213: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.6125 - accuracy: 0.8322 - val_loss: 0.8694 - val_accuracy: 0.8220\n",
            "Epoch 1214/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1858 - accuracy: 0.9369\n",
            "Epoch 1214: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1858 - accuracy: 0.9369 - val_loss: 0.9167 - val_accuracy: 0.8169\n",
            "Epoch 1215/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1937 - accuracy: 0.9314\n",
            "Epoch 1215: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1937 - accuracy: 0.9314 - val_loss: 0.8603 - val_accuracy: 0.8345\n",
            "Epoch 1216/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1895 - accuracy: 0.9348\n",
            "Epoch 1216: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1891 - accuracy: 0.9350 - val_loss: 0.8559 - val_accuracy: 0.8287\n",
            "Epoch 1217/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2133 - accuracy: 0.9219\n",
            "Epoch 1217: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2135 - accuracy: 0.9217 - val_loss: 0.8986 - val_accuracy: 0.8294\n",
            "Epoch 1218/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1900 - accuracy: 0.9341\n",
            "Epoch 1218: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1890 - accuracy: 0.9349 - val_loss: 0.9199 - val_accuracy: 0.8179\n",
            "Epoch 1219/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1947 - accuracy: 0.9299\n",
            "Epoch 1219: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1974 - accuracy: 0.9289 - val_loss: 0.9565 - val_accuracy: 0.8159\n",
            "Epoch 1220/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1812 - accuracy: 0.9348\n",
            "Epoch 1220: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1811 - accuracy: 0.9348 - val_loss: 0.8508 - val_accuracy: 0.8377\n",
            "Epoch 1221/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8721\n",
            "Epoch 1221: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3807 - accuracy: 0.8718 - val_loss: 1.0906 - val_accuracy: 0.7897\n",
            "Epoch 1222/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2385 - accuracy: 0.9117\n",
            "Epoch 1222: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2353 - accuracy: 0.9134 - val_loss: 0.8747 - val_accuracy: 0.8255\n",
            "Epoch 1223/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2251 - accuracy: 0.9183\n",
            "Epoch 1223: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2277 - accuracy: 0.9173 - val_loss: 0.9745 - val_accuracy: 0.8086\n",
            "Epoch 1224/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2535 - accuracy: 0.9081\n",
            "Epoch 1224: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2532 - accuracy: 0.9082 - val_loss: 0.9482 - val_accuracy: 0.8175\n",
            "Epoch 1225/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2028 - accuracy: 0.9288\n",
            "Epoch 1225: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2041 - accuracy: 0.9286 - val_loss: 0.9186 - val_accuracy: 0.8214\n",
            "Epoch 1226/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2117 - accuracy: 0.9248\n",
            "Epoch 1226: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2133 - accuracy: 0.9242 - val_loss: 0.9647 - val_accuracy: 0.8099\n",
            "Epoch 1227/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2337 - accuracy: 0.9168\n",
            "Epoch 1227: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2325 - accuracy: 0.9170 - val_loss: 0.9178 - val_accuracy: 0.8246\n",
            "Epoch 1228/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1962 - accuracy: 0.9279\n",
            "Epoch 1228: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1962 - accuracy: 0.9279 - val_loss: 0.8800 - val_accuracy: 0.8329\n",
            "Epoch 1229/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1993 - accuracy: 0.9286\n",
            "Epoch 1229: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1996 - accuracy: 0.9289 - val_loss: 0.8512 - val_accuracy: 0.8377\n",
            "Epoch 1230/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1988 - accuracy: 0.9288\n",
            "Epoch 1230: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1994 - accuracy: 0.9286 - val_loss: 0.8954 - val_accuracy: 0.8259\n",
            "Epoch 1231/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2093 - accuracy: 0.9259\n",
            "Epoch 1231: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2064 - accuracy: 0.9270 - val_loss: 0.8269 - val_accuracy: 0.8393\n",
            "Epoch 1232/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2416 - accuracy: 0.9144\n",
            "Epoch 1232: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2457 - accuracy: 0.9124 - val_loss: 1.2574 - val_accuracy: 0.7465\n",
            "Epoch 1233/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.6384 - accuracy: 0.8146\n",
            "Epoch 1233: val_accuracy did not improve from 0.84091\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.6273 - accuracy: 0.8155 - val_loss: 1.1157 - val_accuracy: 0.7794\n",
            "Epoch 1234/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2494 - accuracy: 0.9117\n",
            "Epoch 1234: val_accuracy improved from 0.84091 to 0.84251, saving model to /content/asl1/Adam4/cp-1234-0.84.hdf5\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2458 - accuracy: 0.9131 - val_loss: 0.8202 - val_accuracy: 0.8425\n",
            "Epoch 1235/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2021 - accuracy: 0.9275\n",
            "Epoch 1235: val_accuracy did not improve from 0.84251\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2015 - accuracy: 0.9278 - val_loss: 0.8453 - val_accuracy: 0.8412\n",
            "Epoch 1236/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1736 - accuracy: 0.9418\n",
            "Epoch 1236: val_accuracy did not improve from 0.84251\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1735 - accuracy: 0.9414 - val_loss: 0.8448 - val_accuracy: 0.8326\n",
            "Epoch 1237/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1870 - accuracy: 0.9360\n",
            "Epoch 1237: val_accuracy did not improve from 0.84251\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1870 - accuracy: 0.9360 - val_loss: 0.8608 - val_accuracy: 0.8287\n",
            "Epoch 1238/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1908 - accuracy: 0.9340\n",
            "Epoch 1238: val_accuracy did not improve from 0.84251\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1908 - accuracy: 0.9340 - val_loss: 1.0298 - val_accuracy: 0.7894\n",
            "Epoch 1239/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.3264 - accuracy: 0.8903\n",
            "Epoch 1239: val_accuracy did not improve from 0.84251\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3151 - accuracy: 0.8933 - val_loss: 0.8752 - val_accuracy: 0.8243\n",
            "Epoch 1240/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1911 - accuracy: 0.9283\n",
            "Epoch 1240: val_accuracy did not improve from 0.84251\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1922 - accuracy: 0.9284 - val_loss: 0.8726 - val_accuracy: 0.8252\n",
            "Epoch 1241/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2169 - accuracy: 0.9220\n",
            "Epoch 1241: val_accuracy did not improve from 0.84251\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2166 - accuracy: 0.9220 - val_loss: 0.8699 - val_accuracy: 0.8371\n",
            "Epoch 1242/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2563 - accuracy: 0.9076\n",
            "Epoch 1242: val_accuracy did not improve from 0.84251\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2586 - accuracy: 0.9065 - val_loss: 0.9478 - val_accuracy: 0.8108\n",
            "Epoch 1243/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2284 - accuracy: 0.9185\n",
            "Epoch 1243: val_accuracy did not improve from 0.84251\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2278 - accuracy: 0.9189 - val_loss: 0.8409 - val_accuracy: 0.8351\n",
            "Epoch 1244/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2739 - accuracy: 0.8994\n",
            "Epoch 1244: val_accuracy did not improve from 0.84251\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2746 - accuracy: 0.8991 - val_loss: 0.8722 - val_accuracy: 0.8294\n",
            "Epoch 1245/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2688 - accuracy: 0.9038\n",
            "Epoch 1245: val_accuracy did not improve from 0.84251\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2690 - accuracy: 0.9038 - val_loss: 0.9217 - val_accuracy: 0.8115\n",
            "Epoch 1246/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2357 - accuracy: 0.9141\n",
            "Epoch 1246: val_accuracy did not improve from 0.84251\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2357 - accuracy: 0.9141 - val_loss: 0.9392 - val_accuracy: 0.8169\n",
            "Epoch 1247/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2999 - accuracy: 0.8954\n",
            "Epoch 1247: val_accuracy did not improve from 0.84251\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3057 - accuracy: 0.8932 - val_loss: 1.7982 - val_accuracy: 0.6690\n",
            "Epoch 1248/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3478 - accuracy: 0.8848\n",
            "Epoch 1248: val_accuracy did not improve from 0.84251\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3478 - accuracy: 0.8848 - val_loss: 0.9215 - val_accuracy: 0.8172\n",
            "Epoch 1249/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2114 - accuracy: 0.9227\n",
            "Epoch 1249: val_accuracy did not improve from 0.84251\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2129 - accuracy: 0.9224 - val_loss: 0.9863 - val_accuracy: 0.8019\n",
            "Epoch 1250/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1955 - accuracy: 0.9322\n",
            "Epoch 1250: val_accuracy did not improve from 0.84251\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1964 - accuracy: 0.9313 - val_loss: 0.8742 - val_accuracy: 0.8342\n",
            "Epoch 1251/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1970 - accuracy: 0.9306\n",
            "Epoch 1251: val_accuracy did not improve from 0.84251\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1994 - accuracy: 0.9293 - val_loss: 0.9690 - val_accuracy: 0.8067\n",
            "Epoch 1252/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1977 - accuracy: 0.9287\n",
            "Epoch 1252: val_accuracy did not improve from 0.84251\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1976 - accuracy: 0.9285 - val_loss: 0.8657 - val_accuracy: 0.8287\n",
            "Epoch 1253/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3704 - accuracy: 0.8853\n",
            "Epoch 1253: val_accuracy did not improve from 0.84251\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4168 - accuracy: 0.8768 - val_loss: 1.8795 - val_accuracy: 0.6834\n",
            "Epoch 1254/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3316 - accuracy: 0.8895\n",
            "Epoch 1254: val_accuracy did not improve from 0.84251\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3298 - accuracy: 0.8900 - val_loss: 0.9368 - val_accuracy: 0.8102\n",
            "Epoch 1255/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2022 - accuracy: 0.9282\n",
            "Epoch 1255: val_accuracy did not improve from 0.84251\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2006 - accuracy: 0.9290 - val_loss: 0.8483 - val_accuracy: 0.8380\n",
            "Epoch 1256/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1779 - accuracy: 0.9386\n",
            "Epoch 1256: val_accuracy improved from 0.84251 to 0.84315, saving model to /content/asl1/Adam4/cp-1256-0.84.hdf5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1779 - accuracy: 0.9386 - val_loss: 0.8320 - val_accuracy: 0.8431\n",
            "Epoch 1257/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1993 - accuracy: 0.9284\n",
            "Epoch 1257: val_accuracy did not improve from 0.84315\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1975 - accuracy: 0.9289 - val_loss: 0.8727 - val_accuracy: 0.8358\n",
            "Epoch 1258/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1927 - accuracy: 0.9315\n",
            "Epoch 1258: val_accuracy improved from 0.84315 to 0.84667, saving model to /content/asl1/Adam4/cp-1258-0.85.hdf5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1927 - accuracy: 0.9315 - val_loss: 0.8398 - val_accuracy: 0.8467\n",
            "Epoch 1259/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2244 - accuracy: 0.9167\n",
            "Epoch 1259: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2237 - accuracy: 0.9173 - val_loss: 0.9018 - val_accuracy: 0.8230\n",
            "Epoch 1260/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2111 - accuracy: 0.9251\n",
            "Epoch 1260: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2112 - accuracy: 0.9250 - val_loss: 0.8644 - val_accuracy: 0.8348\n",
            "Epoch 1261/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2187 - accuracy: 0.9229\n",
            "Epoch 1261: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2174 - accuracy: 0.9233 - val_loss: 0.8573 - val_accuracy: 0.8415\n",
            "Epoch 1262/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2354 - accuracy: 0.9151\n",
            "Epoch 1262: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2382 - accuracy: 0.9137 - val_loss: 1.0372 - val_accuracy: 0.7967\n",
            "Epoch 1263/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2255 - accuracy: 0.9205\n",
            "Epoch 1263: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2246 - accuracy: 0.9206 - val_loss: 0.8471 - val_accuracy: 0.8371\n",
            "Epoch 1264/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3501 - accuracy: 0.8820\n",
            "Epoch 1264: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3526 - accuracy: 0.8801 - val_loss: 0.9738 - val_accuracy: 0.8076\n",
            "Epoch 1265/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2271 - accuracy: 0.9188\n",
            "Epoch 1265: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2276 - accuracy: 0.9187 - val_loss: 0.9135 - val_accuracy: 0.8230\n",
            "Epoch 1266/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2069 - accuracy: 0.9274\n",
            "Epoch 1266: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.2092 - accuracy: 0.9263 - val_loss: 1.0832 - val_accuracy: 0.7820\n",
            "Epoch 1267/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2312 - accuracy: 0.9146\n",
            "Epoch 1267: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2325 - accuracy: 0.9145 - val_loss: 0.9680 - val_accuracy: 0.8118\n",
            "Epoch 1268/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2287 - accuracy: 0.9170\n",
            "Epoch 1268: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2290 - accuracy: 0.9169 - val_loss: 0.8888 - val_accuracy: 0.8265\n",
            "Epoch 1269/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1963 - accuracy: 0.9315\n",
            "Epoch 1269: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1961 - accuracy: 0.9309 - val_loss: 0.9059 - val_accuracy: 0.8246\n",
            "Epoch 1270/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1801 - accuracy: 0.9343\n",
            "Epoch 1270: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1865 - accuracy: 0.9323 - val_loss: 0.9862 - val_accuracy: 0.8079\n",
            "Epoch 1271/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2809 - accuracy: 0.8984\n",
            "Epoch 1271: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2809 - accuracy: 0.8984 - val_loss: 0.8863 - val_accuracy: 0.8326\n",
            "Epoch 1272/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3572 - accuracy: 0.8732\n",
            "Epoch 1272: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3515 - accuracy: 0.8755 - val_loss: 0.9230 - val_accuracy: 0.8166\n",
            "Epoch 1273/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1857 - accuracy: 0.9360\n",
            "Epoch 1273: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1869 - accuracy: 0.9352 - val_loss: 0.9302 - val_accuracy: 0.8166\n",
            "Epoch 1274/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1943 - accuracy: 0.9294\n",
            "Epoch 1274: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1943 - accuracy: 0.9293 - val_loss: 0.8660 - val_accuracy: 0.8364\n",
            "Epoch 1275/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1860 - accuracy: 0.9316\n",
            "Epoch 1275: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1889 - accuracy: 0.9308 - val_loss: 1.1588 - val_accuracy: 0.7759\n",
            "Epoch 1276/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2080 - accuracy: 0.9272\n",
            "Epoch 1276: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2081 - accuracy: 0.9273 - val_loss: 1.0955 - val_accuracy: 0.7807\n",
            "Epoch 1277/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2987 - accuracy: 0.8925\n",
            "Epoch 1277: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3001 - accuracy: 0.8915 - val_loss: 1.1953 - val_accuracy: 0.7615\n",
            "Epoch 1278/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3006 - accuracy: 0.8961\n",
            "Epoch 1278: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3085 - accuracy: 0.8940 - val_loss: 1.1451 - val_accuracy: 0.7730\n",
            "Epoch 1279/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2809 - accuracy: 0.8991\n",
            "Epoch 1279: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2845 - accuracy: 0.8972 - val_loss: 0.8948 - val_accuracy: 0.8297\n",
            "Epoch 1280/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1915 - accuracy: 0.9322\n",
            "Epoch 1280: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1915 - accuracy: 0.9326 - val_loss: 0.9463 - val_accuracy: 0.8131\n",
            "Epoch 1281/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2156 - accuracy: 0.9232\n",
            "Epoch 1281: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2156 - accuracy: 0.9232 - val_loss: 0.8817 - val_accuracy: 0.8403\n",
            "Epoch 1282/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1738 - accuracy: 0.9385\n",
            "Epoch 1282: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1738 - accuracy: 0.9385 - val_loss: 0.8648 - val_accuracy: 0.8355\n",
            "Epoch 1283/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2326 - accuracy: 0.9167\n",
            "Epoch 1283: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2326 - accuracy: 0.9167 - val_loss: 0.9950 - val_accuracy: 0.8092\n",
            "Epoch 1284/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2390 - accuracy: 0.9141\n",
            "Epoch 1284: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2403 - accuracy: 0.9135 - val_loss: 1.1770 - val_accuracy: 0.7692\n",
            "Epoch 1285/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2863 - accuracy: 0.8967\n",
            "Epoch 1285: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2845 - accuracy: 0.8972 - val_loss: 0.9798 - val_accuracy: 0.8086\n",
            "Epoch 1286/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2117 - accuracy: 0.9244\n",
            "Epoch 1286: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2115 - accuracy: 0.9242 - val_loss: 0.9466 - val_accuracy: 0.8217\n",
            "Epoch 1287/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1999 - accuracy: 0.9265\n",
            "Epoch 1287: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1999 - accuracy: 0.9265 - val_loss: 1.0395 - val_accuracy: 0.8019\n",
            "Epoch 1288/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2047 - accuracy: 0.9249\n",
            "Epoch 1288: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2063 - accuracy: 0.9242 - val_loss: 0.9343 - val_accuracy: 0.8275\n",
            "Epoch 1289/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2624 - accuracy: 0.9043\n",
            "Epoch 1289: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2664 - accuracy: 0.9032 - val_loss: 0.9620 - val_accuracy: 0.8140\n",
            "Epoch 1290/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3158 - accuracy: 0.8880\n",
            "Epoch 1290: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3120 - accuracy: 0.8893 - val_loss: 0.8987 - val_accuracy: 0.8268\n",
            "Epoch 1291/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2066 - accuracy: 0.9259\n",
            "Epoch 1291: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2109 - accuracy: 0.9243 - val_loss: 1.5328 - val_accuracy: 0.7103\n",
            "Epoch 1292/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2815 - accuracy: 0.9032\n",
            "Epoch 1292: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2815 - accuracy: 0.9032 - val_loss: 0.8952 - val_accuracy: 0.8332\n",
            "Epoch 1293/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1831 - accuracy: 0.9344\n",
            "Epoch 1293: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1847 - accuracy: 0.9337 - val_loss: 0.9276 - val_accuracy: 0.8271\n",
            "Epoch 1294/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1660 - accuracy: 0.9413\n",
            "Epoch 1294: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1671 - accuracy: 0.9411 - val_loss: 0.8574 - val_accuracy: 0.8431\n",
            "Epoch 1295/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2219 - accuracy: 0.9192\n",
            "Epoch 1295: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2187 - accuracy: 0.9204 - val_loss: 0.8988 - val_accuracy: 0.8303\n",
            "Epoch 1296/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2408 - accuracy: 0.9141\n",
            "Epoch 1296: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2420 - accuracy: 0.9137 - val_loss: 1.1820 - val_accuracy: 0.7759\n",
            "Epoch 1297/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2490 - accuracy: 0.9109\n",
            "Epoch 1297: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2490 - accuracy: 0.9109 - val_loss: 0.9627 - val_accuracy: 0.8166\n",
            "Epoch 1298/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2346 - accuracy: 0.9162\n",
            "Epoch 1298: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2324 - accuracy: 0.9163 - val_loss: 0.9681 - val_accuracy: 0.8095\n",
            "Epoch 1299/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2256 - accuracy: 0.9173\n",
            "Epoch 1299: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2256 - accuracy: 0.9173 - val_loss: 0.9465 - val_accuracy: 0.8102\n",
            "Epoch 1300/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2474 - accuracy: 0.9108\n",
            "Epoch 1300: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2491 - accuracy: 0.9102 - val_loss: 0.9031 - val_accuracy: 0.8313\n",
            "Epoch 1301/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.4014 - accuracy: 0.8641\n",
            "Epoch 1301: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3968 - accuracy: 0.8660 - val_loss: 1.0343 - val_accuracy: 0.7852\n",
            "Epoch 1302/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2059 - accuracy: 0.9253\n",
            "Epoch 1302: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2060 - accuracy: 0.9253 - val_loss: 0.9282 - val_accuracy: 0.8243\n",
            "Epoch 1303/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1828 - accuracy: 0.9347\n",
            "Epoch 1303: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1831 - accuracy: 0.9347 - val_loss: 0.9055 - val_accuracy: 0.8284\n",
            "Epoch 1304/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2110 - accuracy: 0.9248\n",
            "Epoch 1304: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2254 - accuracy: 0.9209 - val_loss: 1.1072 - val_accuracy: 0.7833\n",
            "Epoch 1305/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3932 - accuracy: 0.8693\n",
            "Epoch 1305: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.3862 - accuracy: 0.8718 - val_loss: 0.9241 - val_accuracy: 0.8220\n",
            "Epoch 1306/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1821 - accuracy: 0.9360\n",
            "Epoch 1306: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1825 - accuracy: 0.9358 - val_loss: 0.9582 - val_accuracy: 0.8086\n",
            "Epoch 1307/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2064 - accuracy: 0.9253\n",
            "Epoch 1307: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2070 - accuracy: 0.9253 - val_loss: 1.0004 - val_accuracy: 0.8057\n",
            "Epoch 1308/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2162 - accuracy: 0.9213\n",
            "Epoch 1308: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2162 - accuracy: 0.9213 - val_loss: 0.9148 - val_accuracy: 0.8284\n",
            "Epoch 1309/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3105 - accuracy: 0.8917\n",
            "Epoch 1309: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3211 - accuracy: 0.8886 - val_loss: 1.2049 - val_accuracy: 0.7628\n",
            "Epoch 1310/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2551 - accuracy: 0.9111\n",
            "Epoch 1310: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2551 - accuracy: 0.9111 - val_loss: 0.8704 - val_accuracy: 0.8377\n",
            "Epoch 1311/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1971 - accuracy: 0.9297\n",
            "Epoch 1311: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1973 - accuracy: 0.9298 - val_loss: 1.0308 - val_accuracy: 0.8019\n",
            "Epoch 1312/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1766 - accuracy: 0.9373\n",
            "Epoch 1312: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1767 - accuracy: 0.9373 - val_loss: 0.8854 - val_accuracy: 0.8278\n",
            "Epoch 1313/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1893 - accuracy: 0.9323\n",
            "Epoch 1313: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1893 - accuracy: 0.9321 - val_loss: 0.9824 - val_accuracy: 0.8073\n",
            "Epoch 1314/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2120 - accuracy: 0.9236\n",
            "Epoch 1314: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2131 - accuracy: 0.9231 - val_loss: 0.9245 - val_accuracy: 0.8239\n",
            "Epoch 1315/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.4038 - accuracy: 0.8668\n",
            "Epoch 1315: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4035 - accuracy: 0.8667 - val_loss: 0.9206 - val_accuracy: 0.8249\n",
            "Epoch 1316/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2182 - accuracy: 0.9199\n",
            "Epoch 1316: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2184 - accuracy: 0.9199 - val_loss: 0.9788 - val_accuracy: 0.8156\n",
            "Epoch 1317/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1787 - accuracy: 0.9381\n",
            "Epoch 1317: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1787 - accuracy: 0.9381 - val_loss: 0.8702 - val_accuracy: 0.8339\n",
            "Epoch 1318/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2064 - accuracy: 0.9229\n",
            "Epoch 1318: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2062 - accuracy: 0.9229 - val_loss: 0.8719 - val_accuracy: 0.8428\n",
            "Epoch 1319/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1886 - accuracy: 0.9326\n",
            "Epoch 1319: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1870 - accuracy: 0.9330 - val_loss: 0.8970 - val_accuracy: 0.8345\n",
            "Epoch 1320/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1831 - accuracy: 0.9338\n",
            "Epoch 1320: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1859 - accuracy: 0.9329 - val_loss: 0.8873 - val_accuracy: 0.8403\n",
            "Epoch 1321/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1840 - accuracy: 0.9352\n",
            "Epoch 1321: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1847 - accuracy: 0.9349 - val_loss: 0.8486 - val_accuracy: 0.8441\n",
            "Epoch 1322/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2215 - accuracy: 0.9196\n",
            "Epoch 1322: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2200 - accuracy: 0.9205 - val_loss: 0.9166 - val_accuracy: 0.8387\n",
            "Epoch 1323/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3977 - accuracy: 0.8723\n",
            "Epoch 1323: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3904 - accuracy: 0.8743 - val_loss: 0.9061 - val_accuracy: 0.8303\n",
            "Epoch 1324/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2482 - accuracy: 0.9124\n",
            "Epoch 1324: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2482 - accuracy: 0.9124 - val_loss: 0.9250 - val_accuracy: 0.8252\n",
            "Epoch 1325/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2792 - accuracy: 0.8988\n",
            "Epoch 1325: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2803 - accuracy: 0.8982 - val_loss: 1.0236 - val_accuracy: 0.8060\n",
            "Epoch 1326/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1807 - accuracy: 0.9352\n",
            "Epoch 1326: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1790 - accuracy: 0.9361 - val_loss: 0.9308 - val_accuracy: 0.8239\n",
            "Epoch 1327/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2484 - accuracy: 0.9099\n",
            "Epoch 1327: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2540 - accuracy: 0.9081 - val_loss: 1.0514 - val_accuracy: 0.8015\n",
            "Epoch 1328/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1955 - accuracy: 0.9282\n",
            "Epoch 1328: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1922 - accuracy: 0.9295 - val_loss: 0.9437 - val_accuracy: 0.8259\n",
            "Epoch 1329/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1855 - accuracy: 0.9323\n",
            "Epoch 1329: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1846 - accuracy: 0.9328 - val_loss: 0.9440 - val_accuracy: 0.8166\n",
            "Epoch 1330/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.4769 - accuracy: 0.8631\n",
            "Epoch 1330: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4680 - accuracy: 0.8650 - val_loss: 0.9813 - val_accuracy: 0.8143\n",
            "Epoch 1331/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2657 - accuracy: 0.9058\n",
            "Epoch 1331: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2653 - accuracy: 0.9059 - val_loss: 0.8753 - val_accuracy: 0.8383\n",
            "Epoch 1332/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1708 - accuracy: 0.9408\n",
            "Epoch 1332: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1716 - accuracy: 0.9405 - val_loss: 1.0096 - val_accuracy: 0.8031\n",
            "Epoch 1333/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1758 - accuracy: 0.9383\n",
            "Epoch 1333: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1762 - accuracy: 0.9381 - val_loss: 0.8729 - val_accuracy: 0.8393\n",
            "Epoch 1334/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2120 - accuracy: 0.9269\n",
            "Epoch 1334: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2121 - accuracy: 0.9267 - val_loss: 1.0762 - val_accuracy: 0.7945\n",
            "Epoch 1335/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2382 - accuracy: 0.9139\n",
            "Epoch 1335: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2347 - accuracy: 0.9154 - val_loss: 0.8737 - val_accuracy: 0.8422\n",
            "Epoch 1336/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2205 - accuracy: 0.9183\n",
            "Epoch 1336: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2205 - accuracy: 0.9185 - val_loss: 1.1594 - val_accuracy: 0.7660\n",
            "Epoch 1337/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2663 - accuracy: 0.9024\n",
            "Epoch 1337: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2643 - accuracy: 0.9030 - val_loss: 0.9334 - val_accuracy: 0.8201\n",
            "Epoch 1338/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1941 - accuracy: 0.9315\n",
            "Epoch 1338: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1941 - accuracy: 0.9315 - val_loss: 1.2424 - val_accuracy: 0.7657\n",
            "Epoch 1339/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2816 - accuracy: 0.9023\n",
            "Epoch 1339: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2788 - accuracy: 0.9032 - val_loss: 0.9228 - val_accuracy: 0.8249\n",
            "Epoch 1340/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1971 - accuracy: 0.9279\n",
            "Epoch 1340: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1992 - accuracy: 0.9274 - val_loss: 0.9461 - val_accuracy: 0.8278\n",
            "Epoch 1341/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2657 - accuracy: 0.9083\n",
            "Epoch 1341: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2631 - accuracy: 0.9089 - val_loss: 0.9404 - val_accuracy: 0.8191\n",
            "Epoch 1342/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2203 - accuracy: 0.9184\n",
            "Epoch 1342: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2196 - accuracy: 0.9187 - val_loss: 0.9140 - val_accuracy: 0.8307\n",
            "Epoch 1343/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1843 - accuracy: 0.9333\n",
            "Epoch 1343: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1852 - accuracy: 0.9329 - val_loss: 1.0015 - val_accuracy: 0.8134\n",
            "Epoch 1344/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1935 - accuracy: 0.9292\n",
            "Epoch 1344: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1931 - accuracy: 0.9292 - val_loss: 1.0405 - val_accuracy: 0.8025\n",
            "Epoch 1345/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3326 - accuracy: 0.8859\n",
            "Epoch 1345: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3328 - accuracy: 0.8856 - val_loss: 1.3018 - val_accuracy: 0.7423\n",
            "Epoch 1346/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3494 - accuracy: 0.8800\n",
            "Epoch 1346: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3494 - accuracy: 0.8800 - val_loss: 1.2012 - val_accuracy: 0.7666\n",
            "Epoch 1347/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2586 - accuracy: 0.9086\n",
            "Epoch 1347: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2558 - accuracy: 0.9098 - val_loss: 0.8998 - val_accuracy: 0.8281\n",
            "Epoch 1348/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1814 - accuracy: 0.9348\n",
            "Epoch 1348: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1810 - accuracy: 0.9349 - val_loss: 0.8801 - val_accuracy: 0.8448\n",
            "Epoch 1349/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1806 - accuracy: 0.9351\n",
            "Epoch 1349: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1827 - accuracy: 0.9345 - val_loss: 1.0298 - val_accuracy: 0.7961\n",
            "Epoch 1350/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1969 - accuracy: 0.9272\n",
            "Epoch 1350: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1970 - accuracy: 0.9270 - val_loss: 0.9303 - val_accuracy: 0.8287\n",
            "Epoch 1351/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1891 - accuracy: 0.9308\n",
            "Epoch 1351: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1917 - accuracy: 0.9299 - val_loss: 0.9592 - val_accuracy: 0.8259\n",
            "Epoch 1352/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1870 - accuracy: 0.9304\n",
            "Epoch 1352: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1867 - accuracy: 0.9306 - val_loss: 0.9297 - val_accuracy: 0.8227\n",
            "Epoch 1353/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2763 - accuracy: 0.9004\n",
            "Epoch 1353: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2763 - accuracy: 0.9004 - val_loss: 0.9457 - val_accuracy: 0.8169\n",
            "Epoch 1354/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2472 - accuracy: 0.9081\n",
            "Epoch 1354: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2463 - accuracy: 0.9085 - val_loss: 0.9053 - val_accuracy: 0.8345\n",
            "Epoch 1355/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1702 - accuracy: 0.9426\n",
            "Epoch 1355: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1766 - accuracy: 0.9403 - val_loss: 1.0105 - val_accuracy: 0.8038\n",
            "Epoch 1356/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.4112 - accuracy: 0.8686\n",
            "Epoch 1356: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4020 - accuracy: 0.8712 - val_loss: 1.0519 - val_accuracy: 0.7955\n",
            "Epoch 1357/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2147 - accuracy: 0.9206\n",
            "Epoch 1357: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2169 - accuracy: 0.9199 - val_loss: 1.0475 - val_accuracy: 0.8076\n",
            "Epoch 1358/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1852 - accuracy: 0.9334\n",
            "Epoch 1358: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1847 - accuracy: 0.9337 - val_loss: 0.8866 - val_accuracy: 0.8351\n",
            "Epoch 1359/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1732 - accuracy: 0.9388\n",
            "Epoch 1359: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1732 - accuracy: 0.9387 - val_loss: 0.9642 - val_accuracy: 0.8211\n",
            "Epoch 1360/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1941 - accuracy: 0.9304\n",
            "Epoch 1360: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1941 - accuracy: 0.9304 - val_loss: 0.8838 - val_accuracy: 0.8355\n",
            "Epoch 1361/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2904 - accuracy: 0.8996\n",
            "Epoch 1361: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.2923 - accuracy: 0.8990 - val_loss: 0.9974 - val_accuracy: 0.8031\n",
            "Epoch 1362/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2248 - accuracy: 0.9184\n",
            "Epoch 1362: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2220 - accuracy: 0.9199 - val_loss: 0.9029 - val_accuracy: 0.8390\n",
            "Epoch 1363/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1869 - accuracy: 0.9333\n",
            "Epoch 1363: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1903 - accuracy: 0.9321 - val_loss: 0.9683 - val_accuracy: 0.8111\n",
            "Epoch 1364/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2893 - accuracy: 0.8996\n",
            "Epoch 1364: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2825 - accuracy: 0.9012 - val_loss: 0.9098 - val_accuracy: 0.8271\n",
            "Epoch 1365/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.1803 - accuracy: 0.9363\n",
            "Epoch 1365: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1838 - accuracy: 0.9346 - val_loss: 0.9310 - val_accuracy: 0.8284\n",
            "Epoch 1366/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2292 - accuracy: 0.9180\n",
            "Epoch 1366: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2292 - accuracy: 0.9181 - val_loss: 0.9889 - val_accuracy: 0.8207\n",
            "Epoch 1367/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1835 - accuracy: 0.9319\n",
            "Epoch 1367: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1833 - accuracy: 0.9320 - val_loss: 0.8946 - val_accuracy: 0.8361\n",
            "Epoch 1368/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1841 - accuracy: 0.9327\n",
            "Epoch 1368: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1841 - accuracy: 0.9327 - val_loss: 0.8963 - val_accuracy: 0.8387\n",
            "Epoch 1369/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2159 - accuracy: 0.9229\n",
            "Epoch 1369: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2185 - accuracy: 0.9218 - val_loss: 1.1266 - val_accuracy: 0.7871\n",
            "Epoch 1370/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2342 - accuracy: 0.9149\n",
            "Epoch 1370: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2316 - accuracy: 0.9157 - val_loss: 0.9648 - val_accuracy: 0.8275\n",
            "Epoch 1371/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2021 - accuracy: 0.9272\n",
            "Epoch 1371: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2056 - accuracy: 0.9257 - val_loss: 0.9258 - val_accuracy: 0.8310\n",
            "Epoch 1372/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2324 - accuracy: 0.9171\n",
            "Epoch 1372: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2312 - accuracy: 0.9177 - val_loss: 0.9454 - val_accuracy: 0.8188\n",
            "Epoch 1373/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2047 - accuracy: 0.9285\n",
            "Epoch 1373: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2047 - accuracy: 0.9285 - val_loss: 1.2477 - val_accuracy: 0.7634\n",
            "Epoch 1374/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3294 - accuracy: 0.8818\n",
            "Epoch 1374: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3294 - accuracy: 0.8818 - val_loss: 1.0364 - val_accuracy: 0.7990\n",
            "Epoch 1375/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.6157 - accuracy: 0.8411\n",
            "Epoch 1375: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.6171 - accuracy: 0.8406 - val_loss: 1.3809 - val_accuracy: 0.7529\n",
            "Epoch 1376/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3122 - accuracy: 0.8906\n",
            "Epoch 1376: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3087 - accuracy: 0.8920 - val_loss: 0.8915 - val_accuracy: 0.8329\n",
            "Epoch 1377/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1577 - accuracy: 0.9457\n",
            "Epoch 1377: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1571 - accuracy: 0.9460 - val_loss: 0.9056 - val_accuracy: 0.8297\n",
            "Epoch 1378/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1550 - accuracy: 0.9464\n",
            "Epoch 1378: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.1554 - accuracy: 0.9465 - val_loss: 0.8748 - val_accuracy: 0.8371\n",
            "Epoch 1379/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1545 - accuracy: 0.9464\n",
            "Epoch 1379: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1554 - accuracy: 0.9458 - val_loss: 0.8961 - val_accuracy: 0.8361\n",
            "Epoch 1380/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1790 - accuracy: 0.9361\n",
            "Epoch 1380: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1784 - accuracy: 0.9365 - val_loss: 0.9826 - val_accuracy: 0.8163\n",
            "Epoch 1381/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2013 - accuracy: 0.9281\n",
            "Epoch 1381: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2013 - accuracy: 0.9280 - val_loss: 0.9811 - val_accuracy: 0.8118\n",
            "Epoch 1382/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2374 - accuracy: 0.9165\n",
            "Epoch 1382: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2387 - accuracy: 0.9159 - val_loss: 0.9923 - val_accuracy: 0.8166\n",
            "Epoch 1383/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3542 - accuracy: 0.8750\n",
            "Epoch 1383: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3559 - accuracy: 0.8741 - val_loss: 1.0290 - val_accuracy: 0.8111\n",
            "Epoch 1384/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2146 - accuracy: 0.9220\n",
            "Epoch 1384: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2174 - accuracy: 0.9211 - val_loss: 1.0633 - val_accuracy: 0.7881\n",
            "Epoch 1385/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2774 - accuracy: 0.9009\n",
            "Epoch 1385: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2747 - accuracy: 0.9013 - val_loss: 0.9126 - val_accuracy: 0.8300\n",
            "Epoch 1386/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1723 - accuracy: 0.9396\n",
            "Epoch 1386: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1725 - accuracy: 0.9396 - val_loss: 0.8884 - val_accuracy: 0.8342\n",
            "Epoch 1387/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1901 - accuracy: 0.9306\n",
            "Epoch 1387: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1892 - accuracy: 0.9309 - val_loss: 0.8762 - val_accuracy: 0.8435\n",
            "Epoch 1388/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1585 - accuracy: 0.9449\n",
            "Epoch 1388: val_accuracy did not improve from 0.84667\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1585 - accuracy: 0.9449 - val_loss: 0.9560 - val_accuracy: 0.8220\n",
            "Epoch 1389/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1539 - accuracy: 0.9459\n",
            "Epoch 1389: val_accuracy improved from 0.84667 to 0.85115, saving model to /content/asl1/Adam4/cp-1389-0.85.hdf5\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1539 - accuracy: 0.9459 - val_loss: 0.8379 - val_accuracy: 0.8512\n",
            "Epoch 1390/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1939 - accuracy: 0.9299\n",
            "Epoch 1390: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1937 - accuracy: 0.9297 - val_loss: 0.9608 - val_accuracy: 0.8163\n",
            "Epoch 1391/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1887 - accuracy: 0.9321\n",
            "Epoch 1391: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1889 - accuracy: 0.9316 - val_loss: 0.9807 - val_accuracy: 0.8156\n",
            "Epoch 1392/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2619 - accuracy: 0.9041\n",
            "Epoch 1392: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2593 - accuracy: 0.9052 - val_loss: 0.9968 - val_accuracy: 0.8009\n",
            "Epoch 1393/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2578 - accuracy: 0.9086\n",
            "Epoch 1393: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2578 - accuracy: 0.9086 - val_loss: 1.1425 - val_accuracy: 0.7859\n",
            "Epoch 1394/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.4962 - accuracy: 0.8627\n",
            "Epoch 1394: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4723 - accuracy: 0.8677 - val_loss: 0.9185 - val_accuracy: 0.8303\n",
            "Epoch 1395/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1645 - accuracy: 0.9420\n",
            "Epoch 1395: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1651 - accuracy: 0.9418 - val_loss: 0.8840 - val_accuracy: 0.8406\n",
            "Epoch 1396/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1683 - accuracy: 0.9406\n",
            "Epoch 1396: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1687 - accuracy: 0.9403 - val_loss: 0.9492 - val_accuracy: 0.8259\n",
            "Epoch 1397/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1772 - accuracy: 0.9342\n",
            "Epoch 1397: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1772 - accuracy: 0.9342 - val_loss: 0.9339 - val_accuracy: 0.8297\n",
            "Epoch 1398/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2279 - accuracy: 0.9152\n",
            "Epoch 1398: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2279 - accuracy: 0.9152 - val_loss: 1.1577 - val_accuracy: 0.7794\n",
            "Epoch 1399/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2332 - accuracy: 0.9147\n",
            "Epoch 1399: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2326 - accuracy: 0.9151 - val_loss: 0.9989 - val_accuracy: 0.8051\n",
            "Epoch 1400/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1842 - accuracy: 0.9342\n",
            "Epoch 1400: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1842 - accuracy: 0.9343 - val_loss: 0.8851 - val_accuracy: 0.8332\n",
            "Epoch 1401/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2286 - accuracy: 0.9174\n",
            "Epoch 1401: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2314 - accuracy: 0.9157 - val_loss: 1.0256 - val_accuracy: 0.7999\n",
            "Epoch 1402/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2295 - accuracy: 0.9169\n",
            "Epoch 1402: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2295 - accuracy: 0.9169 - val_loss: 0.9534 - val_accuracy: 0.8236\n",
            "Epoch 1403/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1826 - accuracy: 0.9329\n",
            "Epoch 1403: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1841 - accuracy: 0.9329 - val_loss: 0.9379 - val_accuracy: 0.8239\n",
            "Epoch 1404/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.1878 - accuracy: 0.9316\n",
            "Epoch 1404: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1851 - accuracy: 0.9329 - val_loss: 0.8792 - val_accuracy: 0.8396\n",
            "Epoch 1405/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3310 - accuracy: 0.8966\n",
            "Epoch 1405: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3423 - accuracy: 0.8924 - val_loss: 1.3548 - val_accuracy: 0.7497\n",
            "Epoch 1406/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2497 - accuracy: 0.9110\n",
            "Epoch 1406: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2493 - accuracy: 0.9110 - val_loss: 0.9768 - val_accuracy: 0.8182\n",
            "Epoch 1407/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1893 - accuracy: 0.9329\n",
            "Epoch 1407: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1898 - accuracy: 0.9327 - val_loss: 0.9200 - val_accuracy: 0.8345\n",
            "Epoch 1408/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2398 - accuracy: 0.9099\n",
            "Epoch 1408: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2406 - accuracy: 0.9095 - val_loss: 0.9555 - val_accuracy: 0.8195\n",
            "Epoch 1409/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2602 - accuracy: 0.9090\n",
            "Epoch 1409: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2602 - accuracy: 0.9090 - val_loss: 1.1228 - val_accuracy: 0.7865\n",
            "Epoch 1410/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2499 - accuracy: 0.9072\n",
            "Epoch 1410: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2463 - accuracy: 0.9082 - val_loss: 0.9579 - val_accuracy: 0.8239\n",
            "Epoch 1411/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2231 - accuracy: 0.9212\n",
            "Epoch 1411: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2205 - accuracy: 0.9217 - val_loss: 0.9073 - val_accuracy: 0.8297\n",
            "Epoch 1412/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1825 - accuracy: 0.9360\n",
            "Epoch 1412: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1847 - accuracy: 0.9356 - val_loss: 0.9061 - val_accuracy: 0.8319\n",
            "Epoch 1413/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2636 - accuracy: 0.9074\n",
            "Epoch 1413: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2605 - accuracy: 0.9085 - val_loss: 0.9199 - val_accuracy: 0.8300\n",
            "Epoch 1414/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1653 - accuracy: 0.9398\n",
            "Epoch 1414: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1683 - accuracy: 0.9386 - val_loss: 0.8889 - val_accuracy: 0.8409\n",
            "Epoch 1415/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1838 - accuracy: 0.9346\n",
            "Epoch 1415: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1835 - accuracy: 0.9345 - val_loss: 1.0824 - val_accuracy: 0.8012\n",
            "Epoch 1416/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2069 - accuracy: 0.9230\n",
            "Epoch 1416: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2023 - accuracy: 0.9250 - val_loss: 0.8688 - val_accuracy: 0.8448\n",
            "Epoch 1417/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1959 - accuracy: 0.9281\n",
            "Epoch 1417: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1978 - accuracy: 0.9274 - val_loss: 0.9453 - val_accuracy: 0.8316\n",
            "Epoch 1418/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2296 - accuracy: 0.9179\n",
            "Epoch 1418: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2383 - accuracy: 0.9155 - val_loss: 1.3332 - val_accuracy: 0.7612\n",
            "Epoch 1419/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2971 - accuracy: 0.8981\n",
            "Epoch 1419: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2971 - accuracy: 0.8981 - val_loss: 1.0063 - val_accuracy: 0.8127\n",
            "Epoch 1420/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2250 - accuracy: 0.9166\n",
            "Epoch 1420: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2254 - accuracy: 0.9165 - val_loss: 1.0878 - val_accuracy: 0.7999\n",
            "Epoch 1421/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2508 - accuracy: 0.9064\n",
            "Epoch 1421: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2477 - accuracy: 0.9077 - val_loss: 0.9797 - val_accuracy: 0.8163\n",
            "Epoch 1422/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1964 - accuracy: 0.9283\n",
            "Epoch 1422: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1958 - accuracy: 0.9287 - val_loss: 0.9665 - val_accuracy: 0.8214\n",
            "Epoch 1423/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1709 - accuracy: 0.9387\n",
            "Epoch 1423: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1709 - accuracy: 0.9387 - val_loss: 0.9583 - val_accuracy: 0.8223\n",
            "Epoch 1424/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2912 - accuracy: 0.8992\n",
            "Epoch 1424: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2928 - accuracy: 0.8984 - val_loss: 1.1190 - val_accuracy: 0.7926\n",
            "Epoch 1425/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1966 - accuracy: 0.9324\n",
            "Epoch 1425: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2048 - accuracy: 0.9289 - val_loss: 1.0397 - val_accuracy: 0.8038\n",
            "Epoch 1426/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2129 - accuracy: 0.9231\n",
            "Epoch 1426: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2120 - accuracy: 0.9235 - val_loss: 1.0358 - val_accuracy: 0.8028\n",
            "Epoch 1427/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2366 - accuracy: 0.9141\n",
            "Epoch 1427: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2396 - accuracy: 0.9125 - val_loss: 1.0971 - val_accuracy: 0.7977\n",
            "Epoch 1428/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2420 - accuracy: 0.9165\n",
            "Epoch 1428: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2420 - accuracy: 0.9165 - val_loss: 1.1192 - val_accuracy: 0.7814\n",
            "Epoch 1429/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3210 - accuracy: 0.8905\n",
            "Epoch 1429: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3182 - accuracy: 0.8916 - val_loss: 1.1333 - val_accuracy: 0.7939\n",
            "Epoch 1430/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1792 - accuracy: 0.9371\n",
            "Epoch 1430: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1771 - accuracy: 0.9370 - val_loss: 0.9829 - val_accuracy: 0.8217\n",
            "Epoch 1431/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1998 - accuracy: 0.9288\n",
            "Epoch 1431: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2049 - accuracy: 0.9273 - val_loss: 1.0657 - val_accuracy: 0.7945\n",
            "Epoch 1432/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1697 - accuracy: 0.9401\n",
            "Epoch 1432: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1721 - accuracy: 0.9393 - val_loss: 0.9217 - val_accuracy: 0.8332\n",
            "Epoch 1433/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2063 - accuracy: 0.9255\n",
            "Epoch 1433: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2059 - accuracy: 0.9260 - val_loss: 0.9428 - val_accuracy: 0.8310\n",
            "Epoch 1434/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2524 - accuracy: 0.9106\n",
            "Epoch 1434: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2479 - accuracy: 0.9120 - val_loss: 0.9425 - val_accuracy: 0.8214\n",
            "Epoch 1435/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2284 - accuracy: 0.9170\n",
            "Epoch 1435: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2278 - accuracy: 0.9172 - val_loss: 1.0588 - val_accuracy: 0.7983\n",
            "Epoch 1436/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.4665 - accuracy: 0.8668\n",
            "Epoch 1436: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.4669 - accuracy: 0.8660 - val_loss: 0.9784 - val_accuracy: 0.8214\n",
            "Epoch 1437/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2186 - accuracy: 0.9221\n",
            "Epoch 1437: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2170 - accuracy: 0.9229 - val_loss: 0.9148 - val_accuracy: 0.8310\n",
            "Epoch 1438/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1828 - accuracy: 0.9363\n",
            "Epoch 1438: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1823 - accuracy: 0.9362 - val_loss: 0.9178 - val_accuracy: 0.8281\n",
            "Epoch 1439/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1615 - accuracy: 0.9432\n",
            "Epoch 1439: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1615 - accuracy: 0.9432 - val_loss: 0.8644 - val_accuracy: 0.8499\n",
            "Epoch 1440/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1534 - accuracy: 0.9475\n",
            "Epoch 1440: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1569 - accuracy: 0.9459 - val_loss: 0.9595 - val_accuracy: 0.8275\n",
            "Epoch 1441/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1780 - accuracy: 0.9344\n",
            "Epoch 1441: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1794 - accuracy: 0.9337 - val_loss: 0.9462 - val_accuracy: 0.8319\n",
            "Epoch 1442/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1828 - accuracy: 0.9347\n",
            "Epoch 1442: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1831 - accuracy: 0.9345 - val_loss: 0.8602 - val_accuracy: 0.8460\n",
            "Epoch 1443/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1725 - accuracy: 0.9378\n",
            "Epoch 1443: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1775 - accuracy: 0.9363 - val_loss: 1.4299 - val_accuracy: 0.7270\n",
            "Epoch 1444/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2886 - accuracy: 0.8981\n",
            "Epoch 1444: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2886 - accuracy: 0.8981 - val_loss: 0.9165 - val_accuracy: 0.8294\n",
            "Epoch 1445/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2998 - accuracy: 0.8982\n",
            "Epoch 1445: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2999 - accuracy: 0.8983 - val_loss: 1.1455 - val_accuracy: 0.7887\n",
            "Epoch 1446/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1741 - accuracy: 0.9390\n",
            "Epoch 1446: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1736 - accuracy: 0.9393 - val_loss: 1.0432 - val_accuracy: 0.7964\n",
            "Epoch 1447/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1706 - accuracy: 0.9384\n",
            "Epoch 1447: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1696 - accuracy: 0.9378 - val_loss: 0.9204 - val_accuracy: 0.8297\n",
            "Epoch 1448/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1908 - accuracy: 0.9302\n",
            "Epoch 1448: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1906 - accuracy: 0.9304 - val_loss: 0.9456 - val_accuracy: 0.8265\n",
            "Epoch 1449/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1420 - accuracy: 0.9498\n",
            "Epoch 1449: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1411 - accuracy: 0.9504 - val_loss: 0.9339 - val_accuracy: 0.8329\n",
            "Epoch 1450/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1739 - accuracy: 0.9394\n",
            "Epoch 1450: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1734 - accuracy: 0.9393 - val_loss: 0.9586 - val_accuracy: 0.8243\n",
            "Epoch 1451/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2462 - accuracy: 0.9085\n",
            "Epoch 1451: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2461 - accuracy: 0.9085 - val_loss: 1.0420 - val_accuracy: 0.8156\n",
            "Epoch 1452/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2588 - accuracy: 0.9055\n",
            "Epoch 1452: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2653 - accuracy: 0.9039 - val_loss: 1.2112 - val_accuracy: 0.7660\n",
            "Epoch 1453/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.4125 - accuracy: 0.8690\n",
            "Epoch 1453: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4086 - accuracy: 0.8702 - val_loss: 0.9874 - val_accuracy: 0.8108\n",
            "Epoch 1454/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1785 - accuracy: 0.9336\n",
            "Epoch 1454: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1780 - accuracy: 0.9336 - val_loss: 0.9132 - val_accuracy: 0.8319\n",
            "Epoch 1455/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2347 - accuracy: 0.9205\n",
            "Epoch 1455: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2443 - accuracy: 0.9166 - val_loss: 1.3362 - val_accuracy: 0.7394\n",
            "Epoch 1456/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2804 - accuracy: 0.9008\n",
            "Epoch 1456: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2804 - accuracy: 0.9008 - val_loss: 1.1259 - val_accuracy: 0.7750\n",
            "Epoch 1457/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1881 - accuracy: 0.9312\n",
            "Epoch 1457: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1868 - accuracy: 0.9317 - val_loss: 0.8622 - val_accuracy: 0.8483\n",
            "Epoch 1458/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1541 - accuracy: 0.9456\n",
            "Epoch 1458: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1574 - accuracy: 0.9445 - val_loss: 1.0061 - val_accuracy: 0.8051\n",
            "Epoch 1459/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1931 - accuracy: 0.9323\n",
            "Epoch 1459: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1913 - accuracy: 0.9323 - val_loss: 0.9066 - val_accuracy: 0.8339\n",
            "Epoch 1460/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1559 - accuracy: 0.9449\n",
            "Epoch 1460: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1608 - accuracy: 0.9430 - val_loss: 0.8842 - val_accuracy: 0.8415\n",
            "Epoch 1461/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2446 - accuracy: 0.9113\n",
            "Epoch 1461: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2446 - accuracy: 0.9113 - val_loss: 1.0479 - val_accuracy: 0.7999\n",
            "Epoch 1462/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1848 - accuracy: 0.9321\n",
            "Epoch 1462: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1827 - accuracy: 0.9325 - val_loss: 0.8765 - val_accuracy: 0.8409\n",
            "Epoch 1463/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2073 - accuracy: 0.9266\n",
            "Epoch 1463: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2073 - accuracy: 0.9266 - val_loss: 0.9472 - val_accuracy: 0.8211\n",
            "Epoch 1464/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1832 - accuracy: 0.9340\n",
            "Epoch 1464: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1821 - accuracy: 0.9346 - val_loss: 0.8910 - val_accuracy: 0.8323\n",
            "Epoch 1465/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3529 - accuracy: 0.8784\n",
            "Epoch 1465: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3457 - accuracy: 0.8812 - val_loss: 0.9284 - val_accuracy: 0.8230\n",
            "Epoch 1466/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2861 - accuracy: 0.8985\n",
            "Epoch 1466: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2859 - accuracy: 0.8984 - val_loss: 1.1397 - val_accuracy: 0.7762\n",
            "Epoch 1467/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2101 - accuracy: 0.9220\n",
            "Epoch 1467: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2150 - accuracy: 0.9205 - val_loss: 1.0515 - val_accuracy: 0.8031\n",
            "Epoch 1468/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.2646 - accuracy: 0.9027\n",
            "Epoch 1468: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2590 - accuracy: 0.9048 - val_loss: 1.0160 - val_accuracy: 0.7983\n",
            "Epoch 1469/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1996 - accuracy: 0.9254\n",
            "Epoch 1469: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2022 - accuracy: 0.9242 - val_loss: 1.1402 - val_accuracy: 0.7903\n",
            "Epoch 1470/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1805 - accuracy: 0.9340\n",
            "Epoch 1470: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1806 - accuracy: 0.9341 - val_loss: 1.0200 - val_accuracy: 0.8060\n",
            "Epoch 1471/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1869 - accuracy: 0.9305\n",
            "Epoch 1471: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1868 - accuracy: 0.9309 - val_loss: 1.0255 - val_accuracy: 0.8095\n",
            "Epoch 1472/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2063 - accuracy: 0.9226\n",
            "Epoch 1472: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2087 - accuracy: 0.9217 - val_loss: 1.0489 - val_accuracy: 0.8028\n",
            "Epoch 1473/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2025 - accuracy: 0.9274\n",
            "Epoch 1473: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2025 - accuracy: 0.9274 - val_loss: 0.9587 - val_accuracy: 0.8239\n",
            "Epoch 1474/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1922 - accuracy: 0.9300\n",
            "Epoch 1474: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1924 - accuracy: 0.9299 - val_loss: 0.9994 - val_accuracy: 0.8156\n",
            "Epoch 1475/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1566 - accuracy: 0.9454\n",
            "Epoch 1475: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1569 - accuracy: 0.9452 - val_loss: 1.0028 - val_accuracy: 0.8198\n",
            "Epoch 1476/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1788 - accuracy: 0.9345\n",
            "Epoch 1476: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1810 - accuracy: 0.9340 - val_loss: 1.0914 - val_accuracy: 0.7990\n",
            "Epoch 1477/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2706 - accuracy: 0.9000\n",
            "Epoch 1477: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2677 - accuracy: 0.9011 - val_loss: 0.9427 - val_accuracy: 0.8339\n",
            "Epoch 1478/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2434 - accuracy: 0.9126\n",
            "Epoch 1478: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2416 - accuracy: 0.9131 - val_loss: 0.9644 - val_accuracy: 0.8278\n",
            "Epoch 1479/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2585 - accuracy: 0.9067\n",
            "Epoch 1479: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2606 - accuracy: 0.9060 - val_loss: 1.0355 - val_accuracy: 0.8060\n",
            "Epoch 1480/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2211 - accuracy: 0.9195\n",
            "Epoch 1480: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2179 - accuracy: 0.9209 - val_loss: 0.9319 - val_accuracy: 0.8371\n",
            "Epoch 1481/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1588 - accuracy: 0.9441\n",
            "Epoch 1481: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1621 - accuracy: 0.9431 - val_loss: 0.8930 - val_accuracy: 0.8323\n",
            "Epoch 1482/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1609 - accuracy: 0.9417\n",
            "Epoch 1482: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1610 - accuracy: 0.9414 - val_loss: 0.9428 - val_accuracy: 0.8294\n",
            "Epoch 1483/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1714 - accuracy: 0.9373\n",
            "Epoch 1483: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1711 - accuracy: 0.9376 - val_loss: 0.9666 - val_accuracy: 0.8297\n",
            "Epoch 1484/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2188 - accuracy: 0.9199\n",
            "Epoch 1484: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2213 - accuracy: 0.9188 - val_loss: 1.0324 - val_accuracy: 0.8044\n",
            "Epoch 1485/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1951 - accuracy: 0.9272\n",
            "Epoch 1485: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1933 - accuracy: 0.9281 - val_loss: 0.9180 - val_accuracy: 0.8374\n",
            "Epoch 1486/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2174 - accuracy: 0.9213\n",
            "Epoch 1486: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2313 - accuracy: 0.9177 - val_loss: 1.4840 - val_accuracy: 0.7414\n",
            "Epoch 1487/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.4871 - accuracy: 0.8532\n",
            "Epoch 1487: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4758 - accuracy: 0.8552 - val_loss: 1.1860 - val_accuracy: 0.7804\n",
            "Epoch 1488/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2596 - accuracy: 0.9039\n",
            "Epoch 1488: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2589 - accuracy: 0.9044 - val_loss: 1.0072 - val_accuracy: 0.8207\n",
            "Epoch 1489/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1818 - accuracy: 0.9320\n",
            "Epoch 1489: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1788 - accuracy: 0.9337 - val_loss: 0.9166 - val_accuracy: 0.8348\n",
            "Epoch 1490/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1499 - accuracy: 0.9486\n",
            "Epoch 1490: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1519 - accuracy: 0.9480 - val_loss: 1.0561 - val_accuracy: 0.7923\n",
            "Epoch 1491/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1899 - accuracy: 0.9305\n",
            "Epoch 1491: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1893 - accuracy: 0.9305 - val_loss: 0.9510 - val_accuracy: 0.8239\n",
            "Epoch 1492/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2542 - accuracy: 0.9112\n",
            "Epoch 1492: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2527 - accuracy: 0.9119 - val_loss: 1.0249 - val_accuracy: 0.8076\n",
            "Epoch 1493/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2005 - accuracy: 0.9287\n",
            "Epoch 1493: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2018 - accuracy: 0.9280 - val_loss: 0.8826 - val_accuracy: 0.8428\n",
            "Epoch 1494/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1981 - accuracy: 0.9262\n",
            "Epoch 1494: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1964 - accuracy: 0.9266 - val_loss: 0.9258 - val_accuracy: 0.8268\n",
            "Epoch 1495/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1605 - accuracy: 0.9454\n",
            "Epoch 1495: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1611 - accuracy: 0.9449 - val_loss: 0.9156 - val_accuracy: 0.8246\n",
            "Epoch 1496/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1766 - accuracy: 0.9360\n",
            "Epoch 1496: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1766 - accuracy: 0.9361 - val_loss: 0.9228 - val_accuracy: 0.8255\n",
            "Epoch 1497/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1761 - accuracy: 0.9368\n",
            "Epoch 1497: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1762 - accuracy: 0.9366 - val_loss: 0.9716 - val_accuracy: 0.8195\n",
            "Epoch 1498/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1534 - accuracy: 0.9471\n",
            "Epoch 1498: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.1556 - accuracy: 0.9461 - val_loss: 0.9738 - val_accuracy: 0.8243\n",
            "Epoch 1499/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2571 - accuracy: 0.9053\n",
            "Epoch 1499: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2571 - accuracy: 0.9053 - val_loss: 1.1770 - val_accuracy: 0.7718\n",
            "Epoch 1500/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2026 - accuracy: 0.9257\n",
            "Epoch 1500: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2020 - accuracy: 0.9259 - val_loss: 0.9274 - val_accuracy: 0.8390\n",
            "Epoch 1501/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.1835 - accuracy: 0.9322\n",
            "Epoch 1501: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1817 - accuracy: 0.9326 - val_loss: 0.9162 - val_accuracy: 0.8387\n",
            "Epoch 1502/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.5853 - accuracy: 0.8485\n",
            "Epoch 1502: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.5647 - accuracy: 0.8520 - val_loss: 0.9954 - val_accuracy: 0.8220\n",
            "Epoch 1503/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1789 - accuracy: 0.9372\n",
            "Epoch 1503: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1774 - accuracy: 0.9379 - val_loss: 0.8639 - val_accuracy: 0.8435\n",
            "Epoch 1504/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1532 - accuracy: 0.9451\n",
            "Epoch 1504: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1534 - accuracy: 0.9453 - val_loss: 0.8818 - val_accuracy: 0.8476\n",
            "Epoch 1505/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1496 - accuracy: 0.9473\n",
            "Epoch 1505: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1492 - accuracy: 0.9474 - val_loss: 0.9753 - val_accuracy: 0.8204\n",
            "Epoch 1506/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2319 - accuracy: 0.9173\n",
            "Epoch 1506: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2262 - accuracy: 0.9198 - val_loss: 0.8744 - val_accuracy: 0.8483\n",
            "Epoch 1507/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1659 - accuracy: 0.9395\n",
            "Epoch 1507: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1660 - accuracy: 0.9395 - val_loss: 0.8908 - val_accuracy: 0.8406\n",
            "Epoch 1508/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1567 - accuracy: 0.9419\n",
            "Epoch 1508: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1583 - accuracy: 0.9408 - val_loss: 1.0589 - val_accuracy: 0.7999\n",
            "Epoch 1509/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1603 - accuracy: 0.9417\n",
            "Epoch 1509: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1605 - accuracy: 0.9413 - val_loss: 0.9546 - val_accuracy: 0.8284\n",
            "Epoch 1510/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1654 - accuracy: 0.9396\n",
            "Epoch 1510: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1663 - accuracy: 0.9394 - val_loss: 1.0691 - val_accuracy: 0.7945\n",
            "Epoch 1511/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2174 - accuracy: 0.9187\n",
            "Epoch 1511: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2279 - accuracy: 0.9149 - val_loss: 1.1092 - val_accuracy: 0.7964\n",
            "Epoch 1512/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2083 - accuracy: 0.9243\n",
            "Epoch 1512: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2084 - accuracy: 0.9243 - val_loss: 0.9612 - val_accuracy: 0.8230\n",
            "Epoch 1513/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2153 - accuracy: 0.9230\n",
            "Epoch 1513: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2166 - accuracy: 0.9225 - val_loss: 0.9286 - val_accuracy: 0.8342\n",
            "Epoch 1514/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2128 - accuracy: 0.9185\n",
            "Epoch 1514: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2165 - accuracy: 0.9174 - val_loss: 1.0978 - val_accuracy: 0.7945\n",
            "Epoch 1515/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3087 - accuracy: 0.8944\n",
            "Epoch 1515: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3140 - accuracy: 0.8940 - val_loss: 1.7284 - val_accuracy: 0.7042\n",
            "Epoch 1516/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.4457 - accuracy: 0.8534\n",
            "Epoch 1516: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4346 - accuracy: 0.8562 - val_loss: 1.1187 - val_accuracy: 0.7855\n",
            "Epoch 1517/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1835 - accuracy: 0.9356\n",
            "Epoch 1517: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1834 - accuracy: 0.9357 - val_loss: 0.8822 - val_accuracy: 0.8480\n",
            "Epoch 1518/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1594 - accuracy: 0.9433\n",
            "Epoch 1518: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1594 - accuracy: 0.9433 - val_loss: 0.9205 - val_accuracy: 0.8358\n",
            "Epoch 1519/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1843 - accuracy: 0.9332\n",
            "Epoch 1519: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1834 - accuracy: 0.9337 - val_loss: 0.9842 - val_accuracy: 0.8223\n",
            "Epoch 1520/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1957 - accuracy: 0.9282\n",
            "Epoch 1520: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1949 - accuracy: 0.9286 - val_loss: 0.9871 - val_accuracy: 0.8243\n",
            "Epoch 1521/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1551 - accuracy: 0.9446\n",
            "Epoch 1521: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1571 - accuracy: 0.9440 - val_loss: 0.8728 - val_accuracy: 0.8508\n",
            "Epoch 1522/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1995 - accuracy: 0.9278\n",
            "Epoch 1522: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2028 - accuracy: 0.9269 - val_loss: 1.0306 - val_accuracy: 0.8166\n",
            "Epoch 1523/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1759 - accuracy: 0.9379\n",
            "Epoch 1523: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1765 - accuracy: 0.9373 - val_loss: 0.9683 - val_accuracy: 0.8262\n",
            "Epoch 1524/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1845 - accuracy: 0.9331\n",
            "Epoch 1524: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1845 - accuracy: 0.9331 - val_loss: 0.9262 - val_accuracy: 0.8339\n",
            "Epoch 1525/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2272 - accuracy: 0.9204\n",
            "Epoch 1525: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2265 - accuracy: 0.9197 - val_loss: 1.0333 - val_accuracy: 0.8111\n",
            "Epoch 1526/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1868 - accuracy: 0.9310\n",
            "Epoch 1526: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1848 - accuracy: 0.9318 - val_loss: 0.9268 - val_accuracy: 0.8374\n",
            "Epoch 1527/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2904 - accuracy: 0.8973\n",
            "Epoch 1527: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3139 - accuracy: 0.8918 - val_loss: 1.2960 - val_accuracy: 0.7682\n",
            "Epoch 1528/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3271 - accuracy: 0.8833\n",
            "Epoch 1528: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3199 - accuracy: 0.8858 - val_loss: 0.9459 - val_accuracy: 0.8236\n",
            "Epoch 1529/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1808 - accuracy: 0.9343\n",
            "Epoch 1529: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1771 - accuracy: 0.9359 - val_loss: 0.9045 - val_accuracy: 0.8431\n",
            "Epoch 1530/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1527 - accuracy: 0.9477\n",
            "Epoch 1530: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1561 - accuracy: 0.9458 - val_loss: 0.9151 - val_accuracy: 0.8348\n",
            "Epoch 1531/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1509 - accuracy: 0.9446\n",
            "Epoch 1531: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1505 - accuracy: 0.9448 - val_loss: 0.9624 - val_accuracy: 0.8223\n",
            "Epoch 1532/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1809 - accuracy: 0.9347\n",
            "Epoch 1532: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1805 - accuracy: 0.9349 - val_loss: 0.9660 - val_accuracy: 0.8351\n",
            "Epoch 1533/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2169 - accuracy: 0.9200\n",
            "Epoch 1533: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2159 - accuracy: 0.9198 - val_loss: 0.9820 - val_accuracy: 0.8201\n",
            "Epoch 1534/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3287 - accuracy: 0.8887\n",
            "Epoch 1534: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3260 - accuracy: 0.8892 - val_loss: 1.0281 - val_accuracy: 0.8054\n",
            "Epoch 1535/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2083 - accuracy: 0.9222\n",
            "Epoch 1535: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2091 - accuracy: 0.9211 - val_loss: 1.1209 - val_accuracy: 0.7926\n",
            "Epoch 1536/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2274 - accuracy: 0.9177\n",
            "Epoch 1536: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2248 - accuracy: 0.9179 - val_loss: 0.9451 - val_accuracy: 0.8371\n",
            "Epoch 1537/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1630 - accuracy: 0.9402\n",
            "Epoch 1537: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1645 - accuracy: 0.9394 - val_loss: 0.9012 - val_accuracy: 0.8383\n",
            "Epoch 1538/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2474 - accuracy: 0.9132\n",
            "Epoch 1538: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2420 - accuracy: 0.9150 - val_loss: 0.9545 - val_accuracy: 0.8243\n",
            "Epoch 1539/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2498 - accuracy: 0.9175\n",
            "Epoch 1539: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2744 - accuracy: 0.9110 - val_loss: 1.2897 - val_accuracy: 0.7711\n",
            "Epoch 1540/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2469 - accuracy: 0.9092\n",
            "Epoch 1540: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2422 - accuracy: 0.9109 - val_loss: 0.9675 - val_accuracy: 0.8259\n",
            "Epoch 1541/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1596 - accuracy: 0.9429\n",
            "Epoch 1541: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1606 - accuracy: 0.9426 - val_loss: 0.9241 - val_accuracy: 0.8396\n",
            "Epoch 1542/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1589 - accuracy: 0.9430\n",
            "Epoch 1542: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1604 - accuracy: 0.9424 - val_loss: 1.0042 - val_accuracy: 0.8188\n",
            "Epoch 1543/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2286 - accuracy: 0.9169\n",
            "Epoch 1543: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2289 - accuracy: 0.9172 - val_loss: 1.1303 - val_accuracy: 0.7939\n",
            "Epoch 1544/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2135 - accuracy: 0.9238\n",
            "Epoch 1544: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2132 - accuracy: 0.9237 - val_loss: 0.9655 - val_accuracy: 0.8265\n",
            "Epoch 1545/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1671 - accuracy: 0.9413\n",
            "Epoch 1545: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1718 - accuracy: 0.9392 - val_loss: 1.1366 - val_accuracy: 0.7907\n",
            "Epoch 1546/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2265 - accuracy: 0.9197\n",
            "Epoch 1546: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2265 - accuracy: 0.9197 - val_loss: 0.9320 - val_accuracy: 0.8374\n",
            "Epoch 1547/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1637 - accuracy: 0.9424\n",
            "Epoch 1547: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1605 - accuracy: 0.9435 - val_loss: 0.8816 - val_accuracy: 0.8473\n",
            "Epoch 1548/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1682 - accuracy: 0.9399\n",
            "Epoch 1548: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1672 - accuracy: 0.9405 - val_loss: 0.9156 - val_accuracy: 0.8319\n",
            "Epoch 1549/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1735 - accuracy: 0.9389\n",
            "Epoch 1549: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1754 - accuracy: 0.9377 - val_loss: 1.0291 - val_accuracy: 0.8118\n",
            "Epoch 1550/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2349 - accuracy: 0.9163\n",
            "Epoch 1550: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2349 - accuracy: 0.9163 - val_loss: 1.1970 - val_accuracy: 0.7830\n",
            "Epoch 1551/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1840 - accuracy: 0.9319\n",
            "Epoch 1551: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1840 - accuracy: 0.9319 - val_loss: 0.9151 - val_accuracy: 0.8435\n",
            "Epoch 1552/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1805 - accuracy: 0.9330\n",
            "Epoch 1552: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1807 - accuracy: 0.9330 - val_loss: 0.9774 - val_accuracy: 0.8262\n",
            "Epoch 1553/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2084 - accuracy: 0.9238\n",
            "Epoch 1553: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2031 - accuracy: 0.9262 - val_loss: 0.9599 - val_accuracy: 0.8364\n",
            "Epoch 1554/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1861 - accuracy: 0.9342\n",
            "Epoch 1554: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1833 - accuracy: 0.9357 - val_loss: 0.9369 - val_accuracy: 0.8342\n",
            "Epoch 1555/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1705 - accuracy: 0.9377\n",
            "Epoch 1555: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1705 - accuracy: 0.9376 - val_loss: 1.0347 - val_accuracy: 0.8134\n",
            "Epoch 1556/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3438 - accuracy: 0.8821\n",
            "Epoch 1556: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3440 - accuracy: 0.8816 - val_loss: 1.1841 - val_accuracy: 0.7878\n",
            "Epoch 1557/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.5911 - accuracy: 0.8336\n",
            "Epoch 1557: val_accuracy did not improve from 0.85115\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.5728 - accuracy: 0.8377 - val_loss: 1.1134 - val_accuracy: 0.7990\n",
            "Epoch 1558/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1683 - accuracy: 0.9370\n",
            "Epoch 1558: val_accuracy improved from 0.85115 to 0.85243, saving model to /content/asl1/Adam4/cp-1558-0.85.hdf5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1679 - accuracy: 0.9372 - val_loss: 0.8835 - val_accuracy: 0.8524\n",
            "Epoch 1559/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1622 - accuracy: 0.9408\n",
            "Epoch 1559: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1614 - accuracy: 0.9411 - val_loss: 0.9734 - val_accuracy: 0.8316\n",
            "Epoch 1560/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.1995 - accuracy: 0.9264\n",
            "Epoch 1560: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1991 - accuracy: 0.9258 - val_loss: 0.9840 - val_accuracy: 0.8227\n",
            "Epoch 1561/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1537 - accuracy: 0.9454\n",
            "Epoch 1561: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1563 - accuracy: 0.9436 - val_loss: 0.9068 - val_accuracy: 0.8371\n",
            "Epoch 1562/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1667 - accuracy: 0.9415\n",
            "Epoch 1562: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1658 - accuracy: 0.9409 - val_loss: 0.9805 - val_accuracy: 0.8195\n",
            "Epoch 1563/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2357 - accuracy: 0.9175\n",
            "Epoch 1563: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2365 - accuracy: 0.9166 - val_loss: 1.1110 - val_accuracy: 0.7983\n",
            "Epoch 1564/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2201 - accuracy: 0.9196\n",
            "Epoch 1564: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2203 - accuracy: 0.9197 - val_loss: 0.9047 - val_accuracy: 0.8425\n",
            "Epoch 1565/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.1607 - accuracy: 0.9407\n",
            "Epoch 1565: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1578 - accuracy: 0.9418 - val_loss: 0.8766 - val_accuracy: 0.8473\n",
            "Epoch 1566/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2222 - accuracy: 0.9216\n",
            "Epoch 1566: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2222 - accuracy: 0.9213 - val_loss: 0.9981 - val_accuracy: 0.8236\n",
            "Epoch 1567/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.2082 - accuracy: 0.9255\n",
            "Epoch 1567: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2125 - accuracy: 0.9237 - val_loss: 0.9979 - val_accuracy: 0.8185\n",
            "Epoch 1568/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1676 - accuracy: 0.9381\n",
            "Epoch 1568: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1678 - accuracy: 0.9381 - val_loss: 1.1176 - val_accuracy: 0.7932\n",
            "Epoch 1569/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2446 - accuracy: 0.9155\n",
            "Epoch 1569: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2419 - accuracy: 0.9163 - val_loss: 1.0507 - val_accuracy: 0.8163\n",
            "Epoch 1570/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1884 - accuracy: 0.9298\n",
            "Epoch 1570: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1886 - accuracy: 0.9297 - val_loss: 0.9643 - val_accuracy: 0.8335\n",
            "Epoch 1571/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3581 - accuracy: 0.8797\n",
            "Epoch 1571: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3586 - accuracy: 0.8796 - val_loss: 1.3475 - val_accuracy: 0.7522\n",
            "Epoch 1572/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2918 - accuracy: 0.8984\n",
            "Epoch 1572: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2881 - accuracy: 0.8993 - val_loss: 1.0619 - val_accuracy: 0.8054\n",
            "Epoch 1573/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1575 - accuracy: 0.9456\n",
            "Epoch 1573: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1586 - accuracy: 0.9450 - val_loss: 0.9474 - val_accuracy: 0.8380\n",
            "Epoch 1574/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1541 - accuracy: 0.9453\n",
            "Epoch 1574: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1541 - accuracy: 0.9453 - val_loss: 0.9177 - val_accuracy: 0.8339\n",
            "Epoch 1575/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1435 - accuracy: 0.9504\n",
            "Epoch 1575: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1447 - accuracy: 0.9497 - val_loss: 0.9546 - val_accuracy: 0.8332\n",
            "Epoch 1576/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1253 - accuracy: 0.9570\n",
            "Epoch 1576: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1259 - accuracy: 0.9568 - val_loss: 0.9121 - val_accuracy: 0.8406\n",
            "Epoch 1577/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1678 - accuracy: 0.9401\n",
            "Epoch 1577: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1679 - accuracy: 0.9397 - val_loss: 0.9698 - val_accuracy: 0.8239\n",
            "Epoch 1578/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1615 - accuracy: 0.9414\n",
            "Epoch 1578: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1638 - accuracy: 0.9402 - val_loss: 1.0543 - val_accuracy: 0.8172\n",
            "Epoch 1579/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2264 - accuracy: 0.9210\n",
            "Epoch 1579: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2261 - accuracy: 0.9209 - val_loss: 0.9141 - val_accuracy: 0.8438\n",
            "Epoch 1580/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1495 - accuracy: 0.9452\n",
            "Epoch 1580: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1491 - accuracy: 0.9456 - val_loss: 0.9475 - val_accuracy: 0.8335\n",
            "Epoch 1581/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1622 - accuracy: 0.9424\n",
            "Epoch 1581: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1621 - accuracy: 0.9422 - val_loss: 0.9213 - val_accuracy: 0.8383\n",
            "Epoch 1582/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2298 - accuracy: 0.9215\n",
            "Epoch 1582: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2272 - accuracy: 0.9225 - val_loss: 1.0799 - val_accuracy: 0.7990\n",
            "Epoch 1583/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2039 - accuracy: 0.9233\n",
            "Epoch 1583: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2021 - accuracy: 0.9241 - val_loss: 0.9228 - val_accuracy: 0.8399\n",
            "Epoch 1584/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2351 - accuracy: 0.9124\n",
            "Epoch 1584: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2352 - accuracy: 0.9123 - val_loss: 1.0278 - val_accuracy: 0.8182\n",
            "Epoch 1585/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3642 - accuracy: 0.8877\n",
            "Epoch 1585: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3761 - accuracy: 0.8839 - val_loss: 1.5720 - val_accuracy: 0.7334\n",
            "Epoch 1586/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2754 - accuracy: 0.9071\n",
            "Epoch 1586: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2751 - accuracy: 0.9072 - val_loss: 0.9184 - val_accuracy: 0.8390\n",
            "Epoch 1587/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1821 - accuracy: 0.9331\n",
            "Epoch 1587: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1821 - accuracy: 0.9331 - val_loss: 0.9362 - val_accuracy: 0.8454\n",
            "Epoch 1588/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1537 - accuracy: 0.9447\n",
            "Epoch 1588: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1543 - accuracy: 0.9446 - val_loss: 0.9693 - val_accuracy: 0.8291\n",
            "Epoch 1589/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1336 - accuracy: 0.9539\n",
            "Epoch 1589: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1340 - accuracy: 0.9537 - val_loss: 0.9936 - val_accuracy: 0.8179\n",
            "Epoch 1590/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1670 - accuracy: 0.9398\n",
            "Epoch 1590: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.1667 - accuracy: 0.9401 - val_loss: 0.9616 - val_accuracy: 0.8390\n",
            "Epoch 1591/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2287 - accuracy: 0.9198\n",
            "Epoch 1591: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2310 - accuracy: 0.9193 - val_loss: 1.0592 - val_accuracy: 0.8163\n",
            "Epoch 1592/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.4871 - accuracy: 0.8484\n",
            "Epoch 1592: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.4790 - accuracy: 0.8504 - val_loss: 0.9845 - val_accuracy: 0.8204\n",
            "Epoch 1593/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1605 - accuracy: 0.9437\n",
            "Epoch 1593: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1597 - accuracy: 0.9440 - val_loss: 0.9429 - val_accuracy: 0.8415\n",
            "Epoch 1594/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1303 - accuracy: 0.9556\n",
            "Epoch 1594: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1308 - accuracy: 0.9550 - val_loss: 0.9207 - val_accuracy: 0.8406\n",
            "Epoch 1595/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1700 - accuracy: 0.9381\n",
            "Epoch 1595: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1682 - accuracy: 0.9389 - val_loss: 0.9540 - val_accuracy: 0.8355\n",
            "Epoch 1596/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1417 - accuracy: 0.9507\n",
            "Epoch 1596: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1417 - accuracy: 0.9507 - val_loss: 0.9455 - val_accuracy: 0.8361\n",
            "Epoch 1597/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3244 - accuracy: 0.8884\n",
            "Epoch 1597: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3217 - accuracy: 0.8891 - val_loss: 1.2485 - val_accuracy: 0.7692\n",
            "Epoch 1598/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2141 - accuracy: 0.9218\n",
            "Epoch 1598: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2141 - accuracy: 0.9218 - val_loss: 0.9819 - val_accuracy: 0.8185\n",
            "Epoch 1599/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1537 - accuracy: 0.9458\n",
            "Epoch 1599: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1536 - accuracy: 0.9459 - val_loss: 0.9301 - val_accuracy: 0.8313\n",
            "Epoch 1600/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1752 - accuracy: 0.9356\n",
            "Epoch 1600: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1835 - accuracy: 0.9329 - val_loss: 1.0581 - val_accuracy: 0.7999\n",
            "Epoch 1601/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1570 - accuracy: 0.9440\n",
            "Epoch 1601: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1563 - accuracy: 0.9444 - val_loss: 0.9330 - val_accuracy: 0.8438\n",
            "Epoch 1602/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1703 - accuracy: 0.9358\n",
            "Epoch 1602: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1689 - accuracy: 0.9366 - val_loss: 0.8923 - val_accuracy: 0.8409\n",
            "Epoch 1603/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.1843 - accuracy: 0.9346\n",
            "Epoch 1603: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1864 - accuracy: 0.9337 - val_loss: 1.0156 - val_accuracy: 0.8102\n",
            "Epoch 1604/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1979 - accuracy: 0.9282\n",
            "Epoch 1604: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1979 - accuracy: 0.9282 - val_loss: 1.0325 - val_accuracy: 0.8201\n",
            "Epoch 1605/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1676 - accuracy: 0.9374\n",
            "Epoch 1605: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1691 - accuracy: 0.9367 - val_loss: 0.9520 - val_accuracy: 0.8329\n",
            "Epoch 1606/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2127 - accuracy: 0.9242\n",
            "Epoch 1606: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2127 - accuracy: 0.9241 - val_loss: 1.0962 - val_accuracy: 0.8044\n",
            "Epoch 1607/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1747 - accuracy: 0.9352\n",
            "Epoch 1607: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1748 - accuracy: 0.9354 - val_loss: 0.9703 - val_accuracy: 0.8271\n",
            "Epoch 1608/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2185 - accuracy: 0.9215\n",
            "Epoch 1608: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2203 - accuracy: 0.9213 - val_loss: 1.1400 - val_accuracy: 0.7878\n",
            "Epoch 1609/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.5746 - accuracy: 0.8391\n",
            "Epoch 1609: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.5749 - accuracy: 0.8389 - val_loss: 1.7412 - val_accuracy: 0.6895\n",
            "Epoch 1610/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2768 - accuracy: 0.9056\n",
            "Epoch 1610: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2741 - accuracy: 0.9065 - val_loss: 0.8936 - val_accuracy: 0.8422\n",
            "Epoch 1611/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1313 - accuracy: 0.9548\n",
            "Epoch 1611: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1324 - accuracy: 0.9541 - val_loss: 0.8872 - val_accuracy: 0.8467\n",
            "Epoch 1612/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1399 - accuracy: 0.9495\n",
            "Epoch 1612: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1410 - accuracy: 0.9488 - val_loss: 0.9816 - val_accuracy: 0.8249\n",
            "Epoch 1613/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1524 - accuracy: 0.9463\n",
            "Epoch 1613: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1531 - accuracy: 0.9454 - val_loss: 1.0121 - val_accuracy: 0.8166\n",
            "Epoch 1614/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1650 - accuracy: 0.9386\n",
            "Epoch 1614: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1661 - accuracy: 0.9383 - val_loss: 0.9697 - val_accuracy: 0.8265\n",
            "Epoch 1615/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1449 - accuracy: 0.9465\n",
            "Epoch 1615: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1455 - accuracy: 0.9465 - val_loss: 1.0036 - val_accuracy: 0.8153\n",
            "Epoch 1616/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2707 - accuracy: 0.9097\n",
            "Epoch 1616: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2840 - accuracy: 0.9056 - val_loss: 1.1088 - val_accuracy: 0.8022\n",
            "Epoch 1617/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2946 - accuracy: 0.8976\n",
            "Epoch 1617: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2946 - accuracy: 0.8976 - val_loss: 0.9205 - val_accuracy: 0.8454\n",
            "Epoch 1618/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1570 - accuracy: 0.9442\n",
            "Epoch 1618: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1570 - accuracy: 0.9442 - val_loss: 0.9993 - val_accuracy: 0.8198\n",
            "Epoch 1619/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1427 - accuracy: 0.9501\n",
            "Epoch 1619: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1428 - accuracy: 0.9501 - val_loss: 0.8932 - val_accuracy: 0.8473\n",
            "Epoch 1620/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1665 - accuracy: 0.9366\n",
            "Epoch 1620: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1666 - accuracy: 0.9366 - val_loss: 1.0280 - val_accuracy: 0.8169\n",
            "Epoch 1621/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1501 - accuracy: 0.9449\n",
            "Epoch 1621: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1514 - accuracy: 0.9446 - val_loss: 1.0783 - val_accuracy: 0.8076\n",
            "Epoch 1622/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1581 - accuracy: 0.9452\n",
            "Epoch 1622: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1584 - accuracy: 0.9443 - val_loss: 0.9355 - val_accuracy: 0.8419\n",
            "Epoch 1623/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1806 - accuracy: 0.9359\n",
            "Epoch 1623: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1806 - accuracy: 0.9354 - val_loss: 1.0297 - val_accuracy: 0.8207\n",
            "Epoch 1624/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1957 - accuracy: 0.9280\n",
            "Epoch 1624: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1971 - accuracy: 0.9273 - val_loss: 1.0823 - val_accuracy: 0.8035\n",
            "Epoch 1625/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.4643 - accuracy: 0.8684\n",
            "Epoch 1625: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4618 - accuracy: 0.8685 - val_loss: 1.3348 - val_accuracy: 0.7650\n",
            "Epoch 1626/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2461 - accuracy: 0.9109\n",
            "Epoch 1626: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2450 - accuracy: 0.9108 - val_loss: 0.9842 - val_accuracy: 0.8351\n",
            "Epoch 1627/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2028 - accuracy: 0.9270\n",
            "Epoch 1627: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2028 - accuracy: 0.9268 - val_loss: 0.9171 - val_accuracy: 0.8403\n",
            "Epoch 1628/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1825 - accuracy: 0.9333\n",
            "Epoch 1628: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1814 - accuracy: 0.9337 - val_loss: 0.9556 - val_accuracy: 0.8297\n",
            "Epoch 1629/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1442 - accuracy: 0.9487\n",
            "Epoch 1629: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1444 - accuracy: 0.9486 - val_loss: 0.9329 - val_accuracy: 0.8390\n",
            "Epoch 1630/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1494 - accuracy: 0.9482\n",
            "Epoch 1630: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1489 - accuracy: 0.9484 - val_loss: 0.9169 - val_accuracy: 0.8377\n",
            "Epoch 1631/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1433 - accuracy: 0.9468\n",
            "Epoch 1631: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1441 - accuracy: 0.9465 - val_loss: 0.9433 - val_accuracy: 0.8348\n",
            "Epoch 1632/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1566 - accuracy: 0.9434\n",
            "Epoch 1632: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1563 - accuracy: 0.9435 - val_loss: 1.0050 - val_accuracy: 0.8313\n",
            "Epoch 1633/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1953 - accuracy: 0.9300\n",
            "Epoch 1633: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1994 - accuracy: 0.9284 - val_loss: 0.9593 - val_accuracy: 0.8319\n",
            "Epoch 1634/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.2516 - accuracy: 0.9097\n",
            "Epoch 1634: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2468 - accuracy: 0.9110 - val_loss: 1.1222 - val_accuracy: 0.7987\n",
            "Epoch 1635/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1695 - accuracy: 0.9389\n",
            "Epoch 1635: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1677 - accuracy: 0.9390 - val_loss: 1.0410 - val_accuracy: 0.8134\n",
            "Epoch 1636/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1870 - accuracy: 0.9308\n",
            "Epoch 1636: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1870 - accuracy: 0.9308 - val_loss: 0.9340 - val_accuracy: 0.8361\n",
            "Epoch 1637/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2213 - accuracy: 0.9201\n",
            "Epoch 1637: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2247 - accuracy: 0.9193 - val_loss: 1.1603 - val_accuracy: 0.7961\n",
            "Epoch 1638/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.4061 - accuracy: 0.8682\n",
            "Epoch 1638: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4047 - accuracy: 0.8685 - val_loss: 1.2897 - val_accuracy: 0.7622\n",
            "Epoch 1639/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2389 - accuracy: 0.9137\n",
            "Epoch 1639: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2347 - accuracy: 0.9148 - val_loss: 0.9762 - val_accuracy: 0.8294\n",
            "Epoch 1640/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1746 - accuracy: 0.9364\n",
            "Epoch 1640: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1737 - accuracy: 0.9367 - val_loss: 0.9166 - val_accuracy: 0.8412\n",
            "Epoch 1641/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1575 - accuracy: 0.9437\n",
            "Epoch 1641: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1585 - accuracy: 0.9434 - val_loss: 1.0146 - val_accuracy: 0.8198\n",
            "Epoch 1642/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1775 - accuracy: 0.9333\n",
            "Epoch 1642: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1775 - accuracy: 0.9333 - val_loss: 0.9494 - val_accuracy: 0.8364\n",
            "Epoch 1643/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1407 - accuracy: 0.9496\n",
            "Epoch 1643: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1405 - accuracy: 0.9499 - val_loss: 0.9755 - val_accuracy: 0.8326\n",
            "Epoch 1644/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2193 - accuracy: 0.9194\n",
            "Epoch 1644: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2140 - accuracy: 0.9217 - val_loss: 0.9581 - val_accuracy: 0.8409\n",
            "Epoch 1645/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1595 - accuracy: 0.9404\n",
            "Epoch 1645: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1612 - accuracy: 0.9396 - val_loss: 0.9514 - val_accuracy: 0.8329\n",
            "Epoch 1646/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2146 - accuracy: 0.9199\n",
            "Epoch 1646: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2155 - accuracy: 0.9197 - val_loss: 1.0671 - val_accuracy: 0.8057\n",
            "Epoch 1647/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2044 - accuracy: 0.9251\n",
            "Epoch 1647: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2022 - accuracy: 0.9258 - val_loss: 1.0062 - val_accuracy: 0.8195\n",
            "Epoch 1648/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1747 - accuracy: 0.9373\n",
            "Epoch 1648: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1758 - accuracy: 0.9369 - val_loss: 1.0118 - val_accuracy: 0.8259\n",
            "Epoch 1649/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1540 - accuracy: 0.9444\n",
            "Epoch 1649: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1538 - accuracy: 0.9447 - val_loss: 0.9763 - val_accuracy: 0.8275\n",
            "Epoch 1650/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1414 - accuracy: 0.9514\n",
            "Epoch 1650: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1414 - accuracy: 0.9514 - val_loss: 0.9078 - val_accuracy: 0.8467\n",
            "Epoch 1651/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1974 - accuracy: 0.9318\n",
            "Epoch 1651: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2047 - accuracy: 0.9302 - val_loss: 1.6110 - val_accuracy: 0.7279\n",
            "Epoch 1652/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.1229 - accuracy: 0.8024\n",
            "Epoch 1652: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.1229 - accuracy: 0.8024 - val_loss: 0.9623 - val_accuracy: 0.8364\n",
            "Epoch 1653/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1321 - accuracy: 0.9541\n",
            "Epoch 1653: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1321 - accuracy: 0.9541 - val_loss: 0.9068 - val_accuracy: 0.8460\n",
            "Epoch 1654/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1392 - accuracy: 0.9516\n",
            "Epoch 1654: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1387 - accuracy: 0.9520 - val_loss: 1.0017 - val_accuracy: 0.8259\n",
            "Epoch 1655/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1328 - accuracy: 0.9543\n",
            "Epoch 1655: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1329 - accuracy: 0.9543 - val_loss: 0.9175 - val_accuracy: 0.8483\n",
            "Epoch 1656/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1326 - accuracy: 0.9549\n",
            "Epoch 1656: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1326 - accuracy: 0.9547 - val_loss: 1.0451 - val_accuracy: 0.8198\n",
            "Epoch 1657/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1368 - accuracy: 0.9537\n",
            "Epoch 1657: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1368 - accuracy: 0.9537 - val_loss: 0.9376 - val_accuracy: 0.8374\n",
            "Epoch 1658/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1446 - accuracy: 0.9460\n",
            "Epoch 1658: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1447 - accuracy: 0.9461 - val_loss: 0.9627 - val_accuracy: 0.8326\n",
            "Epoch 1659/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1308 - accuracy: 0.9519\n",
            "Epoch 1659: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1308 - accuracy: 0.9517 - val_loss: 0.9603 - val_accuracy: 0.8335\n",
            "Epoch 1660/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1352 - accuracy: 0.9508\n",
            "Epoch 1660: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1354 - accuracy: 0.9508 - val_loss: 0.9264 - val_accuracy: 0.8441\n",
            "Epoch 1661/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1459 - accuracy: 0.9476\n",
            "Epoch 1661: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1458 - accuracy: 0.9477 - val_loss: 0.9421 - val_accuracy: 0.8387\n",
            "Epoch 1662/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2113 - accuracy: 0.9234\n",
            "Epoch 1662: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2078 - accuracy: 0.9248 - val_loss: 0.9702 - val_accuracy: 0.8323\n",
            "Epoch 1663/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1756 - accuracy: 0.9344\n",
            "Epoch 1663: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1745 - accuracy: 0.9351 - val_loss: 0.9153 - val_accuracy: 0.8467\n",
            "Epoch 1664/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1459 - accuracy: 0.9467\n",
            "Epoch 1664: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1460 - accuracy: 0.9470 - val_loss: 0.9333 - val_accuracy: 0.8367\n",
            "Epoch 1665/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.1522 - accuracy: 0.9432\n",
            "Epoch 1665: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1526 - accuracy: 0.9429 - val_loss: 0.9682 - val_accuracy: 0.8345\n",
            "Epoch 1666/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1759 - accuracy: 0.9354\n",
            "Epoch 1666: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1751 - accuracy: 0.9356 - val_loss: 0.9611 - val_accuracy: 0.8367\n",
            "Epoch 1667/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1650 - accuracy: 0.9382\n",
            "Epoch 1667: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1654 - accuracy: 0.9381 - val_loss: 1.0808 - val_accuracy: 0.8051\n",
            "Epoch 1668/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.4813 - accuracy: 0.8606\n",
            "Epoch 1668: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.4768 - accuracy: 0.8615 - val_loss: 1.0876 - val_accuracy: 0.8035\n",
            "Epoch 1669/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1906 - accuracy: 0.9319\n",
            "Epoch 1669: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1898 - accuracy: 0.9317 - val_loss: 0.9312 - val_accuracy: 0.8351\n",
            "Epoch 1670/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1486 - accuracy: 0.9472\n",
            "Epoch 1670: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1520 - accuracy: 0.9457 - val_loss: 1.0203 - val_accuracy: 0.8220\n",
            "Epoch 1671/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1883 - accuracy: 0.9334\n",
            "Epoch 1671: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1872 - accuracy: 0.9337 - val_loss: 0.9404 - val_accuracy: 0.8431\n",
            "Epoch 1672/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1305 - accuracy: 0.9557\n",
            "Epoch 1672: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1285 - accuracy: 0.9564 - val_loss: 0.9398 - val_accuracy: 0.8464\n",
            "Epoch 1673/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1724 - accuracy: 0.9373\n",
            "Epoch 1673: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1714 - accuracy: 0.9377 - val_loss: 1.2217 - val_accuracy: 0.7932\n",
            "Epoch 1674/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1976 - accuracy: 0.9246\n",
            "Epoch 1674: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1983 - accuracy: 0.9237 - val_loss: 0.9752 - val_accuracy: 0.8223\n",
            "Epoch 1675/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1655 - accuracy: 0.9373\n",
            "Epoch 1675: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1656 - accuracy: 0.9376 - val_loss: 0.9328 - val_accuracy: 0.8387\n",
            "Epoch 1676/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2208 - accuracy: 0.9183\n",
            "Epoch 1676: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2204 - accuracy: 0.9185 - val_loss: 0.9849 - val_accuracy: 0.8262\n",
            "Epoch 1677/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1765 - accuracy: 0.9359\n",
            "Epoch 1677: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1750 - accuracy: 0.9361 - val_loss: 0.9321 - val_accuracy: 0.8393\n",
            "Epoch 1678/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1703 - accuracy: 0.9381\n",
            "Epoch 1678: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1703 - accuracy: 0.9381 - val_loss: 0.9834 - val_accuracy: 0.8348\n",
            "Epoch 1679/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1593 - accuracy: 0.9432\n",
            "Epoch 1679: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1598 - accuracy: 0.9431 - val_loss: 1.0489 - val_accuracy: 0.8140\n",
            "Epoch 1680/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2298 - accuracy: 0.9159\n",
            "Epoch 1680: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2289 - accuracy: 0.9161 - val_loss: 1.2088 - val_accuracy: 0.7762\n",
            "Epoch 1681/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2639 - accuracy: 0.9045\n",
            "Epoch 1681: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2628 - accuracy: 0.9046 - val_loss: 1.0553 - val_accuracy: 0.8111\n",
            "Epoch 1682/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1470 - accuracy: 0.9469\n",
            "Epoch 1682: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1491 - accuracy: 0.9464 - val_loss: 1.0846 - val_accuracy: 0.8140\n",
            "Epoch 1683/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.8001 - accuracy: 0.8149\n",
            "Epoch 1683: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.7993 - accuracy: 0.8146 - val_loss: 1.3426 - val_accuracy: 0.7618\n",
            "Epoch 1684/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2330 - accuracy: 0.9188\n",
            "Epoch 1684: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2325 - accuracy: 0.9191 - val_loss: 0.9205 - val_accuracy: 0.8422\n",
            "Epoch 1685/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1271 - accuracy: 0.9566\n",
            "Epoch 1685: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1269 - accuracy: 0.9568 - val_loss: 0.9290 - val_accuracy: 0.8438\n",
            "Epoch 1686/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1363 - accuracy: 0.9514\n",
            "Epoch 1686: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1358 - accuracy: 0.9517 - val_loss: 0.9370 - val_accuracy: 0.8409\n",
            "Epoch 1687/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1283 - accuracy: 0.9534\n",
            "Epoch 1687: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1283 - accuracy: 0.9532 - val_loss: 0.9602 - val_accuracy: 0.8383\n",
            "Epoch 1688/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1252 - accuracy: 0.9589\n",
            "Epoch 1688: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1265 - accuracy: 0.9581 - val_loss: 0.9384 - val_accuracy: 0.8448\n",
            "Epoch 1689/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1349 - accuracy: 0.9524\n",
            "Epoch 1689: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1357 - accuracy: 0.9518 - val_loss: 0.9308 - val_accuracy: 0.8406\n",
            "Epoch 1690/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1330 - accuracy: 0.9528\n",
            "Epoch 1690: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1368 - accuracy: 0.9512 - val_loss: 1.0012 - val_accuracy: 0.8278\n",
            "Epoch 1691/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1640 - accuracy: 0.9411\n",
            "Epoch 1691: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1627 - accuracy: 0.9416 - val_loss: 0.9642 - val_accuracy: 0.8406\n",
            "Epoch 1692/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1656 - accuracy: 0.9389\n",
            "Epoch 1692: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1681 - accuracy: 0.9382 - val_loss: 1.1194 - val_accuracy: 0.7990\n",
            "Epoch 1693/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1948 - accuracy: 0.9305\n",
            "Epoch 1693: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1948 - accuracy: 0.9305 - val_loss: 1.0968 - val_accuracy: 0.8038\n",
            "Epoch 1694/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1756 - accuracy: 0.9358\n",
            "Epoch 1694: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1740 - accuracy: 0.9366 - val_loss: 1.0459 - val_accuracy: 0.8207\n",
            "Epoch 1695/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1366 - accuracy: 0.9504\n",
            "Epoch 1695: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1393 - accuracy: 0.9493 - val_loss: 1.0586 - val_accuracy: 0.8086\n",
            "Epoch 1696/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.1563 - accuracy: 0.9443\n",
            "Epoch 1696: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1598 - accuracy: 0.9433 - val_loss: 1.0956 - val_accuracy: 0.7999\n",
            "Epoch 1697/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8752\n",
            "Epoch 1697: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3814 - accuracy: 0.8758 - val_loss: 1.0952 - val_accuracy: 0.7996\n",
            "Epoch 1698/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1790 - accuracy: 0.9341\n",
            "Epoch 1698: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1774 - accuracy: 0.9346 - val_loss: 0.9153 - val_accuracy: 0.8483\n",
            "Epoch 1699/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1732 - accuracy: 0.9368\n",
            "Epoch 1699: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1722 - accuracy: 0.9370 - val_loss: 0.9656 - val_accuracy: 0.8339\n",
            "Epoch 1700/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1485 - accuracy: 0.9480\n",
            "Epoch 1700: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1485 - accuracy: 0.9480 - val_loss: 1.0029 - val_accuracy: 0.8204\n",
            "Epoch 1701/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1775 - accuracy: 0.9338\n",
            "Epoch 1701: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1783 - accuracy: 0.9341 - val_loss: 0.9836 - val_accuracy: 0.8239\n",
            "Epoch 1702/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1565 - accuracy: 0.9420\n",
            "Epoch 1702: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1579 - accuracy: 0.9414 - val_loss: 0.9628 - val_accuracy: 0.8403\n",
            "Epoch 1703/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2111 - accuracy: 0.9226\n",
            "Epoch 1703: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2102 - accuracy: 0.9228 - val_loss: 1.0773 - val_accuracy: 0.8198\n",
            "Epoch 1704/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1590 - accuracy: 0.9416\n",
            "Epoch 1704: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1591 - accuracy: 0.9413 - val_loss: 0.9359 - val_accuracy: 0.8476\n",
            "Epoch 1705/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2087 - accuracy: 0.9231\n",
            "Epoch 1705: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2087 - accuracy: 0.9231 - val_loss: 1.0148 - val_accuracy: 0.8223\n",
            "Epoch 1706/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1598 - accuracy: 0.9420\n",
            "Epoch 1706: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1603 - accuracy: 0.9415 - val_loss: 1.0878 - val_accuracy: 0.8108\n",
            "Epoch 1707/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3137 - accuracy: 0.8910\n",
            "Epoch 1707: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3138 - accuracy: 0.8907 - val_loss: 1.1456 - val_accuracy: 0.7955\n",
            "Epoch 1708/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2252 - accuracy: 0.9182\n",
            "Epoch 1708: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2250 - accuracy: 0.9180 - val_loss: 1.0116 - val_accuracy: 0.8246\n",
            "Epoch 1709/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2070 - accuracy: 0.9270\n",
            "Epoch 1709: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2038 - accuracy: 0.9281 - val_loss: 1.0678 - val_accuracy: 0.8153\n",
            "Epoch 1710/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1698 - accuracy: 0.9373\n",
            "Epoch 1710: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1686 - accuracy: 0.9376 - val_loss: 0.9970 - val_accuracy: 0.8339\n",
            "Epoch 1711/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1308 - accuracy: 0.9543\n",
            "Epoch 1711: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1324 - accuracy: 0.9533 - val_loss: 0.9745 - val_accuracy: 0.8393\n",
            "Epoch 1712/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1665 - accuracy: 0.9407\n",
            "Epoch 1712: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1681 - accuracy: 0.9398 - val_loss: 0.9956 - val_accuracy: 0.8329\n",
            "Epoch 1713/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1807 - accuracy: 0.9331\n",
            "Epoch 1713: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1805 - accuracy: 0.9331 - val_loss: 1.0323 - val_accuracy: 0.8275\n",
            "Epoch 1714/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1529 - accuracy: 0.9439\n",
            "Epoch 1714: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1524 - accuracy: 0.9441 - val_loss: 0.9368 - val_accuracy: 0.8502\n",
            "Epoch 1715/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.8877\n",
            "Epoch 1715: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3756 - accuracy: 0.8890 - val_loss: 1.0801 - val_accuracy: 0.8108\n",
            "Epoch 1716/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1471 - accuracy: 0.9476\n",
            "Epoch 1716: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1466 - accuracy: 0.9478 - val_loss: 1.0590 - val_accuracy: 0.8150\n",
            "Epoch 1717/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1429 - accuracy: 0.9479\n",
            "Epoch 1717: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1430 - accuracy: 0.9477 - val_loss: 1.0586 - val_accuracy: 0.8214\n",
            "Epoch 1718/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2302 - accuracy: 0.9188\n",
            "Epoch 1718: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2325 - accuracy: 0.9177 - val_loss: 1.3948 - val_accuracy: 0.7551\n",
            "Epoch 1719/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2113 - accuracy: 0.9220\n",
            "Epoch 1719: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2068 - accuracy: 0.9234 - val_loss: 0.9358 - val_accuracy: 0.8512\n",
            "Epoch 1720/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1682 - accuracy: 0.9384\n",
            "Epoch 1720: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1663 - accuracy: 0.9389 - val_loss: 0.9428 - val_accuracy: 0.8492\n",
            "Epoch 1721/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1715 - accuracy: 0.9379\n",
            "Epoch 1721: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1717 - accuracy: 0.9378 - val_loss: 1.0475 - val_accuracy: 0.8259\n",
            "Epoch 1722/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1898 - accuracy: 0.9306\n",
            "Epoch 1722: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1893 - accuracy: 0.9307 - val_loss: 0.9716 - val_accuracy: 0.8310\n",
            "Epoch 1723/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1871 - accuracy: 0.9311\n",
            "Epoch 1723: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1852 - accuracy: 0.9320 - val_loss: 1.0517 - val_accuracy: 0.8147\n",
            "Epoch 1724/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1788 - accuracy: 0.9358\n",
            "Epoch 1724: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1788 - accuracy: 0.9358 - val_loss: 0.9798 - val_accuracy: 0.8374\n",
            "Epoch 1725/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1973 - accuracy: 0.9262\n",
            "Epoch 1725: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1933 - accuracy: 0.9277 - val_loss: 1.0000 - val_accuracy: 0.8281\n",
            "Epoch 1726/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1394 - accuracy: 0.9490\n",
            "Epoch 1726: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1388 - accuracy: 0.9493 - val_loss: 1.0311 - val_accuracy: 0.8339\n",
            "Epoch 1727/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1647 - accuracy: 0.9387\n",
            "Epoch 1727: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1637 - accuracy: 0.9391 - val_loss: 0.9744 - val_accuracy: 0.8364\n",
            "Epoch 1728/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1792 - accuracy: 0.9334\n",
            "Epoch 1728: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1799 - accuracy: 0.9330 - val_loss: 1.1156 - val_accuracy: 0.8102\n",
            "Epoch 1729/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3475 - accuracy: 0.8854\n",
            "Epoch 1729: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3616 - accuracy: 0.8820 - val_loss: 1.4341 - val_accuracy: 0.7468\n",
            "Epoch 1730/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.4767 - accuracy: 0.8635\n",
            "Epoch 1730: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4673 - accuracy: 0.8659 - val_loss: 0.9909 - val_accuracy: 0.8326\n",
            "Epoch 1731/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1582 - accuracy: 0.9438\n",
            "Epoch 1731: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1612 - accuracy: 0.9428 - val_loss: 0.9870 - val_accuracy: 0.8316\n",
            "Epoch 1732/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1800 - accuracy: 0.9345\n",
            "Epoch 1732: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1794 - accuracy: 0.9348 - val_loss: 1.0853 - val_accuracy: 0.8134\n",
            "Epoch 1733/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1644 - accuracy: 0.9392\n",
            "Epoch 1733: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1625 - accuracy: 0.9398 - val_loss: 0.9348 - val_accuracy: 0.8419\n",
            "Epoch 1734/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1353 - accuracy: 0.9503\n",
            "Epoch 1734: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1354 - accuracy: 0.9504 - val_loss: 0.9304 - val_accuracy: 0.8383\n",
            "Epoch 1735/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1388 - accuracy: 0.9496\n",
            "Epoch 1735: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1390 - accuracy: 0.9494 - val_loss: 1.0620 - val_accuracy: 0.8108\n",
            "Epoch 1736/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1653 - accuracy: 0.9395\n",
            "Epoch 1736: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1654 - accuracy: 0.9391 - val_loss: 0.9038 - val_accuracy: 0.8361\n",
            "Epoch 1737/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2201 - accuracy: 0.9196\n",
            "Epoch 1737: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2200 - accuracy: 0.9194 - val_loss: 1.0696 - val_accuracy: 0.8076\n",
            "Epoch 1738/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1798 - accuracy: 0.9333\n",
            "Epoch 1738: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1796 - accuracy: 0.9333 - val_loss: 0.9244 - val_accuracy: 0.8415\n",
            "Epoch 1739/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1251 - accuracy: 0.9550\n",
            "Epoch 1739: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1251 - accuracy: 0.9549 - val_loss: 0.9448 - val_accuracy: 0.8374\n",
            "Epoch 1740/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1525 - accuracy: 0.9444\n",
            "Epoch 1740: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1525 - accuracy: 0.9444 - val_loss: 1.1448 - val_accuracy: 0.7961\n",
            "Epoch 1741/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3181 - accuracy: 0.8917\n",
            "Epoch 1741: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3130 - accuracy: 0.8928 - val_loss: 1.0502 - val_accuracy: 0.8230\n",
            "Epoch 1742/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1727 - accuracy: 0.9370\n",
            "Epoch 1742: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1798 - accuracy: 0.9343 - val_loss: 1.2041 - val_accuracy: 0.7785\n",
            "Epoch 1743/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2316 - accuracy: 0.9156\n",
            "Epoch 1743: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2316 - accuracy: 0.9156 - val_loss: 0.9382 - val_accuracy: 0.8383\n",
            "Epoch 1744/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1626 - accuracy: 0.9389\n",
            "Epoch 1744: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1622 - accuracy: 0.9391 - val_loss: 0.9693 - val_accuracy: 0.8361\n",
            "Epoch 1745/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1857 - accuracy: 0.9343\n",
            "Epoch 1745: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1873 - accuracy: 0.9338 - val_loss: 1.0185 - val_accuracy: 0.8188\n",
            "Epoch 1746/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1425 - accuracy: 0.9482\n",
            "Epoch 1746: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1418 - accuracy: 0.9489 - val_loss: 1.0047 - val_accuracy: 0.8230\n",
            "Epoch 1747/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1413 - accuracy: 0.9489\n",
            "Epoch 1747: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1413 - accuracy: 0.9489 - val_loss: 1.0197 - val_accuracy: 0.8351\n",
            "Epoch 1748/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2196 - accuracy: 0.9204\n",
            "Epoch 1748: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2193 - accuracy: 0.9205 - val_loss: 0.9770 - val_accuracy: 0.8377\n",
            "Epoch 1749/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1500 - accuracy: 0.9453\n",
            "Epoch 1749: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1511 - accuracy: 0.9452 - val_loss: 1.0315 - val_accuracy: 0.8217\n",
            "Epoch 1750/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1819 - accuracy: 0.9317\n",
            "Epoch 1750: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1795 - accuracy: 0.9328 - val_loss: 0.9747 - val_accuracy: 0.8403\n",
            "Epoch 1751/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1922 - accuracy: 0.9309\n",
            "Epoch 1751: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1957 - accuracy: 0.9303 - val_loss: 1.2626 - val_accuracy: 0.7820\n",
            "Epoch 1752/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2092 - accuracy: 0.9226\n",
            "Epoch 1752: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2138 - accuracy: 0.9209 - val_loss: 1.5390 - val_accuracy: 0.7305\n",
            "Epoch 1753/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2914 - accuracy: 0.8976\n",
            "Epoch 1753: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2919 - accuracy: 0.8973 - val_loss: 1.1025 - val_accuracy: 0.8035\n",
            "Epoch 1754/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2943 - accuracy: 0.8992\n",
            "Epoch 1754: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2943 - accuracy: 0.8992 - val_loss: 1.0983 - val_accuracy: 0.8115\n",
            "Epoch 1755/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1559 - accuracy: 0.9412\n",
            "Epoch 1755: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1557 - accuracy: 0.9411 - val_loss: 0.9529 - val_accuracy: 0.8412\n",
            "Epoch 1756/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2188 - accuracy: 0.9310\n",
            "Epoch 1756: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2471 - accuracy: 0.9241 - val_loss: 1.1886 - val_accuracy: 0.8035\n",
            "Epoch 1757/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.5014 - accuracy: 0.8662\n",
            "Epoch 1757: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4760 - accuracy: 0.8716 - val_loss: 0.9845 - val_accuracy: 0.8329\n",
            "Epoch 1758/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1230 - accuracy: 0.9570\n",
            "Epoch 1758: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1245 - accuracy: 0.9566 - val_loss: 0.9341 - val_accuracy: 0.8499\n",
            "Epoch 1759/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1446 - accuracy: 0.9490\n",
            "Epoch 1759: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1442 - accuracy: 0.9493 - val_loss: 0.8994 - val_accuracy: 0.8512\n",
            "Epoch 1760/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1257 - accuracy: 0.9550\n",
            "Epoch 1760: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1255 - accuracy: 0.9552 - val_loss: 0.9946 - val_accuracy: 0.8291\n",
            "Epoch 1761/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1420 - accuracy: 0.9493\n",
            "Epoch 1761: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1425 - accuracy: 0.9485 - val_loss: 1.1022 - val_accuracy: 0.8143\n",
            "Epoch 1762/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2426 - accuracy: 0.9132\n",
            "Epoch 1762: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2370 - accuracy: 0.9147 - val_loss: 1.0326 - val_accuracy: 0.8124\n",
            "Epoch 1763/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2142 - accuracy: 0.9222\n",
            "Epoch 1763: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2149 - accuracy: 0.9220 - val_loss: 1.1427 - val_accuracy: 0.7964\n",
            "Epoch 1764/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1580 - accuracy: 0.9422\n",
            "Epoch 1764: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1561 - accuracy: 0.9432 - val_loss: 0.9412 - val_accuracy: 0.8406\n",
            "Epoch 1765/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2054 - accuracy: 0.9280\n",
            "Epoch 1765: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2229 - accuracy: 0.9229 - val_loss: 1.2770 - val_accuracy: 0.7730\n",
            "Epoch 1766/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2570 - accuracy: 0.9073\n",
            "Epoch 1766: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2543 - accuracy: 0.9081 - val_loss: 0.9973 - val_accuracy: 0.8316\n",
            "Epoch 1767/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1618 - accuracy: 0.9399\n",
            "Epoch 1767: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1619 - accuracy: 0.9398 - val_loss: 0.9924 - val_accuracy: 0.8396\n",
            "Epoch 1768/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1625 - accuracy: 0.9392\n",
            "Epoch 1768: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1619 - accuracy: 0.9394 - val_loss: 1.0005 - val_accuracy: 0.8342\n",
            "Epoch 1769/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1424 - accuracy: 0.9505\n",
            "Epoch 1769: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1413 - accuracy: 0.9509 - val_loss: 1.0053 - val_accuracy: 0.8348\n",
            "Epoch 1770/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1788 - accuracy: 0.9347\n",
            "Epoch 1770: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1791 - accuracy: 0.9346 - val_loss: 1.0016 - val_accuracy: 0.8323\n",
            "Epoch 1771/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2267 - accuracy: 0.9177\n",
            "Epoch 1771: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2265 - accuracy: 0.9179 - val_loss: 1.8023 - val_accuracy: 0.7129\n",
            "Epoch 1772/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.5061 - accuracy: 0.8511\n",
            "Epoch 1772: val_accuracy did not improve from 0.85243\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.5038 - accuracy: 0.8516 - val_loss: 0.9933 - val_accuracy: 0.8271\n",
            "Epoch 1773/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1423 - accuracy: 0.9499\n",
            "Epoch 1773: val_accuracy improved from 0.85243 to 0.85595, saving model to /content/asl1/Adam4/cp-1773-0.86.hdf5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1423 - accuracy: 0.9499 - val_loss: 0.9093 - val_accuracy: 0.8560\n",
            "Epoch 1774/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1330 - accuracy: 0.9541\n",
            "Epoch 1774: val_accuracy improved from 0.85595 to 0.85915, saving model to /content/asl1/Adam4/cp-1774-0.86.hdf5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1329 - accuracy: 0.9541 - val_loss: 0.8950 - val_accuracy: 0.8592\n",
            "Epoch 1775/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1473 - accuracy: 0.9468\n",
            "Epoch 1775: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1468 - accuracy: 0.9469 - val_loss: 0.9644 - val_accuracy: 0.8339\n",
            "Epoch 1776/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1431 - accuracy: 0.9484\n",
            "Epoch 1776: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1446 - accuracy: 0.9481 - val_loss: 0.9901 - val_accuracy: 0.8358\n",
            "Epoch 1777/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1470 - accuracy: 0.9456\n",
            "Epoch 1777: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1467 - accuracy: 0.9456 - val_loss: 1.1117 - val_accuracy: 0.8060\n",
            "Epoch 1778/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1343 - accuracy: 0.9519\n",
            "Epoch 1778: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1341 - accuracy: 0.9520 - val_loss: 0.9797 - val_accuracy: 0.8342\n",
            "Epoch 1779/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1965 - accuracy: 0.9292\n",
            "Epoch 1779: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1997 - accuracy: 0.9283 - val_loss: 1.1089 - val_accuracy: 0.8147\n",
            "Epoch 1780/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1399 - accuracy: 0.9507\n",
            "Epoch 1780: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1430 - accuracy: 0.9495 - val_loss: 1.2881 - val_accuracy: 0.7775\n",
            "Epoch 1781/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2312 - accuracy: 0.9149\n",
            "Epoch 1781: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2340 - accuracy: 0.9140 - val_loss: 1.1660 - val_accuracy: 0.8012\n",
            "Epoch 1782/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1594 - accuracy: 0.9422\n",
            "Epoch 1782: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1589 - accuracy: 0.9421 - val_loss: 0.9039 - val_accuracy: 0.8521\n",
            "Epoch 1783/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1584 - accuracy: 0.9427\n",
            "Epoch 1783: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1631 - accuracy: 0.9409 - val_loss: 1.1571 - val_accuracy: 0.7990\n",
            "Epoch 1784/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2783 - accuracy: 0.9015\n",
            "Epoch 1784: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2783 - accuracy: 0.9015 - val_loss: 1.0907 - val_accuracy: 0.8089\n",
            "Epoch 1785/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2990 - accuracy: 0.8952\n",
            "Epoch 1785: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2990 - accuracy: 0.8952 - val_loss: 1.1163 - val_accuracy: 0.7987\n",
            "Epoch 1786/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3152 - accuracy: 0.8934\n",
            "Epoch 1786: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3131 - accuracy: 0.8941 - val_loss: 0.9994 - val_accuracy: 0.8329\n",
            "Epoch 1787/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1676 - accuracy: 0.9378\n",
            "Epoch 1787: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1680 - accuracy: 0.9377 - val_loss: 1.0092 - val_accuracy: 0.8239\n",
            "Epoch 1788/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2061 - accuracy: 0.9222\n",
            "Epoch 1788: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2036 - accuracy: 0.9237 - val_loss: 1.0515 - val_accuracy: 0.8230\n",
            "Epoch 1789/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1537 - accuracy: 0.9440\n",
            "Epoch 1789: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1537 - accuracy: 0.9440 - val_loss: 0.9637 - val_accuracy: 0.8380\n",
            "Epoch 1790/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2295 - accuracy: 0.9182\n",
            "Epoch 1790: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2304 - accuracy: 0.9180 - val_loss: 1.0951 - val_accuracy: 0.8179\n",
            "Epoch 1791/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1399 - accuracy: 0.9503\n",
            "Epoch 1791: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1402 - accuracy: 0.9501 - val_loss: 0.9554 - val_accuracy: 0.8412\n",
            "Epoch 1792/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1355 - accuracy: 0.9526\n",
            "Epoch 1792: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1368 - accuracy: 0.9517 - val_loss: 1.0404 - val_accuracy: 0.8201\n",
            "Epoch 1793/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2247 - accuracy: 0.9213\n",
            "Epoch 1793: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2247 - accuracy: 0.9213 - val_loss: 0.9823 - val_accuracy: 0.8348\n",
            "Epoch 1794/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1484 - accuracy: 0.9463\n",
            "Epoch 1794: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1488 - accuracy: 0.9461 - val_loss: 0.9841 - val_accuracy: 0.8358\n",
            "Epoch 1795/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1661 - accuracy: 0.9404\n",
            "Epoch 1795: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1655 - accuracy: 0.9403 - val_loss: 0.9612 - val_accuracy: 0.8367\n",
            "Epoch 1796/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1593 - accuracy: 0.9404\n",
            "Epoch 1796: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1596 - accuracy: 0.9405 - val_loss: 1.0248 - val_accuracy: 0.8294\n",
            "Epoch 1797/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1712 - accuracy: 0.9388\n",
            "Epoch 1797: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1920 - accuracy: 0.9341 - val_loss: 1.2895 - val_accuracy: 0.7746\n",
            "Epoch 1798/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.4957 - accuracy: 0.8563\n",
            "Epoch 1798: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4839 - accuracy: 0.8595 - val_loss: 1.1793 - val_accuracy: 0.7875\n",
            "Epoch 1799/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1679 - accuracy: 0.9380\n",
            "Epoch 1799: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1659 - accuracy: 0.9388 - val_loss: 0.9468 - val_accuracy: 0.8419\n",
            "Epoch 1800/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1461 - accuracy: 0.9469\n",
            "Epoch 1800: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1461 - accuracy: 0.9469 - val_loss: 1.1417 - val_accuracy: 0.7958\n",
            "Epoch 1801/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1706 - accuracy: 0.9381\n",
            "Epoch 1801: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1702 - accuracy: 0.9382 - val_loss: 0.9662 - val_accuracy: 0.8387\n",
            "Epoch 1802/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1503 - accuracy: 0.9451\n",
            "Epoch 1802: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1500 - accuracy: 0.9451 - val_loss: 0.9353 - val_accuracy: 0.8508\n",
            "Epoch 1803/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1448 - accuracy: 0.9487\n",
            "Epoch 1803: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1444 - accuracy: 0.9489 - val_loss: 0.9520 - val_accuracy: 0.8422\n",
            "Epoch 1804/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1417 - accuracy: 0.9460\n",
            "Epoch 1804: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1435 - accuracy: 0.9455 - val_loss: 1.2654 - val_accuracy: 0.7782\n",
            "Epoch 1805/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1748 - accuracy: 0.9363\n",
            "Epoch 1805: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1750 - accuracy: 0.9361 - val_loss: 1.0073 - val_accuracy: 0.8313\n",
            "Epoch 1806/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1474 - accuracy: 0.9460\n",
            "Epoch 1806: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1474 - accuracy: 0.9459 - val_loss: 0.9446 - val_accuracy: 0.8457\n",
            "Epoch 1807/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1466 - accuracy: 0.9478\n",
            "Epoch 1807: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1463 - accuracy: 0.9480 - val_loss: 0.9542 - val_accuracy: 0.8480\n",
            "Epoch 1808/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.1701 - accuracy: 0.9371\n",
            "Epoch 1808: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1654 - accuracy: 0.9395 - val_loss: 0.9416 - val_accuracy: 0.8435\n",
            "Epoch 1809/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1564 - accuracy: 0.9416\n",
            "Epoch 1809: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1564 - accuracy: 0.9416 - val_loss: 1.2051 - val_accuracy: 0.7990\n",
            "Epoch 1810/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2120 - accuracy: 0.9235\n",
            "Epoch 1810: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2120 - accuracy: 0.9235 - val_loss: 1.1689 - val_accuracy: 0.7999\n",
            "Epoch 1811/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2991 - accuracy: 0.8983\n",
            "Epoch 1811: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2949 - accuracy: 0.8997 - val_loss: 1.0043 - val_accuracy: 0.8419\n",
            "Epoch 1812/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2340 - accuracy: 0.9188\n",
            "Epoch 1812: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2340 - accuracy: 0.9188 - val_loss: 1.3076 - val_accuracy: 0.7718\n",
            "Epoch 1813/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2008 - accuracy: 0.9257\n",
            "Epoch 1813: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1990 - accuracy: 0.9262 - val_loss: 0.9517 - val_accuracy: 0.8345\n",
            "Epoch 1814/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1375 - accuracy: 0.9485\n",
            "Epoch 1814: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1367 - accuracy: 0.9490 - val_loss: 0.9275 - val_accuracy: 0.8473\n",
            "Epoch 1815/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1646 - accuracy: 0.9382\n",
            "Epoch 1815: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1643 - accuracy: 0.9384 - val_loss: 1.0321 - val_accuracy: 0.8214\n",
            "Epoch 1816/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3485 - accuracy: 0.8854\n",
            "Epoch 1816: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3442 - accuracy: 0.8865 - val_loss: 0.9892 - val_accuracy: 0.8262\n",
            "Epoch 1817/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1444 - accuracy: 0.9492\n",
            "Epoch 1817: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1434 - accuracy: 0.9495 - val_loss: 0.9481 - val_accuracy: 0.8512\n",
            "Epoch 1818/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1564 - accuracy: 0.9420\n",
            "Epoch 1818: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1615 - accuracy: 0.9405 - val_loss: 1.1448 - val_accuracy: 0.8019\n",
            "Epoch 1819/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3611 - accuracy: 0.8812\n",
            "Epoch 1819: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3577 - accuracy: 0.8821 - val_loss: 1.0783 - val_accuracy: 0.8115\n",
            "Epoch 1820/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1486 - accuracy: 0.9449\n",
            "Epoch 1820: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.1475 - accuracy: 0.9453 - val_loss: 0.9337 - val_accuracy: 0.8403\n",
            "Epoch 1821/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1217 - accuracy: 0.9581\n",
            "Epoch 1821: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1218 - accuracy: 0.9581 - val_loss: 0.9012 - val_accuracy: 0.8537\n",
            "Epoch 1822/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1260 - accuracy: 0.9540\n",
            "Epoch 1822: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1263 - accuracy: 0.9542 - val_loss: 0.9732 - val_accuracy: 0.8335\n",
            "Epoch 1823/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1427 - accuracy: 0.9509\n",
            "Epoch 1823: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1435 - accuracy: 0.9505 - val_loss: 1.0280 - val_accuracy: 0.8300\n",
            "Epoch 1824/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1376 - accuracy: 0.9505\n",
            "Epoch 1824: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1378 - accuracy: 0.9505 - val_loss: 0.9319 - val_accuracy: 0.8563\n",
            "Epoch 1825/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1616 - accuracy: 0.9408\n",
            "Epoch 1825: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1635 - accuracy: 0.9401 - val_loss: 1.2593 - val_accuracy: 0.7801\n",
            "Epoch 1826/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3471 - accuracy: 0.8840\n",
            "Epoch 1826: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3436 - accuracy: 0.8852 - val_loss: 1.1544 - val_accuracy: 0.7996\n",
            "Epoch 1827/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2490 - accuracy: 0.9114\n",
            "Epoch 1827: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2489 - accuracy: 0.9112 - val_loss: 1.0604 - val_accuracy: 0.8201\n",
            "Epoch 1828/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1809 - accuracy: 0.9338\n",
            "Epoch 1828: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1809 - accuracy: 0.9338 - val_loss: 1.0512 - val_accuracy: 0.8195\n",
            "Epoch 1829/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1846 - accuracy: 0.9294\n",
            "Epoch 1829: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1840 - accuracy: 0.9294 - val_loss: 0.9641 - val_accuracy: 0.8371\n",
            "Epoch 1830/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1547 - accuracy: 0.9430\n",
            "Epoch 1830: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1589 - accuracy: 0.9422 - val_loss: 1.4194 - val_accuracy: 0.7609\n",
            "Epoch 1831/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2342 - accuracy: 0.9152\n",
            "Epoch 1831: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2335 - accuracy: 0.9156 - val_loss: 1.1480 - val_accuracy: 0.8108\n",
            "Epoch 1832/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1560 - accuracy: 0.9412\n",
            "Epoch 1832: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1566 - accuracy: 0.9409 - val_loss: 0.9365 - val_accuracy: 0.8396\n",
            "Epoch 1833/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.5016 - accuracy: 0.8801\n",
            "Epoch 1833: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4914 - accuracy: 0.8800 - val_loss: 1.4287 - val_accuracy: 0.7631\n",
            "Epoch 1834/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1654 - accuracy: 0.9407\n",
            "Epoch 1834: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1628 - accuracy: 0.9414 - val_loss: 0.9689 - val_accuracy: 0.8444\n",
            "Epoch 1835/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1375 - accuracy: 0.9503\n",
            "Epoch 1835: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1375 - accuracy: 0.9501 - val_loss: 0.9804 - val_accuracy: 0.8313\n",
            "Epoch 1836/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1214 - accuracy: 0.9553\n",
            "Epoch 1836: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1218 - accuracy: 0.9549 - val_loss: 0.9342 - val_accuracy: 0.8403\n",
            "Epoch 1837/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1340 - accuracy: 0.9507\n",
            "Epoch 1837: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1338 - accuracy: 0.9508 - val_loss: 0.9901 - val_accuracy: 0.8377\n",
            "Epoch 1838/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1267 - accuracy: 0.9567\n",
            "Epoch 1838: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1264 - accuracy: 0.9566 - val_loss: 0.9104 - val_accuracy: 0.8518\n",
            "Epoch 1839/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1287 - accuracy: 0.9538\n",
            "Epoch 1839: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1287 - accuracy: 0.9537 - val_loss: 1.0088 - val_accuracy: 0.8339\n",
            "Epoch 1840/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2026 - accuracy: 0.9262\n",
            "Epoch 1840: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2048 - accuracy: 0.9256 - val_loss: 1.0620 - val_accuracy: 0.8310\n",
            "Epoch 1841/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.4205 - accuracy: 0.8700\n",
            "Epoch 1841: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.4163 - accuracy: 0.8704 - val_loss: 1.2123 - val_accuracy: 0.7926\n",
            "Epoch 1842/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1963 - accuracy: 0.9284\n",
            "Epoch 1842: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1942 - accuracy: 0.9290 - val_loss: 0.9952 - val_accuracy: 0.8415\n",
            "Epoch 1843/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1504 - accuracy: 0.9454\n",
            "Epoch 1843: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1522 - accuracy: 0.9448 - val_loss: 0.9917 - val_accuracy: 0.8294\n",
            "Epoch 1844/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1570 - accuracy: 0.9442\n",
            "Epoch 1844: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1567 - accuracy: 0.9444 - val_loss: 1.0321 - val_accuracy: 0.8223\n",
            "Epoch 1845/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1481 - accuracy: 0.9440\n",
            "Epoch 1845: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1475 - accuracy: 0.9445 - val_loss: 0.9413 - val_accuracy: 0.8470\n",
            "Epoch 1846/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1259 - accuracy: 0.9563\n",
            "Epoch 1846: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1258 - accuracy: 0.9563 - val_loss: 0.9514 - val_accuracy: 0.8515\n",
            "Epoch 1847/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1345 - accuracy: 0.9533\n",
            "Epoch 1847: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1345 - accuracy: 0.9533 - val_loss: 0.9522 - val_accuracy: 0.8441\n",
            "Epoch 1848/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1233 - accuracy: 0.9559\n",
            "Epoch 1848: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1232 - accuracy: 0.9559 - val_loss: 0.9771 - val_accuracy: 0.8351\n",
            "Epoch 1849/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1571 - accuracy: 0.9426\n",
            "Epoch 1849: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1620 - accuracy: 0.9411 - val_loss: 1.5034 - val_accuracy: 0.7417\n",
            "Epoch 1850/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2067 - accuracy: 0.9258\n",
            "Epoch 1850: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2070 - accuracy: 0.9257 - val_loss: 0.9919 - val_accuracy: 0.8387\n",
            "Epoch 1851/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3878 - accuracy: 0.8852\n",
            "Epoch 1851: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3878 - accuracy: 0.8852 - val_loss: 1.6887 - val_accuracy: 0.7215\n",
            "Epoch 1852/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.4158 - accuracy: 0.8693\n",
            "Epoch 1852: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3977 - accuracy: 0.8745 - val_loss: 1.0995 - val_accuracy: 0.8134\n",
            "Epoch 1853/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1549 - accuracy: 0.9448\n",
            "Epoch 1853: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1551 - accuracy: 0.9446 - val_loss: 1.0436 - val_accuracy: 0.8220\n",
            "Epoch 1854/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1405 - accuracy: 0.9503\n",
            "Epoch 1854: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1400 - accuracy: 0.9506 - val_loss: 1.0959 - val_accuracy: 0.8092\n",
            "Epoch 1855/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1377 - accuracy: 0.9498\n",
            "Epoch 1855: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1396 - accuracy: 0.9492 - val_loss: 1.1609 - val_accuracy: 0.8031\n",
            "Epoch 1856/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1457 - accuracy: 0.9456\n",
            "Epoch 1856: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1493 - accuracy: 0.9440 - val_loss: 0.9293 - val_accuracy: 0.8492\n",
            "Epoch 1857/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1572 - accuracy: 0.9443\n",
            "Epoch 1857: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1565 - accuracy: 0.9443 - val_loss: 1.0429 - val_accuracy: 0.8255\n",
            "Epoch 1858/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1749 - accuracy: 0.9375\n",
            "Epoch 1858: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1804 - accuracy: 0.9358 - val_loss: 1.1760 - val_accuracy: 0.7958\n",
            "Epoch 1859/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2669 - accuracy: 0.9047\n",
            "Epoch 1859: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2584 - accuracy: 0.9077 - val_loss: 0.9730 - val_accuracy: 0.8383\n",
            "Epoch 1860/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1684 - accuracy: 0.9386\n",
            "Epoch 1860: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1675 - accuracy: 0.9389 - val_loss: 1.0029 - val_accuracy: 0.8335\n",
            "Epoch 1861/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1532 - accuracy: 0.9432\n",
            "Epoch 1861: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1543 - accuracy: 0.9426 - val_loss: 1.0980 - val_accuracy: 0.8150\n",
            "Epoch 1862/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1494 - accuracy: 0.9435\n",
            "Epoch 1862: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1533 - accuracy: 0.9413 - val_loss: 1.1926 - val_accuracy: 0.8015\n",
            "Epoch 1863/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2131 - accuracy: 0.9249\n",
            "Epoch 1863: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2057 - accuracy: 0.9274 - val_loss: 0.9499 - val_accuracy: 0.8499\n",
            "Epoch 1864/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.4065 - accuracy: 0.8771\n",
            "Epoch 1864: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4019 - accuracy: 0.8780 - val_loss: 1.1732 - val_accuracy: 0.8003\n",
            "Epoch 1865/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2276 - accuracy: 0.9206\n",
            "Epoch 1865: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2244 - accuracy: 0.9216 - val_loss: 1.1225 - val_accuracy: 0.8166\n",
            "Epoch 1866/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1366 - accuracy: 0.9503\n",
            "Epoch 1866: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1354 - accuracy: 0.9503 - val_loss: 0.9823 - val_accuracy: 0.8355\n",
            "Epoch 1867/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1231 - accuracy: 0.9565\n",
            "Epoch 1867: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1235 - accuracy: 0.9565 - val_loss: 1.0218 - val_accuracy: 0.8307\n",
            "Epoch 1868/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1259 - accuracy: 0.9563\n",
            "Epoch 1868: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1264 - accuracy: 0.9560 - val_loss: 0.9866 - val_accuracy: 0.8319\n",
            "Epoch 1869/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1339 - accuracy: 0.9499\n",
            "Epoch 1869: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1338 - accuracy: 0.9498 - val_loss: 0.9801 - val_accuracy: 0.8393\n",
            "Epoch 1870/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1400 - accuracy: 0.9491\n",
            "Epoch 1870: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1402 - accuracy: 0.9493 - val_loss: 0.9687 - val_accuracy: 0.8502\n",
            "Epoch 1871/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1453 - accuracy: 0.9457\n",
            "Epoch 1871: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1431 - accuracy: 0.9470 - val_loss: 1.0264 - val_accuracy: 0.8303\n",
            "Epoch 1872/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1357 - accuracy: 0.9497\n",
            "Epoch 1872: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1363 - accuracy: 0.9493 - val_loss: 1.0609 - val_accuracy: 0.8185\n",
            "Epoch 1873/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2075 - accuracy: 0.9246\n",
            "Epoch 1873: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2090 - accuracy: 0.9244 - val_loss: 1.0521 - val_accuracy: 0.8137\n",
            "Epoch 1874/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1635 - accuracy: 0.9403\n",
            "Epoch 1874: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1607 - accuracy: 0.9413 - val_loss: 0.9318 - val_accuracy: 0.8512\n",
            "Epoch 1875/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2009 - accuracy: 0.9254\n",
            "Epoch 1875: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2206 - accuracy: 0.9217 - val_loss: 2.1451 - val_accuracy: 0.6690\n",
            "Epoch 1876/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.5549 - accuracy: 0.8566\n",
            "Epoch 1876: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.5524 - accuracy: 0.8571 - val_loss: 1.0339 - val_accuracy: 0.8300\n",
            "Epoch 1877/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1804 - accuracy: 0.9341\n",
            "Epoch 1877: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1797 - accuracy: 0.9344 - val_loss: 0.9593 - val_accuracy: 0.8422\n",
            "Epoch 1878/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1665 - accuracy: 0.9398\n",
            "Epoch 1878: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1675 - accuracy: 0.9395 - val_loss: 1.1522 - val_accuracy: 0.8102\n",
            "Epoch 1879/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1480 - accuracy: 0.9479\n",
            "Epoch 1879: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1483 - accuracy: 0.9477 - val_loss: 0.9743 - val_accuracy: 0.8451\n",
            "Epoch 1880/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1337 - accuracy: 0.9513\n",
            "Epoch 1880: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1337 - accuracy: 0.9513 - val_loss: 1.0329 - val_accuracy: 0.8268\n",
            "Epoch 1881/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1351 - accuracy: 0.9515\n",
            "Epoch 1881: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1341 - accuracy: 0.9516 - val_loss: 0.9276 - val_accuracy: 0.8476\n",
            "Epoch 1882/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1230 - accuracy: 0.9547\n",
            "Epoch 1882: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1232 - accuracy: 0.9545 - val_loss: 0.9827 - val_accuracy: 0.8342\n",
            "Epoch 1883/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1202 - accuracy: 0.9573\n",
            "Epoch 1883: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1206 - accuracy: 0.9570 - val_loss: 0.9846 - val_accuracy: 0.8454\n",
            "Epoch 1884/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1311 - accuracy: 0.9541\n",
            "Epoch 1884: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1321 - accuracy: 0.9544 - val_loss: 0.9823 - val_accuracy: 0.8335\n",
            "Epoch 1885/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1267 - accuracy: 0.9548\n",
            "Epoch 1885: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1273 - accuracy: 0.9547 - val_loss: 0.9734 - val_accuracy: 0.8441\n",
            "Epoch 1886/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1625 - accuracy: 0.9385\n",
            "Epoch 1886: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1631 - accuracy: 0.9386 - val_loss: 1.1077 - val_accuracy: 0.8118\n",
            "Epoch 1887/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.3263 - accuracy: 0.8939\n",
            "Epoch 1887: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3166 - accuracy: 0.8963 - val_loss: 1.0930 - val_accuracy: 0.8079\n",
            "Epoch 1888/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1646 - accuracy: 0.9403\n",
            "Epoch 1888: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1664 - accuracy: 0.9393 - val_loss: 1.1540 - val_accuracy: 0.8041\n",
            "Epoch 1889/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1431 - accuracy: 0.9473\n",
            "Epoch 1889: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1432 - accuracy: 0.9473 - val_loss: 1.0275 - val_accuracy: 0.8361\n",
            "Epoch 1890/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1918 - accuracy: 0.9297\n",
            "Epoch 1890: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1996 - accuracy: 0.9275 - val_loss: 1.2789 - val_accuracy: 0.7903\n",
            "Epoch 1891/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3240 - accuracy: 0.8880\n",
            "Epoch 1891: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3240 - accuracy: 0.8880 - val_loss: 1.3421 - val_accuracy: 0.7871\n",
            "Epoch 1892/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1894 - accuracy: 0.9302\n",
            "Epoch 1892: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1893 - accuracy: 0.9304 - val_loss: 0.9828 - val_accuracy: 0.8377\n",
            "Epoch 1893/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1320 - accuracy: 0.9503\n",
            "Epoch 1893: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1320 - accuracy: 0.9503 - val_loss: 0.9545 - val_accuracy: 0.8399\n",
            "Epoch 1894/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1347 - accuracy: 0.9513\n",
            "Epoch 1894: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1325 - accuracy: 0.9520 - val_loss: 0.9256 - val_accuracy: 0.8531\n",
            "Epoch 1895/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1633 - accuracy: 0.9416\n",
            "Epoch 1895: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1734 - accuracy: 0.9394 - val_loss: 1.1595 - val_accuracy: 0.8163\n",
            "Epoch 1896/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2015 - accuracy: 0.9259\n",
            "Epoch 1896: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2015 - accuracy: 0.9259 - val_loss: 1.0073 - val_accuracy: 0.8377\n",
            "Epoch 1897/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1664 - accuracy: 0.9392\n",
            "Epoch 1897: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1666 - accuracy: 0.9392 - val_loss: 1.2331 - val_accuracy: 0.7932\n",
            "Epoch 1898/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1613 - accuracy: 0.9422\n",
            "Epoch 1898: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1610 - accuracy: 0.9424 - val_loss: 1.1083 - val_accuracy: 0.8111\n",
            "Epoch 1899/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2293 - accuracy: 0.9166\n",
            "Epoch 1899: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2304 - accuracy: 0.9161 - val_loss: 1.1599 - val_accuracy: 0.7951\n",
            "Epoch 1900/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2431 - accuracy: 0.9113\n",
            "Epoch 1900: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2393 - accuracy: 0.9123 - val_loss: 1.1207 - val_accuracy: 0.8220\n",
            "Epoch 1901/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1922 - accuracy: 0.9302\n",
            "Epoch 1901: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1906 - accuracy: 0.9309 - val_loss: 1.0510 - val_accuracy: 0.8239\n",
            "Epoch 1902/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1492 - accuracy: 0.9445\n",
            "Epoch 1902: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1481 - accuracy: 0.9449 - val_loss: 1.0463 - val_accuracy: 0.8271\n",
            "Epoch 1903/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1682 - accuracy: 0.9409\n",
            "Epoch 1903: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1669 - accuracy: 0.9413 - val_loss: 0.9788 - val_accuracy: 0.8483\n",
            "Epoch 1904/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1183 - accuracy: 0.9578\n",
            "Epoch 1904: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1214 - accuracy: 0.9562 - val_loss: 1.0194 - val_accuracy: 0.8403\n",
            "Epoch 1905/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1617 - accuracy: 0.9400\n",
            "Epoch 1905: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1604 - accuracy: 0.9404 - val_loss: 1.0415 - val_accuracy: 0.8335\n",
            "Epoch 1906/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3727 - accuracy: 0.8811\n",
            "Epoch 1906: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3759 - accuracy: 0.8800 - val_loss: 1.3107 - val_accuracy: 0.7788\n",
            "Epoch 1907/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1674 - accuracy: 0.9389\n",
            "Epoch 1907: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1674 - accuracy: 0.9389 - val_loss: 1.0919 - val_accuracy: 0.8076\n",
            "Epoch 1908/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1436 - accuracy: 0.9501\n",
            "Epoch 1908: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1442 - accuracy: 0.9493 - val_loss: 0.9616 - val_accuracy: 0.8451\n",
            "Epoch 1909/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1242 - accuracy: 0.9558\n",
            "Epoch 1909: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1250 - accuracy: 0.9556 - val_loss: 0.9554 - val_accuracy: 0.8438\n",
            "Epoch 1910/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.5855 - accuracy: 0.8418\n",
            "Epoch 1910: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.5727 - accuracy: 0.8444 - val_loss: 1.0891 - val_accuracy: 0.8201\n",
            "Epoch 1911/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1443 - accuracy: 0.9469\n",
            "Epoch 1911: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1443 - accuracy: 0.9471 - val_loss: 0.9232 - val_accuracy: 0.8566\n",
            "Epoch 1912/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1109 - accuracy: 0.9610\n",
            "Epoch 1912: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1106 - accuracy: 0.9612 - val_loss: 1.0401 - val_accuracy: 0.8329\n",
            "Epoch 1913/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1247 - accuracy: 0.9530\n",
            "Epoch 1913: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1281 - accuracy: 0.9512 - val_loss: 1.0462 - val_accuracy: 0.8252\n",
            "Epoch 1914/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1484 - accuracy: 0.9455\n",
            "Epoch 1914: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1473 - accuracy: 0.9461 - val_loss: 1.0237 - val_accuracy: 0.8332\n",
            "Epoch 1915/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1446 - accuracy: 0.9473\n",
            "Epoch 1915: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1475 - accuracy: 0.9461 - val_loss: 1.1167 - val_accuracy: 0.8143\n",
            "Epoch 1916/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1671 - accuracy: 0.9379\n",
            "Epoch 1916: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1679 - accuracy: 0.9379 - val_loss: 0.9655 - val_accuracy: 0.8441\n",
            "Epoch 1917/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1552 - accuracy: 0.9436\n",
            "Epoch 1917: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1560 - accuracy: 0.9431 - val_loss: 1.1404 - val_accuracy: 0.8067\n",
            "Epoch 1918/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1626 - accuracy: 0.9397\n",
            "Epoch 1918: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1633 - accuracy: 0.9395 - val_loss: 1.0755 - val_accuracy: 0.8217\n",
            "Epoch 1919/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2690 - accuracy: 0.9040\n",
            "Epoch 1919: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.2639 - accuracy: 0.9053 - val_loss: 1.0221 - val_accuracy: 0.8355\n",
            "Epoch 1920/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1427 - accuracy: 0.9476\n",
            "Epoch 1920: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1427 - accuracy: 0.9476 - val_loss: 0.9364 - val_accuracy: 0.8483\n",
            "Epoch 1921/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1243 - accuracy: 0.9565\n",
            "Epoch 1921: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1248 - accuracy: 0.9563 - val_loss: 1.0114 - val_accuracy: 0.8355\n",
            "Epoch 1922/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1310 - accuracy: 0.9518\n",
            "Epoch 1922: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1310 - accuracy: 0.9518 - val_loss: 1.0097 - val_accuracy: 0.8348\n",
            "Epoch 1923/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1307 - accuracy: 0.9525\n",
            "Epoch 1923: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1313 - accuracy: 0.9522 - val_loss: 1.0476 - val_accuracy: 0.8249\n",
            "Epoch 1924/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1342 - accuracy: 0.9522\n",
            "Epoch 1924: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1348 - accuracy: 0.9517 - val_loss: 1.0162 - val_accuracy: 0.8342\n",
            "Epoch 1925/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2349 - accuracy: 0.9176\n",
            "Epoch 1925: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2405 - accuracy: 0.9160 - val_loss: 1.3844 - val_accuracy: 0.7538\n",
            "Epoch 1926/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3224 - accuracy: 0.8936\n",
            "Epoch 1926: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3224 - accuracy: 0.8936 - val_loss: 1.1731 - val_accuracy: 0.8038\n",
            "Epoch 1927/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1774 - accuracy: 0.9329\n",
            "Epoch 1927: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1771 - accuracy: 0.9330 - val_loss: 1.0800 - val_accuracy: 0.8134\n",
            "Epoch 1928/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1855 - accuracy: 0.9347\n",
            "Epoch 1928: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1866 - accuracy: 0.9341 - val_loss: 0.9956 - val_accuracy: 0.8377\n",
            "Epoch 1929/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1629 - accuracy: 0.9390\n",
            "Epoch 1929: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1640 - accuracy: 0.9384 - val_loss: 1.1241 - val_accuracy: 0.8083\n",
            "Epoch 1930/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2173 - accuracy: 0.9207\n",
            "Epoch 1930: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2173 - accuracy: 0.9205 - val_loss: 0.9855 - val_accuracy: 0.8467\n",
            "Epoch 1931/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2186 - accuracy: 0.9214\n",
            "Epoch 1931: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2167 - accuracy: 0.9224 - val_loss: 1.1439 - val_accuracy: 0.8131\n",
            "Epoch 1932/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1520 - accuracy: 0.9431\n",
            "Epoch 1932: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1520 - accuracy: 0.9429 - val_loss: 1.0368 - val_accuracy: 0.8268\n",
            "Epoch 1933/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1813 - accuracy: 0.9335\n",
            "Epoch 1933: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1864 - accuracy: 0.9327 - val_loss: 1.6239 - val_accuracy: 0.7407\n",
            "Epoch 1934/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3473 - accuracy: 0.8812\n",
            "Epoch 1934: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3472 - accuracy: 0.8812 - val_loss: 1.0008 - val_accuracy: 0.8351\n",
            "Epoch 1935/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1848 - accuracy: 0.9334\n",
            "Epoch 1935: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.1846 - accuracy: 0.9331 - val_loss: 0.9813 - val_accuracy: 0.8489\n",
            "Epoch 1936/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1548 - accuracy: 0.9432\n",
            "Epoch 1936: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1540 - accuracy: 0.9436 - val_loss: 1.0052 - val_accuracy: 0.8348\n",
            "Epoch 1937/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1526 - accuracy: 0.9439\n",
            "Epoch 1937: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1536 - accuracy: 0.9431 - val_loss: 1.0951 - val_accuracy: 0.8169\n",
            "Epoch 1938/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1377 - accuracy: 0.9492\n",
            "Epoch 1938: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1375 - accuracy: 0.9493 - val_loss: 0.9619 - val_accuracy: 0.8444\n",
            "Epoch 1939/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1736 - accuracy: 0.9356\n",
            "Epoch 1939: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1725 - accuracy: 0.9357 - val_loss: 0.9777 - val_accuracy: 0.8457\n",
            "Epoch 1940/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1218 - accuracy: 0.9566\n",
            "Epoch 1940: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1218 - accuracy: 0.9566 - val_loss: 0.9848 - val_accuracy: 0.8441\n",
            "Epoch 1941/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1469 - accuracy: 0.9469\n",
            "Epoch 1941: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1466 - accuracy: 0.9471 - val_loss: 0.9834 - val_accuracy: 0.8451\n",
            "Epoch 1942/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1327 - accuracy: 0.9500\n",
            "Epoch 1942: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1390 - accuracy: 0.9478 - val_loss: 1.1329 - val_accuracy: 0.8140\n",
            "Epoch 1943/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1789 - accuracy: 0.9313\n",
            "Epoch 1943: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1780 - accuracy: 0.9315 - val_loss: 1.1332 - val_accuracy: 0.8191\n",
            "Epoch 1944/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1511 - accuracy: 0.9447\n",
            "Epoch 1944: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1515 - accuracy: 0.9445 - val_loss: 1.0355 - val_accuracy: 0.8287\n",
            "Epoch 1945/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2217 - accuracy: 0.9196\n",
            "Epoch 1945: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2151 - accuracy: 0.9223 - val_loss: 1.0018 - val_accuracy: 0.8329\n",
            "Epoch 1946/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1355 - accuracy: 0.9498\n",
            "Epoch 1946: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1366 - accuracy: 0.9498 - val_loss: 1.0331 - val_accuracy: 0.8406\n",
            "Epoch 1947/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2015 - accuracy: 0.9268\n",
            "Epoch 1947: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2015 - accuracy: 0.9268 - val_loss: 1.1700 - val_accuracy: 0.8035\n",
            "Epoch 1948/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2495 - accuracy: 0.9114\n",
            "Epoch 1948: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2453 - accuracy: 0.9129 - val_loss: 1.0433 - val_accuracy: 0.8281\n",
            "Epoch 1949/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1753 - accuracy: 0.9355\n",
            "Epoch 1949: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1745 - accuracy: 0.9358 - val_loss: 1.0203 - val_accuracy: 0.8323\n",
            "Epoch 1950/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1427 - accuracy: 0.9478\n",
            "Epoch 1950: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1429 - accuracy: 0.9477 - val_loss: 1.0271 - val_accuracy: 0.8287\n",
            "Epoch 1951/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1785 - accuracy: 0.9331\n",
            "Epoch 1951: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1787 - accuracy: 0.9328 - val_loss: 1.0795 - val_accuracy: 0.8291\n",
            "Epoch 1952/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1304 - accuracy: 0.9512\n",
            "Epoch 1952: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1316 - accuracy: 0.9508 - val_loss: 1.0129 - val_accuracy: 0.8390\n",
            "Epoch 1953/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2236 - accuracy: 0.9212\n",
            "Epoch 1953: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2249 - accuracy: 0.9209 - val_loss: 2.1695 - val_accuracy: 0.6889\n",
            "Epoch 1954/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2787 - accuracy: 0.9081\n",
            "Epoch 1954: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2701 - accuracy: 0.9107 - val_loss: 1.0265 - val_accuracy: 0.8383\n",
            "Epoch 1955/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1891 - accuracy: 0.9294\n",
            "Epoch 1955: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1881 - accuracy: 0.9298 - val_loss: 1.0336 - val_accuracy: 0.8198\n",
            "Epoch 1956/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1840 - accuracy: 0.9329\n",
            "Epoch 1956: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1840 - accuracy: 0.9327 - val_loss: 1.0648 - val_accuracy: 0.8246\n",
            "Epoch 1957/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1279 - accuracy: 0.9536\n",
            "Epoch 1957: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1276 - accuracy: 0.9533 - val_loss: 0.9512 - val_accuracy: 0.8470\n",
            "Epoch 1958/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1752 - accuracy: 0.9389\n",
            "Epoch 1958: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1744 - accuracy: 0.9389 - val_loss: 1.0933 - val_accuracy: 0.8252\n",
            "Epoch 1959/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1479 - accuracy: 0.9457\n",
            "Epoch 1959: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1478 - accuracy: 0.9456 - val_loss: 1.0935 - val_accuracy: 0.8179\n",
            "Epoch 1960/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1851 - accuracy: 0.9333\n",
            "Epoch 1960: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1847 - accuracy: 0.9332 - val_loss: 1.2376 - val_accuracy: 0.7894\n",
            "Epoch 1961/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1481 - accuracy: 0.9462\n",
            "Epoch 1961: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1482 - accuracy: 0.9461 - val_loss: 1.1177 - val_accuracy: 0.8067\n",
            "Epoch 1962/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1411 - accuracy: 0.9479\n",
            "Epoch 1962: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1414 - accuracy: 0.9486 - val_loss: 1.1373 - val_accuracy: 0.8057\n",
            "Epoch 1963/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1904 - accuracy: 0.9303\n",
            "Epoch 1963: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1901 - accuracy: 0.9304 - val_loss: 1.0718 - val_accuracy: 0.8143\n",
            "Epoch 1964/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1323 - accuracy: 0.9516\n",
            "Epoch 1964: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1393 - accuracy: 0.9493 - val_loss: 1.1570 - val_accuracy: 0.8003\n",
            "Epoch 1965/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3492 - accuracy: 0.8853\n",
            "Epoch 1965: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3432 - accuracy: 0.8866 - val_loss: 1.1330 - val_accuracy: 0.8134\n",
            "Epoch 1966/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2012 - accuracy: 0.9266\n",
            "Epoch 1966: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1995 - accuracy: 0.9271 - val_loss: 0.9861 - val_accuracy: 0.8444\n",
            "Epoch 1967/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1143 - accuracy: 0.9589\n",
            "Epoch 1967: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1143 - accuracy: 0.9589 - val_loss: 0.9938 - val_accuracy: 0.8448\n",
            "Epoch 1968/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1353 - accuracy: 0.9504\n",
            "Epoch 1968: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1360 - accuracy: 0.9500 - val_loss: 1.3557 - val_accuracy: 0.7766\n",
            "Epoch 1969/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2010 - accuracy: 0.9257\n",
            "Epoch 1969: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2005 - accuracy: 0.9258 - val_loss: 1.0665 - val_accuracy: 0.8275\n",
            "Epoch 1970/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1278 - accuracy: 0.9527\n",
            "Epoch 1970: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1275 - accuracy: 0.9528 - val_loss: 1.0454 - val_accuracy: 0.8307\n",
            "Epoch 1971/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2503 - accuracy: 0.9161\n",
            "Epoch 1971: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2467 - accuracy: 0.9169 - val_loss: 1.0655 - val_accuracy: 0.8291\n",
            "Epoch 1972/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1667 - accuracy: 0.9381\n",
            "Epoch 1972: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1667 - accuracy: 0.9381 - val_loss: 0.9908 - val_accuracy: 0.8441\n",
            "Epoch 1973/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2412 - accuracy: 0.9204\n",
            "Epoch 1973: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2516 - accuracy: 0.9177 - val_loss: 1.2667 - val_accuracy: 0.7868\n",
            "Epoch 1974/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1581 - accuracy: 0.9400\n",
            "Epoch 1974: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1556 - accuracy: 0.9405 - val_loss: 0.9377 - val_accuracy: 0.8528\n",
            "Epoch 1975/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1543 - accuracy: 0.9456\n",
            "Epoch 1975: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1538 - accuracy: 0.9458 - val_loss: 0.9660 - val_accuracy: 0.8419\n",
            "Epoch 1976/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1539 - accuracy: 0.9431\n",
            "Epoch 1976: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1541 - accuracy: 0.9433 - val_loss: 0.9785 - val_accuracy: 0.8428\n",
            "Epoch 1977/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1350 - accuracy: 0.9513\n",
            "Epoch 1977: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1350 - accuracy: 0.9513 - val_loss: 0.9537 - val_accuracy: 0.8537\n",
            "Epoch 1978/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1624 - accuracy: 0.9403\n",
            "Epoch 1978: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1657 - accuracy: 0.9396 - val_loss: 1.0374 - val_accuracy: 0.8294\n",
            "Epoch 1979/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2124 - accuracy: 0.9232\n",
            "Epoch 1979: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2105 - accuracy: 0.9240 - val_loss: 1.1345 - val_accuracy: 0.8092\n",
            "Epoch 1980/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1287 - accuracy: 0.9528\n",
            "Epoch 1980: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1273 - accuracy: 0.9537 - val_loss: 0.9729 - val_accuracy: 0.8496\n",
            "Epoch 1981/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1443 - accuracy: 0.9461\n",
            "Epoch 1981: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1431 - accuracy: 0.9465 - val_loss: 1.1659 - val_accuracy: 0.8003\n",
            "Epoch 1982/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3319 - accuracy: 0.8946\n",
            "Epoch 1982: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3323 - accuracy: 0.8943 - val_loss: 2.2592 - val_accuracy: 0.6773\n",
            "Epoch 1983/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.6663 - accuracy: 0.8247\n",
            "Epoch 1983: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.6302 - accuracy: 0.8323 - val_loss: 1.0205 - val_accuracy: 0.8278\n",
            "Epoch 1984/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1307 - accuracy: 0.9539\n",
            "Epoch 1984: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1342 - accuracy: 0.9525 - val_loss: 1.0609 - val_accuracy: 0.8211\n",
            "Epoch 1985/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1431 - accuracy: 0.9479\n",
            "Epoch 1985: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1424 - accuracy: 0.9482 - val_loss: 0.9410 - val_accuracy: 0.8492\n",
            "Epoch 1986/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1044 - accuracy: 0.9645\n",
            "Epoch 1986: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1043 - accuracy: 0.9645 - val_loss: 0.9700 - val_accuracy: 0.8451\n",
            "Epoch 1987/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1206 - accuracy: 0.9567\n",
            "Epoch 1987: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1197 - accuracy: 0.9569 - val_loss: 0.9831 - val_accuracy: 0.8460\n",
            "Epoch 1988/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1059 - accuracy: 0.9630\n",
            "Epoch 1988: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1063 - accuracy: 0.9624 - val_loss: 1.0833 - val_accuracy: 0.8223\n",
            "Epoch 1989/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1478 - accuracy: 0.9439\n",
            "Epoch 1989: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1474 - accuracy: 0.9441 - val_loss: 1.0353 - val_accuracy: 0.8374\n",
            "Epoch 1990/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1348 - accuracy: 0.9472\n",
            "Epoch 1990: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1339 - accuracy: 0.9478 - val_loss: 0.9367 - val_accuracy: 0.8515\n",
            "Epoch 1991/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1951 - accuracy: 0.9298\n",
            "Epoch 1991: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1951 - accuracy: 0.9298 - val_loss: 1.1217 - val_accuracy: 0.8159\n",
            "Epoch 1992/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2150 - accuracy: 0.9203\n",
            "Epoch 1992: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2136 - accuracy: 0.9208 - val_loss: 0.9776 - val_accuracy: 0.8409\n",
            "Epoch 1993/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1331 - accuracy: 0.9505\n",
            "Epoch 1993: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1369 - accuracy: 0.9489 - val_loss: 1.0040 - val_accuracy: 0.8307\n",
            "Epoch 1994/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1407 - accuracy: 0.9481\n",
            "Epoch 1994: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1407 - accuracy: 0.9481 - val_loss: 1.0770 - val_accuracy: 0.8278\n",
            "Epoch 1995/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1851 - accuracy: 0.9292\n",
            "Epoch 1995: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1876 - accuracy: 0.9285 - val_loss: 1.2548 - val_accuracy: 0.7843\n",
            "Epoch 1996/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2180 - accuracy: 0.9195\n",
            "Epoch 1996: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2177 - accuracy: 0.9194 - val_loss: 0.9962 - val_accuracy: 0.8390\n",
            "Epoch 1997/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1790 - accuracy: 0.9339\n",
            "Epoch 1997: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1797 - accuracy: 0.9340 - val_loss: 1.0365 - val_accuracy: 0.8323\n",
            "Epoch 1998/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2390 - accuracy: 0.9145\n",
            "Epoch 1998: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2360 - accuracy: 0.9153 - val_loss: 0.9845 - val_accuracy: 0.8406\n",
            "Epoch 1999/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1355 - accuracy: 0.9534\n",
            "Epoch 1999: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1394 - accuracy: 0.9518 - val_loss: 0.9964 - val_accuracy: 0.8409\n",
            "Epoch 2000/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1428 - accuracy: 0.9467\n",
            "Epoch 2000: val_accuracy did not improve from 0.85915\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1428 - accuracy: 0.9467 - val_loss: 1.1234 - val_accuracy: 0.8163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try another model with deferent activation function sigmoid"
      ],
      "metadata": {
        "id": "hqxeG750hdnH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## the best model with 85% accuraccy on validtion data"
      ],
      "metadata": {
        "id": "81cRjSEEhrfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 174\n",
        "\n",
        "model = Sequential()\n",
        "model.add(GRU(33, input_shape=(1, 543)))\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "filepath       = \"/content/asl1/Adam4/cp-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint     = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history2 = model.fit(X_train, y_train_encoded, validation_data=(X_test, y_test_encoded), epochs=2000, batch_size=128,callbacks=callbacks_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oApEcUzN-ya",
        "outputId": "d69c1068-2f48-4d19-87d8-2dc42955d2c3"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 751/2000\n",
            "88/98 [=========================>....] - ETA: 0s - loss: 0.4438 - accuracy: 0.8551\n",
            "Epoch 751: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.4370 - accuracy: 0.8571 - val_loss: 0.9005 - val_accuracy: 0.7730\n",
            "Epoch 752/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3964 - accuracy: 0.8638\n",
            "Epoch 752: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3956 - accuracy: 0.8641 - val_loss: 0.8438 - val_accuracy: 0.8108\n",
            "Epoch 753/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3178 - accuracy: 0.8911\n",
            "Epoch 753: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3181 - accuracy: 0.8912 - val_loss: 0.8042 - val_accuracy: 0.8095\n",
            "Epoch 754/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3712 - accuracy: 0.8716\n",
            "Epoch 754: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3681 - accuracy: 0.8732 - val_loss: 0.8493 - val_accuracy: 0.8060\n",
            "Epoch 755/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2901 - accuracy: 0.8972\n",
            "Epoch 755: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2921 - accuracy: 0.8965 - val_loss: 0.7772 - val_accuracy: 0.8166\n",
            "Epoch 756/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3772 - accuracy: 0.8704\n",
            "Epoch 756: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3772 - accuracy: 0.8704 - val_loss: 1.2587 - val_accuracy: 0.7068\n",
            "Epoch 757/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.4520 - accuracy: 0.8424\n",
            "Epoch 757: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.4490 - accuracy: 0.8435 - val_loss: 0.8598 - val_accuracy: 0.7993\n",
            "Epoch 758/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3495 - accuracy: 0.8793\n",
            "Epoch 758: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3495 - accuracy: 0.8793 - val_loss: 0.8044 - val_accuracy: 0.8143\n",
            "Epoch 759/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3023 - accuracy: 0.8976\n",
            "Epoch 759: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3034 - accuracy: 0.8973 - val_loss: 0.9245 - val_accuracy: 0.7794\n",
            "Epoch 760/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3748 - accuracy: 0.8684\n",
            "Epoch 760: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3727 - accuracy: 0.8693 - val_loss: 0.8229 - val_accuracy: 0.8169\n",
            "Epoch 761/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3573 - accuracy: 0.8736\n",
            "Epoch 761: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3591 - accuracy: 0.8734 - val_loss: 0.8827 - val_accuracy: 0.7900\n",
            "Epoch 762/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3317 - accuracy: 0.8840\n",
            "Epoch 762: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3324 - accuracy: 0.8831 - val_loss: 1.0001 - val_accuracy: 0.7561\n",
            "Epoch 763/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3784 - accuracy: 0.8698\n",
            "Epoch 763: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3718 - accuracy: 0.8721 - val_loss: 0.8860 - val_accuracy: 0.7868\n",
            "Epoch 764/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.3300 - accuracy: 0.8847\n",
            "Epoch 764: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3243 - accuracy: 0.8872 - val_loss: 0.7737 - val_accuracy: 0.8220\n",
            "Epoch 765/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2911 - accuracy: 0.8997\n",
            "Epoch 765: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2980 - accuracy: 0.8976 - val_loss: 1.4557 - val_accuracy: 0.6821\n",
            "Epoch 766/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3698 - accuracy: 0.8740\n",
            "Epoch 766: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3701 - accuracy: 0.8738 - val_loss: 1.0491 - val_accuracy: 0.7586\n",
            "Epoch 767/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.4048 - accuracy: 0.8631\n",
            "Epoch 767: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4048 - accuracy: 0.8631 - val_loss: 1.1184 - val_accuracy: 0.7356\n",
            "Epoch 768/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3133 - accuracy: 0.8916\n",
            "Epoch 768: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3103 - accuracy: 0.8932 - val_loss: 0.8500 - val_accuracy: 0.7961\n",
            "Epoch 769/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2911 - accuracy: 0.8986\n",
            "Epoch 769: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2923 - accuracy: 0.8978 - val_loss: 0.8428 - val_accuracy: 0.8012\n",
            "Epoch 770/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3000 - accuracy: 0.8975\n",
            "Epoch 770: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3009 - accuracy: 0.8972 - val_loss: 0.8372 - val_accuracy: 0.8047\n",
            "Epoch 771/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3411 - accuracy: 0.8788\n",
            "Epoch 771: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3457 - accuracy: 0.8771 - val_loss: 0.8776 - val_accuracy: 0.7926\n",
            "Epoch 772/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2944 - accuracy: 0.8980\n",
            "Epoch 772: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2952 - accuracy: 0.8978 - val_loss: 0.9350 - val_accuracy: 0.7846\n",
            "Epoch 773/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.3791 - accuracy: 0.8658\n",
            "Epoch 773: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3891 - accuracy: 0.8620 - val_loss: 1.0911 - val_accuracy: 0.7577\n",
            "Epoch 774/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3806 - accuracy: 0.8690\n",
            "Epoch 774: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3779 - accuracy: 0.8700 - val_loss: 0.8257 - val_accuracy: 0.8092\n",
            "Epoch 775/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2706 - accuracy: 0.9096\n",
            "Epoch 775: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2754 - accuracy: 0.9077 - val_loss: 0.8626 - val_accuracy: 0.7993\n",
            "Epoch 776/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3125 - accuracy: 0.8912\n",
            "Epoch 776: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3181 - accuracy: 0.8893 - val_loss: 1.1265 - val_accuracy: 0.7420\n",
            "Epoch 777/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3356 - accuracy: 0.8836\n",
            "Epoch 777: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3386 - accuracy: 0.8832 - val_loss: 1.0035 - val_accuracy: 0.7567\n",
            "Epoch 778/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3197 - accuracy: 0.8884\n",
            "Epoch 778: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3197 - accuracy: 0.8884 - val_loss: 0.8543 - val_accuracy: 0.7980\n",
            "Epoch 779/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.4111 - accuracy: 0.8559\n",
            "Epoch 779: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.4089 - accuracy: 0.8574 - val_loss: 0.9399 - val_accuracy: 0.7798\n",
            "Epoch 780/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3090 - accuracy: 0.8929\n",
            "Epoch 780: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3101 - accuracy: 0.8928 - val_loss: 0.8722 - val_accuracy: 0.7987\n",
            "Epoch 781/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3415 - accuracy: 0.8799\n",
            "Epoch 781: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3396 - accuracy: 0.8808 - val_loss: 0.8655 - val_accuracy: 0.8012\n",
            "Epoch 782/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3116 - accuracy: 0.8909\n",
            "Epoch 782: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3111 - accuracy: 0.8910 - val_loss: 0.8199 - val_accuracy: 0.8166\n",
            "Epoch 783/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2734 - accuracy: 0.9078\n",
            "Epoch 783: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2786 - accuracy: 0.9048 - val_loss: 0.9168 - val_accuracy: 0.7830\n",
            "Epoch 784/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3376 - accuracy: 0.8830\n",
            "Epoch 784: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3388 - accuracy: 0.8826 - val_loss: 0.8091 - val_accuracy: 0.8163\n",
            "Epoch 785/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3453 - accuracy: 0.8803\n",
            "Epoch 785: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3453 - accuracy: 0.8801 - val_loss: 1.0059 - val_accuracy: 0.7682\n",
            "Epoch 786/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3401 - accuracy: 0.8796\n",
            "Epoch 786: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3414 - accuracy: 0.8787 - val_loss: 0.8321 - val_accuracy: 0.8044\n",
            "Epoch 787/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3298 - accuracy: 0.8838\n",
            "Epoch 787: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3299 - accuracy: 0.8838 - val_loss: 0.8863 - val_accuracy: 0.7958\n",
            "Epoch 788/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3210 - accuracy: 0.8880\n",
            "Epoch 788: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3224 - accuracy: 0.8873 - val_loss: 0.8366 - val_accuracy: 0.8051\n",
            "Epoch 789/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3147 - accuracy: 0.8893\n",
            "Epoch 789: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3131 - accuracy: 0.8909 - val_loss: 0.8359 - val_accuracy: 0.8111\n",
            "Epoch 790/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3156 - accuracy: 0.8894\n",
            "Epoch 790: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3156 - accuracy: 0.8894 - val_loss: 0.8100 - val_accuracy: 0.8179\n",
            "Epoch 791/2000\n",
            "88/98 [=========================>....] - ETA: 0s - loss: 0.3981 - accuracy: 0.8626\n",
            "Epoch 791: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3993 - accuracy: 0.8618 - val_loss: 0.9230 - val_accuracy: 0.7900\n",
            "Epoch 792/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.3589 - accuracy: 0.8754\n",
            "Epoch 792: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3699 - accuracy: 0.8712 - val_loss: 0.9679 - val_accuracy: 0.7788\n",
            "Epoch 793/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2936 - accuracy: 0.8987\n",
            "Epoch 793: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2941 - accuracy: 0.8976 - val_loss: 0.9918 - val_accuracy: 0.7647\n",
            "Epoch 794/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.3515 - accuracy: 0.8739\n",
            "Epoch 794: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3602 - accuracy: 0.8715 - val_loss: 1.4672 - val_accuracy: 0.6793\n",
            "Epoch 795/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.4387 - accuracy: 0.8492\n",
            "Epoch 795: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4310 - accuracy: 0.8517 - val_loss: 0.7995 - val_accuracy: 0.8172\n",
            "Epoch 796/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3145 - accuracy: 0.8893\n",
            "Epoch 796: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3103 - accuracy: 0.8911 - val_loss: 0.9058 - val_accuracy: 0.7865\n",
            "Epoch 797/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3037 - accuracy: 0.8934\n",
            "Epoch 797: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3043 - accuracy: 0.8927 - val_loss: 0.9338 - val_accuracy: 0.7827\n",
            "Epoch 798/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3548 - accuracy: 0.8767\n",
            "Epoch 798: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3567 - accuracy: 0.8762 - val_loss: 0.8588 - val_accuracy: 0.8051\n",
            "Epoch 799/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3335 - accuracy: 0.8820\n",
            "Epoch 799: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3302 - accuracy: 0.8835 - val_loss: 0.7866 - val_accuracy: 0.8175\n",
            "Epoch 800/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3297 - accuracy: 0.8813\n",
            "Epoch 800: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3296 - accuracy: 0.8812 - val_loss: 0.9886 - val_accuracy: 0.7756\n",
            "Epoch 801/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3936 - accuracy: 0.8668\n",
            "Epoch 801: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3906 - accuracy: 0.8674 - val_loss: 0.8346 - val_accuracy: 0.8118\n",
            "Epoch 802/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3231 - accuracy: 0.8868\n",
            "Epoch 802: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3262 - accuracy: 0.8857 - val_loss: 0.8499 - val_accuracy: 0.8009\n",
            "Epoch 803/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3096 - accuracy: 0.8925\n",
            "Epoch 803: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3116 - accuracy: 0.8916 - val_loss: 1.1284 - val_accuracy: 0.7401\n",
            "Epoch 804/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3302 - accuracy: 0.8858\n",
            "Epoch 804: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3302 - accuracy: 0.8858 - val_loss: 0.8604 - val_accuracy: 0.8006\n",
            "Epoch 805/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3066 - accuracy: 0.8936\n",
            "Epoch 805: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3070 - accuracy: 0.8930 - val_loss: 0.8450 - val_accuracy: 0.7983\n",
            "Epoch 806/2000\n",
            "88/98 [=========================>....] - ETA: 0s - loss: 0.3461 - accuracy: 0.8776\n",
            "Epoch 806: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3394 - accuracy: 0.8803 - val_loss: 0.8768 - val_accuracy: 0.8022\n",
            "Epoch 807/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.3297 - accuracy: 0.8871\n",
            "Epoch 807: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3244 - accuracy: 0.8889 - val_loss: 0.8208 - val_accuracy: 0.8182\n",
            "Epoch 808/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2713 - accuracy: 0.9073\n",
            "Epoch 808: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2707 - accuracy: 0.9074 - val_loss: 0.8103 - val_accuracy: 0.8156\n",
            "Epoch 809/2000\n",
            "88/98 [=========================>....] - ETA: 0s - loss: 0.3366 - accuracy: 0.8826\n",
            "Epoch 809: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3353 - accuracy: 0.8828 - val_loss: 0.9281 - val_accuracy: 0.7846\n",
            "Epoch 810/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3411 - accuracy: 0.8806\n",
            "Epoch 810: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3585 - accuracy: 0.8760 - val_loss: 0.9407 - val_accuracy: 0.7804\n",
            "Epoch 811/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3073 - accuracy: 0.8943\n",
            "Epoch 811: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3042 - accuracy: 0.8951 - val_loss: 0.8827 - val_accuracy: 0.7961\n",
            "Epoch 812/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2814 - accuracy: 0.9030\n",
            "Epoch 812: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2817 - accuracy: 0.9033 - val_loss: 0.8398 - val_accuracy: 0.8111\n",
            "Epoch 813/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.5880 - accuracy: 0.8346\n",
            "Epoch 813: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.5880 - accuracy: 0.8346 - val_loss: 1.1449 - val_accuracy: 0.7289\n",
            "Epoch 814/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3253 - accuracy: 0.8880\n",
            "Epoch 814: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3193 - accuracy: 0.8900 - val_loss: 0.8419 - val_accuracy: 0.8025\n",
            "Epoch 815/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3951 - accuracy: 0.8660\n",
            "Epoch 815: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3930 - accuracy: 0.8661 - val_loss: 0.8854 - val_accuracy: 0.7932\n",
            "Epoch 816/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2848 - accuracy: 0.9041\n",
            "Epoch 816: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2854 - accuracy: 0.9037 - val_loss: 0.8800 - val_accuracy: 0.7993\n",
            "Epoch 817/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3131 - accuracy: 0.8900\n",
            "Epoch 817: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3128 - accuracy: 0.8899 - val_loss: 0.8805 - val_accuracy: 0.7958\n",
            "Epoch 818/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2710 - accuracy: 0.9076\n",
            "Epoch 818: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2719 - accuracy: 0.9074 - val_loss: 0.8183 - val_accuracy: 0.8140\n",
            "Epoch 819/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3159 - accuracy: 0.8890\n",
            "Epoch 819: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3150 - accuracy: 0.8894 - val_loss: 0.8740 - val_accuracy: 0.7967\n",
            "Epoch 820/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2789 - accuracy: 0.9059\n",
            "Epoch 820: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2796 - accuracy: 0.9054 - val_loss: 0.8546 - val_accuracy: 0.8047\n",
            "Epoch 821/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3075 - accuracy: 0.8927\n",
            "Epoch 821: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3070 - accuracy: 0.8929 - val_loss: 0.8891 - val_accuracy: 0.7932\n",
            "Epoch 822/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2975 - accuracy: 0.8986\n",
            "Epoch 822: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3033 - accuracy: 0.8957 - val_loss: 0.8691 - val_accuracy: 0.8009\n",
            "Epoch 823/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3138 - accuracy: 0.8893\n",
            "Epoch 823: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3133 - accuracy: 0.8895 - val_loss: 0.8757 - val_accuracy: 0.7987\n",
            "Epoch 824/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3334 - accuracy: 0.8858\n",
            "Epoch 824: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.3334 - accuracy: 0.8858 - val_loss: 1.2180 - val_accuracy: 0.7186\n",
            "Epoch 825/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2993 - accuracy: 0.8935\n",
            "Epoch 825: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3000 - accuracy: 0.8932 - val_loss: 0.9236 - val_accuracy: 0.7833\n",
            "Epoch 826/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.4076 - accuracy: 0.8597\n",
            "Epoch 826: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4073 - accuracy: 0.8599 - val_loss: 0.9045 - val_accuracy: 0.7830\n",
            "Epoch 827/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2863 - accuracy: 0.8979\n",
            "Epoch 827: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2854 - accuracy: 0.8985 - val_loss: 0.8181 - val_accuracy: 0.8134\n",
            "Epoch 828/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2700 - accuracy: 0.9071\n",
            "Epoch 828: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2718 - accuracy: 0.9063 - val_loss: 0.8533 - val_accuracy: 0.8073\n",
            "Epoch 829/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.3993 - accuracy: 0.8664\n",
            "Epoch 829: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3952 - accuracy: 0.8671 - val_loss: 0.8458 - val_accuracy: 0.8047\n",
            "Epoch 830/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2842 - accuracy: 0.9013\n",
            "Epoch 830: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2854 - accuracy: 0.9009 - val_loss: 0.8739 - val_accuracy: 0.8035\n",
            "Epoch 831/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2708 - accuracy: 0.9067\n",
            "Epoch 831: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2723 - accuracy: 0.9064 - val_loss: 0.8032 - val_accuracy: 0.8185\n",
            "Epoch 832/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3646 - accuracy: 0.8736\n",
            "Epoch 832: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3646 - accuracy: 0.8736 - val_loss: 1.2742 - val_accuracy: 0.7084\n",
            "Epoch 833/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3241 - accuracy: 0.8862\n",
            "Epoch 833: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3300 - accuracy: 0.8843 - val_loss: 0.9242 - val_accuracy: 0.7881\n",
            "Epoch 834/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.3654 - accuracy: 0.8758\n",
            "Epoch 834: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3602 - accuracy: 0.8767 - val_loss: 0.8484 - val_accuracy: 0.8095\n",
            "Epoch 835/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2966 - accuracy: 0.8962\n",
            "Epoch 835: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2969 - accuracy: 0.8960 - val_loss: 0.8155 - val_accuracy: 0.8211\n",
            "Epoch 836/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2970 - accuracy: 0.8959\n",
            "Epoch 836: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2968 - accuracy: 0.8967 - val_loss: 0.8052 - val_accuracy: 0.8249\n",
            "Epoch 837/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2686 - accuracy: 0.9091\n",
            "Epoch 837: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2672 - accuracy: 0.9101 - val_loss: 0.8014 - val_accuracy: 0.8217\n",
            "Epoch 838/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2901 - accuracy: 0.9012\n",
            "Epoch 838: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2868 - accuracy: 0.9027 - val_loss: 0.9290 - val_accuracy: 0.7839\n",
            "Epoch 839/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.4330 - accuracy: 0.8484\n",
            "Epoch 839: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.4339 - accuracy: 0.8483 - val_loss: 1.0187 - val_accuracy: 0.7638\n",
            "Epoch 840/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.4140 - accuracy: 0.8578\n",
            "Epoch 840: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.4117 - accuracy: 0.8590 - val_loss: 0.8847 - val_accuracy: 0.7942\n",
            "Epoch 841/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3063 - accuracy: 0.8903\n",
            "Epoch 841: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3011 - accuracy: 0.8926 - val_loss: 0.8111 - val_accuracy: 0.8217\n",
            "Epoch 842/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2774 - accuracy: 0.9005\n",
            "Epoch 842: val_accuracy did not improve from 0.82714\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.2818 - accuracy: 0.8987 - val_loss: 0.8066 - val_accuracy: 0.8182\n",
            "Epoch 843/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2938 - accuracy: 0.8989\n",
            "Epoch 843: val_accuracy improved from 0.82714 to 0.82746, saving model to /content/asl1/Adam4/cp-843-0.83.hdf5\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 0.2926 - accuracy: 0.8993 - val_loss: 0.7687 - val_accuracy: 0.8275\n",
            "Epoch 844/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3763 - accuracy: 0.8682\n",
            "Epoch 844: val_accuracy did not improve from 0.82746\n",
            "98/98 [==============================] - 2s 17ms/step - loss: 0.3732 - accuracy: 0.8691 - val_loss: 0.7847 - val_accuracy: 0.8230\n",
            "Epoch 845/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2687 - accuracy: 0.9058\n",
            "Epoch 845: val_accuracy did not improve from 0.82746\n",
            "98/98 [==============================] - 1s 14ms/step - loss: 0.2701 - accuracy: 0.9054 - val_loss: 0.8852 - val_accuracy: 0.7942\n",
            "Epoch 846/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2815 - accuracy: 0.9024\n",
            "Epoch 846: val_accuracy did not improve from 0.82746\n",
            "98/98 [==============================] - 1s 12ms/step - loss: 0.2828 - accuracy: 0.9023 - val_loss: 0.8517 - val_accuracy: 0.8191\n",
            "Epoch 847/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3215 - accuracy: 0.8900\n",
            "Epoch 847: val_accuracy did not improve from 0.82746\n",
            "98/98 [==============================] - 1s 15ms/step - loss: 0.3189 - accuracy: 0.8903 - val_loss: 0.9152 - val_accuracy: 0.7948\n",
            "Epoch 848/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2904 - accuracy: 0.9003\n",
            "Epoch 848: val_accuracy did not improve from 0.82746\n",
            "98/98 [==============================] - 1s 13ms/step - loss: 0.2904 - accuracy: 0.9003 - val_loss: 0.9430 - val_accuracy: 0.7849\n",
            "Epoch 849/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.4267 - accuracy: 0.8538\n",
            "Epoch 849: val_accuracy did not improve from 0.82746\n",
            "98/98 [==============================] - 1s 12ms/step - loss: 0.4267 - accuracy: 0.8538 - val_loss: 0.9018 - val_accuracy: 0.7916\n",
            "Epoch 850/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3399 - accuracy: 0.8818\n",
            "Epoch 850: val_accuracy did not improve from 0.82746\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.3386 - accuracy: 0.8821 - val_loss: 0.8157 - val_accuracy: 0.8204\n",
            "Epoch 851/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2709 - accuracy: 0.9062\n",
            "Epoch 851: val_accuracy did not improve from 0.82746\n",
            "98/98 [==============================] - 1s 12ms/step - loss: 0.2705 - accuracy: 0.9062 - val_loss: 0.8036 - val_accuracy: 0.8236\n",
            "Epoch 852/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2692 - accuracy: 0.9067\n",
            "Epoch 852: val_accuracy did not improve from 0.82746\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.2702 - accuracy: 0.9060 - val_loss: 0.8401 - val_accuracy: 0.8172\n",
            "Epoch 853/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2956 - accuracy: 0.8952\n",
            "Epoch 853: val_accuracy did not improve from 0.82746\n",
            "98/98 [==============================] - 1s 12ms/step - loss: 0.2979 - accuracy: 0.8942 - val_loss: 0.9298 - val_accuracy: 0.7926\n",
            "Epoch 854/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.4296 - accuracy: 0.8542\n",
            "Epoch 854: val_accuracy did not improve from 0.82746\n",
            "98/98 [==============================] - 1s 11ms/step - loss: 0.4288 - accuracy: 0.8540 - val_loss: 0.8563 - val_accuracy: 0.8095\n",
            "Epoch 855/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2708 - accuracy: 0.9062\n",
            "Epoch 855: val_accuracy did not improve from 0.82746\n",
            "98/98 [==============================] - 2s 16ms/step - loss: 0.2706 - accuracy: 0.9061 - val_loss: 0.8965 - val_accuracy: 0.7967\n",
            "Epoch 856/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3101 - accuracy: 0.8910\n",
            "Epoch 856: val_accuracy did not improve from 0.82746\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3108 - accuracy: 0.8908 - val_loss: 0.8672 - val_accuracy: 0.8028\n",
            "Epoch 857/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2834 - accuracy: 0.9021\n",
            "Epoch 857: val_accuracy did not improve from 0.82746\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2859 - accuracy: 0.9009 - val_loss: 0.8296 - val_accuracy: 0.8150\n",
            "Epoch 858/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2886 - accuracy: 0.8991\n",
            "Epoch 858: val_accuracy did not improve from 0.82746\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2897 - accuracy: 0.8988 - val_loss: 0.9012 - val_accuracy: 0.7958\n",
            "Epoch 859/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.5659 - accuracy: 0.8273\n",
            "Epoch 859: val_accuracy did not improve from 0.82746\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.5646 - accuracy: 0.8275 - val_loss: 0.8497 - val_accuracy: 0.8099\n",
            "Epoch 860/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3252 - accuracy: 0.8832\n",
            "Epoch 860: val_accuracy did not improve from 0.82746\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3261 - accuracy: 0.8823 - val_loss: 0.7873 - val_accuracy: 0.8207\n",
            "Epoch 861/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2630 - accuracy: 0.9102\n",
            "Epoch 861: val_accuracy improved from 0.82746 to 0.83291, saving model to /content/asl1/Adam4/cp-861-0.83.hdf5\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2638 - accuracy: 0.9102 - val_loss: 0.7946 - val_accuracy: 0.8329\n",
            "Epoch 862/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2666 - accuracy: 0.9066\n",
            "Epoch 862: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2666 - accuracy: 0.9066 - val_loss: 0.7910 - val_accuracy: 0.8217\n",
            "Epoch 863/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2684 - accuracy: 0.9052\n",
            "Epoch 863: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2677 - accuracy: 0.9055 - val_loss: 1.0129 - val_accuracy: 0.7618\n",
            "Epoch 864/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.4250 - accuracy: 0.8565\n",
            "Epoch 864: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4180 - accuracy: 0.8585 - val_loss: 0.8355 - val_accuracy: 0.8111\n",
            "Epoch 865/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3582 - accuracy: 0.8748\n",
            "Epoch 865: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3582 - accuracy: 0.8748 - val_loss: 0.8849 - val_accuracy: 0.8054\n",
            "Epoch 866/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2674 - accuracy: 0.9067\n",
            "Epoch 866: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2684 - accuracy: 0.9060 - val_loss: 0.7911 - val_accuracy: 0.8271\n",
            "Epoch 867/2000\n",
            "88/98 [=========================>....] - ETA: 0s - loss: 0.2573 - accuracy: 0.9138\n",
            "Epoch 867: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2581 - accuracy: 0.9121 - val_loss: 0.8236 - val_accuracy: 0.8172\n",
            "Epoch 868/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2966 - accuracy: 0.8933\n",
            "Epoch 868: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2960 - accuracy: 0.8943 - val_loss: 0.9045 - val_accuracy: 0.7961\n",
            "Epoch 869/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2929 - accuracy: 0.8957\n",
            "Epoch 869: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2929 - accuracy: 0.8957 - val_loss: 1.2076 - val_accuracy: 0.7343\n",
            "Epoch 870/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3124 - accuracy: 0.8920\n",
            "Epoch 870: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3191 - accuracy: 0.8898 - val_loss: 0.8874 - val_accuracy: 0.7913\n",
            "Epoch 871/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3703 - accuracy: 0.8695\n",
            "Epoch 871: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3693 - accuracy: 0.8698 - val_loss: 1.0985 - val_accuracy: 0.7596\n",
            "Epoch 872/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2923 - accuracy: 0.9000\n",
            "Epoch 872: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2923 - accuracy: 0.9000 - val_loss: 0.9033 - val_accuracy: 0.7926\n",
            "Epoch 873/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3011 - accuracy: 0.8931\n",
            "Epoch 873: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3041 - accuracy: 0.8915 - val_loss: 1.1184 - val_accuracy: 0.7558\n",
            "Epoch 874/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3759 - accuracy: 0.8654\n",
            "Epoch 874: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3765 - accuracy: 0.8651 - val_loss: 0.9467 - val_accuracy: 0.7727\n",
            "Epoch 875/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2975 - accuracy: 0.8948\n",
            "Epoch 875: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2975 - accuracy: 0.8948 - val_loss: 0.8372 - val_accuracy: 0.8159\n",
            "Epoch 876/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2650 - accuracy: 0.9078\n",
            "Epoch 876: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2660 - accuracy: 0.9068 - val_loss: 0.8019 - val_accuracy: 0.8169\n",
            "Epoch 877/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.4252 - accuracy: 0.8527\n",
            "Epoch 877: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.4375 - accuracy: 0.8490 - val_loss: 1.1936 - val_accuracy: 0.7247\n",
            "Epoch 878/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3103 - accuracy: 0.8912\n",
            "Epoch 878: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3103 - accuracy: 0.8912 - val_loss: 0.8087 - val_accuracy: 0.8265\n",
            "Epoch 879/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2447 - accuracy: 0.9160\n",
            "Epoch 879: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2450 - accuracy: 0.9161 - val_loss: 0.8556 - val_accuracy: 0.8051\n",
            "Epoch 880/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3175 - accuracy: 0.8870\n",
            "Epoch 880: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3175 - accuracy: 0.8870 - val_loss: 0.8998 - val_accuracy: 0.7955\n",
            "Epoch 881/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2894 - accuracy: 0.8978\n",
            "Epoch 881: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2879 - accuracy: 0.8986 - val_loss: 0.9224 - val_accuracy: 0.7887\n",
            "Epoch 882/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2815 - accuracy: 0.8985\n",
            "Epoch 882: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2818 - accuracy: 0.8990 - val_loss: 0.9396 - val_accuracy: 0.7871\n",
            "Epoch 883/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3010 - accuracy: 0.8917\n",
            "Epoch 883: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2991 - accuracy: 0.8924 - val_loss: 0.8331 - val_accuracy: 0.8175\n",
            "Epoch 884/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2955 - accuracy: 0.8961\n",
            "Epoch 884: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2954 - accuracy: 0.8962 - val_loss: 0.8778 - val_accuracy: 0.8006\n",
            "Epoch 885/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2969 - accuracy: 0.8974\n",
            "Epoch 885: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3008 - accuracy: 0.8960 - val_loss: 1.1290 - val_accuracy: 0.7478\n",
            "Epoch 886/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3540 - accuracy: 0.8757\n",
            "Epoch 886: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3523 - accuracy: 0.8764 - val_loss: 0.8271 - val_accuracy: 0.8182\n",
            "Epoch 887/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2742 - accuracy: 0.9023\n",
            "Epoch 887: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2784 - accuracy: 0.9004 - val_loss: 0.8915 - val_accuracy: 0.8019\n",
            "Epoch 888/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.2810 - accuracy: 0.9022\n",
            "Epoch 888: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2849 - accuracy: 0.9004 - val_loss: 1.2658 - val_accuracy: 0.7231\n",
            "Epoch 889/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3962 - accuracy: 0.8674\n",
            "Epoch 889: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3898 - accuracy: 0.8684 - val_loss: 0.8552 - val_accuracy: 0.8073\n",
            "Epoch 890/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.2504 - accuracy: 0.9145\n",
            "Epoch 890: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2492 - accuracy: 0.9149 - val_loss: 0.8595 - val_accuracy: 0.8134\n",
            "Epoch 891/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2517 - accuracy: 0.9114\n",
            "Epoch 891: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2526 - accuracy: 0.9117 - val_loss: 0.7957 - val_accuracy: 0.8278\n",
            "Epoch 892/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.4173 - accuracy: 0.8572\n",
            "Epoch 892: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.4223 - accuracy: 0.8559 - val_loss: 0.9165 - val_accuracy: 0.8022\n",
            "Epoch 893/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2988 - accuracy: 0.8961\n",
            "Epoch 893: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2928 - accuracy: 0.8985 - val_loss: 0.8017 - val_accuracy: 0.8259\n",
            "Epoch 894/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2830 - accuracy: 0.9002\n",
            "Epoch 894: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2825 - accuracy: 0.9007 - val_loss: 0.9095 - val_accuracy: 0.7996\n",
            "Epoch 895/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.4114 - accuracy: 0.8598\n",
            "Epoch 895: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.4108 - accuracy: 0.8602 - val_loss: 0.9783 - val_accuracy: 0.7769\n",
            "Epoch 896/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2819 - accuracy: 0.9001\n",
            "Epoch 896: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2815 - accuracy: 0.9003 - val_loss: 0.8098 - val_accuracy: 0.8220\n",
            "Epoch 897/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2742 - accuracy: 0.9011\n",
            "Epoch 897: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2748 - accuracy: 0.9012 - val_loss: 0.7989 - val_accuracy: 0.8223\n",
            "Epoch 898/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2578 - accuracy: 0.9123\n",
            "Epoch 898: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2604 - accuracy: 0.9112 - val_loss: 0.9864 - val_accuracy: 0.7814\n",
            "Epoch 899/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3192 - accuracy: 0.8862\n",
            "Epoch 899: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.3199 - accuracy: 0.8859 - val_loss: 0.8233 - val_accuracy: 0.8172\n",
            "Epoch 900/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2611 - accuracy: 0.9090\n",
            "Epoch 900: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2640 - accuracy: 0.9077 - val_loss: 0.9522 - val_accuracy: 0.7772\n",
            "Epoch 901/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2536 - accuracy: 0.9128\n",
            "Epoch 901: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2536 - accuracy: 0.9128 - val_loss: 1.0019 - val_accuracy: 0.7676\n",
            "Epoch 902/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3349 - accuracy: 0.8826\n",
            "Epoch 902: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3473 - accuracy: 0.8788 - val_loss: 1.8932 - val_accuracy: 0.6316\n",
            "Epoch 903/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.4846 - accuracy: 0.8459\n",
            "Epoch 903: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4639 - accuracy: 0.8521 - val_loss: 0.8533 - val_accuracy: 0.8102\n",
            "Epoch 904/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2517 - accuracy: 0.9134\n",
            "Epoch 904: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2540 - accuracy: 0.9124 - val_loss: 0.9075 - val_accuracy: 0.8070\n",
            "Epoch 905/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2546 - accuracy: 0.9112\n",
            "Epoch 905: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2563 - accuracy: 0.9109 - val_loss: 0.8614 - val_accuracy: 0.8102\n",
            "Epoch 906/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2971 - accuracy: 0.8940\n",
            "Epoch 906: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2959 - accuracy: 0.8946 - val_loss: 0.8697 - val_accuracy: 0.8102\n",
            "Epoch 907/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3556 - accuracy: 0.8753\n",
            "Epoch 907: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3599 - accuracy: 0.8739 - val_loss: 1.0728 - val_accuracy: 0.7705\n",
            "Epoch 908/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3435 - accuracy: 0.8796\n",
            "Epoch 908: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3410 - accuracy: 0.8804 - val_loss: 0.8138 - val_accuracy: 0.8179\n",
            "Epoch 909/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2740 - accuracy: 0.9042\n",
            "Epoch 909: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2740 - accuracy: 0.9042 - val_loss: 0.8512 - val_accuracy: 0.8134\n",
            "Epoch 910/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2927 - accuracy: 0.8941\n",
            "Epoch 910: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2937 - accuracy: 0.8934 - val_loss: 0.8967 - val_accuracy: 0.8022\n",
            "Epoch 911/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2575 - accuracy: 0.9104\n",
            "Epoch 911: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2586 - accuracy: 0.9099 - val_loss: 0.8384 - val_accuracy: 0.8137\n",
            "Epoch 912/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2680 - accuracy: 0.9073\n",
            "Epoch 912: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2692 - accuracy: 0.9067 - val_loss: 0.9380 - val_accuracy: 0.7913\n",
            "Epoch 913/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2811 - accuracy: 0.9040\n",
            "Epoch 913: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2793 - accuracy: 0.9043 - val_loss: 0.8668 - val_accuracy: 0.8172\n",
            "Epoch 914/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2564 - accuracy: 0.9105\n",
            "Epoch 914: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2563 - accuracy: 0.9102 - val_loss: 0.8536 - val_accuracy: 0.8191\n",
            "Epoch 915/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2583 - accuracy: 0.9093\n",
            "Epoch 915: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2592 - accuracy: 0.9090 - val_loss: 0.8421 - val_accuracy: 0.8137\n",
            "Epoch 916/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2845 - accuracy: 0.9010\n",
            "Epoch 916: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2921 - accuracy: 0.8984 - val_loss: 0.8797 - val_accuracy: 0.8054\n",
            "Epoch 917/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2738 - accuracy: 0.9000\n",
            "Epoch 917: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2738 - accuracy: 0.9000 - val_loss: 0.8661 - val_accuracy: 0.7987\n",
            "Epoch 918/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2963 - accuracy: 0.8943\n",
            "Epoch 918: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2963 - accuracy: 0.8943 - val_loss: 0.8555 - val_accuracy: 0.8153\n",
            "Epoch 919/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3010 - accuracy: 0.8920\n",
            "Epoch 919: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.3037 - accuracy: 0.8901 - val_loss: 0.9798 - val_accuracy: 0.7865\n",
            "Epoch 920/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3320 - accuracy: 0.8852\n",
            "Epoch 920: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3320 - accuracy: 0.8852 - val_loss: 1.0159 - val_accuracy: 0.7737\n",
            "Epoch 921/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2856 - accuracy: 0.8998\n",
            "Epoch 921: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2893 - accuracy: 0.8992 - val_loss: 0.9596 - val_accuracy: 0.7830\n",
            "Epoch 922/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.6277 - accuracy: 0.8275\n",
            "Epoch 922: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.6277 - accuracy: 0.8275 - val_loss: 1.4763 - val_accuracy: 0.6908\n",
            "Epoch 923/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3697 - accuracy: 0.8714\n",
            "Epoch 923: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3682 - accuracy: 0.8716 - val_loss: 0.8824 - val_accuracy: 0.8083\n",
            "Epoch 924/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2883 - accuracy: 0.8984\n",
            "Epoch 924: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2879 - accuracy: 0.8980 - val_loss: 0.8386 - val_accuracy: 0.8147\n",
            "Epoch 925/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2749 - accuracy: 0.9021\n",
            "Epoch 925: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2733 - accuracy: 0.9025 - val_loss: 0.8792 - val_accuracy: 0.7942\n",
            "Epoch 926/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2555 - accuracy: 0.9087\n",
            "Epoch 926: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2560 - accuracy: 0.9081 - val_loss: 0.8813 - val_accuracy: 0.8006\n",
            "Epoch 927/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2510 - accuracy: 0.9102\n",
            "Epoch 927: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2518 - accuracy: 0.9101 - val_loss: 0.8719 - val_accuracy: 0.8031\n",
            "Epoch 928/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2862 - accuracy: 0.8967\n",
            "Epoch 928: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2822 - accuracy: 0.8976 - val_loss: 0.8584 - val_accuracy: 0.8140\n",
            "Epoch 929/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.4361 - accuracy: 0.8573\n",
            "Epoch 929: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4367 - accuracy: 0.8569 - val_loss: 1.1671 - val_accuracy: 0.7330\n",
            "Epoch 930/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3122 - accuracy: 0.8867\n",
            "Epoch 930: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3107 - accuracy: 0.8872 - val_loss: 0.8727 - val_accuracy: 0.8015\n",
            "Epoch 931/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.2579 - accuracy: 0.9110\n",
            "Epoch 931: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2551 - accuracy: 0.9123 - val_loss: 0.8340 - val_accuracy: 0.8246\n",
            "Epoch 932/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2312 - accuracy: 0.9199\n",
            "Epoch 932: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2321 - accuracy: 0.9193 - val_loss: 0.8540 - val_accuracy: 0.8172\n",
            "Epoch 933/2000\n",
            "88/98 [=========================>....] - ETA: 0s - loss: 0.2388 - accuracy: 0.9180\n",
            "Epoch 933: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2369 - accuracy: 0.9188 - val_loss: 0.8757 - val_accuracy: 0.8105\n",
            "Epoch 934/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2256 - accuracy: 0.9211\n",
            "Epoch 934: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2256 - accuracy: 0.9211 - val_loss: 0.8303 - val_accuracy: 0.8198\n",
            "Epoch 935/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2751 - accuracy: 0.9054\n",
            "Epoch 935: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2760 - accuracy: 0.9051 - val_loss: 0.9447 - val_accuracy: 0.7926\n",
            "Epoch 936/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.3853 - accuracy: 0.8644\n",
            "Epoch 936: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3885 - accuracy: 0.8633 - val_loss: 0.9148 - val_accuracy: 0.7939\n",
            "Epoch 937/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8659\n",
            "Epoch 937: val_accuracy did not improve from 0.83291\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3816 - accuracy: 0.8663 - val_loss: 0.9665 - val_accuracy: 0.7833\n",
            "Epoch 938/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2746 - accuracy: 0.9035\n",
            "Epoch 938: val_accuracy improved from 0.83291 to 0.83611, saving model to /content/asl1/Adam4/cp-938-0.84.hdf5\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2734 - accuracy: 0.9042 - val_loss: 0.7819 - val_accuracy: 0.8361\n",
            "Epoch 939/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3552 - accuracy: 0.8753\n",
            "Epoch 939: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3514 - accuracy: 0.8764 - val_loss: 0.9491 - val_accuracy: 0.7919\n",
            "Epoch 940/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2388 - accuracy: 0.9196\n",
            "Epoch 940: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.2383 - accuracy: 0.9198 - val_loss: 0.8595 - val_accuracy: 0.8140\n",
            "Epoch 941/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2333 - accuracy: 0.9170\n",
            "Epoch 941: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2319 - accuracy: 0.9179 - val_loss: 0.7962 - val_accuracy: 0.8243\n",
            "Epoch 942/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2751 - accuracy: 0.9021\n",
            "Epoch 942: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2740 - accuracy: 0.9028 - val_loss: 0.8414 - val_accuracy: 0.8211\n",
            "Epoch 943/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2521 - accuracy: 0.9128\n",
            "Epoch 943: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2526 - accuracy: 0.9125 - val_loss: 0.8467 - val_accuracy: 0.8156\n",
            "Epoch 944/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.4888 - accuracy: 0.8529\n",
            "Epoch 944: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4816 - accuracy: 0.8552 - val_loss: 0.8470 - val_accuracy: 0.8201\n",
            "Epoch 945/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2615 - accuracy: 0.9122\n",
            "Epoch 945: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2666 - accuracy: 0.9105 - val_loss: 1.0081 - val_accuracy: 0.7743\n",
            "Epoch 946/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3228 - accuracy: 0.8851\n",
            "Epoch 946: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3237 - accuracy: 0.8848 - val_loss: 0.9585 - val_accuracy: 0.7875\n",
            "Epoch 947/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2689 - accuracy: 0.9086\n",
            "Epoch 947: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2688 - accuracy: 0.9085 - val_loss: 0.8767 - val_accuracy: 0.8134\n",
            "Epoch 948/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2931 - accuracy: 0.8968\n",
            "Epoch 948: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2921 - accuracy: 0.8969 - val_loss: 0.8472 - val_accuracy: 0.8223\n",
            "Epoch 949/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2369 - accuracy: 0.9182\n",
            "Epoch 949: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2382 - accuracy: 0.9173 - val_loss: 0.8761 - val_accuracy: 0.8131\n",
            "Epoch 950/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2943 - accuracy: 0.8947\n",
            "Epoch 950: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3002 - accuracy: 0.8934 - val_loss: 1.0134 - val_accuracy: 0.7762\n",
            "Epoch 951/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2802 - accuracy: 0.9006\n",
            "Epoch 951: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2763 - accuracy: 0.9021 - val_loss: 0.7999 - val_accuracy: 0.8268\n",
            "Epoch 952/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2763 - accuracy: 0.9058\n",
            "Epoch 952: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2860 - accuracy: 0.9021 - val_loss: 0.9915 - val_accuracy: 0.7702\n",
            "Epoch 953/2000\n",
            "88/98 [=========================>....] - ETA: 0s - loss: 0.3141 - accuracy: 0.8888\n",
            "Epoch 953: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3063 - accuracy: 0.8914 - val_loss: 0.8599 - val_accuracy: 0.8217\n",
            "Epoch 954/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2663 - accuracy: 0.9060\n",
            "Epoch 954: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2662 - accuracy: 0.9053 - val_loss: 0.8887 - val_accuracy: 0.8115\n",
            "Epoch 955/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2588 - accuracy: 0.9088\n",
            "Epoch 955: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2549 - accuracy: 0.9102 - val_loss: 0.8218 - val_accuracy: 0.8329\n",
            "Epoch 956/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.4554 - accuracy: 0.8621\n",
            "Epoch 956: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.4535 - accuracy: 0.8613 - val_loss: 1.2810 - val_accuracy: 0.7343\n",
            "Epoch 957/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.4138 - accuracy: 0.8543\n",
            "Epoch 957: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.4145 - accuracy: 0.8538 - val_loss: 0.8490 - val_accuracy: 0.8047\n",
            "Epoch 958/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2450 - accuracy: 0.9147\n",
            "Epoch 958: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2453 - accuracy: 0.9142 - val_loss: 0.8373 - val_accuracy: 0.8259\n",
            "Epoch 959/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2514 - accuracy: 0.9131\n",
            "Epoch 959: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2502 - accuracy: 0.9134 - val_loss: 0.8321 - val_accuracy: 0.8236\n",
            "Epoch 960/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2487 - accuracy: 0.9138\n",
            "Epoch 960: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2483 - accuracy: 0.9139 - val_loss: 0.8489 - val_accuracy: 0.8099\n",
            "Epoch 961/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2531 - accuracy: 0.9086\n",
            "Epoch 961: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2524 - accuracy: 0.9090 - val_loss: 0.8044 - val_accuracy: 0.8204\n",
            "Epoch 962/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2340 - accuracy: 0.9206\n",
            "Epoch 962: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2351 - accuracy: 0.9201 - val_loss: 0.8161 - val_accuracy: 0.8185\n",
            "Epoch 963/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2790 - accuracy: 0.8984\n",
            "Epoch 963: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2787 - accuracy: 0.8984 - val_loss: 0.9144 - val_accuracy: 0.7990\n",
            "Epoch 964/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2762 - accuracy: 0.9020\n",
            "Epoch 964: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2754 - accuracy: 0.9026 - val_loss: 0.8381 - val_accuracy: 0.8201\n",
            "Epoch 965/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2728 - accuracy: 0.9037\n",
            "Epoch 965: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2736 - accuracy: 0.9039 - val_loss: 0.8386 - val_accuracy: 0.8191\n",
            "Epoch 966/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2816 - accuracy: 0.9025\n",
            "Epoch 966: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2821 - accuracy: 0.9020 - val_loss: 0.9484 - val_accuracy: 0.7900\n",
            "Epoch 967/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2818 - accuracy: 0.9024\n",
            "Epoch 967: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2821 - accuracy: 0.9020 - val_loss: 1.1876 - val_accuracy: 0.7436\n",
            "Epoch 968/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.4401 - accuracy: 0.8532\n",
            "Epoch 968: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4322 - accuracy: 0.8558 - val_loss: 0.9820 - val_accuracy: 0.7820\n",
            "Epoch 969/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2515 - accuracy: 0.9141\n",
            "Epoch 969: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2510 - accuracy: 0.9141 - val_loss: 0.8125 - val_accuracy: 0.8291\n",
            "Epoch 970/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2549 - accuracy: 0.9098\n",
            "Epoch 970: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2540 - accuracy: 0.9110 - val_loss: 0.9185 - val_accuracy: 0.7983\n",
            "Epoch 971/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2989 - accuracy: 0.8929\n",
            "Epoch 971: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2989 - accuracy: 0.8929 - val_loss: 0.8979 - val_accuracy: 0.7967\n",
            "Epoch 972/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2508 - accuracy: 0.9131\n",
            "Epoch 972: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2613 - accuracy: 0.9096 - val_loss: 1.0058 - val_accuracy: 0.7884\n",
            "Epoch 973/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2531 - accuracy: 0.9092\n",
            "Epoch 973: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2520 - accuracy: 0.9098 - val_loss: 0.8447 - val_accuracy: 0.8223\n",
            "Epoch 974/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2164 - accuracy: 0.9265\n",
            "Epoch 974: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2167 - accuracy: 0.9261 - val_loss: 0.8254 - val_accuracy: 0.8230\n",
            "Epoch 975/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2532 - accuracy: 0.9113\n",
            "Epoch 975: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2532 - accuracy: 0.9113 - val_loss: 0.8774 - val_accuracy: 0.8057\n",
            "Epoch 976/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2625 - accuracy: 0.9087\n",
            "Epoch 976: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2604 - accuracy: 0.9095 - val_loss: 0.8117 - val_accuracy: 0.8294\n",
            "Epoch 977/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.8471 - accuracy: 0.7923\n",
            "Epoch 977: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.8383 - accuracy: 0.7937 - val_loss: 1.1450 - val_accuracy: 0.7417\n",
            "Epoch 978/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2690 - accuracy: 0.9073\n",
            "Epoch 978: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2690 - accuracy: 0.9073 - val_loss: 0.9011 - val_accuracy: 0.8079\n",
            "Epoch 979/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2526 - accuracy: 0.9133\n",
            "Epoch 979: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2526 - accuracy: 0.9133 - val_loss: 0.9200 - val_accuracy: 0.7999\n",
            "Epoch 980/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2308 - accuracy: 0.9190\n",
            "Epoch 980: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2308 - accuracy: 0.9191 - val_loss: 0.8730 - val_accuracy: 0.8121\n",
            "Epoch 981/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2324 - accuracy: 0.9205\n",
            "Epoch 981: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2324 - accuracy: 0.9205 - val_loss: 0.8522 - val_accuracy: 0.8211\n",
            "Epoch 982/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2589 - accuracy: 0.9071\n",
            "Epoch 982: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2589 - accuracy: 0.9071 - val_loss: 0.9151 - val_accuracy: 0.8067\n",
            "Epoch 983/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2517 - accuracy: 0.9124\n",
            "Epoch 983: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2517 - accuracy: 0.9125 - val_loss: 0.9377 - val_accuracy: 0.8006\n",
            "Epoch 984/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2509 - accuracy: 0.9088\n",
            "Epoch 984: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2509 - accuracy: 0.9088 - val_loss: 0.9745 - val_accuracy: 0.7961\n",
            "Epoch 985/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2468 - accuracy: 0.9138\n",
            "Epoch 985: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2470 - accuracy: 0.9137 - val_loss: 0.8081 - val_accuracy: 0.8265\n",
            "Epoch 986/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.2541 - accuracy: 0.9106\n",
            "Epoch 986: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2564 - accuracy: 0.9100 - val_loss: 0.9393 - val_accuracy: 0.7897\n",
            "Epoch 987/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2813 - accuracy: 0.9025\n",
            "Epoch 987: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2799 - accuracy: 0.9028 - val_loss: 1.3165 - val_accuracy: 0.7260\n",
            "Epoch 988/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3569 - accuracy: 0.8836\n",
            "Epoch 988: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3689 - accuracy: 0.8798 - val_loss: 1.0792 - val_accuracy: 0.7554\n",
            "Epoch 989/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2772 - accuracy: 0.9000\n",
            "Epoch 989: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2772 - accuracy: 0.9000 - val_loss: 0.8392 - val_accuracy: 0.8137\n",
            "Epoch 990/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2356 - accuracy: 0.9195\n",
            "Epoch 990: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2358 - accuracy: 0.9195 - val_loss: 0.8282 - val_accuracy: 0.8259\n",
            "Epoch 991/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2367 - accuracy: 0.9174\n",
            "Epoch 991: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2359 - accuracy: 0.9175 - val_loss: 0.8062 - val_accuracy: 0.8316\n",
            "Epoch 992/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2464 - accuracy: 0.9143\n",
            "Epoch 992: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2591 - accuracy: 0.9093 - val_loss: 1.0911 - val_accuracy: 0.7737\n",
            "Epoch 993/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.4874 - accuracy: 0.8459\n",
            "Epoch 993: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4791 - accuracy: 0.8472 - val_loss: 0.8902 - val_accuracy: 0.8067\n",
            "Epoch 994/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3046 - accuracy: 0.8929\n",
            "Epoch 994: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3105 - accuracy: 0.8910 - val_loss: 0.9965 - val_accuracy: 0.7702\n",
            "Epoch 995/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3301 - accuracy: 0.8827\n",
            "Epoch 995: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.3292 - accuracy: 0.8832 - val_loss: 0.9502 - val_accuracy: 0.7891\n",
            "Epoch 996/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2437 - accuracy: 0.9172\n",
            "Epoch 996: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2437 - accuracy: 0.9172 - val_loss: 0.8251 - val_accuracy: 0.8252\n",
            "Epoch 997/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2626 - accuracy: 0.9067\n",
            "Epoch 997: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2635 - accuracy: 0.9062 - val_loss: 0.8167 - val_accuracy: 0.8163\n",
            "Epoch 998/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.2569 - accuracy: 0.9112\n",
            "Epoch 998: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2608 - accuracy: 0.9093 - val_loss: 0.8299 - val_accuracy: 0.8246\n",
            "Epoch 999/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2766 - accuracy: 0.9010\n",
            "Epoch 999: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2801 - accuracy: 0.8997 - val_loss: 0.9453 - val_accuracy: 0.7980\n",
            "Epoch 1000/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2703 - accuracy: 0.9028\n",
            "Epoch 1000: val_accuracy did not improve from 0.83611\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2703 - accuracy: 0.9028 - val_loss: 0.8704 - val_accuracy: 0.8086\n",
            "Epoch 1001/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2214 - accuracy: 0.9239\n",
            "Epoch 1001: val_accuracy improved from 0.83611 to 0.83707, saving model to /content/asl1/Adam4/cp-1001-0.84.hdf5\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2212 - accuracy: 0.9240 - val_loss: 0.7951 - val_accuracy: 0.8371\n",
            "Epoch 1002/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3642 - accuracy: 0.8854\n",
            "Epoch 1002: val_accuracy did not improve from 0.83707\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3929 - accuracy: 0.8772 - val_loss: 2.2906 - val_accuracy: 0.6060\n",
            "Epoch 1003/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8713\n",
            "Epoch 1003: val_accuracy did not improve from 0.83707\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3780 - accuracy: 0.8716 - val_loss: 0.8763 - val_accuracy: 0.8127\n",
            "Epoch 1004/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2322 - accuracy: 0.9192\n",
            "Epoch 1004: val_accuracy did not improve from 0.83707\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2342 - accuracy: 0.9183 - val_loss: 0.8883 - val_accuracy: 0.8131\n",
            "Epoch 1005/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2254 - accuracy: 0.9206\n",
            "Epoch 1005: val_accuracy did not improve from 0.83707\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2260 - accuracy: 0.9206 - val_loss: 0.8399 - val_accuracy: 0.8198\n",
            "Epoch 1006/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2720 - accuracy: 0.9055\n",
            "Epoch 1006: val_accuracy did not improve from 0.83707\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2723 - accuracy: 0.9051 - val_loss: 0.8925 - val_accuracy: 0.8140\n",
            "Epoch 1007/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2508 - accuracy: 0.9126\n",
            "Epoch 1007: val_accuracy did not improve from 0.83707\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2532 - accuracy: 0.9111 - val_loss: 0.9218 - val_accuracy: 0.8019\n",
            "Epoch 1008/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3230 - accuracy: 0.8875\n",
            "Epoch 1008: val_accuracy did not improve from 0.83707\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3240 - accuracy: 0.8873 - val_loss: 1.0101 - val_accuracy: 0.7730\n",
            "Epoch 1009/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3460 - accuracy: 0.8796\n",
            "Epoch 1009: val_accuracy did not improve from 0.83707\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3668 - accuracy: 0.8763 - val_loss: 3.0731 - val_accuracy: 0.5557\n",
            "Epoch 1010/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.5443 - accuracy: 0.8419\n",
            "Epoch 1010: val_accuracy did not improve from 0.83707\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.5351 - accuracy: 0.8446 - val_loss: 0.8493 - val_accuracy: 0.8166\n",
            "Epoch 1011/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2354 - accuracy: 0.9178\n",
            "Epoch 1011: val_accuracy did not improve from 0.83707\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2362 - accuracy: 0.9173 - val_loss: 0.9554 - val_accuracy: 0.7926\n",
            "Epoch 1012/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2813 - accuracy: 0.9021\n",
            "Epoch 1012: val_accuracy did not improve from 0.83707\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2812 - accuracy: 0.9015 - val_loss: 0.8355 - val_accuracy: 0.8268\n",
            "Epoch 1013/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2286 - accuracy: 0.9202\n",
            "Epoch 1013: val_accuracy did not improve from 0.83707\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2307 - accuracy: 0.9197 - val_loss: 0.8767 - val_accuracy: 0.8111\n",
            "Epoch 1014/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2642 - accuracy: 0.9042\n",
            "Epoch 1014: val_accuracy did not improve from 0.83707\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2627 - accuracy: 0.9051 - val_loss: 0.8137 - val_accuracy: 0.8332\n",
            "Epoch 1015/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2413 - accuracy: 0.9153\n",
            "Epoch 1015: val_accuracy did not improve from 0.83707\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2404 - accuracy: 0.9153 - val_loss: 0.8457 - val_accuracy: 0.8201\n",
            "Epoch 1016/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2213 - accuracy: 0.9235\n",
            "Epoch 1016: val_accuracy did not improve from 0.83707\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2260 - accuracy: 0.9216 - val_loss: 0.9307 - val_accuracy: 0.8035\n",
            "Epoch 1017/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2453 - accuracy: 0.9119\n",
            "Epoch 1017: val_accuracy did not improve from 0.83707\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2445 - accuracy: 0.9120 - val_loss: 0.9594 - val_accuracy: 0.7971\n",
            "Epoch 1018/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3439 - accuracy: 0.8798\n",
            "Epoch 1018: val_accuracy did not improve from 0.83707\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3443 - accuracy: 0.8797 - val_loss: 1.0489 - val_accuracy: 0.7692\n",
            "Epoch 1019/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2648 - accuracy: 0.9048\n",
            "Epoch 1019: val_accuracy did not improve from 0.83707\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2690 - accuracy: 0.9037 - val_loss: 1.1199 - val_accuracy: 0.7612\n",
            "Epoch 1020/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3124 - accuracy: 0.8923\n",
            "Epoch 1020: val_accuracy did not improve from 0.83707\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3096 - accuracy: 0.8929 - val_loss: 0.8362 - val_accuracy: 0.8303\n",
            "Epoch 1021/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2634 - accuracy: 0.9068\n",
            "Epoch 1021: val_accuracy did not improve from 0.83707\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2611 - accuracy: 0.9075 - val_loss: 0.8538 - val_accuracy: 0.8223\n",
            "Epoch 1022/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2754 - accuracy: 0.8993\n",
            "Epoch 1022: val_accuracy did not improve from 0.83707\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2766 - accuracy: 0.8992 - val_loss: 0.8779 - val_accuracy: 0.8201\n",
            "Epoch 1023/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2322 - accuracy: 0.9190\n",
            "Epoch 1023: val_accuracy did not improve from 0.83707\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2367 - accuracy: 0.9176 - val_loss: 0.8386 - val_accuracy: 0.8271\n",
            "Epoch 1024/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3207 - accuracy: 0.8860\n",
            "Epoch 1024: val_accuracy did not improve from 0.83707\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3194 - accuracy: 0.8864 - val_loss: 0.8823 - val_accuracy: 0.8147\n",
            "Epoch 1025/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2686 - accuracy: 0.9051\n",
            "Epoch 1025: val_accuracy did not improve from 0.83707\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2671 - accuracy: 0.9056 - val_loss: 0.8806 - val_accuracy: 0.8079\n",
            "Epoch 1026/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2579 - accuracy: 0.9109\n",
            "Epoch 1026: val_accuracy did not improve from 0.83707\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2581 - accuracy: 0.9110 - val_loss: 0.8436 - val_accuracy: 0.8236\n",
            "Epoch 1027/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2674 - accuracy: 0.9080\n",
            "Epoch 1027: val_accuracy did not improve from 0.83707\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2877 - accuracy: 0.9016 - val_loss: 0.9324 - val_accuracy: 0.7987\n",
            "Epoch 1028/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3234 - accuracy: 0.8844\n",
            "Epoch 1028: val_accuracy did not improve from 0.83707\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3228 - accuracy: 0.8847 - val_loss: 0.8785 - val_accuracy: 0.8092\n",
            "Epoch 1029/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2484 - accuracy: 0.9107\n",
            "Epoch 1029: val_accuracy did not improve from 0.83707\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2467 - accuracy: 0.9113 - val_loss: 0.9086 - val_accuracy: 0.7948\n",
            "Epoch 1030/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2344 - accuracy: 0.9182\n",
            "Epoch 1030: val_accuracy did not improve from 0.83707\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2344 - accuracy: 0.9182 - val_loss: 0.8341 - val_accuracy: 0.8300\n",
            "Epoch 1031/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3309 - accuracy: 0.8847\n",
            "Epoch 1031: val_accuracy did not improve from 0.83707\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3309 - accuracy: 0.8847 - val_loss: 0.9054 - val_accuracy: 0.8063\n",
            "Epoch 1032/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2489 - accuracy: 0.9141\n",
            "Epoch 1032: val_accuracy did not improve from 0.83707\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2489 - accuracy: 0.9139 - val_loss: 0.8475 - val_accuracy: 0.8217\n",
            "Epoch 1033/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2709 - accuracy: 0.9028\n",
            "Epoch 1033: val_accuracy did not improve from 0.83707\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2709 - accuracy: 0.9028 - val_loss: 0.9165 - val_accuracy: 0.8051\n",
            "Epoch 1034/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2670 - accuracy: 0.9043\n",
            "Epoch 1034: val_accuracy did not improve from 0.83707\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2648 - accuracy: 0.9048 - val_loss: 0.9039 - val_accuracy: 0.8022\n",
            "Epoch 1035/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2150 - accuracy: 0.9256\n",
            "Epoch 1035: val_accuracy improved from 0.83707 to 0.83963, saving model to /content/asl1/Adam4/cp-1035-0.84.hdf5\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2150 - accuracy: 0.9257 - val_loss: 0.7913 - val_accuracy: 0.8396\n",
            "Epoch 1036/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2125 - accuracy: 0.9268\n",
            "Epoch 1036: val_accuracy did not improve from 0.83963\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.2143 - accuracy: 0.9261 - val_loss: 0.8727 - val_accuracy: 0.8166\n",
            "Epoch 1037/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2306 - accuracy: 0.9189\n",
            "Epoch 1037: val_accuracy did not improve from 0.83963\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2314 - accuracy: 0.9188 - val_loss: 0.9073 - val_accuracy: 0.8089\n",
            "Epoch 1038/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.3635 - accuracy: 0.8725\n",
            "Epoch 1038: val_accuracy did not improve from 0.83963\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3587 - accuracy: 0.8748 - val_loss: 0.8119 - val_accuracy: 0.8233\n",
            "Epoch 1039/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2754 - accuracy: 0.9020\n",
            "Epoch 1039: val_accuracy did not improve from 0.83963\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2741 - accuracy: 0.9028 - val_loss: 0.9332 - val_accuracy: 0.8060\n",
            "Epoch 1040/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2302 - accuracy: 0.9186\n",
            "Epoch 1040: val_accuracy did not improve from 0.83963\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2329 - accuracy: 0.9172 - val_loss: 0.8345 - val_accuracy: 0.8307\n",
            "Epoch 1041/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.4637 - accuracy: 0.8503\n",
            "Epoch 1041: val_accuracy did not improve from 0.83963\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4621 - accuracy: 0.8494 - val_loss: 0.9476 - val_accuracy: 0.7855\n",
            "Epoch 1042/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3171 - accuracy: 0.8871\n",
            "Epoch 1042: val_accuracy did not improve from 0.83963\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3167 - accuracy: 0.8870 - val_loss: 0.9065 - val_accuracy: 0.8121\n",
            "Epoch 1043/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2717 - accuracy: 0.9015\n",
            "Epoch 1043: val_accuracy did not improve from 0.83963\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2724 - accuracy: 0.9006 - val_loss: 0.9024 - val_accuracy: 0.8051\n",
            "Epoch 1044/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2560 - accuracy: 0.9083\n",
            "Epoch 1044: val_accuracy did not improve from 0.83963\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2637 - accuracy: 0.9053 - val_loss: 0.8861 - val_accuracy: 0.8099\n",
            "Epoch 1045/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2447 - accuracy: 0.9153\n",
            "Epoch 1045: val_accuracy did not improve from 0.83963\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2436 - accuracy: 0.9156 - val_loss: 0.9580 - val_accuracy: 0.7926\n",
            "Epoch 1046/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2450 - accuracy: 0.9126\n",
            "Epoch 1046: val_accuracy did not improve from 0.83963\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2439 - accuracy: 0.9132 - val_loss: 0.9230 - val_accuracy: 0.8175\n",
            "Epoch 1047/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2513 - accuracy: 0.9124\n",
            "Epoch 1047: val_accuracy improved from 0.83963 to 0.84475, saving model to /content/asl1/Adam4/cp-1047-0.84.hdf5\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2520 - accuracy: 0.9121 - val_loss: 0.7948 - val_accuracy: 0.8448\n",
            "Epoch 1048/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3385 - accuracy: 0.8882\n",
            "Epoch 1048: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3382 - accuracy: 0.8884 - val_loss: 0.8788 - val_accuracy: 0.8057\n",
            "Epoch 1049/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2449 - accuracy: 0.9144\n",
            "Epoch 1049: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2469 - accuracy: 0.9133 - val_loss: 0.8880 - val_accuracy: 0.8079\n",
            "Epoch 1050/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2722 - accuracy: 0.9019\n",
            "Epoch 1050: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2737 - accuracy: 0.9015 - val_loss: 0.9756 - val_accuracy: 0.7859\n",
            "Epoch 1051/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3174 - accuracy: 0.8876\n",
            "Epoch 1051: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3169 - accuracy: 0.8881 - val_loss: 1.0000 - val_accuracy: 0.7894\n",
            "Epoch 1052/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2916 - accuracy: 0.8943\n",
            "Epoch 1052: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2881 - accuracy: 0.8956 - val_loss: 0.9891 - val_accuracy: 0.7721\n",
            "Epoch 1053/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2204 - accuracy: 0.9234\n",
            "Epoch 1053: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2198 - accuracy: 0.9235 - val_loss: 0.8013 - val_accuracy: 0.8332\n",
            "Epoch 1054/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2184 - accuracy: 0.9224\n",
            "Epoch 1054: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2188 - accuracy: 0.9221 - val_loss: 0.8304 - val_accuracy: 0.8236\n",
            "Epoch 1055/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2201 - accuracy: 0.9256\n",
            "Epoch 1055: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2195 - accuracy: 0.9253 - val_loss: 0.8648 - val_accuracy: 0.8255\n",
            "Epoch 1056/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2724 - accuracy: 0.9024\n",
            "Epoch 1056: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2727 - accuracy: 0.9022 - val_loss: 1.0069 - val_accuracy: 0.7859\n",
            "Epoch 1057/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2784 - accuracy: 0.8999\n",
            "Epoch 1057: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2791 - accuracy: 0.8995 - val_loss: 0.9140 - val_accuracy: 0.8025\n",
            "Epoch 1058/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2651 - accuracy: 0.9046\n",
            "Epoch 1058: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2616 - accuracy: 0.9057 - val_loss: 0.8614 - val_accuracy: 0.8262\n",
            "Epoch 1059/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.4948 - accuracy: 0.8419\n",
            "Epoch 1059: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4836 - accuracy: 0.8452 - val_loss: 0.8952 - val_accuracy: 0.8182\n",
            "Epoch 1060/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2312 - accuracy: 0.9187\n",
            "Epoch 1060: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2301 - accuracy: 0.9188 - val_loss: 0.8236 - val_accuracy: 0.8303\n",
            "Epoch 1061/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2344 - accuracy: 0.9174\n",
            "Epoch 1061: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2347 - accuracy: 0.9170 - val_loss: 0.9225 - val_accuracy: 0.8127\n",
            "Epoch 1062/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2203 - accuracy: 0.9215\n",
            "Epoch 1062: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2204 - accuracy: 0.9215 - val_loss: 0.9212 - val_accuracy: 0.8015\n",
            "Epoch 1063/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2354 - accuracy: 0.9164\n",
            "Epoch 1063: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2369 - accuracy: 0.9153 - val_loss: 0.8735 - val_accuracy: 0.8172\n",
            "Epoch 1064/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2346 - accuracy: 0.9174\n",
            "Epoch 1064: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2338 - accuracy: 0.9175 - val_loss: 0.8862 - val_accuracy: 0.8115\n",
            "Epoch 1065/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2357 - accuracy: 0.9150\n",
            "Epoch 1065: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2370 - accuracy: 0.9146 - val_loss: 0.8197 - val_accuracy: 0.8220\n",
            "Epoch 1066/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2600 - accuracy: 0.9054\n",
            "Epoch 1066: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2615 - accuracy: 0.9046 - val_loss: 0.9739 - val_accuracy: 0.7993\n",
            "Epoch 1067/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2880 - accuracy: 0.8980\n",
            "Epoch 1067: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2881 - accuracy: 0.8979 - val_loss: 0.8713 - val_accuracy: 0.8163\n",
            "Epoch 1068/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3172 - accuracy: 0.8874\n",
            "Epoch 1068: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3145 - accuracy: 0.8880 - val_loss: 1.1464 - val_accuracy: 0.7628\n",
            "Epoch 1069/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2730 - accuracy: 0.9010\n",
            "Epoch 1069: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2730 - accuracy: 0.9010 - val_loss: 0.8600 - val_accuracy: 0.8268\n",
            "Epoch 1070/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2807 - accuracy: 0.8993\n",
            "Epoch 1070: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2810 - accuracy: 0.8992 - val_loss: 0.8776 - val_accuracy: 0.8214\n",
            "Epoch 1071/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2680 - accuracy: 0.9018\n",
            "Epoch 1071: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2663 - accuracy: 0.9028 - val_loss: 0.8746 - val_accuracy: 0.8166\n",
            "Epoch 1072/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2416 - accuracy: 0.9138\n",
            "Epoch 1072: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2424 - accuracy: 0.9133 - val_loss: 0.9791 - val_accuracy: 0.7987\n",
            "Epoch 1073/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3689 - accuracy: 0.8713\n",
            "Epoch 1073: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3691 - accuracy: 0.8710 - val_loss: 1.1234 - val_accuracy: 0.7513\n",
            "Epoch 1074/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3420 - accuracy: 0.8792\n",
            "Epoch 1074: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3440 - accuracy: 0.8784 - val_loss: 1.1804 - val_accuracy: 0.7382\n",
            "Epoch 1075/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2816 - accuracy: 0.8999\n",
            "Epoch 1075: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2774 - accuracy: 0.9006 - val_loss: 0.8573 - val_accuracy: 0.8265\n",
            "Epoch 1076/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2891 - accuracy: 0.8975\n",
            "Epoch 1076: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2880 - accuracy: 0.8980 - val_loss: 0.9183 - val_accuracy: 0.8028\n",
            "Epoch 1077/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2575 - accuracy: 0.9098\n",
            "Epoch 1077: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2545 - accuracy: 0.9113 - val_loss: 0.8368 - val_accuracy: 0.8278\n",
            "Epoch 1078/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2596 - accuracy: 0.9088\n",
            "Epoch 1078: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2675 - accuracy: 0.9059 - val_loss: 1.2241 - val_accuracy: 0.7404\n",
            "Epoch 1079/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2816 - accuracy: 0.8984\n",
            "Epoch 1079: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2824 - accuracy: 0.8980 - val_loss: 0.9704 - val_accuracy: 0.7862\n",
            "Epoch 1080/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2805 - accuracy: 0.8981\n",
            "Epoch 1080: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2856 - accuracy: 0.8962 - val_loss: 0.9700 - val_accuracy: 0.8009\n",
            "Epoch 1081/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2654 - accuracy: 0.9043\n",
            "Epoch 1081: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2663 - accuracy: 0.9040 - val_loss: 1.0092 - val_accuracy: 0.7923\n",
            "Epoch 1082/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2574 - accuracy: 0.9089\n",
            "Epoch 1082: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2564 - accuracy: 0.9093 - val_loss: 0.8643 - val_accuracy: 0.8182\n",
            "Epoch 1083/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2082 - accuracy: 0.9278\n",
            "Epoch 1083: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2089 - accuracy: 0.9275 - val_loss: 0.8797 - val_accuracy: 0.8195\n",
            "Epoch 1084/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3619 - accuracy: 0.8769\n",
            "Epoch 1084: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3619 - accuracy: 0.8769 - val_loss: 1.3764 - val_accuracy: 0.7238\n",
            "Epoch 1085/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2876 - accuracy: 0.9005\n",
            "Epoch 1085: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2849 - accuracy: 0.9014 - val_loss: 0.9034 - val_accuracy: 0.8063\n",
            "Epoch 1086/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2609 - accuracy: 0.9054\n",
            "Epoch 1086: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2609 - accuracy: 0.9054 - val_loss: 0.9851 - val_accuracy: 0.7932\n",
            "Epoch 1087/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2336 - accuracy: 0.9166\n",
            "Epoch 1087: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2335 - accuracy: 0.9167 - val_loss: 0.8765 - val_accuracy: 0.8207\n",
            "Epoch 1088/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2164 - accuracy: 0.9236\n",
            "Epoch 1088: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2156 - accuracy: 0.9244 - val_loss: 0.9048 - val_accuracy: 0.8089\n",
            "Epoch 1089/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2469 - accuracy: 0.9132\n",
            "Epoch 1089: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2435 - accuracy: 0.9142 - val_loss: 0.7968 - val_accuracy: 0.8323\n",
            "Epoch 1090/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2299 - accuracy: 0.9169\n",
            "Epoch 1090: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2299 - accuracy: 0.9169 - val_loss: 0.8587 - val_accuracy: 0.8137\n",
            "Epoch 1091/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2257 - accuracy: 0.9196\n",
            "Epoch 1091: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2271 - accuracy: 0.9193 - val_loss: 0.9287 - val_accuracy: 0.8035\n",
            "Epoch 1092/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2438 - accuracy: 0.9125\n",
            "Epoch 1092: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2438 - accuracy: 0.9125 - val_loss: 0.9077 - val_accuracy: 0.8169\n",
            "Epoch 1093/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2533 - accuracy: 0.9102\n",
            "Epoch 1093: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2503 - accuracy: 0.9111 - val_loss: 0.9143 - val_accuracy: 0.8070\n",
            "Epoch 1094/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2802 - accuracy: 0.9008\n",
            "Epoch 1094: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2867 - accuracy: 0.8984 - val_loss: 1.0805 - val_accuracy: 0.7714\n",
            "Epoch 1095/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.8717\n",
            "Epoch 1095: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3776 - accuracy: 0.8722 - val_loss: 1.1566 - val_accuracy: 0.7542\n",
            "Epoch 1096/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3084 - accuracy: 0.8869\n",
            "Epoch 1096: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3119 - accuracy: 0.8862 - val_loss: 0.9872 - val_accuracy: 0.7859\n",
            "Epoch 1097/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3417 - accuracy: 0.8783\n",
            "Epoch 1097: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3419 - accuracy: 0.8784 - val_loss: 0.9077 - val_accuracy: 0.8185\n",
            "Epoch 1098/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2859 - accuracy: 0.8989\n",
            "Epoch 1098: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2871 - accuracy: 0.8981 - val_loss: 1.0147 - val_accuracy: 0.7855\n",
            "Epoch 1099/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2483 - accuracy: 0.9123\n",
            "Epoch 1099: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2466 - accuracy: 0.9125 - val_loss: 0.8673 - val_accuracy: 0.8172\n",
            "Epoch 1100/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2258 - accuracy: 0.9208\n",
            "Epoch 1100: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2242 - accuracy: 0.9209 - val_loss: 0.8239 - val_accuracy: 0.8371\n",
            "Epoch 1101/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2019 - accuracy: 0.9288\n",
            "Epoch 1101: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2019 - accuracy: 0.9288 - val_loss: 0.9024 - val_accuracy: 0.8259\n",
            "Epoch 1102/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2238 - accuracy: 0.9192\n",
            "Epoch 1102: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2238 - accuracy: 0.9192 - val_loss: 0.9639 - val_accuracy: 0.7961\n",
            "Epoch 1103/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2608 - accuracy: 0.9093\n",
            "Epoch 1103: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2594 - accuracy: 0.9094 - val_loss: 0.7932 - val_accuracy: 0.8435\n",
            "Epoch 1104/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2028 - accuracy: 0.9271\n",
            "Epoch 1104: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2065 - accuracy: 0.9255 - val_loss: 0.9827 - val_accuracy: 0.7923\n",
            "Epoch 1105/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2646 - accuracy: 0.9047\n",
            "Epoch 1105: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2613 - accuracy: 0.9062 - val_loss: 0.8996 - val_accuracy: 0.8195\n",
            "Epoch 1106/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.6461 - accuracy: 0.8375\n",
            "Epoch 1106: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.6449 - accuracy: 0.8375 - val_loss: 1.4313 - val_accuracy: 0.7087\n",
            "Epoch 1107/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3234 - accuracy: 0.8887\n",
            "Epoch 1107: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3222 - accuracy: 0.8891 - val_loss: 0.9170 - val_accuracy: 0.8115\n",
            "Epoch 1108/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2296 - accuracy: 0.9183\n",
            "Epoch 1108: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2296 - accuracy: 0.9183 - val_loss: 0.8582 - val_accuracy: 0.8207\n",
            "Epoch 1109/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2051 - accuracy: 0.9292\n",
            "Epoch 1109: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2083 - accuracy: 0.9284 - val_loss: 0.8323 - val_accuracy: 0.8310\n",
            "Epoch 1110/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1930 - accuracy: 0.9343\n",
            "Epoch 1110: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1948 - accuracy: 0.9335 - val_loss: 0.8436 - val_accuracy: 0.8243\n",
            "Epoch 1111/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2030 - accuracy: 0.9304\n",
            "Epoch 1111: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2036 - accuracy: 0.9302 - val_loss: 0.8927 - val_accuracy: 0.8156\n",
            "Epoch 1112/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2149 - accuracy: 0.9221\n",
            "Epoch 1112: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2181 - accuracy: 0.9207 - val_loss: 0.8793 - val_accuracy: 0.8201\n",
            "Epoch 1113/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2449 - accuracy: 0.9127\n",
            "Epoch 1113: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2458 - accuracy: 0.9121 - val_loss: 0.9676 - val_accuracy: 0.7932\n",
            "Epoch 1114/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2047 - accuracy: 0.9275\n",
            "Epoch 1114: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2070 - accuracy: 0.9266 - val_loss: 0.9893 - val_accuracy: 0.7935\n",
            "Epoch 1115/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.4975 - accuracy: 0.8413\n",
            "Epoch 1115: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4937 - accuracy: 0.8424 - val_loss: 1.4145 - val_accuracy: 0.7234\n",
            "Epoch 1116/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2959 - accuracy: 0.8944\n",
            "Epoch 1116: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2975 - accuracy: 0.8932 - val_loss: 0.8862 - val_accuracy: 0.8191\n",
            "Epoch 1117/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2993 - accuracy: 0.8914\n",
            "Epoch 1117: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3001 - accuracy: 0.8912 - val_loss: 0.9451 - val_accuracy: 0.7967\n",
            "Epoch 1118/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2244 - accuracy: 0.9207\n",
            "Epoch 1118: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2269 - accuracy: 0.9197 - val_loss: 0.9778 - val_accuracy: 0.7942\n",
            "Epoch 1119/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2163 - accuracy: 0.9239\n",
            "Epoch 1119: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2157 - accuracy: 0.9242 - val_loss: 0.9351 - val_accuracy: 0.8057\n",
            "Epoch 1120/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2087 - accuracy: 0.9257\n",
            "Epoch 1120: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2123 - accuracy: 0.9238 - val_loss: 0.9055 - val_accuracy: 0.8227\n",
            "Epoch 1121/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2347 - accuracy: 0.9180\n",
            "Epoch 1121: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2340 - accuracy: 0.9181 - val_loss: 0.9215 - val_accuracy: 0.8111\n",
            "Epoch 1122/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2128 - accuracy: 0.9263\n",
            "Epoch 1122: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2186 - accuracy: 0.9242 - val_loss: 0.8850 - val_accuracy: 0.8127\n",
            "Epoch 1123/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2140 - accuracy: 0.9275\n",
            "Epoch 1123: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2146 - accuracy: 0.9274 - val_loss: 0.9798 - val_accuracy: 0.7884\n",
            "Epoch 1124/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2540 - accuracy: 0.9089\n",
            "Epoch 1124: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2540 - accuracy: 0.9089 - val_loss: 0.9485 - val_accuracy: 0.8067\n",
            "Epoch 1125/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3670 - accuracy: 0.8775\n",
            "Epoch 1125: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3776 - accuracy: 0.8741 - val_loss: 1.2986 - val_accuracy: 0.7183\n",
            "Epoch 1126/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8687\n",
            "Epoch 1126: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3785 - accuracy: 0.8703 - val_loss: 0.8776 - val_accuracy: 0.8121\n",
            "Epoch 1127/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2703 - accuracy: 0.9027\n",
            "Epoch 1127: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2701 - accuracy: 0.9029 - val_loss: 0.8811 - val_accuracy: 0.8268\n",
            "Epoch 1128/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2112 - accuracy: 0.9268\n",
            "Epoch 1128: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2131 - accuracy: 0.9257 - val_loss: 0.9250 - val_accuracy: 0.8115\n",
            "Epoch 1129/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2373 - accuracy: 0.9142\n",
            "Epoch 1129: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2362 - accuracy: 0.9150 - val_loss: 0.8185 - val_accuracy: 0.8371\n",
            "Epoch 1130/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1858 - accuracy: 0.9369\n",
            "Epoch 1130: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1867 - accuracy: 0.9362 - val_loss: 0.8151 - val_accuracy: 0.8403\n",
            "Epoch 1131/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2125 - accuracy: 0.9280\n",
            "Epoch 1131: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2134 - accuracy: 0.9265 - val_loss: 0.8714 - val_accuracy: 0.8233\n",
            "Epoch 1132/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2389 - accuracy: 0.9160\n",
            "Epoch 1132: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2374 - accuracy: 0.9163 - val_loss: 0.8465 - val_accuracy: 0.8351\n",
            "Epoch 1133/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2153 - accuracy: 0.9244\n",
            "Epoch 1133: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2166 - accuracy: 0.9237 - val_loss: 0.9717 - val_accuracy: 0.8012\n",
            "Epoch 1134/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2298 - accuracy: 0.9195\n",
            "Epoch 1134: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2317 - accuracy: 0.9185 - val_loss: 0.8948 - val_accuracy: 0.8092\n",
            "Epoch 1135/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2575 - accuracy: 0.9064\n",
            "Epoch 1135: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2575 - accuracy: 0.9064 - val_loss: 0.9338 - val_accuracy: 0.8095\n",
            "Epoch 1136/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2204 - accuracy: 0.9192\n",
            "Epoch 1136: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2212 - accuracy: 0.9191 - val_loss: 0.9024 - val_accuracy: 0.8163\n",
            "Epoch 1137/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3001 - accuracy: 0.8924\n",
            "Epoch 1137: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2998 - accuracy: 0.8924 - val_loss: 0.8917 - val_accuracy: 0.8211\n",
            "Epoch 1138/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2815 - accuracy: 0.8969\n",
            "Epoch 1138: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2798 - accuracy: 0.8977 - val_loss: 0.8813 - val_accuracy: 0.8230\n",
            "Epoch 1139/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2623 - accuracy: 0.9043\n",
            "Epoch 1139: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2622 - accuracy: 0.9044 - val_loss: 0.8893 - val_accuracy: 0.8323\n",
            "Epoch 1140/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3409 - accuracy: 0.8797\n",
            "Epoch 1140: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3853 - accuracy: 0.8720 - val_loss: 3.1154 - val_accuracy: 0.5547\n",
            "Epoch 1141/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.8444 - accuracy: 0.7959\n",
            "Epoch 1141: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.8097 - accuracy: 0.8027 - val_loss: 0.8584 - val_accuracy: 0.8294\n",
            "Epoch 1142/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2005 - accuracy: 0.9300\n",
            "Epoch 1142: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1998 - accuracy: 0.9303 - val_loss: 0.8320 - val_accuracy: 0.8364\n",
            "Epoch 1143/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2044 - accuracy: 0.9289\n",
            "Epoch 1143: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2051 - accuracy: 0.9285 - val_loss: 0.8955 - val_accuracy: 0.8265\n",
            "Epoch 1144/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2035 - accuracy: 0.9299\n",
            "Epoch 1144: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2024 - accuracy: 0.9304 - val_loss: 0.8080 - val_accuracy: 0.8431\n",
            "Epoch 1145/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1974 - accuracy: 0.9304\n",
            "Epoch 1145: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1961 - accuracy: 0.9312 - val_loss: 0.9062 - val_accuracy: 0.8227\n",
            "Epoch 1146/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2029 - accuracy: 0.9280\n",
            "Epoch 1146: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2119 - accuracy: 0.9258 - val_loss: 0.9241 - val_accuracy: 0.8153\n",
            "Epoch 1147/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2858 - accuracy: 0.9008\n",
            "Epoch 1147: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2858 - accuracy: 0.9008 - val_loss: 1.0155 - val_accuracy: 0.7849\n",
            "Epoch 1148/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2456 - accuracy: 0.9121\n",
            "Epoch 1148: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2434 - accuracy: 0.9124 - val_loss: 0.9402 - val_accuracy: 0.8070\n",
            "Epoch 1149/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2495 - accuracy: 0.9109\n",
            "Epoch 1149: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2470 - accuracy: 0.9117 - val_loss: 0.9206 - val_accuracy: 0.8028\n",
            "Epoch 1150/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1977 - accuracy: 0.9324\n",
            "Epoch 1150: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1989 - accuracy: 0.9322 - val_loss: 0.8362 - val_accuracy: 0.8294\n",
            "Epoch 1151/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2160 - accuracy: 0.9226\n",
            "Epoch 1151: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2173 - accuracy: 0.9221 - val_loss: 0.9115 - val_accuracy: 0.8166\n",
            "Epoch 1152/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2760 - accuracy: 0.9000\n",
            "Epoch 1152: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2760 - accuracy: 0.9000 - val_loss: 1.0404 - val_accuracy: 0.7823\n",
            "Epoch 1153/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2725 - accuracy: 0.9027\n",
            "Epoch 1153: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2728 - accuracy: 0.9024 - val_loss: 0.8458 - val_accuracy: 0.8351\n",
            "Epoch 1154/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2606 - accuracy: 0.9077\n",
            "Epoch 1154: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2639 - accuracy: 0.9060 - val_loss: 1.0697 - val_accuracy: 0.7746\n",
            "Epoch 1155/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2654 - accuracy: 0.9041\n",
            "Epoch 1155: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2650 - accuracy: 0.9038 - val_loss: 0.8931 - val_accuracy: 0.8191\n",
            "Epoch 1156/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2301 - accuracy: 0.9176\n",
            "Epoch 1156: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2313 - accuracy: 0.9169 - val_loss: 0.9751 - val_accuracy: 0.7871\n",
            "Epoch 1157/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2303 - accuracy: 0.9176\n",
            "Epoch 1157: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2304 - accuracy: 0.9177 - val_loss: 0.9606 - val_accuracy: 0.7955\n",
            "Epoch 1158/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2617 - accuracy: 0.9062\n",
            "Epoch 1158: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2597 - accuracy: 0.9069 - val_loss: 0.9488 - val_accuracy: 0.8102\n",
            "Epoch 1159/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2515 - accuracy: 0.9104\n",
            "Epoch 1159: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2517 - accuracy: 0.9101 - val_loss: 0.9225 - val_accuracy: 0.8143\n",
            "Epoch 1160/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2452 - accuracy: 0.9144\n",
            "Epoch 1160: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2455 - accuracy: 0.9147 - val_loss: 0.9219 - val_accuracy: 0.8051\n",
            "Epoch 1161/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2616 - accuracy: 0.9059\n",
            "Epoch 1161: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2604 - accuracy: 0.9065 - val_loss: 0.9337 - val_accuracy: 0.8092\n",
            "Epoch 1162/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2350 - accuracy: 0.9161\n",
            "Epoch 1162: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2350 - accuracy: 0.9161 - val_loss: 1.0720 - val_accuracy: 0.7865\n",
            "Epoch 1163/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2354 - accuracy: 0.9145\n",
            "Epoch 1163: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2352 - accuracy: 0.9145 - val_loss: 0.8133 - val_accuracy: 0.8329\n",
            "Epoch 1164/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2484 - accuracy: 0.9135\n",
            "Epoch 1164: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2473 - accuracy: 0.9134 - val_loss: 0.9488 - val_accuracy: 0.8025\n",
            "Epoch 1165/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.4735 - accuracy: 0.8518\n",
            "Epoch 1165: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.4948 - accuracy: 0.8474 - val_loss: 1.0972 - val_accuracy: 0.7804\n",
            "Epoch 1166/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3064 - accuracy: 0.8899\n",
            "Epoch 1166: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3064 - accuracy: 0.8899 - val_loss: 0.8907 - val_accuracy: 0.8143\n",
            "Epoch 1167/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2212 - accuracy: 0.9198\n",
            "Epoch 1167: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2230 - accuracy: 0.9189 - val_loss: 0.8435 - val_accuracy: 0.8303\n",
            "Epoch 1168/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2243 - accuracy: 0.9188\n",
            "Epoch 1168: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2263 - accuracy: 0.9181 - val_loss: 0.9273 - val_accuracy: 0.8067\n",
            "Epoch 1169/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2785 - accuracy: 0.8998\n",
            "Epoch 1169: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2732 - accuracy: 0.9014 - val_loss: 0.8668 - val_accuracy: 0.8284\n",
            "Epoch 1170/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2268 - accuracy: 0.9177\n",
            "Epoch 1170: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2278 - accuracy: 0.9172 - val_loss: 0.8907 - val_accuracy: 0.8095\n",
            "Epoch 1171/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2714 - accuracy: 0.9001\n",
            "Epoch 1171: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2714 - accuracy: 0.9003 - val_loss: 0.8802 - val_accuracy: 0.8233\n",
            "Epoch 1172/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1920 - accuracy: 0.9307\n",
            "Epoch 1172: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1926 - accuracy: 0.9303 - val_loss: 0.8351 - val_accuracy: 0.8431\n",
            "Epoch 1173/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.2212 - accuracy: 0.9213\n",
            "Epoch 1173: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2233 - accuracy: 0.9205 - val_loss: 0.9274 - val_accuracy: 0.8156\n",
            "Epoch 1174/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2510 - accuracy: 0.9096\n",
            "Epoch 1174: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2508 - accuracy: 0.9098 - val_loss: 0.9533 - val_accuracy: 0.8131\n",
            "Epoch 1175/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2288 - accuracy: 0.9205\n",
            "Epoch 1175: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2302 - accuracy: 0.9197 - val_loss: 0.8494 - val_accuracy: 0.8351\n",
            "Epoch 1176/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2530 - accuracy: 0.9078\n",
            "Epoch 1176: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2505 - accuracy: 0.9089 - val_loss: 0.8330 - val_accuracy: 0.8249\n",
            "Epoch 1177/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2328 - accuracy: 0.9180\n",
            "Epoch 1177: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2332 - accuracy: 0.9177 - val_loss: 1.0072 - val_accuracy: 0.7810\n",
            "Epoch 1178/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2148 - accuracy: 0.9256\n",
            "Epoch 1178: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2152 - accuracy: 0.9253 - val_loss: 0.9168 - val_accuracy: 0.8204\n",
            "Epoch 1179/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2351 - accuracy: 0.9137\n",
            "Epoch 1179: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2354 - accuracy: 0.9140 - val_loss: 1.0630 - val_accuracy: 0.7788\n",
            "Epoch 1180/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2350 - accuracy: 0.9171\n",
            "Epoch 1180: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2354 - accuracy: 0.9171 - val_loss: 0.9493 - val_accuracy: 0.8076\n",
            "Epoch 1181/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2501 - accuracy: 0.9094\n",
            "Epoch 1181: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2477 - accuracy: 0.9107 - val_loss: 0.8972 - val_accuracy: 0.8230\n",
            "Epoch 1182/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2125 - accuracy: 0.9250\n",
            "Epoch 1182: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2139 - accuracy: 0.9242 - val_loss: 0.9075 - val_accuracy: 0.8275\n",
            "Epoch 1183/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2855 - accuracy: 0.8970\n",
            "Epoch 1183: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2876 - accuracy: 0.8964 - val_loss: 0.9205 - val_accuracy: 0.8207\n",
            "Epoch 1184/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3259 - accuracy: 0.8849\n",
            "Epoch 1184: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.3254 - accuracy: 0.8848 - val_loss: 0.9894 - val_accuracy: 0.8019\n",
            "Epoch 1185/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2460 - accuracy: 0.9117\n",
            "Epoch 1185: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2502 - accuracy: 0.9101 - val_loss: 1.1020 - val_accuracy: 0.7753\n",
            "Epoch 1186/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2356 - accuracy: 0.9160\n",
            "Epoch 1186: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2367 - accuracy: 0.9156 - val_loss: 0.9155 - val_accuracy: 0.8310\n",
            "Epoch 1187/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2385 - accuracy: 0.9158\n",
            "Epoch 1187: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2376 - accuracy: 0.9161 - val_loss: 0.8586 - val_accuracy: 0.8239\n",
            "Epoch 1188/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2196 - accuracy: 0.9204\n",
            "Epoch 1188: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2194 - accuracy: 0.9204 - val_loss: 0.8158 - val_accuracy: 0.8425\n",
            "Epoch 1189/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2265 - accuracy: 0.9179\n",
            "Epoch 1189: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2280 - accuracy: 0.9173 - val_loss: 1.0888 - val_accuracy: 0.7836\n",
            "Epoch 1190/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.9250 - accuracy: 0.7739\n",
            "Epoch 1190: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.9250 - accuracy: 0.7739 - val_loss: 1.1579 - val_accuracy: 0.7631\n",
            "Epoch 1191/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2456 - accuracy: 0.9120\n",
            "Epoch 1191: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2448 - accuracy: 0.9124 - val_loss: 0.8400 - val_accuracy: 0.8300\n",
            "Epoch 1192/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2043 - accuracy: 0.9300\n",
            "Epoch 1192: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2043 - accuracy: 0.9302 - val_loss: 0.9126 - val_accuracy: 0.8147\n",
            "Epoch 1193/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2031 - accuracy: 0.9302\n",
            "Epoch 1193: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2005 - accuracy: 0.9313 - val_loss: 0.8456 - val_accuracy: 0.8377\n",
            "Epoch 1194/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1708 - accuracy: 0.9423\n",
            "Epoch 1194: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1711 - accuracy: 0.9425 - val_loss: 0.9598 - val_accuracy: 0.8022\n",
            "Epoch 1195/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1774 - accuracy: 0.9396\n",
            "Epoch 1195: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1765 - accuracy: 0.9402 - val_loss: 0.8380 - val_accuracy: 0.8355\n",
            "Epoch 1196/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1850 - accuracy: 0.9347\n",
            "Epoch 1196: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1861 - accuracy: 0.9342 - val_loss: 0.8805 - val_accuracy: 0.8262\n",
            "Epoch 1197/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2280 - accuracy: 0.9186\n",
            "Epoch 1197: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2278 - accuracy: 0.9186 - val_loss: 0.9917 - val_accuracy: 0.7846\n",
            "Epoch 1198/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2230 - accuracy: 0.9193\n",
            "Epoch 1198: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2314 - accuracy: 0.9170 - val_loss: 0.9505 - val_accuracy: 0.8051\n",
            "Epoch 1199/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2181 - accuracy: 0.9210\n",
            "Epoch 1199: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2183 - accuracy: 0.9213 - val_loss: 0.8454 - val_accuracy: 0.8335\n",
            "Epoch 1200/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2776 - accuracy: 0.9034\n",
            "Epoch 1200: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2719 - accuracy: 0.9052 - val_loss: 0.8649 - val_accuracy: 0.8348\n",
            "Epoch 1201/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2153 - accuracy: 0.9244\n",
            "Epoch 1201: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2174 - accuracy: 0.9241 - val_loss: 0.8789 - val_accuracy: 0.8303\n",
            "Epoch 1202/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2289 - accuracy: 0.9164\n",
            "Epoch 1202: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2280 - accuracy: 0.9169 - val_loss: 0.9338 - val_accuracy: 0.8108\n",
            "Epoch 1203/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2346 - accuracy: 0.9184\n",
            "Epoch 1203: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2319 - accuracy: 0.9192 - val_loss: 0.8782 - val_accuracy: 0.8252\n",
            "Epoch 1204/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2296 - accuracy: 0.9186\n",
            "Epoch 1204: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2306 - accuracy: 0.9174 - val_loss: 0.9721 - val_accuracy: 0.7958\n",
            "Epoch 1205/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2188 - accuracy: 0.9280\n",
            "Epoch 1205: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2216 - accuracy: 0.9273 - val_loss: 1.0858 - val_accuracy: 0.7798\n",
            "Epoch 1206/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2708 - accuracy: 0.9017\n",
            "Epoch 1206: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2668 - accuracy: 0.9033 - val_loss: 0.9521 - val_accuracy: 0.8115\n",
            "Epoch 1207/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1939 - accuracy: 0.9317\n",
            "Epoch 1207: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1939 - accuracy: 0.9317 - val_loss: 0.8342 - val_accuracy: 0.8310\n",
            "Epoch 1208/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2464 - accuracy: 0.9125\n",
            "Epoch 1208: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2485 - accuracy: 0.9120 - val_loss: 1.4780 - val_accuracy: 0.7173\n",
            "Epoch 1209/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.4182 - accuracy: 0.8629\n",
            "Epoch 1209: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4097 - accuracy: 0.8655 - val_loss: 0.8601 - val_accuracy: 0.8217\n",
            "Epoch 1210/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2097 - accuracy: 0.9246\n",
            "Epoch 1210: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2075 - accuracy: 0.9255 - val_loss: 0.8818 - val_accuracy: 0.8323\n",
            "Epoch 1211/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.4364 - accuracy: 0.8763\n",
            "Epoch 1211: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4459 - accuracy: 0.8732 - val_loss: 1.4268 - val_accuracy: 0.7295\n",
            "Epoch 1212/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3067 - accuracy: 0.8954\n",
            "Epoch 1212: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2991 - accuracy: 0.8978 - val_loss: 0.8707 - val_accuracy: 0.8332\n",
            "Epoch 1213/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1975 - accuracy: 0.9311\n",
            "Epoch 1213: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2028 - accuracy: 0.9287 - val_loss: 0.9501 - val_accuracy: 0.8019\n",
            "Epoch 1214/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2429 - accuracy: 0.9103\n",
            "Epoch 1214: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2432 - accuracy: 0.9105 - val_loss: 0.8410 - val_accuracy: 0.8287\n",
            "Epoch 1215/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.1802 - accuracy: 0.9365\n",
            "Epoch 1215: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1824 - accuracy: 0.9352 - val_loss: 0.8819 - val_accuracy: 0.8166\n",
            "Epoch 1216/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2146 - accuracy: 0.9241\n",
            "Epoch 1216: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2133 - accuracy: 0.9250 - val_loss: 0.8590 - val_accuracy: 0.8342\n",
            "Epoch 1217/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1834 - accuracy: 0.9347\n",
            "Epoch 1217: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1834 - accuracy: 0.9349 - val_loss: 0.8738 - val_accuracy: 0.8217\n",
            "Epoch 1218/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2038 - accuracy: 0.9287\n",
            "Epoch 1218: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2083 - accuracy: 0.9268 - val_loss: 1.0969 - val_accuracy: 0.7830\n",
            "Epoch 1219/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1913 - accuracy: 0.9337\n",
            "Epoch 1219: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1911 - accuracy: 0.9336 - val_loss: 0.8883 - val_accuracy: 0.8220\n",
            "Epoch 1220/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2584 - accuracy: 0.9086\n",
            "Epoch 1220: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2582 - accuracy: 0.9086 - val_loss: 1.0004 - val_accuracy: 0.7932\n",
            "Epoch 1221/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2481 - accuracy: 0.9093\n",
            "Epoch 1221: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2486 - accuracy: 0.9093 - val_loss: 1.0221 - val_accuracy: 0.7862\n",
            "Epoch 1222/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3046 - accuracy: 0.8928\n",
            "Epoch 1222: val_accuracy did not improve from 0.84475\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3048 - accuracy: 0.8922 - val_loss: 1.3093 - val_accuracy: 0.7414\n",
            "Epoch 1223/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3129 - accuracy: 0.8915\n",
            "Epoch 1223: val_accuracy improved from 0.84475 to 0.84507, saving model to /content/asl1/Adam4/cp-1223-0.85.hdf5\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.3062 - accuracy: 0.8933 - val_loss: 0.8382 - val_accuracy: 0.8451\n",
            "Epoch 1224/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2182 - accuracy: 0.9220\n",
            "Epoch 1224: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2182 - accuracy: 0.9220 - val_loss: 0.9813 - val_accuracy: 0.7964\n",
            "Epoch 1225/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.5506 - accuracy: 0.8359\n",
            "Epoch 1225: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.5389 - accuracy: 0.8379 - val_loss: 1.0626 - val_accuracy: 0.7910\n",
            "Epoch 1226/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2565 - accuracy: 0.9060\n",
            "Epoch 1226: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2525 - accuracy: 0.9076 - val_loss: 0.8693 - val_accuracy: 0.8307\n",
            "Epoch 1227/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1991 - accuracy: 0.9287\n",
            "Epoch 1227: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1992 - accuracy: 0.9286 - val_loss: 0.8393 - val_accuracy: 0.8303\n",
            "Epoch 1228/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1940 - accuracy: 0.9302\n",
            "Epoch 1228: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1936 - accuracy: 0.9305 - val_loss: 0.9041 - val_accuracy: 0.8156\n",
            "Epoch 1229/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1848 - accuracy: 0.9343\n",
            "Epoch 1229: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1859 - accuracy: 0.9340 - val_loss: 0.8457 - val_accuracy: 0.8287\n",
            "Epoch 1230/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1700 - accuracy: 0.9408\n",
            "Epoch 1230: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1721 - accuracy: 0.9404 - val_loss: 0.8312 - val_accuracy: 0.8339\n",
            "Epoch 1231/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1996 - accuracy: 0.9279\n",
            "Epoch 1231: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1999 - accuracy: 0.9281 - val_loss: 0.9204 - val_accuracy: 0.8265\n",
            "Epoch 1232/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2171 - accuracy: 0.9205\n",
            "Epoch 1232: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2208 - accuracy: 0.9198 - val_loss: 0.9406 - val_accuracy: 0.8079\n",
            "Epoch 1233/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2281 - accuracy: 0.9188\n",
            "Epoch 1233: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2285 - accuracy: 0.9189 - val_loss: 0.9666 - val_accuracy: 0.8070\n",
            "Epoch 1234/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2400 - accuracy: 0.9153\n",
            "Epoch 1234: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2385 - accuracy: 0.9161 - val_loss: 0.9019 - val_accuracy: 0.8227\n",
            "Epoch 1235/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2722 - accuracy: 0.9007\n",
            "Epoch 1235: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2689 - accuracy: 0.9018 - val_loss: 0.9287 - val_accuracy: 0.8217\n",
            "Epoch 1236/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3188 - accuracy: 0.8899\n",
            "Epoch 1236: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3188 - accuracy: 0.8899 - val_loss: 0.8547 - val_accuracy: 0.8287\n",
            "Epoch 1237/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.1924 - accuracy: 0.9312\n",
            "Epoch 1237: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1931 - accuracy: 0.9306 - val_loss: 0.8579 - val_accuracy: 0.8287\n",
            "Epoch 1238/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2034 - accuracy: 0.9275\n",
            "Epoch 1238: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2042 - accuracy: 0.9273 - val_loss: 0.9346 - val_accuracy: 0.8108\n",
            "Epoch 1239/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2399 - accuracy: 0.9136\n",
            "Epoch 1239: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2398 - accuracy: 0.9132 - val_loss: 0.9704 - val_accuracy: 0.8060\n",
            "Epoch 1240/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2301 - accuracy: 0.9180\n",
            "Epoch 1240: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2300 - accuracy: 0.9181 - val_loss: 0.8898 - val_accuracy: 0.8310\n",
            "Epoch 1241/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2651 - accuracy: 0.9035\n",
            "Epoch 1241: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2636 - accuracy: 0.9039 - val_loss: 0.9754 - val_accuracy: 0.7964\n",
            "Epoch 1242/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2775 - accuracy: 0.9016\n",
            "Epoch 1242: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2792 - accuracy: 0.9011 - val_loss: 0.8973 - val_accuracy: 0.8342\n",
            "Epoch 1243/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2409 - accuracy: 0.9119\n",
            "Epoch 1243: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2409 - accuracy: 0.9119 - val_loss: 0.9350 - val_accuracy: 0.8137\n",
            "Epoch 1244/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3352 - accuracy: 0.8880\n",
            "Epoch 1244: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3431 - accuracy: 0.8859 - val_loss: 1.3378 - val_accuracy: 0.7337\n",
            "Epoch 1245/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2866 - accuracy: 0.8967\n",
            "Epoch 1245: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.2846 - accuracy: 0.8974 - val_loss: 0.9117 - val_accuracy: 0.8134\n",
            "Epoch 1246/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1910 - accuracy: 0.9324\n",
            "Epoch 1246: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1917 - accuracy: 0.9319 - val_loss: 0.8371 - val_accuracy: 0.8374\n",
            "Epoch 1247/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1676 - accuracy: 0.9421\n",
            "Epoch 1247: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1679 - accuracy: 0.9417 - val_loss: 0.8806 - val_accuracy: 0.8319\n",
            "Epoch 1248/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1915 - accuracy: 0.9317\n",
            "Epoch 1248: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1928 - accuracy: 0.9312 - val_loss: 0.8534 - val_accuracy: 0.8284\n",
            "Epoch 1249/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2050 - accuracy: 0.9252\n",
            "Epoch 1249: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2058 - accuracy: 0.9249 - val_loss: 1.0657 - val_accuracy: 0.7766\n",
            "Epoch 1250/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2256 - accuracy: 0.9177\n",
            "Epoch 1250: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2217 - accuracy: 0.9190 - val_loss: 0.8722 - val_accuracy: 0.8287\n",
            "Epoch 1251/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2049 - accuracy: 0.9241\n",
            "Epoch 1251: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2061 - accuracy: 0.9237 - val_loss: 0.8774 - val_accuracy: 0.8291\n",
            "Epoch 1252/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1879 - accuracy: 0.9299\n",
            "Epoch 1252: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1894 - accuracy: 0.9298 - val_loss: 0.9856 - val_accuracy: 0.7974\n",
            "Epoch 1253/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2999 - accuracy: 0.8915\n",
            "Epoch 1253: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2979 - accuracy: 0.8922 - val_loss: 0.9384 - val_accuracy: 0.8153\n",
            "Epoch 1254/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.3766 - accuracy: 0.8729\n",
            "Epoch 1254: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3825 - accuracy: 0.8711 - val_loss: 1.4287 - val_accuracy: 0.7100\n",
            "Epoch 1255/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3656 - accuracy: 0.8815\n",
            "Epoch 1255: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3656 - accuracy: 0.8815 - val_loss: 0.8941 - val_accuracy: 0.8281\n",
            "Epoch 1256/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1904 - accuracy: 0.9338\n",
            "Epoch 1256: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1905 - accuracy: 0.9339 - val_loss: 0.8442 - val_accuracy: 0.8361\n",
            "Epoch 1257/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2637 - accuracy: 0.9084\n",
            "Epoch 1257: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2636 - accuracy: 0.9085 - val_loss: 1.0815 - val_accuracy: 0.7846\n",
            "Epoch 1258/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2147 - accuracy: 0.9248\n",
            "Epoch 1258: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2148 - accuracy: 0.9249 - val_loss: 0.9176 - val_accuracy: 0.8191\n",
            "Epoch 1259/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2503 - accuracy: 0.9111\n",
            "Epoch 1259: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2512 - accuracy: 0.9103 - val_loss: 0.8852 - val_accuracy: 0.8255\n",
            "Epoch 1260/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1984 - accuracy: 0.9250\n",
            "Epoch 1260: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1997 - accuracy: 0.9247 - val_loss: 0.9254 - val_accuracy: 0.8214\n",
            "Epoch 1261/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1911 - accuracy: 0.9308\n",
            "Epoch 1261: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1911 - accuracy: 0.9305 - val_loss: 0.9586 - val_accuracy: 0.8051\n",
            "Epoch 1262/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2470 - accuracy: 0.9119\n",
            "Epoch 1262: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2467 - accuracy: 0.9117 - val_loss: 0.9095 - val_accuracy: 0.8140\n",
            "Epoch 1263/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3075 - accuracy: 0.8951\n",
            "Epoch 1263: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3065 - accuracy: 0.8953 - val_loss: 0.9663 - val_accuracy: 0.8070\n",
            "Epoch 1264/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2272 - accuracy: 0.9169\n",
            "Epoch 1264: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.2244 - accuracy: 0.9178 - val_loss: 0.8533 - val_accuracy: 0.8284\n",
            "Epoch 1265/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2201 - accuracy: 0.9211\n",
            "Epoch 1265: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2188 - accuracy: 0.9213 - val_loss: 0.9064 - val_accuracy: 0.8243\n",
            "Epoch 1266/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2043 - accuracy: 0.9252\n",
            "Epoch 1266: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2060 - accuracy: 0.9243 - val_loss: 0.8930 - val_accuracy: 0.8246\n",
            "Epoch 1267/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2271 - accuracy: 0.9174\n",
            "Epoch 1267: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2272 - accuracy: 0.9173 - val_loss: 0.9833 - val_accuracy: 0.7964\n",
            "Epoch 1268/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3407 - accuracy: 0.8814\n",
            "Epoch 1268: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3405 - accuracy: 0.8813 - val_loss: 0.8737 - val_accuracy: 0.8300\n",
            "Epoch 1269/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.4000 - accuracy: 0.8647\n",
            "Epoch 1269: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3946 - accuracy: 0.8664 - val_loss: 0.9692 - val_accuracy: 0.7942\n",
            "Epoch 1270/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.2518 - accuracy: 0.9098\n",
            "Epoch 1270: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2529 - accuracy: 0.9094 - val_loss: 1.0348 - val_accuracy: 0.8012\n",
            "Epoch 1271/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2213 - accuracy: 0.9220\n",
            "Epoch 1271: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2221 - accuracy: 0.9217 - val_loss: 0.9442 - val_accuracy: 0.8115\n",
            "Epoch 1272/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1998 - accuracy: 0.9275\n",
            "Epoch 1272: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1990 - accuracy: 0.9278 - val_loss: 0.9266 - val_accuracy: 0.8169\n",
            "Epoch 1273/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2100 - accuracy: 0.9242\n",
            "Epoch 1273: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2100 - accuracy: 0.9242 - val_loss: 0.8629 - val_accuracy: 0.8262\n",
            "Epoch 1274/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2543 - accuracy: 0.9083\n",
            "Epoch 1274: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2541 - accuracy: 0.9084 - val_loss: 0.9317 - val_accuracy: 0.8086\n",
            "Epoch 1275/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2162 - accuracy: 0.9211\n",
            "Epoch 1275: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2166 - accuracy: 0.9209 - val_loss: 0.8492 - val_accuracy: 0.8332\n",
            "Epoch 1276/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2074 - accuracy: 0.9263\n",
            "Epoch 1276: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2059 - accuracy: 0.9271 - val_loss: 0.8923 - val_accuracy: 0.8255\n",
            "Epoch 1277/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2474 - accuracy: 0.9081\n",
            "Epoch 1277: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2487 - accuracy: 0.9084 - val_loss: 0.9844 - val_accuracy: 0.8086\n",
            "Epoch 1278/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1861 - accuracy: 0.9350\n",
            "Epoch 1278: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1861 - accuracy: 0.9350 - val_loss: 0.9339 - val_accuracy: 0.8131\n",
            "Epoch 1279/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2448 - accuracy: 0.9115\n",
            "Epoch 1279: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2432 - accuracy: 0.9126 - val_loss: 0.9110 - val_accuracy: 0.8214\n",
            "Epoch 1280/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2584 - accuracy: 0.9062\n",
            "Epoch 1280: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2551 - accuracy: 0.9076 - val_loss: 0.9622 - val_accuracy: 0.8156\n",
            "Epoch 1281/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2110 - accuracy: 0.9237\n",
            "Epoch 1281: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2107 - accuracy: 0.9237 - val_loss: 0.9267 - val_accuracy: 0.8115\n",
            "Epoch 1282/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2021 - accuracy: 0.9253\n",
            "Epoch 1282: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2021 - accuracy: 0.9253 - val_loss: 0.9464 - val_accuracy: 0.8150\n",
            "Epoch 1283/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1902 - accuracy: 0.9325\n",
            "Epoch 1283: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1898 - accuracy: 0.9319 - val_loss: 0.9155 - val_accuracy: 0.8153\n",
            "Epoch 1284/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2078 - accuracy: 0.9235\n",
            "Epoch 1284: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2082 - accuracy: 0.9233 - val_loss: 1.0064 - val_accuracy: 0.8015\n",
            "Epoch 1285/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2662 - accuracy: 0.9035\n",
            "Epoch 1285: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2683 - accuracy: 0.9030 - val_loss: 1.4169 - val_accuracy: 0.7215\n",
            "Epoch 1286/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2889 - accuracy: 0.8985\n",
            "Epoch 1286: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2889 - accuracy: 0.8985 - val_loss: 1.0521 - val_accuracy: 0.7923\n",
            "Epoch 1287/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2380 - accuracy: 0.9153\n",
            "Epoch 1287: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2371 - accuracy: 0.9153 - val_loss: 0.9857 - val_accuracy: 0.7996\n",
            "Epoch 1288/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2005 - accuracy: 0.9258\n",
            "Epoch 1288: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2006 - accuracy: 0.9259 - val_loss: 0.9985 - val_accuracy: 0.8006\n",
            "Epoch 1289/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2211 - accuracy: 0.9177\n",
            "Epoch 1289: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2211 - accuracy: 0.9177 - val_loss: 0.8570 - val_accuracy: 0.8383\n",
            "Epoch 1290/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2191 - accuracy: 0.9216\n",
            "Epoch 1290: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2195 - accuracy: 0.9215 - val_loss: 1.1346 - val_accuracy: 0.7746\n",
            "Epoch 1291/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2198 - accuracy: 0.9227\n",
            "Epoch 1291: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2198 - accuracy: 0.9227 - val_loss: 0.8873 - val_accuracy: 0.8259\n",
            "Epoch 1292/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.2535 - accuracy: 0.9119\n",
            "Epoch 1292: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2639 - accuracy: 0.9081 - val_loss: 1.4888 - val_accuracy: 0.7173\n",
            "Epoch 1293/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.3133 - accuracy: 0.8898\n",
            "Epoch 1293: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3060 - accuracy: 0.8924 - val_loss: 0.9675 - val_accuracy: 0.8086\n",
            "Epoch 1294/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2046 - accuracy: 0.9269\n",
            "Epoch 1294: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2050 - accuracy: 0.9261 - val_loss: 0.9258 - val_accuracy: 0.8150\n",
            "Epoch 1295/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.5580 - accuracy: 0.8577\n",
            "Epoch 1295: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.5512 - accuracy: 0.8581 - val_loss: 1.0312 - val_accuracy: 0.7903\n",
            "Epoch 1296/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2197 - accuracy: 0.9188\n",
            "Epoch 1296: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2165 - accuracy: 0.9198 - val_loss: 0.8638 - val_accuracy: 0.8284\n",
            "Epoch 1297/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1836 - accuracy: 0.9357\n",
            "Epoch 1297: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1859 - accuracy: 0.9346 - val_loss: 0.8444 - val_accuracy: 0.8265\n",
            "Epoch 1298/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2182 - accuracy: 0.9222\n",
            "Epoch 1298: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2182 - accuracy: 0.9222 - val_loss: 0.9733 - val_accuracy: 0.8038\n",
            "Epoch 1299/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1873 - accuracy: 0.9338\n",
            "Epoch 1299: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1859 - accuracy: 0.9343 - val_loss: 0.8615 - val_accuracy: 0.8307\n",
            "Epoch 1300/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1796 - accuracy: 0.9371\n",
            "Epoch 1300: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1811 - accuracy: 0.9363 - val_loss: 0.9130 - val_accuracy: 0.8156\n",
            "Epoch 1301/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2092 - accuracy: 0.9225\n",
            "Epoch 1301: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2095 - accuracy: 0.9223 - val_loss: 0.9336 - val_accuracy: 0.8163\n",
            "Epoch 1302/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2008 - accuracy: 0.9288\n",
            "Epoch 1302: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2006 - accuracy: 0.9288 - val_loss: 0.9853 - val_accuracy: 0.8073\n",
            "Epoch 1303/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2018 - accuracy: 0.9284\n",
            "Epoch 1303: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2018 - accuracy: 0.9285 - val_loss: 0.9286 - val_accuracy: 0.8249\n",
            "Epoch 1304/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2065 - accuracy: 0.9250\n",
            "Epoch 1304: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2054 - accuracy: 0.9257 - val_loss: 0.8550 - val_accuracy: 0.8415\n",
            "Epoch 1305/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1965 - accuracy: 0.9295\n",
            "Epoch 1305: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1954 - accuracy: 0.9299 - val_loss: 0.8402 - val_accuracy: 0.8415\n",
            "Epoch 1306/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1731 - accuracy: 0.9379\n",
            "Epoch 1306: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1742 - accuracy: 0.9377 - val_loss: 0.8517 - val_accuracy: 0.8335\n",
            "Epoch 1307/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3441 - accuracy: 0.8844\n",
            "Epoch 1307: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3441 - accuracy: 0.8844 - val_loss: 0.9783 - val_accuracy: 0.8092\n",
            "Epoch 1308/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1793 - accuracy: 0.9377\n",
            "Epoch 1308: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1789 - accuracy: 0.9377 - val_loss: 0.8495 - val_accuracy: 0.8399\n",
            "Epoch 1309/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2825 - accuracy: 0.9010\n",
            "Epoch 1309: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2822 - accuracy: 0.9020 - val_loss: 1.0512 - val_accuracy: 0.7948\n",
            "Epoch 1310/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2467 - accuracy: 0.9099\n",
            "Epoch 1310: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2428 - accuracy: 0.9112 - val_loss: 0.9197 - val_accuracy: 0.8153\n",
            "Epoch 1311/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2153 - accuracy: 0.9231\n",
            "Epoch 1311: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2142 - accuracy: 0.9237 - val_loss: 0.9067 - val_accuracy: 0.8255\n",
            "Epoch 1312/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1965 - accuracy: 0.9317\n",
            "Epoch 1312: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1991 - accuracy: 0.9308 - val_loss: 0.8981 - val_accuracy: 0.8284\n",
            "Epoch 1313/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3114 - accuracy: 0.8969\n",
            "Epoch 1313: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3206 - accuracy: 0.8946 - val_loss: 0.9934 - val_accuracy: 0.8019\n",
            "Epoch 1314/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3609 - accuracy: 0.8786\n",
            "Epoch 1314: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3589 - accuracy: 0.8790 - val_loss: 0.8740 - val_accuracy: 0.8367\n",
            "Epoch 1315/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1797 - accuracy: 0.9347\n",
            "Epoch 1315: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1792 - accuracy: 0.9345 - val_loss: 0.8409 - val_accuracy: 0.8403\n",
            "Epoch 1316/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1825 - accuracy: 0.9346\n",
            "Epoch 1316: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1855 - accuracy: 0.9333 - val_loss: 0.9877 - val_accuracy: 0.8083\n",
            "Epoch 1317/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2092 - accuracy: 0.9250\n",
            "Epoch 1317: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2193 - accuracy: 0.9217 - val_loss: 0.9679 - val_accuracy: 0.8028\n",
            "Epoch 1318/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1973 - accuracy: 0.9300\n",
            "Epoch 1318: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1973 - accuracy: 0.9301 - val_loss: 0.8453 - val_accuracy: 0.8374\n",
            "Epoch 1319/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1849 - accuracy: 0.9348\n",
            "Epoch 1319: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1853 - accuracy: 0.9349 - val_loss: 0.9410 - val_accuracy: 0.8070\n",
            "Epoch 1320/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.9166 - accuracy: 0.7952\n",
            "Epoch 1320: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.9007 - accuracy: 0.7975 - val_loss: 1.0343 - val_accuracy: 0.7961\n",
            "Epoch 1321/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1914 - accuracy: 0.9310\n",
            "Epoch 1321: val_accuracy did not improve from 0.84507\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1914 - accuracy: 0.9312 - val_loss: 0.8690 - val_accuracy: 0.8265\n",
            "Epoch 1322/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1716 - accuracy: 0.9403\n",
            "Epoch 1322: val_accuracy improved from 0.84507 to 0.85147, saving model to /content/asl1/Adam4/cp-1322-0.85.hdf5\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1711 - accuracy: 0.9407 - val_loss: 0.8087 - val_accuracy: 0.8515\n",
            "Epoch 1323/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1701 - accuracy: 0.9406\n",
            "Epoch 1323: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1698 - accuracy: 0.9408 - val_loss: 0.8881 - val_accuracy: 0.8268\n",
            "Epoch 1324/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1666 - accuracy: 0.9423\n",
            "Epoch 1324: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1665 - accuracy: 0.9427 - val_loss: 0.8405 - val_accuracy: 0.8390\n",
            "Epoch 1325/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1740 - accuracy: 0.9369\n",
            "Epoch 1325: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1723 - accuracy: 0.9377 - val_loss: 0.8506 - val_accuracy: 0.8310\n",
            "Epoch 1326/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1710 - accuracy: 0.9402\n",
            "Epoch 1326: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1710 - accuracy: 0.9402 - val_loss: 0.9422 - val_accuracy: 0.8079\n",
            "Epoch 1327/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1859 - accuracy: 0.9364\n",
            "Epoch 1327: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1870 - accuracy: 0.9361 - val_loss: 0.8505 - val_accuracy: 0.8348\n",
            "Epoch 1328/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1898 - accuracy: 0.9322\n",
            "Epoch 1328: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1892 - accuracy: 0.9327 - val_loss: 0.8412 - val_accuracy: 0.8396\n",
            "Epoch 1329/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2482 - accuracy: 0.9104\n",
            "Epoch 1329: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2473 - accuracy: 0.9109 - val_loss: 0.9116 - val_accuracy: 0.8195\n",
            "Epoch 1330/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1909 - accuracy: 0.9316\n",
            "Epoch 1330: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1909 - accuracy: 0.9316 - val_loss: 0.8396 - val_accuracy: 0.8358\n",
            "Epoch 1331/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1986 - accuracy: 0.9273\n",
            "Epoch 1331: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1999 - accuracy: 0.9265 - val_loss: 0.9348 - val_accuracy: 0.8156\n",
            "Epoch 1332/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2276 - accuracy: 0.9163\n",
            "Epoch 1332: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2236 - accuracy: 0.9177 - val_loss: 0.8835 - val_accuracy: 0.8284\n",
            "Epoch 1333/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2584 - accuracy: 0.9102\n",
            "Epoch 1333: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2567 - accuracy: 0.9104 - val_loss: 0.9307 - val_accuracy: 0.8172\n",
            "Epoch 1334/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2257 - accuracy: 0.9206\n",
            "Epoch 1334: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2277 - accuracy: 0.9194 - val_loss: 0.9918 - val_accuracy: 0.8140\n",
            "Epoch 1335/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2595 - accuracy: 0.9055\n",
            "Epoch 1335: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2607 - accuracy: 0.9045 - val_loss: 0.9569 - val_accuracy: 0.8060\n",
            "Epoch 1336/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2592 - accuracy: 0.9096\n",
            "Epoch 1336: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2557 - accuracy: 0.9116 - val_loss: 0.9292 - val_accuracy: 0.8223\n",
            "Epoch 1337/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2159 - accuracy: 0.9203\n",
            "Epoch 1337: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2189 - accuracy: 0.9194 - val_loss: 1.0499 - val_accuracy: 0.7939\n",
            "Epoch 1338/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2287 - accuracy: 0.9153\n",
            "Epoch 1338: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2294 - accuracy: 0.9153 - val_loss: 0.9147 - val_accuracy: 0.8332\n",
            "Epoch 1339/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2170 - accuracy: 0.9201\n",
            "Epoch 1339: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2150 - accuracy: 0.9211 - val_loss: 0.9807 - val_accuracy: 0.8140\n",
            "Epoch 1340/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2352 - accuracy: 0.9140\n",
            "Epoch 1340: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2336 - accuracy: 0.9145 - val_loss: 1.1463 - val_accuracy: 0.7686\n",
            "Epoch 1341/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1896 - accuracy: 0.9330\n",
            "Epoch 1341: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1915 - accuracy: 0.9321 - val_loss: 0.9737 - val_accuracy: 0.8054\n",
            "Epoch 1342/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2203 - accuracy: 0.9203\n",
            "Epoch 1342: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2212 - accuracy: 0.9201 - val_loss: 0.9436 - val_accuracy: 0.8089\n",
            "Epoch 1343/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2805 - accuracy: 0.8985\n",
            "Epoch 1343: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2879 - accuracy: 0.8971 - val_loss: 1.8867 - val_accuracy: 0.6565\n",
            "Epoch 1344/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.4340 - accuracy: 0.8648\n",
            "Epoch 1344: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.4334 - accuracy: 0.8651 - val_loss: 1.0550 - val_accuracy: 0.7804\n",
            "Epoch 1345/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2059 - accuracy: 0.9244\n",
            "Epoch 1345: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2024 - accuracy: 0.9265 - val_loss: 0.8878 - val_accuracy: 0.8399\n",
            "Epoch 1346/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1666 - accuracy: 0.9414\n",
            "Epoch 1346: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1661 - accuracy: 0.9418 - val_loss: 0.9284 - val_accuracy: 0.8131\n",
            "Epoch 1347/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2134 - accuracy: 0.9252\n",
            "Epoch 1347: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2140 - accuracy: 0.9248 - val_loss: 0.9890 - val_accuracy: 0.8041\n",
            "Epoch 1348/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2059 - accuracy: 0.9214\n",
            "Epoch 1348: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2163 - accuracy: 0.9179 - val_loss: 1.5259 - val_accuracy: 0.7113\n",
            "Epoch 1349/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3562 - accuracy: 0.8851\n",
            "Epoch 1349: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3549 - accuracy: 0.8855 - val_loss: 1.0161 - val_accuracy: 0.7939\n",
            "Epoch 1350/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2013 - accuracy: 0.9267\n",
            "Epoch 1350: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2013 - accuracy: 0.9267 - val_loss: 0.9034 - val_accuracy: 0.8278\n",
            "Epoch 1351/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1762 - accuracy: 0.9368\n",
            "Epoch 1351: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1762 - accuracy: 0.9368 - val_loss: 0.8861 - val_accuracy: 0.8300\n",
            "Epoch 1352/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1886 - accuracy: 0.9332\n",
            "Epoch 1352: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1877 - accuracy: 0.9336 - val_loss: 0.9991 - val_accuracy: 0.8022\n",
            "Epoch 1353/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1665 - accuracy: 0.9419\n",
            "Epoch 1353: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1642 - accuracy: 0.9421 - val_loss: 0.8595 - val_accuracy: 0.8294\n",
            "Epoch 1354/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2541 - accuracy: 0.9099\n",
            "Epoch 1354: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2601 - accuracy: 0.9073 - val_loss: 0.8971 - val_accuracy: 0.8230\n",
            "Epoch 1355/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1927 - accuracy: 0.9292\n",
            "Epoch 1355: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1922 - accuracy: 0.9292 - val_loss: 0.8947 - val_accuracy: 0.8316\n",
            "Epoch 1356/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1899 - accuracy: 0.9319\n",
            "Epoch 1356: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1891 - accuracy: 0.9321 - val_loss: 0.8790 - val_accuracy: 0.8393\n",
            "Epoch 1357/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3083 - accuracy: 0.8964\n",
            "Epoch 1357: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3077 - accuracy: 0.8965 - val_loss: 1.1024 - val_accuracy: 0.7875\n",
            "Epoch 1358/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.4300 - accuracy: 0.8792\n",
            "Epoch 1358: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4318 - accuracy: 0.8788 - val_loss: 2.7136 - val_accuracy: 0.5711\n",
            "Epoch 1359/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.4130 - accuracy: 0.8668\n",
            "Epoch 1359: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4110 - accuracy: 0.8674 - val_loss: 0.8960 - val_accuracy: 0.8275\n",
            "Epoch 1360/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1980 - accuracy: 0.9291\n",
            "Epoch 1360: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1997 - accuracy: 0.9283 - val_loss: 0.9162 - val_accuracy: 0.8268\n",
            "Epoch 1361/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1863 - accuracy: 0.9337\n",
            "Epoch 1361: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1892 - accuracy: 0.9323 - val_loss: 0.9420 - val_accuracy: 0.8175\n",
            "Epoch 1362/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2016 - accuracy: 0.9265\n",
            "Epoch 1362: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2019 - accuracy: 0.9264 - val_loss: 1.0035 - val_accuracy: 0.7987\n",
            "Epoch 1363/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2298 - accuracy: 0.9146\n",
            "Epoch 1363: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2300 - accuracy: 0.9145 - val_loss: 0.9280 - val_accuracy: 0.8134\n",
            "Epoch 1364/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2095 - accuracy: 0.9244\n",
            "Epoch 1364: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2088 - accuracy: 0.9248 - val_loss: 0.9054 - val_accuracy: 0.8323\n",
            "Epoch 1365/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3235 - accuracy: 0.8886\n",
            "Epoch 1365: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3235 - accuracy: 0.8886 - val_loss: 0.9854 - val_accuracy: 0.7971\n",
            "Epoch 1366/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1787 - accuracy: 0.9361\n",
            "Epoch 1366: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1781 - accuracy: 0.9364 - val_loss: 0.8947 - val_accuracy: 0.8342\n",
            "Epoch 1367/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1535 - accuracy: 0.9451\n",
            "Epoch 1367: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1540 - accuracy: 0.9449 - val_loss: 0.8755 - val_accuracy: 0.8319\n",
            "Epoch 1368/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1907 - accuracy: 0.9312\n",
            "Epoch 1368: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1962 - accuracy: 0.9296 - val_loss: 1.3447 - val_accuracy: 0.7343\n",
            "Epoch 1369/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2852 - accuracy: 0.9017\n",
            "Epoch 1369: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2852 - accuracy: 0.9017 - val_loss: 0.9336 - val_accuracy: 0.8233\n",
            "Epoch 1370/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2507 - accuracy: 0.9084\n",
            "Epoch 1370: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2494 - accuracy: 0.9089 - val_loss: 0.8752 - val_accuracy: 0.8287\n",
            "Epoch 1371/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1814 - accuracy: 0.9361\n",
            "Epoch 1371: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1823 - accuracy: 0.9361 - val_loss: 0.8747 - val_accuracy: 0.8367\n",
            "Epoch 1372/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2050 - accuracy: 0.9282\n",
            "Epoch 1372: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2068 - accuracy: 0.9267 - val_loss: 0.9735 - val_accuracy: 0.8003\n",
            "Epoch 1373/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2231 - accuracy: 0.9181\n",
            "Epoch 1373: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2231 - accuracy: 0.9181 - val_loss: 1.0962 - val_accuracy: 0.7670\n",
            "Epoch 1374/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1748 - accuracy: 0.9373\n",
            "Epoch 1374: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1759 - accuracy: 0.9368 - val_loss: 0.8730 - val_accuracy: 0.8300\n",
            "Epoch 1375/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1756 - accuracy: 0.9362\n",
            "Epoch 1375: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1752 - accuracy: 0.9364 - val_loss: 0.8370 - val_accuracy: 0.8435\n",
            "Epoch 1376/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1944 - accuracy: 0.9346\n",
            "Epoch 1376: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1918 - accuracy: 0.9353 - val_loss: 0.8549 - val_accuracy: 0.8364\n",
            "Epoch 1377/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1978 - accuracy: 0.9267\n",
            "Epoch 1377: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1962 - accuracy: 0.9274 - val_loss: 0.8734 - val_accuracy: 0.8345\n",
            "Epoch 1378/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2498 - accuracy: 0.9125\n",
            "Epoch 1378: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2498 - accuracy: 0.9125 - val_loss: 1.0109 - val_accuracy: 0.7939\n",
            "Epoch 1379/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2412 - accuracy: 0.9128\n",
            "Epoch 1379: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2404 - accuracy: 0.9125 - val_loss: 0.9466 - val_accuracy: 0.8230\n",
            "Epoch 1380/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2662 - accuracy: 0.9056\n",
            "Epoch 1380: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2718 - accuracy: 0.9036 - val_loss: 1.2574 - val_accuracy: 0.7391\n",
            "Epoch 1381/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2894 - accuracy: 0.8973\n",
            "Epoch 1381: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2960 - accuracy: 0.8955 - val_loss: 1.0393 - val_accuracy: 0.7999\n",
            "Epoch 1382/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2576 - accuracy: 0.9061\n",
            "Epoch 1382: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2525 - accuracy: 0.9081 - val_loss: 0.9699 - val_accuracy: 0.8134\n",
            "Epoch 1383/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2106 - accuracy: 0.9232\n",
            "Epoch 1383: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2106 - accuracy: 0.9233 - val_loss: 0.9752 - val_accuracy: 0.8118\n",
            "Epoch 1384/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1965 - accuracy: 0.9286\n",
            "Epoch 1384: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1946 - accuracy: 0.9287 - val_loss: 0.8400 - val_accuracy: 0.8358\n",
            "Epoch 1385/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.1658 - accuracy: 0.9391\n",
            "Epoch 1385: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1691 - accuracy: 0.9377 - val_loss: 1.0297 - val_accuracy: 0.7903\n",
            "Epoch 1386/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2520 - accuracy: 0.9115\n",
            "Epoch 1386: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2523 - accuracy: 0.9110 - val_loss: 1.1338 - val_accuracy: 0.7746\n",
            "Epoch 1387/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2524 - accuracy: 0.9091\n",
            "Epoch 1387: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2500 - accuracy: 0.9101 - val_loss: 0.9738 - val_accuracy: 0.8108\n",
            "Epoch 1388/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2267 - accuracy: 0.9172\n",
            "Epoch 1388: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2268 - accuracy: 0.9169 - val_loss: 0.8673 - val_accuracy: 0.8303\n",
            "Epoch 1389/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1884 - accuracy: 0.9317\n",
            "Epoch 1389: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1883 - accuracy: 0.9317 - val_loss: 1.0814 - val_accuracy: 0.7810\n",
            "Epoch 1390/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1894 - accuracy: 0.9317\n",
            "Epoch 1390: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1884 - accuracy: 0.9328 - val_loss: 0.9210 - val_accuracy: 0.8175\n",
            "Epoch 1391/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1765 - accuracy: 0.9377\n",
            "Epoch 1391: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1799 - accuracy: 0.9367 - val_loss: 0.9233 - val_accuracy: 0.8319\n",
            "Epoch 1392/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2990 - accuracy: 0.8958\n",
            "Epoch 1392: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2964 - accuracy: 0.8960 - val_loss: 1.0233 - val_accuracy: 0.8003\n",
            "Epoch 1393/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2050 - accuracy: 0.9249\n",
            "Epoch 1393: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2044 - accuracy: 0.9252 - val_loss: 0.9958 - val_accuracy: 0.8137\n",
            "Epoch 1394/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2074 - accuracy: 0.9239\n",
            "Epoch 1394: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2075 - accuracy: 0.9241 - val_loss: 0.8850 - val_accuracy: 0.8323\n",
            "Epoch 1395/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1726 - accuracy: 0.9387\n",
            "Epoch 1395: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1721 - accuracy: 0.9389 - val_loss: 0.8829 - val_accuracy: 0.8335\n",
            "Epoch 1396/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.4740 - accuracy: 0.8865\n",
            "Epoch 1396: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4920 - accuracy: 0.8795 - val_loss: 1.3978 - val_accuracy: 0.7311\n",
            "Epoch 1397/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2481 - accuracy: 0.9119\n",
            "Epoch 1397: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2479 - accuracy: 0.9120 - val_loss: 0.9931 - val_accuracy: 0.8073\n",
            "Epoch 1398/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1899 - accuracy: 0.9311\n",
            "Epoch 1398: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1913 - accuracy: 0.9309 - val_loss: 0.9743 - val_accuracy: 0.8057\n",
            "Epoch 1399/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1911 - accuracy: 0.9328\n",
            "Epoch 1399: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1925 - accuracy: 0.9321 - val_loss: 0.9505 - val_accuracy: 0.8236\n",
            "Epoch 1400/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1863 - accuracy: 0.9349\n",
            "Epoch 1400: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1863 - accuracy: 0.9349 - val_loss: 0.8525 - val_accuracy: 0.8412\n",
            "Epoch 1401/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1881 - accuracy: 0.9325\n",
            "Epoch 1401: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1899 - accuracy: 0.9320 - val_loss: 0.9240 - val_accuracy: 0.8185\n",
            "Epoch 1402/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1827 - accuracy: 0.9353\n",
            "Epoch 1402: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1820 - accuracy: 0.9357 - val_loss: 0.8910 - val_accuracy: 0.8348\n",
            "Epoch 1403/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1615 - accuracy: 0.9425\n",
            "Epoch 1403: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1611 - accuracy: 0.9426 - val_loss: 0.8618 - val_accuracy: 0.8361\n",
            "Epoch 1404/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1749 - accuracy: 0.9375\n",
            "Epoch 1404: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1747 - accuracy: 0.9371 - val_loss: 0.8258 - val_accuracy: 0.8480\n",
            "Epoch 1405/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2219 - accuracy: 0.9230\n",
            "Epoch 1405: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2441 - accuracy: 0.9189 - val_loss: 2.1109 - val_accuracy: 0.6626\n",
            "Epoch 1406/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.4027 - accuracy: 0.8687\n",
            "Epoch 1406: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4027 - accuracy: 0.8687 - val_loss: 1.1092 - val_accuracy: 0.7804\n",
            "Epoch 1407/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2640 - accuracy: 0.9083\n",
            "Epoch 1407: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2589 - accuracy: 0.9101 - val_loss: 0.9995 - val_accuracy: 0.7916\n",
            "Epoch 1408/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1939 - accuracy: 0.9300\n",
            "Epoch 1408: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1923 - accuracy: 0.9309 - val_loss: 0.9604 - val_accuracy: 0.8118\n",
            "Epoch 1409/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1978 - accuracy: 0.9304\n",
            "Epoch 1409: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1976 - accuracy: 0.9305 - val_loss: 0.8872 - val_accuracy: 0.8310\n",
            "Epoch 1410/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1789 - accuracy: 0.9353\n",
            "Epoch 1410: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1797 - accuracy: 0.9351 - val_loss: 0.9289 - val_accuracy: 0.8185\n",
            "Epoch 1411/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1587 - accuracy: 0.9431\n",
            "Epoch 1411: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1574 - accuracy: 0.9434 - val_loss: 0.8549 - val_accuracy: 0.8419\n",
            "Epoch 1412/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1902 - accuracy: 0.9328\n",
            "Epoch 1412: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1908 - accuracy: 0.9326 - val_loss: 1.0330 - val_accuracy: 0.7977\n",
            "Epoch 1413/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1971 - accuracy: 0.9290\n",
            "Epoch 1413: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1971 - accuracy: 0.9290 - val_loss: 0.9511 - val_accuracy: 0.8086\n",
            "Epoch 1414/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3016 - accuracy: 0.8964\n",
            "Epoch 1414: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3008 - accuracy: 0.8966 - val_loss: 1.0020 - val_accuracy: 0.7990\n",
            "Epoch 1415/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2046 - accuracy: 0.9245\n",
            "Epoch 1415: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2022 - accuracy: 0.9255 - val_loss: 0.9221 - val_accuracy: 0.8223\n",
            "Epoch 1416/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1962 - accuracy: 0.9294\n",
            "Epoch 1416: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2052 - accuracy: 0.9251 - val_loss: 1.3380 - val_accuracy: 0.7468\n",
            "Epoch 1417/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.2899 - accuracy: 0.8954\n",
            "Epoch 1417: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2852 - accuracy: 0.8968 - val_loss: 0.9243 - val_accuracy: 0.8252\n",
            "Epoch 1418/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3918 - accuracy: 0.8806\n",
            "Epoch 1418: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3852 - accuracy: 0.8821 - val_loss: 0.8837 - val_accuracy: 0.8326\n",
            "Epoch 1419/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1796 - accuracy: 0.9349\n",
            "Epoch 1419: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1810 - accuracy: 0.9345 - val_loss: 0.9902 - val_accuracy: 0.8204\n",
            "Epoch 1420/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1881 - accuracy: 0.9314\n",
            "Epoch 1420: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1891 - accuracy: 0.9314 - val_loss: 0.9720 - val_accuracy: 0.8073\n",
            "Epoch 1421/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2105 - accuracy: 0.9212\n",
            "Epoch 1421: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2106 - accuracy: 0.9214 - val_loss: 0.8743 - val_accuracy: 0.8351\n",
            "Epoch 1422/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2074 - accuracy: 0.9227\n",
            "Epoch 1422: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2078 - accuracy: 0.9224 - val_loss: 0.9412 - val_accuracy: 0.8246\n",
            "Epoch 1423/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1662 - accuracy: 0.9403\n",
            "Epoch 1423: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1657 - accuracy: 0.9402 - val_loss: 0.9006 - val_accuracy: 0.8281\n",
            "Epoch 1424/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1860 - accuracy: 0.9343\n",
            "Epoch 1424: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1859 - accuracy: 0.9341 - val_loss: 0.9622 - val_accuracy: 0.8086\n",
            "Epoch 1425/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1843 - accuracy: 0.9326\n",
            "Epoch 1425: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1844 - accuracy: 0.9326 - val_loss: 0.9264 - val_accuracy: 0.8223\n",
            "Epoch 1426/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3787 - accuracy: 0.8760\n",
            "Epoch 1426: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3806 - accuracy: 0.8752 - val_loss: 1.2150 - val_accuracy: 0.7737\n",
            "Epoch 1427/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2893 - accuracy: 0.8957\n",
            "Epoch 1427: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2832 - accuracy: 0.8978 - val_loss: 0.9368 - val_accuracy: 0.8156\n",
            "Epoch 1428/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2046 - accuracy: 0.9248\n",
            "Epoch 1428: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2042 - accuracy: 0.9251 - val_loss: 0.8878 - val_accuracy: 0.8387\n",
            "Epoch 1429/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1944 - accuracy: 0.9305\n",
            "Epoch 1429: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1960 - accuracy: 0.9296 - val_loss: 1.1782 - val_accuracy: 0.7650\n",
            "Epoch 1430/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1640 - accuracy: 0.9420\n",
            "Epoch 1430: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1637 - accuracy: 0.9420 - val_loss: 0.9088 - val_accuracy: 0.8291\n",
            "Epoch 1431/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1680 - accuracy: 0.9415\n",
            "Epoch 1431: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1685 - accuracy: 0.9409 - val_loss: 0.9290 - val_accuracy: 0.8255\n",
            "Epoch 1432/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1952 - accuracy: 0.9291\n",
            "Epoch 1432: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1951 - accuracy: 0.9291 - val_loss: 0.9333 - val_accuracy: 0.8332\n",
            "Epoch 1433/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2725 - accuracy: 0.9025\n",
            "Epoch 1433: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2732 - accuracy: 0.9020 - val_loss: 0.8947 - val_accuracy: 0.8355\n",
            "Epoch 1434/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2004 - accuracy: 0.9253\n",
            "Epoch 1434: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1992 - accuracy: 0.9260 - val_loss: 0.9799 - val_accuracy: 0.8233\n",
            "Epoch 1435/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2659 - accuracy: 0.9061\n",
            "Epoch 1435: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2693 - accuracy: 0.9049 - val_loss: 0.9367 - val_accuracy: 0.8163\n",
            "Epoch 1436/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.4912 - accuracy: 0.8429\n",
            "Epoch 1436: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4905 - accuracy: 0.8429 - val_loss: 1.2328 - val_accuracy: 0.7516\n",
            "Epoch 1437/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2019 - accuracy: 0.9291\n",
            "Epoch 1437: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2007 - accuracy: 0.9299 - val_loss: 0.9114 - val_accuracy: 0.8297\n",
            "Epoch 1438/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1571 - accuracy: 0.9461\n",
            "Epoch 1438: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1571 - accuracy: 0.9461 - val_loss: 0.8613 - val_accuracy: 0.8496\n",
            "Epoch 1439/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1755 - accuracy: 0.9343\n",
            "Epoch 1439: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1767 - accuracy: 0.9341 - val_loss: 0.8527 - val_accuracy: 0.8428\n",
            "Epoch 1440/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1693 - accuracy: 0.9378\n",
            "Epoch 1440: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1693 - accuracy: 0.9378 - val_loss: 0.9224 - val_accuracy: 0.8297\n",
            "Epoch 1441/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2452 - accuracy: 0.9119\n",
            "Epoch 1441: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2426 - accuracy: 0.9122 - val_loss: 0.9120 - val_accuracy: 0.8329\n",
            "Epoch 1442/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1813 - accuracy: 0.9343\n",
            "Epoch 1442: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1817 - accuracy: 0.9336 - val_loss: 0.9973 - val_accuracy: 0.8063\n",
            "Epoch 1443/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1890 - accuracy: 0.9325\n",
            "Epoch 1443: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1897 - accuracy: 0.9316 - val_loss: 0.9322 - val_accuracy: 0.8172\n",
            "Epoch 1444/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1935 - accuracy: 0.9297\n",
            "Epoch 1444: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1935 - accuracy: 0.9297 - val_loss: 1.0194 - val_accuracy: 0.7999\n",
            "Epoch 1445/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2762 - accuracy: 0.9027\n",
            "Epoch 1445: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2680 - accuracy: 0.9058 - val_loss: 0.9403 - val_accuracy: 0.8211\n",
            "Epoch 1446/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2455 - accuracy: 0.9131\n",
            "Epoch 1446: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2599 - accuracy: 0.9091 - val_loss: 1.1597 - val_accuracy: 0.7769\n",
            "Epoch 1447/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.3361 - accuracy: 0.8853\n",
            "Epoch 1447: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3277 - accuracy: 0.8872 - val_loss: 0.9178 - val_accuracy: 0.8220\n",
            "Epoch 1448/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2301 - accuracy: 0.9164\n",
            "Epoch 1448: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2302 - accuracy: 0.9168 - val_loss: 0.9591 - val_accuracy: 0.8124\n",
            "Epoch 1449/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2061 - accuracy: 0.9250\n",
            "Epoch 1449: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2089 - accuracy: 0.9242 - val_loss: 0.9590 - val_accuracy: 0.8105\n",
            "Epoch 1450/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1714 - accuracy: 0.9383\n",
            "Epoch 1450: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1720 - accuracy: 0.9383 - val_loss: 0.8559 - val_accuracy: 0.8428\n",
            "Epoch 1451/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1540 - accuracy: 0.9449\n",
            "Epoch 1451: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1540 - accuracy: 0.9449 - val_loss: 1.0106 - val_accuracy: 0.8134\n",
            "Epoch 1452/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1773 - accuracy: 0.9367\n",
            "Epoch 1452: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1803 - accuracy: 0.9359 - val_loss: 1.0575 - val_accuracy: 0.8003\n",
            "Epoch 1453/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2294 - accuracy: 0.9166\n",
            "Epoch 1453: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2293 - accuracy: 0.9165 - val_loss: 0.9729 - val_accuracy: 0.8201\n",
            "Epoch 1454/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2201 - accuracy: 0.9189\n",
            "Epoch 1454: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2245 - accuracy: 0.9179 - val_loss: 0.8797 - val_accuracy: 0.8316\n",
            "Epoch 1455/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2551 - accuracy: 0.9098\n",
            "Epoch 1455: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2501 - accuracy: 0.9117 - val_loss: 0.8810 - val_accuracy: 0.8387\n",
            "Epoch 1456/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1862 - accuracy: 0.9319\n",
            "Epoch 1456: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1874 - accuracy: 0.9309 - val_loss: 0.8625 - val_accuracy: 0.8374\n",
            "Epoch 1457/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2263 - accuracy: 0.9190\n",
            "Epoch 1457: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2361 - accuracy: 0.9155 - val_loss: 1.1496 - val_accuracy: 0.7673\n",
            "Epoch 1458/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3139 - accuracy: 0.8858\n",
            "Epoch 1458: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3122 - accuracy: 0.8863 - val_loss: 0.9391 - val_accuracy: 0.8246\n",
            "Epoch 1459/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2305 - accuracy: 0.9177\n",
            "Epoch 1459: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2264 - accuracy: 0.9192 - val_loss: 0.9470 - val_accuracy: 0.8204\n",
            "Epoch 1460/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1620 - accuracy: 0.9435\n",
            "Epoch 1460: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1615 - accuracy: 0.9436 - val_loss: 0.8866 - val_accuracy: 0.8374\n",
            "Epoch 1461/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1858 - accuracy: 0.9316\n",
            "Epoch 1461: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1834 - accuracy: 0.9326 - val_loss: 0.9463 - val_accuracy: 0.8284\n",
            "Epoch 1462/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2145 - accuracy: 0.9205\n",
            "Epoch 1462: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2149 - accuracy: 0.9207 - val_loss: 0.9027 - val_accuracy: 0.8345\n",
            "Epoch 1463/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1699 - accuracy: 0.9391\n",
            "Epoch 1463: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1692 - accuracy: 0.9397 - val_loss: 0.8611 - val_accuracy: 0.8412\n",
            "Epoch 1464/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1547 - accuracy: 0.9455\n",
            "Epoch 1464: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1552 - accuracy: 0.9455 - val_loss: 0.8714 - val_accuracy: 0.8345\n",
            "Epoch 1465/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1911 - accuracy: 0.9317\n",
            "Epoch 1465: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1927 - accuracy: 0.9315 - val_loss: 0.9338 - val_accuracy: 0.8182\n",
            "Epoch 1466/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.3205 - accuracy: 0.8879\n",
            "Epoch 1466: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3162 - accuracy: 0.8898 - val_loss: 1.0724 - val_accuracy: 0.7967\n",
            "Epoch 1467/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1994 - accuracy: 0.9264\n",
            "Epoch 1467: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1994 - accuracy: 0.9264 - val_loss: 0.9327 - val_accuracy: 0.8259\n",
            "Epoch 1468/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1899 - accuracy: 0.9303\n",
            "Epoch 1468: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1921 - accuracy: 0.9295 - val_loss: 0.9015 - val_accuracy: 0.8310\n",
            "Epoch 1469/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2373 - accuracy: 0.9149\n",
            "Epoch 1469: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2358 - accuracy: 0.9153 - val_loss: 1.0461 - val_accuracy: 0.7955\n",
            "Epoch 1470/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2914 - accuracy: 0.9034\n",
            "Epoch 1470: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2913 - accuracy: 0.9033 - val_loss: 0.9431 - val_accuracy: 0.8211\n",
            "Epoch 1471/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2534 - accuracy: 0.9068\n",
            "Epoch 1471: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2586 - accuracy: 0.9052 - val_loss: 1.2342 - val_accuracy: 0.7705\n",
            "Epoch 1472/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.2064 - accuracy: 0.9256\n",
            "Epoch 1472: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2046 - accuracy: 0.9263 - val_loss: 0.9025 - val_accuracy: 0.8259\n",
            "Epoch 1473/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1963 - accuracy: 0.9301\n",
            "Epoch 1473: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1963 - accuracy: 0.9301 - val_loss: 0.8815 - val_accuracy: 0.8355\n",
            "Epoch 1474/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1900 - accuracy: 0.9319\n",
            "Epoch 1474: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1932 - accuracy: 0.9305 - val_loss: 0.9867 - val_accuracy: 0.8108\n",
            "Epoch 1475/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2244 - accuracy: 0.9180\n",
            "Epoch 1475: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2236 - accuracy: 0.9181 - val_loss: 1.0063 - val_accuracy: 0.8108\n",
            "Epoch 1476/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1667 - accuracy: 0.9393\n",
            "Epoch 1476: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1662 - accuracy: 0.9396 - val_loss: 0.9533 - val_accuracy: 0.8207\n",
            "Epoch 1477/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2775 - accuracy: 0.9001\n",
            "Epoch 1477: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2773 - accuracy: 0.9000 - val_loss: 1.3022 - val_accuracy: 0.7497\n",
            "Epoch 1478/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.3305 - accuracy: 0.8854\n",
            "Epoch 1478: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3227 - accuracy: 0.8876 - val_loss: 0.8719 - val_accuracy: 0.8374\n",
            "Epoch 1479/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2375 - accuracy: 0.9173\n",
            "Epoch 1479: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2535 - accuracy: 0.9135 - val_loss: 1.1147 - val_accuracy: 0.7916\n",
            "Epoch 1480/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1913 - accuracy: 0.9287\n",
            "Epoch 1480: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1883 - accuracy: 0.9301 - val_loss: 0.8599 - val_accuracy: 0.8483\n",
            "Epoch 1481/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1500 - accuracy: 0.9477\n",
            "Epoch 1481: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1496 - accuracy: 0.9480 - val_loss: 0.9249 - val_accuracy: 0.8355\n",
            "Epoch 1482/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1846 - accuracy: 0.9313\n",
            "Epoch 1482: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1847 - accuracy: 0.9314 - val_loss: 0.9255 - val_accuracy: 0.8342\n",
            "Epoch 1483/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2055 - accuracy: 0.9254\n",
            "Epoch 1483: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2055 - accuracy: 0.9254 - val_loss: 1.0088 - val_accuracy: 0.8153\n",
            "Epoch 1484/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2013 - accuracy: 0.9280\n",
            "Epoch 1484: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2023 - accuracy: 0.9276 - val_loss: 1.0463 - val_accuracy: 0.7983\n",
            "Epoch 1485/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1736 - accuracy: 0.9363\n",
            "Epoch 1485: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1733 - accuracy: 0.9369 - val_loss: 0.8980 - val_accuracy: 0.8358\n",
            "Epoch 1486/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2467 - accuracy: 0.9160\n",
            "Epoch 1486: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3165 - accuracy: 0.9052 - val_loss: 1.1388 - val_accuracy: 0.7839\n",
            "Epoch 1487/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3379 - accuracy: 0.8902\n",
            "Epoch 1487: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3367 - accuracy: 0.8904 - val_loss: 0.9388 - val_accuracy: 0.8262\n",
            "Epoch 1488/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1905 - accuracy: 0.9313\n",
            "Epoch 1488: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1916 - accuracy: 0.9303 - val_loss: 0.9115 - val_accuracy: 0.8406\n",
            "Epoch 1489/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1811 - accuracy: 0.9332\n",
            "Epoch 1489: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1792 - accuracy: 0.9337 - val_loss: 0.8427 - val_accuracy: 0.8441\n",
            "Epoch 1490/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1862 - accuracy: 0.9342\n",
            "Epoch 1490: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1877 - accuracy: 0.9336 - val_loss: 0.9441 - val_accuracy: 0.8201\n",
            "Epoch 1491/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2030 - accuracy: 0.9269\n",
            "Epoch 1491: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2017 - accuracy: 0.9275 - val_loss: 0.9007 - val_accuracy: 0.8396\n",
            "Epoch 1492/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1906 - accuracy: 0.9310\n",
            "Epoch 1492: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1908 - accuracy: 0.9309 - val_loss: 0.8675 - val_accuracy: 0.8387\n",
            "Epoch 1493/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1918 - accuracy: 0.9295\n",
            "Epoch 1493: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1919 - accuracy: 0.9296 - val_loss: 0.8934 - val_accuracy: 0.8316\n",
            "Epoch 1494/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2003 - accuracy: 0.9268\n",
            "Epoch 1494: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2014 - accuracy: 0.9266 - val_loss: 0.9592 - val_accuracy: 0.8182\n",
            "Epoch 1495/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1786 - accuracy: 0.9343\n",
            "Epoch 1495: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1786 - accuracy: 0.9343 - val_loss: 1.0182 - val_accuracy: 0.8137\n",
            "Epoch 1496/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1674 - accuracy: 0.9424\n",
            "Epoch 1496: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1681 - accuracy: 0.9421 - val_loss: 0.9154 - val_accuracy: 0.8358\n",
            "Epoch 1497/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2746 - accuracy: 0.9003\n",
            "Epoch 1497: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2715 - accuracy: 0.9011 - val_loss: 0.9272 - val_accuracy: 0.8191\n",
            "Epoch 1498/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1926 - accuracy: 0.9290\n",
            "Epoch 1498: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1930 - accuracy: 0.9288 - val_loss: 0.9957 - val_accuracy: 0.8127\n",
            "Epoch 1499/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1881 - accuracy: 0.9295\n",
            "Epoch 1499: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1923 - accuracy: 0.9281 - val_loss: 1.0865 - val_accuracy: 0.7923\n",
            "Epoch 1500/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.5138 - accuracy: 0.8548\n",
            "Epoch 1500: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.4991 - accuracy: 0.8578 - val_loss: 0.9585 - val_accuracy: 0.8137\n",
            "Epoch 1501/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3026 - accuracy: 0.8972\n",
            "Epoch 1501: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3025 - accuracy: 0.8971 - val_loss: 1.0229 - val_accuracy: 0.8073\n",
            "Epoch 1502/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2214 - accuracy: 0.9194\n",
            "Epoch 1502: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2199 - accuracy: 0.9197 - val_loss: 0.8927 - val_accuracy: 0.8454\n",
            "Epoch 1503/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1592 - accuracy: 0.9434\n",
            "Epoch 1503: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1592 - accuracy: 0.9434 - val_loss: 0.9951 - val_accuracy: 0.8137\n",
            "Epoch 1504/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1791 - accuracy: 0.9357\n",
            "Epoch 1504: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1791 - accuracy: 0.9357 - val_loss: 1.1033 - val_accuracy: 0.7926\n",
            "Epoch 1505/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2003 - accuracy: 0.9260\n",
            "Epoch 1505: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2038 - accuracy: 0.9245 - val_loss: 1.1794 - val_accuracy: 0.7939\n",
            "Epoch 1506/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2505 - accuracy: 0.9103\n",
            "Epoch 1506: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2496 - accuracy: 0.9104 - val_loss: 1.0005 - val_accuracy: 0.8083\n",
            "Epoch 1507/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2089 - accuracy: 0.9248\n",
            "Epoch 1507: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2084 - accuracy: 0.9250 - val_loss: 0.9352 - val_accuracy: 0.8348\n",
            "Epoch 1508/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1638 - accuracy: 0.9420\n",
            "Epoch 1508: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1638 - accuracy: 0.9421 - val_loss: 0.9801 - val_accuracy: 0.8182\n",
            "Epoch 1509/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1693 - accuracy: 0.9368\n",
            "Epoch 1509: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1685 - accuracy: 0.9372 - val_loss: 0.9333 - val_accuracy: 0.8316\n",
            "Epoch 1510/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1819 - accuracy: 0.9343\n",
            "Epoch 1510: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1827 - accuracy: 0.9338 - val_loss: 1.0040 - val_accuracy: 0.8019\n",
            "Epoch 1511/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1823 - accuracy: 0.9320\n",
            "Epoch 1511: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1800 - accuracy: 0.9332 - val_loss: 0.9352 - val_accuracy: 0.8323\n",
            "Epoch 1512/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1679 - accuracy: 0.9393\n",
            "Epoch 1512: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1679 - accuracy: 0.9393 - val_loss: 0.9374 - val_accuracy: 0.8259\n",
            "Epoch 1513/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1646 - accuracy: 0.9419\n",
            "Epoch 1513: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1643 - accuracy: 0.9418 - val_loss: 0.8970 - val_accuracy: 0.8355\n",
            "Epoch 1514/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2453 - accuracy: 0.9142\n",
            "Epoch 1514: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2480 - accuracy: 0.9135 - val_loss: 1.0778 - val_accuracy: 0.7891\n",
            "Epoch 1515/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2757 - accuracy: 0.8999\n",
            "Epoch 1515: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2718 - accuracy: 0.9014 - val_loss: 0.9667 - val_accuracy: 0.8220\n",
            "Epoch 1516/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1624 - accuracy: 0.9417\n",
            "Epoch 1516: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1620 - accuracy: 0.9422 - val_loss: 0.9295 - val_accuracy: 0.8271\n",
            "Epoch 1517/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2147 - accuracy: 0.9205\n",
            "Epoch 1517: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2139 - accuracy: 0.9206 - val_loss: 0.9911 - val_accuracy: 0.8153\n",
            "Epoch 1518/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1915 - accuracy: 0.9287\n",
            "Epoch 1518: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1915 - accuracy: 0.9287 - val_loss: 0.8932 - val_accuracy: 0.8262\n",
            "Epoch 1519/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1867 - accuracy: 0.9306\n",
            "Epoch 1519: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1865 - accuracy: 0.9306 - val_loss: 1.0616 - val_accuracy: 0.8015\n",
            "Epoch 1520/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1933 - accuracy: 0.9261\n",
            "Epoch 1520: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1938 - accuracy: 0.9260 - val_loss: 1.0064 - val_accuracy: 0.8015\n",
            "Epoch 1521/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2090 - accuracy: 0.9226\n",
            "Epoch 1521: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2115 - accuracy: 0.9221 - val_loss: 0.9402 - val_accuracy: 0.8246\n",
            "Epoch 1522/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1991 - accuracy: 0.9263\n",
            "Epoch 1522: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1997 - accuracy: 0.9261 - val_loss: 0.9312 - val_accuracy: 0.8329\n",
            "Epoch 1523/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2416 - accuracy: 0.9129\n",
            "Epoch 1523: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2404 - accuracy: 0.9129 - val_loss: 1.1259 - val_accuracy: 0.7868\n",
            "Epoch 1524/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2202 - accuracy: 0.9195\n",
            "Epoch 1524: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2187 - accuracy: 0.9206 - val_loss: 0.9388 - val_accuracy: 0.8326\n",
            "Epoch 1525/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1800 - accuracy: 0.9349\n",
            "Epoch 1525: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1809 - accuracy: 0.9344 - val_loss: 0.9172 - val_accuracy: 0.8313\n",
            "Epoch 1526/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.4615 - accuracy: 0.8602\n",
            "Epoch 1526: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4554 - accuracy: 0.8617 - val_loss: 1.1229 - val_accuracy: 0.7903\n",
            "Epoch 1527/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2036 - accuracy: 0.9266\n",
            "Epoch 1527: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2034 - accuracy: 0.9267 - val_loss: 0.9208 - val_accuracy: 0.8329\n",
            "Epoch 1528/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.1566 - accuracy: 0.9436\n",
            "Epoch 1528: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1571 - accuracy: 0.9434 - val_loss: 0.8721 - val_accuracy: 0.8396\n",
            "Epoch 1529/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1746 - accuracy: 0.9356\n",
            "Epoch 1529: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1792 - accuracy: 0.9339 - val_loss: 1.1127 - val_accuracy: 0.7843\n",
            "Epoch 1530/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2021 - accuracy: 0.9248\n",
            "Epoch 1530: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2031 - accuracy: 0.9249 - val_loss: 0.9167 - val_accuracy: 0.8399\n",
            "Epoch 1531/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.1591 - accuracy: 0.9429\n",
            "Epoch 1531: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1580 - accuracy: 0.9431 - val_loss: 0.9138 - val_accuracy: 0.8291\n",
            "Epoch 1532/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1721 - accuracy: 0.9385\n",
            "Epoch 1532: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1716 - accuracy: 0.9385 - val_loss: 0.8911 - val_accuracy: 0.8406\n",
            "Epoch 1533/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2316 - accuracy: 0.9179\n",
            "Epoch 1533: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2291 - accuracy: 0.9191 - val_loss: 1.0982 - val_accuracy: 0.7865\n",
            "Epoch 1534/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2757 - accuracy: 0.9088\n",
            "Epoch 1534: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2781 - accuracy: 0.9076 - val_loss: 1.1973 - val_accuracy: 0.7868\n",
            "Epoch 1535/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.4318 - accuracy: 0.8667\n",
            "Epoch 1535: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4283 - accuracy: 0.8664 - val_loss: 1.0259 - val_accuracy: 0.8156\n",
            "Epoch 1536/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1874 - accuracy: 0.9295\n",
            "Epoch 1536: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1868 - accuracy: 0.9299 - val_loss: 0.9285 - val_accuracy: 0.8326\n",
            "Epoch 1537/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1469 - accuracy: 0.9499\n",
            "Epoch 1537: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1474 - accuracy: 0.9493 - val_loss: 0.8956 - val_accuracy: 0.8380\n",
            "Epoch 1538/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1605 - accuracy: 0.9425\n",
            "Epoch 1538: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1612 - accuracy: 0.9427 - val_loss: 0.9365 - val_accuracy: 0.8275\n",
            "Epoch 1539/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1927 - accuracy: 0.9290\n",
            "Epoch 1539: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1928 - accuracy: 0.9289 - val_loss: 1.0276 - val_accuracy: 0.8102\n",
            "Epoch 1540/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1945 - accuracy: 0.9307\n",
            "Epoch 1540: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1937 - accuracy: 0.9309 - val_loss: 0.9318 - val_accuracy: 0.8281\n",
            "Epoch 1541/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1739 - accuracy: 0.9387\n",
            "Epoch 1541: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1739 - accuracy: 0.9387 - val_loss: 0.9615 - val_accuracy: 0.8284\n",
            "Epoch 1542/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1772 - accuracy: 0.9349\n",
            "Epoch 1542: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1769 - accuracy: 0.9349 - val_loss: 0.8908 - val_accuracy: 0.8387\n",
            "Epoch 1543/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2127 - accuracy: 0.9237\n",
            "Epoch 1543: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2148 - accuracy: 0.9237 - val_loss: 1.0859 - val_accuracy: 0.7897\n",
            "Epoch 1544/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1681 - accuracy: 0.9405\n",
            "Epoch 1544: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1657 - accuracy: 0.9409 - val_loss: 0.9044 - val_accuracy: 0.8438\n",
            "Epoch 1545/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1586 - accuracy: 0.9449\n",
            "Epoch 1545: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1586 - accuracy: 0.9449 - val_loss: 0.9868 - val_accuracy: 0.8089\n",
            "Epoch 1546/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2946 - accuracy: 0.8965\n",
            "Epoch 1546: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2974 - accuracy: 0.8956 - val_loss: 1.1036 - val_accuracy: 0.7935\n",
            "Epoch 1547/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2655 - accuracy: 0.9039\n",
            "Epoch 1547: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2663 - accuracy: 0.9034 - val_loss: 0.9266 - val_accuracy: 0.8383\n",
            "Epoch 1548/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1752 - accuracy: 0.9375\n",
            "Epoch 1548: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1887 - accuracy: 0.9329 - val_loss: 0.9331 - val_accuracy: 0.8255\n",
            "Epoch 1549/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.5031 - accuracy: 0.8550\n",
            "Epoch 1549: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4962 - accuracy: 0.8564 - val_loss: 1.1498 - val_accuracy: 0.7820\n",
            "Epoch 1550/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2021 - accuracy: 0.9267\n",
            "Epoch 1550: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2021 - accuracy: 0.9267 - val_loss: 0.9342 - val_accuracy: 0.8259\n",
            "Epoch 1551/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1666 - accuracy: 0.9388\n",
            "Epoch 1551: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1669 - accuracy: 0.9389 - val_loss: 0.9184 - val_accuracy: 0.8303\n",
            "Epoch 1552/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1707 - accuracy: 0.9388\n",
            "Epoch 1552: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1707 - accuracy: 0.9388 - val_loss: 0.9185 - val_accuracy: 0.8380\n",
            "Epoch 1553/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1543 - accuracy: 0.9444\n",
            "Epoch 1553: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1535 - accuracy: 0.9452 - val_loss: 0.9702 - val_accuracy: 0.8166\n",
            "Epoch 1554/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2001 - accuracy: 0.9260\n",
            "Epoch 1554: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2001 - accuracy: 0.9260 - val_loss: 0.9954 - val_accuracy: 0.8111\n",
            "Epoch 1555/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1997 - accuracy: 0.9257\n",
            "Epoch 1555: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2004 - accuracy: 0.9257 - val_loss: 1.0873 - val_accuracy: 0.7964\n",
            "Epoch 1556/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1695 - accuracy: 0.9386\n",
            "Epoch 1556: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1707 - accuracy: 0.9381 - val_loss: 0.8808 - val_accuracy: 0.8383\n",
            "Epoch 1557/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1909 - accuracy: 0.9296\n",
            "Epoch 1557: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1931 - accuracy: 0.9293 - val_loss: 1.0602 - val_accuracy: 0.7983\n",
            "Epoch 1558/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1779 - accuracy: 0.9340\n",
            "Epoch 1558: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1764 - accuracy: 0.9345 - val_loss: 1.0571 - val_accuracy: 0.8006\n",
            "Epoch 1559/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3288 - accuracy: 0.9018\n",
            "Epoch 1559: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3345 - accuracy: 0.9000 - val_loss: 1.3266 - val_accuracy: 0.7458\n",
            "Epoch 1560/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2232 - accuracy: 0.9199\n",
            "Epoch 1560: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2229 - accuracy: 0.9201 - val_loss: 0.9237 - val_accuracy: 0.8374\n",
            "Epoch 1561/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1990 - accuracy: 0.9265\n",
            "Epoch 1561: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1990 - accuracy: 0.9265 - val_loss: 1.2884 - val_accuracy: 0.7510\n",
            "Epoch 1562/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2323 - accuracy: 0.9155\n",
            "Epoch 1562: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2319 - accuracy: 0.9156 - val_loss: 0.9489 - val_accuracy: 0.8201\n",
            "Epoch 1563/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.2084 - accuracy: 0.9252\n",
            "Epoch 1563: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2023 - accuracy: 0.9275 - val_loss: 0.9689 - val_accuracy: 0.8220\n",
            "Epoch 1564/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1522 - accuracy: 0.9455\n",
            "Epoch 1564: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1524 - accuracy: 0.9452 - val_loss: 0.9098 - val_accuracy: 0.8345\n",
            "Epoch 1565/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1382 - accuracy: 0.9497\n",
            "Epoch 1565: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1382 - accuracy: 0.9497 - val_loss: 0.9141 - val_accuracy: 0.8348\n",
            "Epoch 1566/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1844 - accuracy: 0.9337\n",
            "Epoch 1566: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1885 - accuracy: 0.9314 - val_loss: 0.9954 - val_accuracy: 0.8137\n",
            "Epoch 1567/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1877 - accuracy: 0.9303\n",
            "Epoch 1567: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1870 - accuracy: 0.9303 - val_loss: 0.8962 - val_accuracy: 0.8374\n",
            "Epoch 1568/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1931 - accuracy: 0.9290\n",
            "Epoch 1568: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1926 - accuracy: 0.9293 - val_loss: 0.8364 - val_accuracy: 0.8470\n",
            "Epoch 1569/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1773 - accuracy: 0.9349\n",
            "Epoch 1569: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1785 - accuracy: 0.9345 - val_loss: 0.9627 - val_accuracy: 0.8217\n",
            "Epoch 1570/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1711 - accuracy: 0.9399\n",
            "Epoch 1570: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1708 - accuracy: 0.9397 - val_loss: 0.9561 - val_accuracy: 0.8294\n",
            "Epoch 1571/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1565 - accuracy: 0.9423\n",
            "Epoch 1571: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1577 - accuracy: 0.9417 - val_loss: 1.0811 - val_accuracy: 0.7983\n",
            "Epoch 1572/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2667 - accuracy: 0.9033\n",
            "Epoch 1572: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2758 - accuracy: 0.9006 - val_loss: 1.1741 - val_accuracy: 0.7903\n",
            "Epoch 1573/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2981 - accuracy: 0.8950\n",
            "Epoch 1573: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2953 - accuracy: 0.8956 - val_loss: 1.0292 - val_accuracy: 0.8073\n",
            "Epoch 1574/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2044 - accuracy: 0.9269\n",
            "Epoch 1574: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2037 - accuracy: 0.9271 - val_loss: 1.0054 - val_accuracy: 0.8220\n",
            "Epoch 1575/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1578 - accuracy: 0.9415\n",
            "Epoch 1575: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1575 - accuracy: 0.9417 - val_loss: 0.9691 - val_accuracy: 0.8201\n",
            "Epoch 1576/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.7856 - accuracy: 0.8250\n",
            "Epoch 1576: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.7824 - accuracy: 0.8254 - val_loss: 1.2926 - val_accuracy: 0.7561\n",
            "Epoch 1577/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1959 - accuracy: 0.9297\n",
            "Epoch 1577: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1959 - accuracy: 0.9297 - val_loss: 0.9500 - val_accuracy: 0.8387\n",
            "Epoch 1578/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1622 - accuracy: 0.9416\n",
            "Epoch 1578: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1611 - accuracy: 0.9421 - val_loss: 0.9372 - val_accuracy: 0.8409\n",
            "Epoch 1579/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1581 - accuracy: 0.9411\n",
            "Epoch 1579: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1582 - accuracy: 0.9409 - val_loss: 0.9000 - val_accuracy: 0.8358\n",
            "Epoch 1580/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1487 - accuracy: 0.9480\n",
            "Epoch 1580: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1498 - accuracy: 0.9473 - val_loss: 0.9682 - val_accuracy: 0.8182\n",
            "Epoch 1581/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1449 - accuracy: 0.9489\n",
            "Epoch 1581: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1468 - accuracy: 0.9477 - val_loss: 0.9567 - val_accuracy: 0.8297\n",
            "Epoch 1582/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1489 - accuracy: 0.9461\n",
            "Epoch 1582: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1489 - accuracy: 0.9465 - val_loss: 0.8775 - val_accuracy: 0.8476\n",
            "Epoch 1583/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1447 - accuracy: 0.9481\n",
            "Epoch 1583: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1444 - accuracy: 0.9481 - val_loss: 1.0460 - val_accuracy: 0.8076\n",
            "Epoch 1584/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1770 - accuracy: 0.9356\n",
            "Epoch 1584: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1770 - accuracy: 0.9356 - val_loss: 0.9502 - val_accuracy: 0.8252\n",
            "Epoch 1585/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2850 - accuracy: 0.9028\n",
            "Epoch 1585: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2809 - accuracy: 0.9036 - val_loss: 0.9612 - val_accuracy: 0.8211\n",
            "Epoch 1586/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1666 - accuracy: 0.9419\n",
            "Epoch 1586: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1666 - accuracy: 0.9419 - val_loss: 0.9296 - val_accuracy: 0.8332\n",
            "Epoch 1587/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1608 - accuracy: 0.9405\n",
            "Epoch 1587: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1588 - accuracy: 0.9415 - val_loss: 0.8990 - val_accuracy: 0.8406\n",
            "Epoch 1588/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1636 - accuracy: 0.9417\n",
            "Epoch 1588: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1636 - accuracy: 0.9417 - val_loss: 0.9212 - val_accuracy: 0.8358\n",
            "Epoch 1589/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1615 - accuracy: 0.9425\n",
            "Epoch 1589: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1616 - accuracy: 0.9425 - val_loss: 0.9028 - val_accuracy: 0.8367\n",
            "Epoch 1590/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1742 - accuracy: 0.9363\n",
            "Epoch 1590: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1751 - accuracy: 0.9357 - val_loss: 1.0398 - val_accuracy: 0.8063\n",
            "Epoch 1591/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2047 - accuracy: 0.9255\n",
            "Epoch 1591: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2011 - accuracy: 0.9266 - val_loss: 0.9218 - val_accuracy: 0.8361\n",
            "Epoch 1592/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3226 - accuracy: 0.8878\n",
            "Epoch 1592: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3226 - accuracy: 0.8878 - val_loss: 1.1931 - val_accuracy: 0.7641\n",
            "Epoch 1593/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1937 - accuracy: 0.9296\n",
            "Epoch 1593: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2037 - accuracy: 0.9260 - val_loss: 1.2599 - val_accuracy: 0.7590\n",
            "Epoch 1594/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2197 - accuracy: 0.9217\n",
            "Epoch 1594: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2188 - accuracy: 0.9221 - val_loss: 1.0896 - val_accuracy: 0.7932\n",
            "Epoch 1595/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2597 - accuracy: 0.9089\n",
            "Epoch 1595: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.2550 - accuracy: 0.9106 - val_loss: 0.9321 - val_accuracy: 0.8243\n",
            "Epoch 1596/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1636 - accuracy: 0.9415\n",
            "Epoch 1596: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1627 - accuracy: 0.9421 - val_loss: 0.8957 - val_accuracy: 0.8422\n",
            "Epoch 1597/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1645 - accuracy: 0.9403\n",
            "Epoch 1597: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1662 - accuracy: 0.9395 - val_loss: 0.9970 - val_accuracy: 0.8124\n",
            "Epoch 1598/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.9919 - accuracy: 0.8081\n",
            "Epoch 1598: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.9725 - accuracy: 0.8107 - val_loss: 1.0098 - val_accuracy: 0.8249\n",
            "Epoch 1599/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.1975 - accuracy: 0.9294\n",
            "Epoch 1599: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1941 - accuracy: 0.9304 - val_loss: 0.9015 - val_accuracy: 0.8406\n",
            "Epoch 1600/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1780 - accuracy: 0.9332\n",
            "Epoch 1600: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1811 - accuracy: 0.9317 - val_loss: 0.9413 - val_accuracy: 0.8281\n",
            "Epoch 1601/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1731 - accuracy: 0.9358\n",
            "Epoch 1601: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1709 - accuracy: 0.9369 - val_loss: 0.9198 - val_accuracy: 0.8364\n",
            "Epoch 1602/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1295 - accuracy: 0.9553\n",
            "Epoch 1602: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1295 - accuracy: 0.9553 - val_loss: 1.0140 - val_accuracy: 0.8067\n",
            "Epoch 1603/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1440 - accuracy: 0.9482\n",
            "Epoch 1603: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1439 - accuracy: 0.9484 - val_loss: 1.0107 - val_accuracy: 0.8172\n",
            "Epoch 1604/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.1555 - accuracy: 0.9436\n",
            "Epoch 1604: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1553 - accuracy: 0.9437 - val_loss: 0.9128 - val_accuracy: 0.8380\n",
            "Epoch 1605/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2565 - accuracy: 0.9111\n",
            "Epoch 1605: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2510 - accuracy: 0.9128 - val_loss: 0.9931 - val_accuracy: 0.8220\n",
            "Epoch 1606/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1628 - accuracy: 0.9412\n",
            "Epoch 1606: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1648 - accuracy: 0.9410 - val_loss: 0.9367 - val_accuracy: 0.8294\n",
            "Epoch 1607/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1563 - accuracy: 0.9430\n",
            "Epoch 1607: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1571 - accuracy: 0.9427 - val_loss: 0.9305 - val_accuracy: 0.8284\n",
            "Epoch 1608/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1493 - accuracy: 0.9444\n",
            "Epoch 1608: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1495 - accuracy: 0.9445 - val_loss: 1.0475 - val_accuracy: 0.8105\n",
            "Epoch 1609/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1813 - accuracy: 0.9361\n",
            "Epoch 1609: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1813 - accuracy: 0.9361 - val_loss: 1.2067 - val_accuracy: 0.7830\n",
            "Epoch 1610/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1943 - accuracy: 0.9284\n",
            "Epoch 1610: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1917 - accuracy: 0.9293 - val_loss: 0.9127 - val_accuracy: 0.8329\n",
            "Epoch 1611/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1817 - accuracy: 0.9346\n",
            "Epoch 1611: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1831 - accuracy: 0.9340 - val_loss: 1.1378 - val_accuracy: 0.7804\n",
            "Epoch 1612/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2304 - accuracy: 0.9161\n",
            "Epoch 1612: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2285 - accuracy: 0.9168 - val_loss: 0.9604 - val_accuracy: 0.8329\n",
            "Epoch 1613/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1662 - accuracy: 0.9383\n",
            "Epoch 1613: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1660 - accuracy: 0.9383 - val_loss: 0.8958 - val_accuracy: 0.8431\n",
            "Epoch 1614/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1426 - accuracy: 0.9485\n",
            "Epoch 1614: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1427 - accuracy: 0.9486 - val_loss: 0.9314 - val_accuracy: 0.8345\n",
            "Epoch 1615/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1769 - accuracy: 0.9359\n",
            "Epoch 1615: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1834 - accuracy: 0.9339 - val_loss: 1.2898 - val_accuracy: 0.7526\n",
            "Epoch 1616/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3701 - accuracy: 0.8779\n",
            "Epoch 1616: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.3701 - accuracy: 0.8777 - val_loss: 1.0501 - val_accuracy: 0.7929\n",
            "Epoch 1617/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.4434 - accuracy: 0.8618\n",
            "Epoch 1617: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.4365 - accuracy: 0.8635 - val_loss: 1.0389 - val_accuracy: 0.8131\n",
            "Epoch 1618/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1999 - accuracy: 0.9249\n",
            "Epoch 1618: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2014 - accuracy: 0.9245 - val_loss: 0.9903 - val_accuracy: 0.8172\n",
            "Epoch 1619/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1643 - accuracy: 0.9412\n",
            "Epoch 1619: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1638 - accuracy: 0.9417 - val_loss: 0.9361 - val_accuracy: 0.8348\n",
            "Epoch 1620/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1541 - accuracy: 0.9467\n",
            "Epoch 1620: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1534 - accuracy: 0.9470 - val_loss: 0.8922 - val_accuracy: 0.8355\n",
            "Epoch 1621/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2055 - accuracy: 0.9240\n",
            "Epoch 1621: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2050 - accuracy: 0.9243 - val_loss: 0.9684 - val_accuracy: 0.8252\n",
            "Epoch 1622/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1537 - accuracy: 0.9447\n",
            "Epoch 1622: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1541 - accuracy: 0.9445 - val_loss: 0.9018 - val_accuracy: 0.8377\n",
            "Epoch 1623/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1449 - accuracy: 0.9503\n",
            "Epoch 1623: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1457 - accuracy: 0.9498 - val_loss: 0.9306 - val_accuracy: 0.8294\n",
            "Epoch 1624/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2111 - accuracy: 0.9221\n",
            "Epoch 1624: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2111 - accuracy: 0.9221 - val_loss: 0.9069 - val_accuracy: 0.8396\n",
            "Epoch 1625/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1786 - accuracy: 0.9340\n",
            "Epoch 1625: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1794 - accuracy: 0.9339 - val_loss: 1.0097 - val_accuracy: 0.8163\n",
            "Epoch 1626/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1641 - accuracy: 0.9391\n",
            "Epoch 1626: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1623 - accuracy: 0.9397 - val_loss: 0.9815 - val_accuracy: 0.8207\n",
            "Epoch 1627/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1594 - accuracy: 0.9405\n",
            "Epoch 1627: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1595 - accuracy: 0.9402 - val_loss: 0.9555 - val_accuracy: 0.8239\n",
            "Epoch 1628/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2379 - accuracy: 0.9129\n",
            "Epoch 1628: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2379 - accuracy: 0.9129 - val_loss: 1.0872 - val_accuracy: 0.8009\n",
            "Epoch 1629/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.3360 - accuracy: 0.8856\n",
            "Epoch 1629: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3331 - accuracy: 0.8866 - val_loss: 1.0304 - val_accuracy: 0.8140\n",
            "Epoch 1630/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2285 - accuracy: 0.9157\n",
            "Epoch 1630: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2285 - accuracy: 0.9157 - val_loss: 1.4372 - val_accuracy: 0.7295\n",
            "Epoch 1631/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1999 - accuracy: 0.9269\n",
            "Epoch 1631: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1999 - accuracy: 0.9269 - val_loss: 0.9508 - val_accuracy: 0.8259\n",
            "Epoch 1632/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1555 - accuracy: 0.9470\n",
            "Epoch 1632: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1565 - accuracy: 0.9465 - val_loss: 0.9114 - val_accuracy: 0.8399\n",
            "Epoch 1633/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1476 - accuracy: 0.9473\n",
            "Epoch 1633: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1471 - accuracy: 0.9476 - val_loss: 0.9042 - val_accuracy: 0.8348\n",
            "Epoch 1634/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1437 - accuracy: 0.9497\n",
            "Epoch 1634: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1437 - accuracy: 0.9497 - val_loss: 0.9172 - val_accuracy: 0.8326\n",
            "Epoch 1635/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2642 - accuracy: 0.9068\n",
            "Epoch 1635: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2619 - accuracy: 0.9075 - val_loss: 0.9711 - val_accuracy: 0.8217\n",
            "Epoch 1636/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1996 - accuracy: 0.9320\n",
            "Epoch 1636: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2043 - accuracy: 0.9308 - val_loss: 1.0210 - val_accuracy: 0.8121\n",
            "Epoch 1637/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2282 - accuracy: 0.9168\n",
            "Epoch 1637: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2242 - accuracy: 0.9182 - val_loss: 0.9942 - val_accuracy: 0.8239\n",
            "Epoch 1638/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1427 - accuracy: 0.9491\n",
            "Epoch 1638: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1422 - accuracy: 0.9491 - val_loss: 0.9094 - val_accuracy: 0.8451\n",
            "Epoch 1639/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1587 - accuracy: 0.9410\n",
            "Epoch 1639: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1587 - accuracy: 0.9410 - val_loss: 0.9101 - val_accuracy: 0.8460\n",
            "Epoch 1640/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1675 - accuracy: 0.9382\n",
            "Epoch 1640: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1671 - accuracy: 0.9386 - val_loss: 0.9210 - val_accuracy: 0.8425\n",
            "Epoch 1641/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1355 - accuracy: 0.9519\n",
            "Epoch 1641: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1355 - accuracy: 0.9519 - val_loss: 0.9015 - val_accuracy: 0.8422\n",
            "Epoch 1642/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1468 - accuracy: 0.9455\n",
            "Epoch 1642: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1501 - accuracy: 0.9439 - val_loss: 0.9082 - val_accuracy: 0.8355\n",
            "Epoch 1643/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2158 - accuracy: 0.9236\n",
            "Epoch 1643: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2162 - accuracy: 0.9233 - val_loss: 1.1248 - val_accuracy: 0.7974\n",
            "Epoch 1644/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3068 - accuracy: 0.8930\n",
            "Epoch 1644: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3066 - accuracy: 0.8933 - val_loss: 1.1038 - val_accuracy: 0.7955\n",
            "Epoch 1645/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2666 - accuracy: 0.9053\n",
            "Epoch 1645: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2641 - accuracy: 0.9060 - val_loss: 1.0399 - val_accuracy: 0.8127\n",
            "Epoch 1646/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1895 - accuracy: 0.9294\n",
            "Epoch 1646: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1913 - accuracy: 0.9285 - val_loss: 1.0776 - val_accuracy: 0.7971\n",
            "Epoch 1647/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1495 - accuracy: 0.9449\n",
            "Epoch 1647: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1499 - accuracy: 0.9448 - val_loss: 0.9499 - val_accuracy: 0.8249\n",
            "Epoch 1648/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1672 - accuracy: 0.9385\n",
            "Epoch 1648: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1685 - accuracy: 0.9381 - val_loss: 0.8806 - val_accuracy: 0.8489\n",
            "Epoch 1649/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2070 - accuracy: 0.9269\n",
            "Epoch 1649: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2066 - accuracy: 0.9271 - val_loss: 0.9492 - val_accuracy: 0.8297\n",
            "Epoch 1650/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.5380 - accuracy: 0.8628\n",
            "Epoch 1650: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.5414 - accuracy: 0.8622 - val_loss: 2.5815 - val_accuracy: 0.6098\n",
            "Epoch 1651/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3766 - accuracy: 0.8841\n",
            "Epoch 1651: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3638 - accuracy: 0.8876 - val_loss: 0.8737 - val_accuracy: 0.8476\n",
            "Epoch 1652/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1483 - accuracy: 0.9481\n",
            "Epoch 1652: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1481 - accuracy: 0.9482 - val_loss: 0.9388 - val_accuracy: 0.8348\n",
            "Epoch 1653/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1271 - accuracy: 0.9566\n",
            "Epoch 1653: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1287 - accuracy: 0.9563 - val_loss: 0.8618 - val_accuracy: 0.8512\n",
            "Epoch 1654/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1339 - accuracy: 0.9530\n",
            "Epoch 1654: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1330 - accuracy: 0.9535 - val_loss: 0.8914 - val_accuracy: 0.8409\n",
            "Epoch 1655/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1370 - accuracy: 0.9511\n",
            "Epoch 1655: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1393 - accuracy: 0.9501 - val_loss: 1.2067 - val_accuracy: 0.7737\n",
            "Epoch 1656/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1824 - accuracy: 0.9350\n",
            "Epoch 1656: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1861 - accuracy: 0.9337 - val_loss: 1.1061 - val_accuracy: 0.8025\n",
            "Epoch 1657/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2203 - accuracy: 0.9187\n",
            "Epoch 1657: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2176 - accuracy: 0.9197 - val_loss: 0.9632 - val_accuracy: 0.8323\n",
            "Epoch 1658/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1833 - accuracy: 0.9313\n",
            "Epoch 1658: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1833 - accuracy: 0.9313 - val_loss: 0.9768 - val_accuracy: 0.8204\n",
            "Epoch 1659/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1989 - accuracy: 0.9269\n",
            "Epoch 1659: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1989 - accuracy: 0.9269 - val_loss: 1.0075 - val_accuracy: 0.8262\n",
            "Epoch 1660/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1591 - accuracy: 0.9435\n",
            "Epoch 1660: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1591 - accuracy: 0.9435 - val_loss: 0.9316 - val_accuracy: 0.8326\n",
            "Epoch 1661/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1716 - accuracy: 0.9398\n",
            "Epoch 1661: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1696 - accuracy: 0.9406 - val_loss: 0.9457 - val_accuracy: 0.8364\n",
            "Epoch 1662/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1391 - accuracy: 0.9517\n",
            "Epoch 1662: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1383 - accuracy: 0.9520 - val_loss: 0.9121 - val_accuracy: 0.8367\n",
            "Epoch 1663/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1602 - accuracy: 0.9418\n",
            "Epoch 1663: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1681 - accuracy: 0.9393 - val_loss: 1.1329 - val_accuracy: 0.7820\n",
            "Epoch 1664/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2792 - accuracy: 0.9052\n",
            "Epoch 1664: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2878 - accuracy: 0.9022 - val_loss: 1.0567 - val_accuracy: 0.8163\n",
            "Epoch 1665/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2205 - accuracy: 0.9201\n",
            "Epoch 1665: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2196 - accuracy: 0.9204 - val_loss: 0.8929 - val_accuracy: 0.8441\n",
            "Epoch 1666/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1760 - accuracy: 0.9345\n",
            "Epoch 1666: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1749 - accuracy: 0.9353 - val_loss: 0.9557 - val_accuracy: 0.8371\n",
            "Epoch 1667/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1558 - accuracy: 0.9424\n",
            "Epoch 1667: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1541 - accuracy: 0.9433 - val_loss: 0.8915 - val_accuracy: 0.8467\n",
            "Epoch 1668/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1245 - accuracy: 0.9573\n",
            "Epoch 1668: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1262 - accuracy: 0.9567 - val_loss: 1.0798 - val_accuracy: 0.8070\n",
            "Epoch 1669/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2572 - accuracy: 0.9062\n",
            "Epoch 1669: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2606 - accuracy: 0.9042 - val_loss: 1.2223 - val_accuracy: 0.7775\n",
            "Epoch 1670/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.2063 - accuracy: 0.9243\n",
            "Epoch 1670: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2060 - accuracy: 0.9243 - val_loss: 1.0746 - val_accuracy: 0.8083\n",
            "Epoch 1671/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1731 - accuracy: 0.9378\n",
            "Epoch 1671: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1725 - accuracy: 0.9385 - val_loss: 0.9849 - val_accuracy: 0.8230\n",
            "Epoch 1672/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1908 - accuracy: 0.9295\n",
            "Epoch 1672: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1908 - accuracy: 0.9295 - val_loss: 0.9374 - val_accuracy: 0.8271\n",
            "Epoch 1673/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1846 - accuracy: 0.9321\n",
            "Epoch 1673: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1874 - accuracy: 0.9313 - val_loss: 0.9488 - val_accuracy: 0.8419\n",
            "Epoch 1674/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.4351 - accuracy: 0.8697\n",
            "Epoch 1674: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4297 - accuracy: 0.8708 - val_loss: 0.9333 - val_accuracy: 0.8393\n",
            "Epoch 1675/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1877 - accuracy: 0.9333\n",
            "Epoch 1675: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1877 - accuracy: 0.9333 - val_loss: 0.9574 - val_accuracy: 0.8313\n",
            "Epoch 1676/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1504 - accuracy: 0.9482\n",
            "Epoch 1676: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1512 - accuracy: 0.9480 - val_loss: 0.9151 - val_accuracy: 0.8454\n",
            "Epoch 1677/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1353 - accuracy: 0.9517\n",
            "Epoch 1677: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1353 - accuracy: 0.9517 - val_loss: 0.9527 - val_accuracy: 0.8275\n",
            "Epoch 1678/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1527 - accuracy: 0.9462\n",
            "Epoch 1678: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1527 - accuracy: 0.9462 - val_loss: 0.8947 - val_accuracy: 0.8448\n",
            "Epoch 1679/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1578 - accuracy: 0.9417\n",
            "Epoch 1679: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1590 - accuracy: 0.9412 - val_loss: 1.9607 - val_accuracy: 0.6780\n",
            "Epoch 1680/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2574 - accuracy: 0.9105\n",
            "Epoch 1680: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2512 - accuracy: 0.9117 - val_loss: 0.9355 - val_accuracy: 0.8339\n",
            "Epoch 1681/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1731 - accuracy: 0.9355\n",
            "Epoch 1681: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1737 - accuracy: 0.9357 - val_loss: 1.0137 - val_accuracy: 0.8243\n",
            "Epoch 1682/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1509 - accuracy: 0.9450\n",
            "Epoch 1682: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1517 - accuracy: 0.9446 - val_loss: 1.0011 - val_accuracy: 0.8063\n",
            "Epoch 1683/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1830 - accuracy: 0.9359\n",
            "Epoch 1683: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1839 - accuracy: 0.9356 - val_loss: 0.9559 - val_accuracy: 0.8332\n",
            "Epoch 1684/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2736 - accuracy: 0.9076\n",
            "Epoch 1684: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2716 - accuracy: 0.9079 - val_loss: 1.0917 - val_accuracy: 0.7977\n",
            "Epoch 1685/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2596 - accuracy: 0.9071\n",
            "Epoch 1685: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2593 - accuracy: 0.9072 - val_loss: 1.0796 - val_accuracy: 0.7887\n",
            "Epoch 1686/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2163 - accuracy: 0.9219\n",
            "Epoch 1686: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2150 - accuracy: 0.9221 - val_loss: 1.0413 - val_accuracy: 0.8163\n",
            "Epoch 1687/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1650 - accuracy: 0.9400\n",
            "Epoch 1687: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1650 - accuracy: 0.9400 - val_loss: 1.0493 - val_accuracy: 0.8108\n",
            "Epoch 1688/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1570 - accuracy: 0.9438\n",
            "Epoch 1688: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1568 - accuracy: 0.9437 - val_loss: 0.9459 - val_accuracy: 0.8262\n",
            "Epoch 1689/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1960 - accuracy: 0.9291\n",
            "Epoch 1689: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2011 - accuracy: 0.9277 - val_loss: 1.1515 - val_accuracy: 0.7775\n",
            "Epoch 1690/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1786 - accuracy: 0.9352\n",
            "Epoch 1690: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1784 - accuracy: 0.9351 - val_loss: 1.1214 - val_accuracy: 0.8073\n",
            "Epoch 1691/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.8771 - accuracy: 0.7897\n",
            "Epoch 1691: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.8742 - accuracy: 0.7902 - val_loss: 1.4600 - val_accuracy: 0.7593\n",
            "Epoch 1692/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1950 - accuracy: 0.9293\n",
            "Epoch 1692: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1913 - accuracy: 0.9308 - val_loss: 0.9595 - val_accuracy: 0.8444\n",
            "Epoch 1693/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1364 - accuracy: 0.9537\n",
            "Epoch 1693: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1360 - accuracy: 0.9537 - val_loss: 0.9510 - val_accuracy: 0.8390\n",
            "Epoch 1694/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1305 - accuracy: 0.9527\n",
            "Epoch 1694: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1316 - accuracy: 0.9525 - val_loss: 0.9940 - val_accuracy: 0.8307\n",
            "Epoch 1695/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1565 - accuracy: 0.9436\n",
            "Epoch 1695: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1554 - accuracy: 0.9442 - val_loss: 0.9161 - val_accuracy: 0.8428\n",
            "Epoch 1696/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1372 - accuracy: 0.9514\n",
            "Epoch 1696: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1360 - accuracy: 0.9520 - val_loss: 0.9010 - val_accuracy: 0.8486\n",
            "Epoch 1697/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1457 - accuracy: 0.9489\n",
            "Epoch 1697: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1457 - accuracy: 0.9489 - val_loss: 1.1728 - val_accuracy: 0.7891\n",
            "Epoch 1698/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1575 - accuracy: 0.9416\n",
            "Epoch 1698: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1560 - accuracy: 0.9420 - val_loss: 0.9142 - val_accuracy: 0.8431\n",
            "Epoch 1699/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1501 - accuracy: 0.9437\n",
            "Epoch 1699: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1513 - accuracy: 0.9430 - val_loss: 0.9329 - val_accuracy: 0.8406\n",
            "Epoch 1700/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1604 - accuracy: 0.9413\n",
            "Epoch 1700: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1606 - accuracy: 0.9412 - val_loss: 0.9899 - val_accuracy: 0.8313\n",
            "Epoch 1701/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1415 - accuracy: 0.9481\n",
            "Epoch 1701: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1414 - accuracy: 0.9482 - val_loss: 0.8877 - val_accuracy: 0.8480\n",
            "Epoch 1702/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1401 - accuracy: 0.9497\n",
            "Epoch 1702: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1401 - accuracy: 0.9497 - val_loss: 0.9643 - val_accuracy: 0.8339\n",
            "Epoch 1703/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1617 - accuracy: 0.9408\n",
            "Epoch 1703: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1651 - accuracy: 0.9392 - val_loss: 1.0276 - val_accuracy: 0.8108\n",
            "Epoch 1704/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2787 - accuracy: 0.9116\n",
            "Epoch 1704: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2804 - accuracy: 0.9111 - val_loss: 2.7015 - val_accuracy: 0.6079\n",
            "Epoch 1705/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3354 - accuracy: 0.8943\n",
            "Epoch 1705: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3305 - accuracy: 0.8948 - val_loss: 1.1544 - val_accuracy: 0.7935\n",
            "Epoch 1706/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2412 - accuracy: 0.9149\n",
            "Epoch 1706: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2396 - accuracy: 0.9155 - val_loss: 1.0022 - val_accuracy: 0.8300\n",
            "Epoch 1707/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1456 - accuracy: 0.9480\n",
            "Epoch 1707: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1462 - accuracy: 0.9477 - val_loss: 0.9843 - val_accuracy: 0.8230\n",
            "Epoch 1708/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1630 - accuracy: 0.9414\n",
            "Epoch 1708: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1632 - accuracy: 0.9413 - val_loss: 1.1621 - val_accuracy: 0.7855\n",
            "Epoch 1709/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1750 - accuracy: 0.9368\n",
            "Epoch 1709: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1822 - accuracy: 0.9341 - val_loss: 1.1396 - val_accuracy: 0.7862\n",
            "Epoch 1710/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1740 - accuracy: 0.9367\n",
            "Epoch 1710: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1730 - accuracy: 0.9362 - val_loss: 1.0169 - val_accuracy: 0.8236\n",
            "Epoch 1711/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1834 - accuracy: 0.9324\n",
            "Epoch 1711: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1820 - accuracy: 0.9327 - val_loss: 0.9787 - val_accuracy: 0.8380\n",
            "Epoch 1712/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1721 - accuracy: 0.9365\n",
            "Epoch 1712: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1701 - accuracy: 0.9377 - val_loss: 0.9763 - val_accuracy: 0.8291\n",
            "Epoch 1713/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1645 - accuracy: 0.9386\n",
            "Epoch 1713: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1645 - accuracy: 0.9386 - val_loss: 0.9655 - val_accuracy: 0.8287\n",
            "Epoch 1714/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1842 - accuracy: 0.9329\n",
            "Epoch 1714: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1862 - accuracy: 0.9319 - val_loss: 1.0355 - val_accuracy: 0.8191\n",
            "Epoch 1715/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1946 - accuracy: 0.9290\n",
            "Epoch 1715: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1937 - accuracy: 0.9291 - val_loss: 0.9528 - val_accuracy: 0.8284\n",
            "Epoch 1716/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1444 - accuracy: 0.9468\n",
            "Epoch 1716: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.1524 - accuracy: 0.9439 - val_loss: 1.0055 - val_accuracy: 0.8150\n",
            "Epoch 1717/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2451 - accuracy: 0.9085\n",
            "Epoch 1717: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2446 - accuracy: 0.9082 - val_loss: 1.0662 - val_accuracy: 0.8063\n",
            "Epoch 1718/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1915 - accuracy: 0.9290\n",
            "Epoch 1718: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1908 - accuracy: 0.9293 - val_loss: 1.0619 - val_accuracy: 0.8195\n",
            "Epoch 1719/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2808 - accuracy: 0.9014\n",
            "Epoch 1719: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2808 - accuracy: 0.9014 - val_loss: 1.2180 - val_accuracy: 0.7753\n",
            "Epoch 1720/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2539 - accuracy: 0.9068\n",
            "Epoch 1720: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2496 - accuracy: 0.9077 - val_loss: 0.9686 - val_accuracy: 0.8310\n",
            "Epoch 1721/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1968 - accuracy: 0.9284\n",
            "Epoch 1721: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1933 - accuracy: 0.9300 - val_loss: 0.9434 - val_accuracy: 0.8415\n",
            "Epoch 1722/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1712 - accuracy: 0.9368\n",
            "Epoch 1722: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1727 - accuracy: 0.9359 - val_loss: 1.1058 - val_accuracy: 0.8028\n",
            "Epoch 1723/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1656 - accuracy: 0.9396\n",
            "Epoch 1723: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1656 - accuracy: 0.9396 - val_loss: 0.9399 - val_accuracy: 0.8428\n",
            "Epoch 1724/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1558 - accuracy: 0.9423\n",
            "Epoch 1724: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1551 - accuracy: 0.9426 - val_loss: 0.9895 - val_accuracy: 0.8329\n",
            "Epoch 1725/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1764 - accuracy: 0.9401\n",
            "Epoch 1725: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1764 - accuracy: 0.9401 - val_loss: 1.1641 - val_accuracy: 0.7939\n",
            "Epoch 1726/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2915 - accuracy: 0.9009\n",
            "Epoch 1726: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2853 - accuracy: 0.9031 - val_loss: 0.9824 - val_accuracy: 0.8364\n",
            "Epoch 1727/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1496 - accuracy: 0.9474\n",
            "Epoch 1727: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1502 - accuracy: 0.9472 - val_loss: 1.0006 - val_accuracy: 0.8271\n",
            "Epoch 1728/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1449 - accuracy: 0.9475\n",
            "Epoch 1728: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1464 - accuracy: 0.9467 - val_loss: 0.9639 - val_accuracy: 0.8339\n",
            "Epoch 1729/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1520 - accuracy: 0.9453\n",
            "Epoch 1729: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1517 - accuracy: 0.9450 - val_loss: 0.9492 - val_accuracy: 0.8371\n",
            "Epoch 1730/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1912 - accuracy: 0.9326\n",
            "Epoch 1730: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1951 - accuracy: 0.9304 - val_loss: 1.1622 - val_accuracy: 0.7942\n",
            "Epoch 1731/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.4246 - accuracy: 0.8845\n",
            "Epoch 1731: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4566 - accuracy: 0.8774 - val_loss: 1.8108 - val_accuracy: 0.7023\n",
            "Epoch 1732/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3622 - accuracy: 0.8861\n",
            "Epoch 1732: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3565 - accuracy: 0.8876 - val_loss: 0.9877 - val_accuracy: 0.8323\n",
            "Epoch 1733/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1477 - accuracy: 0.9496\n",
            "Epoch 1733: val_accuracy did not improve from 0.85147\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1469 - accuracy: 0.9498 - val_loss: 0.9824 - val_accuracy: 0.8345\n",
            "Epoch 1734/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1887 - accuracy: 0.9315\n",
            "Epoch 1734: val_accuracy improved from 0.85147 to 0.85403, saving model to /content/asl1/Adam4/cp-1734-0.85.hdf5\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.1887 - accuracy: 0.9315 - val_loss: 0.8976 - val_accuracy: 0.8540\n",
            "Epoch 1735/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2143 - accuracy: 0.9240\n",
            "Epoch 1735: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2182 - accuracy: 0.9220 - val_loss: 1.0388 - val_accuracy: 0.8067\n",
            "Epoch 1736/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1602 - accuracy: 0.9416\n",
            "Epoch 1736: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1601 - accuracy: 0.9416 - val_loss: 0.9569 - val_accuracy: 0.8303\n",
            "Epoch 1737/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1437 - accuracy: 0.9475\n",
            "Epoch 1737: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1434 - accuracy: 0.9474 - val_loss: 0.9076 - val_accuracy: 0.8518\n",
            "Epoch 1738/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1145 - accuracy: 0.9596\n",
            "Epoch 1738: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1152 - accuracy: 0.9590 - val_loss: 0.9558 - val_accuracy: 0.8371\n",
            "Epoch 1739/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1720 - accuracy: 0.9381\n",
            "Epoch 1739: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1708 - accuracy: 0.9382 - val_loss: 0.9969 - val_accuracy: 0.8249\n",
            "Epoch 1740/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1390 - accuracy: 0.9493\n",
            "Epoch 1740: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1395 - accuracy: 0.9493 - val_loss: 1.0239 - val_accuracy: 0.8230\n",
            "Epoch 1741/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1788 - accuracy: 0.9343\n",
            "Epoch 1741: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1812 - accuracy: 0.9329 - val_loss: 1.1404 - val_accuracy: 0.8031\n",
            "Epoch 1742/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2497 - accuracy: 0.9096\n",
            "Epoch 1742: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2477 - accuracy: 0.9100 - val_loss: 1.1211 - val_accuracy: 0.8121\n",
            "Epoch 1743/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2057 - accuracy: 0.9231\n",
            "Epoch 1743: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2052 - accuracy: 0.9232 - val_loss: 1.2129 - val_accuracy: 0.7794\n",
            "Epoch 1744/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1950 - accuracy: 0.9297\n",
            "Epoch 1744: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1938 - accuracy: 0.9301 - val_loss: 0.9634 - val_accuracy: 0.8313\n",
            "Epoch 1745/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.1375 - accuracy: 0.9515\n",
            "Epoch 1745: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1359 - accuracy: 0.9519 - val_loss: 0.9502 - val_accuracy: 0.8377\n",
            "Epoch 1746/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.8098 - accuracy: 0.8393\n",
            "Epoch 1746: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.8085 - accuracy: 0.8346 - val_loss: 1.5163 - val_accuracy: 0.7247\n",
            "Epoch 1747/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2299 - accuracy: 0.9182\n",
            "Epoch 1747: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2248 - accuracy: 0.9204 - val_loss: 0.9385 - val_accuracy: 0.8351\n",
            "Epoch 1748/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1286 - accuracy: 0.9557\n",
            "Epoch 1748: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1281 - accuracy: 0.9562 - val_loss: 0.9125 - val_accuracy: 0.8358\n",
            "Epoch 1749/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1324 - accuracy: 0.9527\n",
            "Epoch 1749: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1321 - accuracy: 0.9528 - val_loss: 0.9938 - val_accuracy: 0.8281\n",
            "Epoch 1750/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1422 - accuracy: 0.9486\n",
            "Epoch 1750: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1411 - accuracy: 0.9494 - val_loss: 0.9758 - val_accuracy: 0.8287\n",
            "Epoch 1751/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1615 - accuracy: 0.9409\n",
            "Epoch 1751: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1615 - accuracy: 0.9409 - val_loss: 0.9704 - val_accuracy: 0.8319\n",
            "Epoch 1752/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1584 - accuracy: 0.9425\n",
            "Epoch 1752: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1578 - accuracy: 0.9428 - val_loss: 0.9419 - val_accuracy: 0.8332\n",
            "Epoch 1753/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1368 - accuracy: 0.9519\n",
            "Epoch 1753: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1373 - accuracy: 0.9517 - val_loss: 0.9022 - val_accuracy: 0.8380\n",
            "Epoch 1754/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1322 - accuracy: 0.9540\n",
            "Epoch 1754: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1316 - accuracy: 0.9544 - val_loss: 0.9617 - val_accuracy: 0.8364\n",
            "Epoch 1755/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1602 - accuracy: 0.9417\n",
            "Epoch 1755: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1602 - accuracy: 0.9417 - val_loss: 0.9005 - val_accuracy: 0.8428\n",
            "Epoch 1756/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1542 - accuracy: 0.9438\n",
            "Epoch 1756: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1534 - accuracy: 0.9441 - val_loss: 0.9188 - val_accuracy: 0.8480\n",
            "Epoch 1757/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1417 - accuracy: 0.9483\n",
            "Epoch 1757: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1417 - accuracy: 0.9485 - val_loss: 0.9293 - val_accuracy: 0.8496\n",
            "Epoch 1758/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2331 - accuracy: 0.9165\n",
            "Epoch 1758: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2385 - accuracy: 0.9145 - val_loss: 1.2880 - val_accuracy: 0.7670\n",
            "Epoch 1759/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.4496 - accuracy: 0.8655\n",
            "Epoch 1759: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4446 - accuracy: 0.8668 - val_loss: 1.0767 - val_accuracy: 0.8223\n",
            "Epoch 1760/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1553 - accuracy: 0.9433\n",
            "Epoch 1760: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1558 - accuracy: 0.9431 - val_loss: 0.9429 - val_accuracy: 0.8383\n",
            "Epoch 1761/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1454 - accuracy: 0.9487\n",
            "Epoch 1761: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1431 - accuracy: 0.9497 - val_loss: 0.9491 - val_accuracy: 0.8332\n",
            "Epoch 1762/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1394 - accuracy: 0.9522\n",
            "Epoch 1762: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1400 - accuracy: 0.9516 - val_loss: 0.9376 - val_accuracy: 0.8438\n",
            "Epoch 1763/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1460 - accuracy: 0.9473\n",
            "Epoch 1763: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1469 - accuracy: 0.9465 - val_loss: 0.9534 - val_accuracy: 0.8307\n",
            "Epoch 1764/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1465 - accuracy: 0.9460\n",
            "Epoch 1764: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1498 - accuracy: 0.9455 - val_loss: 0.9559 - val_accuracy: 0.8358\n",
            "Epoch 1765/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1601 - accuracy: 0.9412\n",
            "Epoch 1765: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1606 - accuracy: 0.9410 - val_loss: 0.9853 - val_accuracy: 0.8233\n",
            "Epoch 1766/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2690 - accuracy: 0.9053\n",
            "Epoch 1766: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2713 - accuracy: 0.9051 - val_loss: 1.2902 - val_accuracy: 0.7737\n",
            "Epoch 1767/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1939 - accuracy: 0.9278\n",
            "Epoch 1767: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1910 - accuracy: 0.9291 - val_loss: 1.0769 - val_accuracy: 0.8239\n",
            "Epoch 1768/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2193 - accuracy: 0.9212\n",
            "Epoch 1768: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2188 - accuracy: 0.9214 - val_loss: 0.9894 - val_accuracy: 0.8303\n",
            "Epoch 1769/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1693 - accuracy: 0.9388\n",
            "Epoch 1769: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1696 - accuracy: 0.9385 - val_loss: 0.9483 - val_accuracy: 0.8358\n",
            "Epoch 1770/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1439 - accuracy: 0.9490\n",
            "Epoch 1770: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1439 - accuracy: 0.9490 - val_loss: 0.9256 - val_accuracy: 0.8396\n",
            "Epoch 1771/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1754 - accuracy: 0.9373\n",
            "Epoch 1771: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1758 - accuracy: 0.9370 - val_loss: 1.0525 - val_accuracy: 0.8035\n",
            "Epoch 1772/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2175 - accuracy: 0.9232\n",
            "Epoch 1772: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2225 - accuracy: 0.9221 - val_loss: 1.2867 - val_accuracy: 0.7689\n",
            "Epoch 1773/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3248 - accuracy: 0.8916\n",
            "Epoch 1773: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.3266 - accuracy: 0.8912 - val_loss: 1.0398 - val_accuracy: 0.8131\n",
            "Epoch 1774/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2361 - accuracy: 0.9173\n",
            "Epoch 1774: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2354 - accuracy: 0.9174 - val_loss: 1.0668 - val_accuracy: 0.8134\n",
            "Epoch 1775/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2896 - accuracy: 0.9019\n",
            "Epoch 1775: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2871 - accuracy: 0.9024 - val_loss: 1.1663 - val_accuracy: 0.7849\n",
            "Epoch 1776/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1753 - accuracy: 0.9389\n",
            "Epoch 1776: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1757 - accuracy: 0.9393 - val_loss: 0.9632 - val_accuracy: 0.8323\n",
            "Epoch 1777/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1670 - accuracy: 0.9379\n",
            "Epoch 1777: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1663 - accuracy: 0.9378 - val_loss: 0.9884 - val_accuracy: 0.8275\n",
            "Epoch 1778/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1335 - accuracy: 0.9545\n",
            "Epoch 1778: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1335 - accuracy: 0.9545 - val_loss: 0.9752 - val_accuracy: 0.8246\n",
            "Epoch 1779/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1436 - accuracy: 0.9481\n",
            "Epoch 1779: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1433 - accuracy: 0.9481 - val_loss: 0.9298 - val_accuracy: 0.8425\n",
            "Epoch 1780/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1525 - accuracy: 0.9435\n",
            "Epoch 1780: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1529 - accuracy: 0.9433 - val_loss: 0.9556 - val_accuracy: 0.8387\n",
            "Epoch 1781/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1486 - accuracy: 0.9443\n",
            "Epoch 1781: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1486 - accuracy: 0.9445 - val_loss: 0.8936 - val_accuracy: 0.8496\n",
            "Epoch 1782/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1451 - accuracy: 0.9470\n",
            "Epoch 1782: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1447 - accuracy: 0.9472 - val_loss: 1.0266 - val_accuracy: 0.8182\n",
            "Epoch 1783/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.5413 - accuracy: 0.8542\n",
            "Epoch 1783: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.5196 - accuracy: 0.8573 - val_loss: 1.0324 - val_accuracy: 0.8163\n",
            "Epoch 1784/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2553 - accuracy: 0.9089\n",
            "Epoch 1784: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2504 - accuracy: 0.9101 - val_loss: 1.0447 - val_accuracy: 0.8220\n",
            "Epoch 1785/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1479 - accuracy: 0.9470\n",
            "Epoch 1785: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1509 - accuracy: 0.9455 - val_loss: 0.9472 - val_accuracy: 0.8406\n",
            "Epoch 1786/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1446 - accuracy: 0.9462\n",
            "Epoch 1786: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1455 - accuracy: 0.9455 - val_loss: 0.9881 - val_accuracy: 0.8249\n",
            "Epoch 1787/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1746 - accuracy: 0.9362\n",
            "Epoch 1787: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1747 - accuracy: 0.9363 - val_loss: 1.0639 - val_accuracy: 0.8230\n",
            "Epoch 1788/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1674 - accuracy: 0.9375\n",
            "Epoch 1788: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1679 - accuracy: 0.9380 - val_loss: 0.9396 - val_accuracy: 0.8415\n",
            "Epoch 1789/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2287 - accuracy: 0.9186\n",
            "Epoch 1789: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2516 - accuracy: 0.9113 - val_loss: 1.3458 - val_accuracy: 0.7714\n",
            "Epoch 1790/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2309 - accuracy: 0.9199\n",
            "Epoch 1790: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2302 - accuracy: 0.9201 - val_loss: 0.9984 - val_accuracy: 0.8332\n",
            "Epoch 1791/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2359 - accuracy: 0.9147\n",
            "Epoch 1791: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2359 - accuracy: 0.9147 - val_loss: 1.1079 - val_accuracy: 0.8076\n",
            "Epoch 1792/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1720 - accuracy: 0.9364\n",
            "Epoch 1792: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1720 - accuracy: 0.9364 - val_loss: 0.9469 - val_accuracy: 0.8457\n",
            "Epoch 1793/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1554 - accuracy: 0.9430\n",
            "Epoch 1793: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1554 - accuracy: 0.9430 - val_loss: 0.9216 - val_accuracy: 0.8438\n",
            "Epoch 1794/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1454 - accuracy: 0.9493\n",
            "Epoch 1794: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1460 - accuracy: 0.9489 - val_loss: 0.9566 - val_accuracy: 0.8345\n",
            "Epoch 1795/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2755 - accuracy: 0.8995\n",
            "Epoch 1795: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.2769 - accuracy: 0.8989 - val_loss: 1.1436 - val_accuracy: 0.7935\n",
            "Epoch 1796/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2287 - accuracy: 0.9187\n",
            "Epoch 1796: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2260 - accuracy: 0.9194 - val_loss: 0.9470 - val_accuracy: 0.8361\n",
            "Epoch 1797/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1399 - accuracy: 0.9504\n",
            "Epoch 1797: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1399 - accuracy: 0.9504 - val_loss: 1.0842 - val_accuracy: 0.8035\n",
            "Epoch 1798/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1562 - accuracy: 0.9419\n",
            "Epoch 1798: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1564 - accuracy: 0.9420 - val_loss: 0.9102 - val_accuracy: 0.8508\n",
            "Epoch 1799/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1623 - accuracy: 0.9409\n",
            "Epoch 1799: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1636 - accuracy: 0.9403 - val_loss: 1.1209 - val_accuracy: 0.8015\n",
            "Epoch 1800/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1772 - accuracy: 0.9357\n",
            "Epoch 1800: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1813 - accuracy: 0.9344 - val_loss: 1.1129 - val_accuracy: 0.8054\n",
            "Epoch 1801/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1912 - accuracy: 0.9301\n",
            "Epoch 1801: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1899 - accuracy: 0.9306 - val_loss: 0.9628 - val_accuracy: 0.8335\n",
            "Epoch 1802/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2589 - accuracy: 0.9080\n",
            "Epoch 1802: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2525 - accuracy: 0.9093 - val_loss: 1.0243 - val_accuracy: 0.8220\n",
            "Epoch 1803/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2133 - accuracy: 0.9197\n",
            "Epoch 1803: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2133 - accuracy: 0.9197 - val_loss: 1.0221 - val_accuracy: 0.8195\n",
            "Epoch 1804/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1510 - accuracy: 0.9460\n",
            "Epoch 1804: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1513 - accuracy: 0.9457 - val_loss: 1.0005 - val_accuracy: 0.8310\n",
            "Epoch 1805/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1191 - accuracy: 0.9576\n",
            "Epoch 1805: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1210 - accuracy: 0.9571 - val_loss: 1.0586 - val_accuracy: 0.8182\n",
            "Epoch 1806/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.1522 - accuracy: 0.9441\n",
            "Epoch 1806: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1540 - accuracy: 0.9433 - val_loss: 0.9906 - val_accuracy: 0.8275\n",
            "Epoch 1807/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1544 - accuracy: 0.9442\n",
            "Epoch 1807: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1526 - accuracy: 0.9447 - val_loss: 0.9992 - val_accuracy: 0.8294\n",
            "Epoch 1808/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1577 - accuracy: 0.9418\n",
            "Epoch 1808: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1590 - accuracy: 0.9413 - val_loss: 0.9988 - val_accuracy: 0.8255\n",
            "Epoch 1809/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2460 - accuracy: 0.9130\n",
            "Epoch 1809: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2490 - accuracy: 0.9118 - val_loss: 1.1086 - val_accuracy: 0.8073\n",
            "Epoch 1810/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.5719 - accuracy: 0.8478\n",
            "Epoch 1810: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.5496 - accuracy: 0.8519 - val_loss: 1.0465 - val_accuracy: 0.8163\n",
            "Epoch 1811/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1468 - accuracy: 0.9475\n",
            "Epoch 1811: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1463 - accuracy: 0.9478 - val_loss: 1.0193 - val_accuracy: 0.8204\n",
            "Epoch 1812/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1307 - accuracy: 0.9542\n",
            "Epoch 1812: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1331 - accuracy: 0.9533 - val_loss: 0.9347 - val_accuracy: 0.8464\n",
            "Epoch 1813/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1609 - accuracy: 0.9427\n",
            "Epoch 1813: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1608 - accuracy: 0.9428 - val_loss: 1.1039 - val_accuracy: 0.7990\n",
            "Epoch 1814/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1835 - accuracy: 0.9325\n",
            "Epoch 1814: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1819 - accuracy: 0.9332 - val_loss: 0.9756 - val_accuracy: 0.8329\n",
            "Epoch 1815/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1209 - accuracy: 0.9572\n",
            "Epoch 1815: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1215 - accuracy: 0.9571 - val_loss: 1.0900 - val_accuracy: 0.7996\n",
            "Epoch 1816/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1296 - accuracy: 0.9542\n",
            "Epoch 1816: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1307 - accuracy: 0.9538 - val_loss: 1.0043 - val_accuracy: 0.8188\n",
            "Epoch 1817/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1593 - accuracy: 0.9419\n",
            "Epoch 1817: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1579 - accuracy: 0.9421 - val_loss: 1.0426 - val_accuracy: 0.8121\n",
            "Epoch 1818/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1671 - accuracy: 0.9390\n",
            "Epoch 1818: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1625 - accuracy: 0.9405 - val_loss: 1.0246 - val_accuracy: 0.8198\n",
            "Epoch 1819/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1536 - accuracy: 0.9453\n",
            "Epoch 1819: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1541 - accuracy: 0.9454 - val_loss: 0.9170 - val_accuracy: 0.8422\n",
            "Epoch 1820/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1413 - accuracy: 0.9476\n",
            "Epoch 1820: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1413 - accuracy: 0.9476 - val_loss: 1.0192 - val_accuracy: 0.8230\n",
            "Epoch 1821/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1860 - accuracy: 0.9325\n",
            "Epoch 1821: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1860 - accuracy: 0.9325 - val_loss: 1.0790 - val_accuracy: 0.8217\n",
            "Epoch 1822/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.4584 - accuracy: 0.8668\n",
            "Epoch 1822: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4651 - accuracy: 0.8651 - val_loss: 1.2888 - val_accuracy: 0.7737\n",
            "Epoch 1823/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2139 - accuracy: 0.9218\n",
            "Epoch 1823: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2113 - accuracy: 0.9227 - val_loss: 0.9775 - val_accuracy: 0.8262\n",
            "Epoch 1824/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1380 - accuracy: 0.9492\n",
            "Epoch 1824: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1379 - accuracy: 0.9489 - val_loss: 0.9409 - val_accuracy: 0.8464\n",
            "Epoch 1825/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1594 - accuracy: 0.9413\n",
            "Epoch 1825: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1610 - accuracy: 0.9407 - val_loss: 1.0069 - val_accuracy: 0.8297\n",
            "Epoch 1826/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1432 - accuracy: 0.9465\n",
            "Epoch 1826: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1428 - accuracy: 0.9465 - val_loss: 1.2595 - val_accuracy: 0.7791\n",
            "Epoch 1827/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2483 - accuracy: 0.9108\n",
            "Epoch 1827: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2456 - accuracy: 0.9118 - val_loss: 0.9642 - val_accuracy: 0.8319\n",
            "Epoch 1828/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1275 - accuracy: 0.9545\n",
            "Epoch 1828: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1275 - accuracy: 0.9545 - val_loss: 1.0025 - val_accuracy: 0.8307\n",
            "Epoch 1829/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1703 - accuracy: 0.9371\n",
            "Epoch 1829: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1675 - accuracy: 0.9385 - val_loss: 0.9840 - val_accuracy: 0.8335\n",
            "Epoch 1830/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1459 - accuracy: 0.9463\n",
            "Epoch 1830: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1447 - accuracy: 0.9468 - val_loss: 0.9760 - val_accuracy: 0.8371\n",
            "Epoch 1831/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1786 - accuracy: 0.9352\n",
            "Epoch 1831: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1791 - accuracy: 0.9351 - val_loss: 0.9179 - val_accuracy: 0.8457\n",
            "Epoch 1832/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1323 - accuracy: 0.9535\n",
            "Epoch 1832: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1317 - accuracy: 0.9537 - val_loss: 0.9936 - val_accuracy: 0.8291\n",
            "Epoch 1833/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1835 - accuracy: 0.9330\n",
            "Epoch 1833: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1830 - accuracy: 0.9330 - val_loss: 0.9852 - val_accuracy: 0.8345\n",
            "Epoch 1834/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1537 - accuracy: 0.9427\n",
            "Epoch 1834: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1538 - accuracy: 0.9429 - val_loss: 1.0228 - val_accuracy: 0.8294\n",
            "Epoch 1835/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1608 - accuracy: 0.9407\n",
            "Epoch 1835: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1611 - accuracy: 0.9404 - val_loss: 1.0378 - val_accuracy: 0.8287\n",
            "Epoch 1836/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1792 - accuracy: 0.9334\n",
            "Epoch 1836: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1792 - accuracy: 0.9334 - val_loss: 1.0878 - val_accuracy: 0.8111\n",
            "Epoch 1837/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2138 - accuracy: 0.9194\n",
            "Epoch 1837: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2138 - accuracy: 0.9194 - val_loss: 1.1980 - val_accuracy: 0.7894\n",
            "Epoch 1838/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2284 - accuracy: 0.9166\n",
            "Epoch 1838: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2275 - accuracy: 0.9165 - val_loss: 1.1454 - val_accuracy: 0.7951\n",
            "Epoch 1839/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1968 - accuracy: 0.9314\n",
            "Epoch 1839: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1961 - accuracy: 0.9318 - val_loss: 1.0724 - val_accuracy: 0.8121\n",
            "Epoch 1840/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2086 - accuracy: 0.9233\n",
            "Epoch 1840: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2041 - accuracy: 0.9248 - val_loss: 1.0884 - val_accuracy: 0.8022\n",
            "Epoch 1841/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1619 - accuracy: 0.9404\n",
            "Epoch 1841: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1663 - accuracy: 0.9392 - val_loss: 1.3318 - val_accuracy: 0.7628\n",
            "Epoch 1842/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2224 - accuracy: 0.9186\n",
            "Epoch 1842: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2216 - accuracy: 0.9191 - val_loss: 0.9855 - val_accuracy: 0.8351\n",
            "Epoch 1843/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1931 - accuracy: 0.9303\n",
            "Epoch 1843: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1927 - accuracy: 0.9306 - val_loss: 1.0104 - val_accuracy: 0.8204\n",
            "Epoch 1844/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2843 - accuracy: 0.9014\n",
            "Epoch 1844: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2772 - accuracy: 0.9036 - val_loss: 0.9472 - val_accuracy: 0.8444\n",
            "Epoch 1845/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1577 - accuracy: 0.9401\n",
            "Epoch 1845: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1576 - accuracy: 0.9401 - val_loss: 1.0488 - val_accuracy: 0.8147\n",
            "Epoch 1846/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1945 - accuracy: 0.9292\n",
            "Epoch 1846: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1941 - accuracy: 0.9293 - val_loss: 1.0067 - val_accuracy: 0.8278\n",
            "Epoch 1847/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2181 - accuracy: 0.9207\n",
            "Epoch 1847: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2168 - accuracy: 0.9215 - val_loss: 1.0378 - val_accuracy: 0.8243\n",
            "Epoch 1848/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1900 - accuracy: 0.9307\n",
            "Epoch 1848: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1878 - accuracy: 0.9313 - val_loss: 1.0972 - val_accuracy: 0.8070\n",
            "Epoch 1849/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1325 - accuracy: 0.9528\n",
            "Epoch 1849: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1319 - accuracy: 0.9529 - val_loss: 1.0082 - val_accuracy: 0.8255\n",
            "Epoch 1850/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1267 - accuracy: 0.9556\n",
            "Epoch 1850: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1275 - accuracy: 0.9553 - val_loss: 0.9335 - val_accuracy: 0.8435\n",
            "Epoch 1851/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1515 - accuracy: 0.9458\n",
            "Epoch 1851: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1513 - accuracy: 0.9459 - val_loss: 1.0240 - val_accuracy: 0.8335\n",
            "Epoch 1852/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1741 - accuracy: 0.9351\n",
            "Epoch 1852: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1744 - accuracy: 0.9351 - val_loss: 1.0093 - val_accuracy: 0.8223\n",
            "Epoch 1853/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1842 - accuracy: 0.9299\n",
            "Epoch 1853: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1886 - accuracy: 0.9289 - val_loss: 1.2295 - val_accuracy: 0.7788\n",
            "Epoch 1854/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1571 - accuracy: 0.9424\n",
            "Epoch 1854: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1572 - accuracy: 0.9422 - val_loss: 1.0438 - val_accuracy: 0.8217\n",
            "Epoch 1855/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.5633 - accuracy: 0.8708\n",
            "Epoch 1855: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.5682 - accuracy: 0.8683 - val_loss: 1.5685 - val_accuracy: 0.7247\n",
            "Epoch 1856/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3143 - accuracy: 0.8936\n",
            "Epoch 1856: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3143 - accuracy: 0.8936 - val_loss: 1.0026 - val_accuracy: 0.8390\n",
            "Epoch 1857/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.1232 - accuracy: 0.9577\n",
            "Epoch 1857: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1224 - accuracy: 0.9580 - val_loss: 0.9160 - val_accuracy: 0.8476\n",
            "Epoch 1858/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1188 - accuracy: 0.9579\n",
            "Epoch 1858: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1188 - accuracy: 0.9579 - val_loss: 0.9182 - val_accuracy: 0.8467\n",
            "Epoch 1859/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1127 - accuracy: 0.9622\n",
            "Epoch 1859: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1164 - accuracy: 0.9602 - val_loss: 0.9999 - val_accuracy: 0.8268\n",
            "Epoch 1860/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1552 - accuracy: 0.9441\n",
            "Epoch 1860: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1548 - accuracy: 0.9441 - val_loss: 0.9693 - val_accuracy: 0.8335\n",
            "Epoch 1861/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1361 - accuracy: 0.9518\n",
            "Epoch 1861: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1340 - accuracy: 0.9523 - val_loss: 1.0458 - val_accuracy: 0.8220\n",
            "Epoch 1862/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1304 - accuracy: 0.9534\n",
            "Epoch 1862: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1310 - accuracy: 0.9528 - val_loss: 0.9995 - val_accuracy: 0.8374\n",
            "Epoch 1863/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1354 - accuracy: 0.9511\n",
            "Epoch 1863: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1344 - accuracy: 0.9511 - val_loss: 0.9024 - val_accuracy: 0.8470\n",
            "Epoch 1864/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1695 - accuracy: 0.9385\n",
            "Epoch 1864: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1695 - accuracy: 0.9385 - val_loss: 1.5573 - val_accuracy: 0.7196\n",
            "Epoch 1865/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2748 - accuracy: 0.9018\n",
            "Epoch 1865: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2748 - accuracy: 0.9018 - val_loss: 0.9543 - val_accuracy: 0.8278\n",
            "Epoch 1866/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.1358 - accuracy: 0.9496\n",
            "Epoch 1866: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1357 - accuracy: 0.9504 - val_loss: 1.0181 - val_accuracy: 0.8204\n",
            "Epoch 1867/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1874 - accuracy: 0.9293\n",
            "Epoch 1867: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1871 - accuracy: 0.9293 - val_loss: 1.0508 - val_accuracy: 0.8236\n",
            "Epoch 1868/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2300 - accuracy: 0.9168\n",
            "Epoch 1868: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2274 - accuracy: 0.9175 - val_loss: 1.0495 - val_accuracy: 0.8182\n",
            "Epoch 1869/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.2219 - accuracy: 0.9186\n",
            "Epoch 1869: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2148 - accuracy: 0.9211 - val_loss: 0.9751 - val_accuracy: 0.8390\n",
            "Epoch 1870/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1408 - accuracy: 0.9497\n",
            "Epoch 1870: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1424 - accuracy: 0.9486 - val_loss: 1.0259 - val_accuracy: 0.8230\n",
            "Epoch 1871/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.4575 - accuracy: 0.8570\n",
            "Epoch 1871: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.4554 - accuracy: 0.8577 - val_loss: 1.1090 - val_accuracy: 0.7987\n",
            "Epoch 1872/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1529 - accuracy: 0.9445\n",
            "Epoch 1872: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1554 - accuracy: 0.9434 - val_loss: 1.1256 - val_accuracy: 0.7987\n",
            "Epoch 1873/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1368 - accuracy: 0.9491\n",
            "Epoch 1873: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1368 - accuracy: 0.9491 - val_loss: 0.9550 - val_accuracy: 0.8431\n",
            "Epoch 1874/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1141 - accuracy: 0.9618\n",
            "Epoch 1874: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1157 - accuracy: 0.9614 - val_loss: 0.9265 - val_accuracy: 0.8460\n",
            "Epoch 1875/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2035 - accuracy: 0.9292\n",
            "Epoch 1875: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2015 - accuracy: 0.9297 - val_loss: 0.9774 - val_accuracy: 0.8380\n",
            "Epoch 1876/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1349 - accuracy: 0.9495\n",
            "Epoch 1876: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1347 - accuracy: 0.9496 - val_loss: 0.9506 - val_accuracy: 0.8364\n",
            "Epoch 1877/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1097 - accuracy: 0.9624\n",
            "Epoch 1877: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1104 - accuracy: 0.9621 - val_loss: 0.9054 - val_accuracy: 0.8489\n",
            "Epoch 1878/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1654 - accuracy: 0.9378\n",
            "Epoch 1878: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1654 - accuracy: 0.9375 - val_loss: 0.9950 - val_accuracy: 0.8265\n",
            "Epoch 1879/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1505 - accuracy: 0.9446\n",
            "Epoch 1879: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1515 - accuracy: 0.9441 - val_loss: 1.0372 - val_accuracy: 0.8175\n",
            "Epoch 1880/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.3423 - accuracy: 0.8905\n",
            "Epoch 1880: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3414 - accuracy: 0.8908 - val_loss: 1.4367 - val_accuracy: 0.7590\n",
            "Epoch 1881/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1824 - accuracy: 0.9340\n",
            "Epoch 1881: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1796 - accuracy: 0.9349 - val_loss: 1.0581 - val_accuracy: 0.8233\n",
            "Epoch 1882/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1412 - accuracy: 0.9488\n",
            "Epoch 1882: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1414 - accuracy: 0.9484 - val_loss: 0.9913 - val_accuracy: 0.8316\n",
            "Epoch 1883/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1678 - accuracy: 0.9372\n",
            "Epoch 1883: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1678 - accuracy: 0.9379 - val_loss: 1.0593 - val_accuracy: 0.8361\n",
            "Epoch 1884/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2280 - accuracy: 0.9181\n",
            "Epoch 1884: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2280 - accuracy: 0.9181 - val_loss: 0.9889 - val_accuracy: 0.8303\n",
            "Epoch 1885/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1699 - accuracy: 0.9381\n",
            "Epoch 1885: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1698 - accuracy: 0.9381 - val_loss: 1.0617 - val_accuracy: 0.8243\n",
            "Epoch 1886/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3906 - accuracy: 0.8868\n",
            "Epoch 1886: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3906 - accuracy: 0.8868 - val_loss: 1.2976 - val_accuracy: 0.7695\n",
            "Epoch 1887/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1947 - accuracy: 0.9267\n",
            "Epoch 1887: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1973 - accuracy: 0.9258 - val_loss: 1.2219 - val_accuracy: 0.7769\n",
            "Epoch 1888/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1662 - accuracy: 0.9401\n",
            "Epoch 1888: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1663 - accuracy: 0.9400 - val_loss: 0.9278 - val_accuracy: 0.8367\n",
            "Epoch 1889/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1656 - accuracy: 0.9405\n",
            "Epoch 1889: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1654 - accuracy: 0.9406 - val_loss: 0.9925 - val_accuracy: 0.8310\n",
            "Epoch 1890/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1222 - accuracy: 0.9572\n",
            "Epoch 1890: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1238 - accuracy: 0.9569 - val_loss: 1.0214 - val_accuracy: 0.8313\n",
            "Epoch 1891/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1406 - accuracy: 0.9498\n",
            "Epoch 1891: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1398 - accuracy: 0.9501 - val_loss: 1.0062 - val_accuracy: 0.8361\n",
            "Epoch 1892/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1247 - accuracy: 0.9535\n",
            "Epoch 1892: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1244 - accuracy: 0.9536 - val_loss: 0.9992 - val_accuracy: 0.8297\n",
            "Epoch 1893/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1349 - accuracy: 0.9522\n",
            "Epoch 1893: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1345 - accuracy: 0.9525 - val_loss: 1.0575 - val_accuracy: 0.8335\n",
            "Epoch 1894/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1975 - accuracy: 0.9292\n",
            "Epoch 1894: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1963 - accuracy: 0.9294 - val_loss: 0.9835 - val_accuracy: 0.8396\n",
            "Epoch 1895/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1927 - accuracy: 0.9301\n",
            "Epoch 1895: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1927 - accuracy: 0.9305 - val_loss: 1.4986 - val_accuracy: 0.7369\n",
            "Epoch 1896/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2176 - accuracy: 0.9211\n",
            "Epoch 1896: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2169 - accuracy: 0.9212 - val_loss: 0.9569 - val_accuracy: 0.8355\n",
            "Epoch 1897/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1177 - accuracy: 0.9589\n",
            "Epoch 1897: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1172 - accuracy: 0.9589 - val_loss: 0.9514 - val_accuracy: 0.8419\n",
            "Epoch 1898/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1300 - accuracy: 0.9535\n",
            "Epoch 1898: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1347 - accuracy: 0.9520 - val_loss: 1.0151 - val_accuracy: 0.8300\n",
            "Epoch 1899/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1751 - accuracy: 0.9359\n",
            "Epoch 1899: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1790 - accuracy: 0.9344 - val_loss: 1.0178 - val_accuracy: 0.8265\n",
            "Epoch 1900/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1708 - accuracy: 0.9389\n",
            "Epoch 1900: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1708 - accuracy: 0.9389 - val_loss: 1.0052 - val_accuracy: 0.8284\n",
            "Epoch 1901/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.1365 - accuracy: 0.9495\n",
            "Epoch 1901: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1374 - accuracy: 0.9484 - val_loss: 0.9961 - val_accuracy: 0.8214\n",
            "Epoch 1902/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1537 - accuracy: 0.9436\n",
            "Epoch 1902: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1541 - accuracy: 0.9433 - val_loss: 1.0077 - val_accuracy: 0.8259\n",
            "Epoch 1903/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1745 - accuracy: 0.9363\n",
            "Epoch 1903: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1766 - accuracy: 0.9360 - val_loss: 1.1095 - val_accuracy: 0.8038\n",
            "Epoch 1904/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.4559 - accuracy: 0.8586\n",
            "Epoch 1904: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4519 - accuracy: 0.8592 - val_loss: 1.1335 - val_accuracy: 0.8079\n",
            "Epoch 1905/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.4363 - accuracy: 0.8710\n",
            "Epoch 1905: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4179 - accuracy: 0.8754 - val_loss: 0.9598 - val_accuracy: 0.8438\n",
            "Epoch 1906/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1351 - accuracy: 0.9514\n",
            "Epoch 1906: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1351 - accuracy: 0.9514 - val_loss: 0.9802 - val_accuracy: 0.8358\n",
            "Epoch 1907/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1398 - accuracy: 0.9464\n",
            "Epoch 1907: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1391 - accuracy: 0.9467 - val_loss: 0.9639 - val_accuracy: 0.8464\n",
            "Epoch 1908/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1165 - accuracy: 0.9584\n",
            "Epoch 1908: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1163 - accuracy: 0.9585 - val_loss: 0.9604 - val_accuracy: 0.8448\n",
            "Epoch 1909/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1073 - accuracy: 0.9629\n",
            "Epoch 1909: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1071 - accuracy: 0.9631 - val_loss: 0.9295 - val_accuracy: 0.8454\n",
            "Epoch 1910/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1512 - accuracy: 0.9445\n",
            "Epoch 1910: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1507 - accuracy: 0.9446 - val_loss: 0.9195 - val_accuracy: 0.8480\n",
            "Epoch 1911/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1344 - accuracy: 0.9519\n",
            "Epoch 1911: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1362 - accuracy: 0.9511 - val_loss: 0.9802 - val_accuracy: 0.8342\n",
            "Epoch 1912/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1424 - accuracy: 0.9475\n",
            "Epoch 1912: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1420 - accuracy: 0.9478 - val_loss: 1.0208 - val_accuracy: 0.8348\n",
            "Epoch 1913/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1624 - accuracy: 0.9401\n",
            "Epoch 1913: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1633 - accuracy: 0.9399 - val_loss: 1.2005 - val_accuracy: 0.7955\n",
            "Epoch 1914/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1967 - accuracy: 0.9267\n",
            "Epoch 1914: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1965 - accuracy: 0.9271 - val_loss: 0.9657 - val_accuracy: 0.8268\n",
            "Epoch 1915/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1361 - accuracy: 0.9498\n",
            "Epoch 1915: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1352 - accuracy: 0.9504 - val_loss: 0.9577 - val_accuracy: 0.8480\n",
            "Epoch 1916/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1494 - accuracy: 0.9466\n",
            "Epoch 1916: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1538 - accuracy: 0.9456 - val_loss: 1.3877 - val_accuracy: 0.7558\n",
            "Epoch 1917/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2193 - accuracy: 0.9195\n",
            "Epoch 1917: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2192 - accuracy: 0.9193 - val_loss: 1.0641 - val_accuracy: 0.8204\n",
            "Epoch 1918/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.3358 - accuracy: 0.8950\n",
            "Epoch 1918: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3575 - accuracy: 0.8927 - val_loss: 1.8840 - val_accuracy: 0.6994\n",
            "Epoch 1919/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.7900 - accuracy: 0.8315\n",
            "Epoch 1919: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.7799 - accuracy: 0.8331 - val_loss: 1.0547 - val_accuracy: 0.8281\n",
            "Epoch 1920/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1509 - accuracy: 0.9461\n",
            "Epoch 1920: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1476 - accuracy: 0.9469 - val_loss: 0.9329 - val_accuracy: 0.8499\n",
            "Epoch 1921/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1150 - accuracy: 0.9603\n",
            "Epoch 1921: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1162 - accuracy: 0.9597 - val_loss: 0.9574 - val_accuracy: 0.8419\n",
            "Epoch 1922/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1223 - accuracy: 0.9565\n",
            "Epoch 1922: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1213 - accuracy: 0.9571 - val_loss: 0.9589 - val_accuracy: 0.8355\n",
            "Epoch 1923/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1124 - accuracy: 0.9612\n",
            "Epoch 1923: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1128 - accuracy: 0.9607 - val_loss: 0.9884 - val_accuracy: 0.8332\n",
            "Epoch 1924/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1252 - accuracy: 0.9554\n",
            "Epoch 1924: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1251 - accuracy: 0.9555 - val_loss: 1.0898 - val_accuracy: 0.8121\n",
            "Epoch 1925/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1244 - accuracy: 0.9555\n",
            "Epoch 1925: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1260 - accuracy: 0.9553 - val_loss: 0.9506 - val_accuracy: 0.8409\n",
            "Epoch 1926/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1451 - accuracy: 0.9469\n",
            "Epoch 1926: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1426 - accuracy: 0.9478 - val_loss: 0.9309 - val_accuracy: 0.8483\n",
            "Epoch 1927/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1212 - accuracy: 0.9584\n",
            "Epoch 1927: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1214 - accuracy: 0.9581 - val_loss: 1.0493 - val_accuracy: 0.8351\n",
            "Epoch 1928/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1303 - accuracy: 0.9523\n",
            "Epoch 1928: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1305 - accuracy: 0.9522 - val_loss: 0.9222 - val_accuracy: 0.8502\n",
            "Epoch 1929/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2084 - accuracy: 0.9248\n",
            "Epoch 1929: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2160 - accuracy: 0.9227 - val_loss: 1.2608 - val_accuracy: 0.7891\n",
            "Epoch 1930/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1588 - accuracy: 0.9426\n",
            "Epoch 1930: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1599 - accuracy: 0.9419 - val_loss: 1.0516 - val_accuracy: 0.8188\n",
            "Epoch 1931/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1329 - accuracy: 0.9517\n",
            "Epoch 1931: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1325 - accuracy: 0.9519 - val_loss: 0.9333 - val_accuracy: 0.8387\n",
            "Epoch 1932/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.2610 - accuracy: 0.9105\n",
            "Epoch 1932: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2581 - accuracy: 0.9112 - val_loss: 0.9654 - val_accuracy: 0.8403\n",
            "Epoch 1933/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1798 - accuracy: 0.9349\n",
            "Epoch 1933: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1790 - accuracy: 0.9354 - val_loss: 1.0684 - val_accuracy: 0.8204\n",
            "Epoch 1934/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1525 - accuracy: 0.9444\n",
            "Epoch 1934: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1503 - accuracy: 0.9453 - val_loss: 1.0276 - val_accuracy: 0.8278\n",
            "Epoch 1935/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2149 - accuracy: 0.9227\n",
            "Epoch 1935: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2149 - accuracy: 0.9227 - val_loss: 0.9623 - val_accuracy: 0.8335\n",
            "Epoch 1936/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2478 - accuracy: 0.9185\n",
            "Epoch 1936: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.2499 - accuracy: 0.9178 - val_loss: 1.1582 - val_accuracy: 0.7996\n",
            "Epoch 1937/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2520 - accuracy: 0.9087\n",
            "Epoch 1937: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2522 - accuracy: 0.9087 - val_loss: 1.0868 - val_accuracy: 0.8182\n",
            "Epoch 1938/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1628 - accuracy: 0.9410\n",
            "Epoch 1938: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1602 - accuracy: 0.9413 - val_loss: 1.0807 - val_accuracy: 0.8207\n",
            "Epoch 1939/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1327 - accuracy: 0.9521\n",
            "Epoch 1939: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1361 - accuracy: 0.9507 - val_loss: 1.0472 - val_accuracy: 0.8249\n",
            "Epoch 1940/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1516 - accuracy: 0.9448\n",
            "Epoch 1940: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1509 - accuracy: 0.9450 - val_loss: 1.0131 - val_accuracy: 0.8278\n",
            "Epoch 1941/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.1605 - accuracy: 0.9417\n",
            "Epoch 1941: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1742 - accuracy: 0.9369 - val_loss: 1.1901 - val_accuracy: 0.7865\n",
            "Epoch 1942/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.2126 - accuracy: 0.9221\n",
            "Epoch 1942: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2115 - accuracy: 0.9221 - val_loss: 1.0892 - val_accuracy: 0.8153\n",
            "Epoch 1943/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1859 - accuracy: 0.9317\n",
            "Epoch 1943: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1864 - accuracy: 0.9314 - val_loss: 0.9740 - val_accuracy: 0.8358\n",
            "Epoch 1944/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1417 - accuracy: 0.9475\n",
            "Epoch 1944: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1414 - accuracy: 0.9477 - val_loss: 1.4141 - val_accuracy: 0.7478\n",
            "Epoch 1945/2000\n",
            "89/98 [==========================>...] - ETA: 0s - loss: 0.4348 - accuracy: 0.8716\n",
            "Epoch 1945: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4144 - accuracy: 0.8758 - val_loss: 1.0119 - val_accuracy: 0.8300\n",
            "Epoch 1946/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1558 - accuracy: 0.9448\n",
            "Epoch 1946: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1537 - accuracy: 0.9451 - val_loss: 1.0129 - val_accuracy: 0.8319\n",
            "Epoch 1947/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1454 - accuracy: 0.9464\n",
            "Epoch 1947: val_accuracy did not improve from 0.85403\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1464 - accuracy: 0.9457 - val_loss: 1.0024 - val_accuracy: 0.8262\n",
            "Epoch 1948/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1518 - accuracy: 0.9459\n",
            "Epoch 1948: val_accuracy improved from 0.85403 to 0.85435, saving model to /content/asl1/Adam4/cp-1948-0.85.hdf5\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1518 - accuracy: 0.9458 - val_loss: 0.9447 - val_accuracy: 0.8544\n",
            "Epoch 1949/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1308 - accuracy: 0.9505\n",
            "Epoch 1949: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1302 - accuracy: 0.9507 - val_loss: 0.9789 - val_accuracy: 0.8399\n",
            "Epoch 1950/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1108 - accuracy: 0.9605\n",
            "Epoch 1950: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1108 - accuracy: 0.9605 - val_loss: 0.9600 - val_accuracy: 0.8419\n",
            "Epoch 1951/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1299 - accuracy: 0.9514\n",
            "Epoch 1951: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1298 - accuracy: 0.9514 - val_loss: 1.0135 - val_accuracy: 0.8371\n",
            "Epoch 1952/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1744 - accuracy: 0.9393\n",
            "Epoch 1952: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1801 - accuracy: 0.9374 - val_loss: 1.0997 - val_accuracy: 0.7987\n",
            "Epoch 1953/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.2769 - accuracy: 0.9041\n",
            "Epoch 1953: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2758 - accuracy: 0.9041 - val_loss: 1.0509 - val_accuracy: 0.8204\n",
            "Epoch 1954/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1641 - accuracy: 0.9397\n",
            "Epoch 1954: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1653 - accuracy: 0.9388 - val_loss: 1.1057 - val_accuracy: 0.8108\n",
            "Epoch 1955/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1690 - accuracy: 0.9374\n",
            "Epoch 1955: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1680 - accuracy: 0.9378 - val_loss: 0.9666 - val_accuracy: 0.8422\n",
            "Epoch 1956/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1294 - accuracy: 0.9548\n",
            "Epoch 1956: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1297 - accuracy: 0.9548 - val_loss: 0.9517 - val_accuracy: 0.8419\n",
            "Epoch 1957/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1532 - accuracy: 0.9423\n",
            "Epoch 1957: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1558 - accuracy: 0.9413 - val_loss: 0.9906 - val_accuracy: 0.8249\n",
            "Epoch 1958/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1571 - accuracy: 0.9427\n",
            "Epoch 1958: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1551 - accuracy: 0.9433 - val_loss: 0.9773 - val_accuracy: 0.8377\n",
            "Epoch 1959/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1915 - accuracy: 0.9285\n",
            "Epoch 1959: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1915 - accuracy: 0.9285 - val_loss: 1.0399 - val_accuracy: 0.8204\n",
            "Epoch 1960/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1948 - accuracy: 0.9311\n",
            "Epoch 1960: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1925 - accuracy: 0.9318 - val_loss: 1.0281 - val_accuracy: 0.8310\n",
            "Epoch 1961/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.2477 - accuracy: 0.9103\n",
            "Epoch 1961: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2516 - accuracy: 0.9084 - val_loss: 1.0666 - val_accuracy: 0.8239\n",
            "Epoch 1962/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2261 - accuracy: 0.9222\n",
            "Epoch 1962: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2195 - accuracy: 0.9245 - val_loss: 0.9908 - val_accuracy: 0.8303\n",
            "Epoch 1963/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.9020 - accuracy: 0.8351\n",
            "Epoch 1963: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.8988 - accuracy: 0.8339 - val_loss: 1.8848 - val_accuracy: 0.6972\n",
            "Epoch 1964/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2879 - accuracy: 0.9034\n",
            "Epoch 1964: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2812 - accuracy: 0.9051 - val_loss: 1.0283 - val_accuracy: 0.8339\n",
            "Epoch 1965/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1189 - accuracy: 0.9582\n",
            "Epoch 1965: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1188 - accuracy: 0.9583 - val_loss: 0.9830 - val_accuracy: 0.8374\n",
            "Epoch 1966/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.1161 - accuracy: 0.9597\n",
            "Epoch 1966: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1165 - accuracy: 0.9596 - val_loss: 0.9280 - val_accuracy: 0.8540\n",
            "Epoch 1967/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1046 - accuracy: 0.9642\n",
            "Epoch 1967: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1071 - accuracy: 0.9628 - val_loss: 1.0463 - val_accuracy: 0.8233\n",
            "Epoch 1968/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1159 - accuracy: 0.9582\n",
            "Epoch 1968: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1155 - accuracy: 0.9584 - val_loss: 0.9362 - val_accuracy: 0.8431\n",
            "Epoch 1969/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1155 - accuracy: 0.9595\n",
            "Epoch 1969: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1153 - accuracy: 0.9595 - val_loss: 0.9656 - val_accuracy: 0.8399\n",
            "Epoch 1970/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1328 - accuracy: 0.9519\n",
            "Epoch 1970: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1305 - accuracy: 0.9527 - val_loss: 0.9442 - val_accuracy: 0.8412\n",
            "Epoch 1971/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1414 - accuracy: 0.9464\n",
            "Epoch 1971: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1482 - accuracy: 0.9447 - val_loss: 1.1023 - val_accuracy: 0.8076\n",
            "Epoch 1972/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.1642 - accuracy: 0.9391\n",
            "Epoch 1972: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1638 - accuracy: 0.9391 - val_loss: 0.9795 - val_accuracy: 0.8348\n",
            "Epoch 1973/2000\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.1269 - accuracy: 0.9535\n",
            "Epoch 1973: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1268 - accuracy: 0.9536 - val_loss: 0.9921 - val_accuracy: 0.8412\n",
            "Epoch 1974/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1364 - accuracy: 0.9505\n",
            "Epoch 1974: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1374 - accuracy: 0.9499 - val_loss: 0.9594 - val_accuracy: 0.8435\n",
            "Epoch 1975/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1315 - accuracy: 0.9532\n",
            "Epoch 1975: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1311 - accuracy: 0.9533 - val_loss: 0.9419 - val_accuracy: 0.8387\n",
            "Epoch 1976/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1184 - accuracy: 0.9583\n",
            "Epoch 1976: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1221 - accuracy: 0.9569 - val_loss: 1.1207 - val_accuracy: 0.8102\n",
            "Epoch 1977/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1885 - accuracy: 0.9328\n",
            "Epoch 1977: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1865 - accuracy: 0.9336 - val_loss: 0.9795 - val_accuracy: 0.8355\n",
            "Epoch 1978/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1120 - accuracy: 0.9604\n",
            "Epoch 1978: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1138 - accuracy: 0.9596 - val_loss: 0.9853 - val_accuracy: 0.8431\n",
            "Epoch 1979/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1533 - accuracy: 0.9417\n",
            "Epoch 1979: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1541 - accuracy: 0.9412 - val_loss: 1.0072 - val_accuracy: 0.8431\n",
            "Epoch 1980/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1620 - accuracy: 0.9399\n",
            "Epoch 1980: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1620 - accuracy: 0.9399 - val_loss: 1.0437 - val_accuracy: 0.8367\n",
            "Epoch 1981/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1517 - accuracy: 0.9453\n",
            "Epoch 1981: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1517 - accuracy: 0.9453 - val_loss: 1.0224 - val_accuracy: 0.8243\n",
            "Epoch 1982/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.4209 - accuracy: 0.8725\n",
            "Epoch 1982: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4314 - accuracy: 0.8704 - val_loss: 1.6530 - val_accuracy: 0.7289\n",
            "Epoch 1983/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.2280 - accuracy: 0.9211\n",
            "Epoch 1983: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2264 - accuracy: 0.9217 - val_loss: 1.0421 - val_accuracy: 0.8201\n",
            "Epoch 1984/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1187 - accuracy: 0.9573\n",
            "Epoch 1984: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1185 - accuracy: 0.9574 - val_loss: 1.0233 - val_accuracy: 0.8316\n",
            "Epoch 1985/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.1584 - accuracy: 0.9409\n",
            "Epoch 1985: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1613 - accuracy: 0.9402 - val_loss: 1.3938 - val_accuracy: 0.7500\n",
            "Epoch 1986/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1362 - accuracy: 0.9502\n",
            "Epoch 1986: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1369 - accuracy: 0.9497 - val_loss: 0.9600 - val_accuracy: 0.8387\n",
            "Epoch 1987/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.1234 - accuracy: 0.9563\n",
            "Epoch 1987: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1231 - accuracy: 0.9562 - val_loss: 0.9047 - val_accuracy: 0.8502\n",
            "Epoch 1988/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2222 - accuracy: 0.9186\n",
            "Epoch 1988: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2254 - accuracy: 0.9173 - val_loss: 1.1608 - val_accuracy: 0.8092\n",
            "Epoch 1989/2000\n",
            "95/98 [============================>.] - ETA: 0s - loss: 0.2094 - accuracy: 0.9248\n",
            "Epoch 1989: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.2086 - accuracy: 0.9248 - val_loss: 1.2056 - val_accuracy: 0.7820\n",
            "Epoch 1990/2000\n",
            "91/98 [==========================>...] - ETA: 0s - loss: 0.1594 - accuracy: 0.9412\n",
            "Epoch 1990: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1616 - accuracy: 0.9397 - val_loss: 1.0286 - val_accuracy: 0.8169\n",
            "Epoch 1991/2000\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1441 - accuracy: 0.9480\n",
            "Epoch 1991: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1441 - accuracy: 0.9480 - val_loss: 1.0416 - val_accuracy: 0.8198\n",
            "Epoch 1992/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1461 - accuracy: 0.9465\n",
            "Epoch 1992: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1483 - accuracy: 0.9457 - val_loss: 1.0488 - val_accuracy: 0.8252\n",
            "Epoch 1993/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1673 - accuracy: 0.9368\n",
            "Epoch 1993: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 0.1670 - accuracy: 0.9369 - val_loss: 0.9850 - val_accuracy: 0.8371\n",
            "Epoch 1994/2000\n",
            "96/98 [============================>.] - ETA: 0s - loss: 0.1760 - accuracy: 0.9351\n",
            "Epoch 1994: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.1754 - accuracy: 0.9353 - val_loss: 0.9864 - val_accuracy: 0.8294\n",
            "Epoch 1995/2000\n",
            "94/98 [===========================>..] - ETA: 0s - loss: 0.3381 - accuracy: 0.8915\n",
            "Epoch 1995: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3308 - accuracy: 0.8937 - val_loss: 1.0802 - val_accuracy: 0.8188\n",
            "Epoch 1996/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1257 - accuracy: 0.9563\n",
            "Epoch 1996: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.1270 - accuracy: 0.9553 - val_loss: 0.9729 - val_accuracy: 0.8367\n",
            "Epoch 1997/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.2049 - accuracy: 0.9244\n",
            "Epoch 1997: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.2143 - accuracy: 0.9212 - val_loss: 1.2599 - val_accuracy: 0.7721\n",
            "Epoch 1998/2000\n",
            "90/98 [==========================>...] - ETA: 0s - loss: 0.1981 - accuracy: 0.9280\n",
            "Epoch 1998: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.1939 - accuracy: 0.9293 - val_loss: 1.0289 - val_accuracy: 0.8201\n",
            "Epoch 1999/2000\n",
            "93/98 [===========================>..] - ETA: 0s - loss: 0.5349 - accuracy: 0.8627\n",
            "Epoch 1999: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.5740 - accuracy: 0.8562 - val_loss: 2.2840 - val_accuracy: 0.6450\n",
            "Epoch 2000/2000\n",
            "92/98 [===========================>..] - ETA: 0s - loss: 0.3539 - accuracy: 0.8927\n",
            "Epoch 2000: val_accuracy did not improve from 0.85435\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.3428 - accuracy: 0.8953 - val_loss: 1.0110 - val_accuracy: 0.8252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# plot hsitory of trainig"
      ],
      "metadata": {
        "id": "hFQTglAtPNOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(history2,2000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "MqFOrgouPNUa",
        "outputId": "49a3819a-6833-4ef9-962b-e96656214a02"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion matrix"
      ],
      "metadata": {
        "id": "U4iqDt07PJr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have a model and history object\n",
        "\n",
        "# Get the predicted and true labels\n",
        "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "y_true = y_test_encoded\n",
        "\n",
        "# Compute confusion matrix\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(conf_matrix, cmap='Blues')\n",
        "plt.colorbar()\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.xticks(np.arange(len(conf_matrix)), labels=class_names)\n",
        "plt.yticks(np.arange(len(conf_matrix)), labels=class_names)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "vgv21bGUN_8V",
        "outputId": "111467ba-5f90-4013-ea8c-02c0b3783d41"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7d201bffbb50> and will run it as-is.\n",
            "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x7d201bffbb50>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7d201bffbb50> and will run it as-is.\n",
            "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x7d201bffbb50>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "98/98 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zsppm-6O8cg",
        "outputId": "63d3c6eb-0803-41b6-e6c3-fa1de2465549"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.7596\n",
            "Recall: 0.7132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pancing the data set"
      ],
      "metadata": {
        "id": "jxcSb8_V6PS3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## before"
      ],
      "metadata": {
        "id": "0FWkA06Y6Uni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.subfolder.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcyaSwWN6WMM",
        "outputId": "9ab41032-8c5c-4f35-d48f-e99871a9b029"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Short             201\n",
              "Reading (1)       201\n",
              "Stupid            201\n",
              "Medical School    201\n",
              "Psychology        193\n",
              "                 ... \n",
              "Yesterday2 (1)     58\n",
              "Yesterday (1)      57\n",
              "Specialization     57\n",
              "Boasts             53\n",
              "Sends              53\n",
              "Name: subfolder, Length: 174, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label='subfolder'\n",
        "\n",
        "g = df[['all_future','subfolder']].groupby(label, group_keys=False)\n",
        "balanced_df = pd.DataFrame(g.apply(lambda x: x.sample(g.size().min()))).reset_index(drop=True)\n",
        "balanced_df.subfolder.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNSLrPZD6OWk",
        "outputId": "98359e1e-2675-49f1-9523-757b74393808"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Yesterday2 (1)    53\n",
              "Above             53\n",
              "Accounting        53\n",
              "Active            53\n",
              "Addition          53\n",
              "                  ..\n",
              "Annoyed (1)       53\n",
              "Apologizes        53\n",
              "Bell (1)          53\n",
              "Benefit           53\n",
              "Bigger            53\n",
              "Name: subfolder, Length: 174, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "X=np.asarray(balanced_df['all_future'])\n",
        "X = np.array(X.tolist())\n",
        "X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, balanced_df['subfolder'], test_size=0.2, random_state=42)\n",
        "# Initialize the LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit and transform the target classes (y_train and y_test)\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)"
      ],
      "metadata": {
        "id": "eXm3JF3N7E5I"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 174\n",
        "\n",
        "model = Sequential()\n",
        "model.add(GRU(256, return_sequences=True, input_shape=(1, 543)))\n",
        "model.add(GRU(128 ))\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "filepath       = \"/content/asl/Adam3/cp-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint     = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history2 = model.fit(X_train, y_train_encoded, validation_data=(X_test, y_test_encoded), epochs=700, batch_size=128,callbacks=callbacks_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTiJ0hyp65qq",
        "outputId": "1a1c3f57-c576-4559-e6e7-7a3269132da0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_4 (GRU)                 (None, 1, 256)            615168    \n",
            "                                                                 \n",
            " gru_5 (GRU)                 (None, 128)               148224    \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 174)               44718     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 841134 (3.21 MB)\n",
            "Trainable params: 841134 (3.21 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 5.1466 - accuracy: 0.0070\n",
            "Epoch 1: val_accuracy improved from -inf to 0.00867, saving model to /content/asl/Adam3/cp-01-0.01.hdf5\n",
            "58/58 [==============================] - 5s 18ms/step - loss: 5.1466 - accuracy: 0.0070 - val_loss: 5.0525 - val_accuracy: 0.0087\n",
            "Epoch 2/700\n",
            "19/58 [========>.....................] - ETA: 0s - loss: 4.9862 - accuracy: 0.0127"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "56/58 [===========================>..] - ETA: 0s - loss: 4.9524 - accuracy: 0.0116\n",
            "Epoch 2: val_accuracy improved from 0.00867 to 0.01301, saving model to /content/asl/Adam3/cp-02-0.01.hdf5\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.9510 - accuracy: 0.0114 - val_loss: 4.9147 - val_accuracy: 0.0130\n",
            "Epoch 3/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 4.8270 - accuracy: 0.0197\n",
            "Epoch 3: val_accuracy improved from 0.01301 to 0.02222, saving model to /content/asl/Adam3/cp-03-0.02.hdf5\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.8273 - accuracy: 0.0199 - val_loss: 4.8031 - val_accuracy: 0.0222\n",
            "Epoch 4/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 4.7011 - accuracy: 0.0286\n",
            "Epoch 4: val_accuracy improved from 0.02222 to 0.02439, saving model to /content/asl/Adam3/cp-04-0.02.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 4.6982 - accuracy: 0.0286 - val_loss: 4.6594 - val_accuracy: 0.0244\n",
            "Epoch 5/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 4.5426 - accuracy: 0.0374\n",
            "Epoch 5: val_accuracy improved from 0.02439 to 0.04499, saving model to /content/asl/Adam3/cp-05-0.04.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 4.5426 - accuracy: 0.0374 - val_loss: 4.4824 - val_accuracy: 0.0450\n",
            "Epoch 6/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 4.3597 - accuracy: 0.0487\n",
            "Epoch 6: val_accuracy improved from 0.04499 to 0.05908, saving model to /content/asl/Adam3/cp-06-0.06.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 4.3494 - accuracy: 0.0481 - val_loss: 4.3267 - val_accuracy: 0.0591\n",
            "Epoch 7/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 4.0861 - accuracy: 0.0805\n",
            "Epoch 7: val_accuracy improved from 0.05908 to 0.06992, saving model to /content/asl/Adam3/cp-07-0.07.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 4.0832 - accuracy: 0.0798 - val_loss: 4.1547 - val_accuracy: 0.0699\n",
            "Epoch 8/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 3.8837 - accuracy: 0.0903\n",
            "Epoch 8: val_accuracy improved from 0.06992 to 0.09756, saving model to /content/asl/Adam3/cp-08-0.10.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.8785 - accuracy: 0.0912 - val_loss: 3.8393 - val_accuracy: 0.0976\n",
            "Epoch 9/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 3.7313 - accuracy: 0.1095\n",
            "Epoch 9: val_accuracy improved from 0.09756 to 0.11274, saving model to /content/asl/Adam3/cp-09-0.11.hdf5\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 3.7275 - accuracy: 0.1097 - val_loss: 3.7158 - val_accuracy: 0.1127\n",
            "Epoch 10/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 3.5716 - accuracy: 0.1309\n",
            "Epoch 10: val_accuracy improved from 0.11274 to 0.12791, saving model to /content/asl/Adam3/cp-10-0.13.hdf5\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 3.5617 - accuracy: 0.1338 - val_loss: 3.6230 - val_accuracy: 0.1279\n",
            "Epoch 11/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 3.5163 - accuracy: 0.1376\n",
            "Epoch 11: val_accuracy did not improve from 0.12791\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 3.5136 - accuracy: 0.1381 - val_loss: 3.7051 - val_accuracy: 0.1068\n",
            "Epoch 12/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 3.3811 - accuracy: 0.1614\n",
            "Epoch 12: val_accuracy improved from 0.12791 to 0.16369, saving model to /content/asl/Adam3/cp-12-0.16.hdf5\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 3.3781 - accuracy: 0.1601 - val_loss: 3.3708 - val_accuracy: 0.1637\n",
            "Epoch 13/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 3.2318 - accuracy: 0.1830\n",
            "Epoch 13: val_accuracy improved from 0.16369 to 0.16640, saving model to /content/asl/Adam3/cp-13-0.17.hdf5\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 3.2299 - accuracy: 0.1834 - val_loss: 3.3956 - val_accuracy: 0.1664\n",
            "Epoch 14/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 3.1656 - accuracy: 0.1896\n",
            "Epoch 14: val_accuracy did not improve from 0.16640\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 3.1717 - accuracy: 0.1872 - val_loss: 3.2865 - val_accuracy: 0.1621\n",
            "Epoch 15/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 3.1394 - accuracy: 0.1899\n",
            "Epoch 15: val_accuracy improved from 0.16640 to 0.20217, saving model to /content/asl/Adam3/cp-15-0.20.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.1397 - accuracy: 0.1902 - val_loss: 3.1028 - val_accuracy: 0.2022\n",
            "Epoch 16/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 2.9840 - accuracy: 0.2237\n",
            "Epoch 16: val_accuracy improved from 0.20217 to 0.23957, saving model to /content/asl/Adam3/cp-16-0.24.hdf5\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9704 - accuracy: 0.2269 - val_loss: 2.9863 - val_accuracy: 0.2396\n",
            "Epoch 17/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 2.8551 - accuracy: 0.2505\n",
            "Epoch 17: val_accuracy improved from 0.23957 to 0.26341, saving model to /content/asl/Adam3/cp-17-0.26.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8553 - accuracy: 0.2504 - val_loss: 2.8849 - val_accuracy: 0.2634\n",
            "Epoch 18/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 2.7637 - accuracy: 0.2609\n",
            "Epoch 18: val_accuracy did not improve from 0.26341\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7653 - accuracy: 0.2601 - val_loss: 2.9879 - val_accuracy: 0.2249\n",
            "Epoch 19/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 2.7504 - accuracy: 0.2486\n",
            "Epoch 19: val_accuracy did not improve from 0.26341\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7555 - accuracy: 0.2477 - val_loss: 2.9363 - val_accuracy: 0.2320\n",
            "Epoch 20/700\n",
            "50/58 [========================>.....] - ETA: 0s - loss: 2.8086 - accuracy: 0.2417\n",
            "Epoch 20: val_accuracy did not improve from 0.26341\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 2.8134 - accuracy: 0.2407 - val_loss: 2.8559 - val_accuracy: 0.2385\n",
            "Epoch 21/700\n",
            "49/58 [========================>.....] - ETA: 0s - loss: 2.6453 - accuracy: 0.2785\n",
            "Epoch 21: val_accuracy improved from 0.26341 to 0.29431, saving model to /content/asl/Adam3/cp-21-0.29.hdf5\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.6479 - accuracy: 0.2756 - val_loss: 2.7217 - val_accuracy: 0.2943\n",
            "Epoch 22/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 2.6090 - accuracy: 0.2801\n",
            "Epoch 22: val_accuracy did not improve from 0.29431\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.6059 - accuracy: 0.2811 - val_loss: 2.7636 - val_accuracy: 0.2499\n",
            "Epoch 23/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 2.6309 - accuracy: 0.2736\n",
            "Epoch 23: val_accuracy did not improve from 0.29431\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.6325 - accuracy: 0.2736 - val_loss: 2.6686 - val_accuracy: 0.2786\n",
            "Epoch 24/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 2.5132 - accuracy: 0.3034\n",
            "Epoch 24: val_accuracy improved from 0.29431 to 0.30732, saving model to /content/asl/Adam3/cp-24-0.31.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5069 - accuracy: 0.3064 - val_loss: 2.5866 - val_accuracy: 0.3073\n",
            "Epoch 25/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 2.4926 - accuracy: 0.3018\n",
            "Epoch 25: val_accuracy did not improve from 0.30732\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.4894 - accuracy: 0.3031 - val_loss: 2.6032 - val_accuracy: 0.2997\n",
            "Epoch 26/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 2.4422 - accuracy: 0.3244\n",
            "Epoch 26: val_accuracy improved from 0.30732 to 0.30840, saving model to /content/asl/Adam3/cp-26-0.31.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.4429 - accuracy: 0.3243 - val_loss: 2.5343 - val_accuracy: 0.3084\n",
            "Epoch 27/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 2.3936 - accuracy: 0.3307\n",
            "Epoch 27: val_accuracy did not improve from 0.30840\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.4089 - accuracy: 0.3256 - val_loss: 2.8504 - val_accuracy: 0.2320\n",
            "Epoch 28/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 2.5177 - accuracy: 0.3010\n",
            "Epoch 28: val_accuracy improved from 0.30840 to 0.32737, saving model to /content/asl/Adam3/cp-28-0.33.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5079 - accuracy: 0.3031 - val_loss: 2.4683 - val_accuracy: 0.3274\n",
            "Epoch 29/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 2.3192 - accuracy: 0.3504\n",
            "Epoch 29: val_accuracy did not improve from 0.32737\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.3286 - accuracy: 0.3459 - val_loss: 2.5447 - val_accuracy: 0.3041\n",
            "Epoch 30/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 2.3189 - accuracy: 0.3368\n",
            "Epoch 30: val_accuracy improved from 0.32737 to 0.34634, saving model to /content/asl/Adam3/cp-30-0.35.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.3176 - accuracy: 0.3385 - val_loss: 2.4005 - val_accuracy: 0.3463\n",
            "Epoch 31/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 2.2154 - accuracy: 0.3714\n",
            "Epoch 31: val_accuracy did not improve from 0.34634\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.2344 - accuracy: 0.3667 - val_loss: 2.6094 - val_accuracy: 0.2894\n",
            "Epoch 32/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 2.2699 - accuracy: 0.3520\n",
            "Epoch 32: val_accuracy did not improve from 0.34634\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.2737 - accuracy: 0.3520 - val_loss: 2.4118 - val_accuracy: 0.3442\n",
            "Epoch 33/700\n",
            "50/58 [========================>.....] - ETA: 0s - loss: 2.1986 - accuracy: 0.3733\n",
            "Epoch 33: val_accuracy improved from 0.34634 to 0.34797, saving model to /content/asl/Adam3/cp-33-0.35.hdf5\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 2.1815 - accuracy: 0.3779 - val_loss: 2.4016 - val_accuracy: 0.3480\n",
            "Epoch 34/700\n",
            "49/58 [========================>.....] - ETA: 0s - loss: 2.2234 - accuracy: 0.3626\n",
            "Epoch 34: val_accuracy improved from 0.34797 to 0.37940, saving model to /content/asl/Adam3/cp-34-0.38.hdf5\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.2316 - accuracy: 0.3609 - val_loss: 2.2817 - val_accuracy: 0.3794\n",
            "Epoch 35/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 2.1162 - accuracy: 0.3954\n",
            "Epoch 35: val_accuracy did not improve from 0.37940\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.1145 - accuracy: 0.3941 - val_loss: 2.5309 - val_accuracy: 0.2840\n",
            "Epoch 36/700\n",
            "50/58 [========================>.....] - ETA: 0s - loss: 2.2414 - accuracy: 0.3539\n",
            "Epoch 36: val_accuracy did not improve from 0.37940\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.2383 - accuracy: 0.3543 - val_loss: 2.3502 - val_accuracy: 0.3485\n",
            "Epoch 37/700\n",
            "49/58 [========================>.....] - ETA: 0s - loss: 2.0836 - accuracy: 0.3999\n",
            "Epoch 37: val_accuracy did not improve from 0.37940\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.0787 - accuracy: 0.4011 - val_loss: 2.4428 - val_accuracy: 0.3176\n",
            "Epoch 38/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 2.1446 - accuracy: 0.3759\n",
            "Epoch 38: val_accuracy improved from 0.37940 to 0.39946, saving model to /content/asl/Adam3/cp-38-0.40.hdf5\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 2.1280 - accuracy: 0.3792 - val_loss: 2.2294 - val_accuracy: 0.3995\n",
            "Epoch 39/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 2.0309 - accuracy: 0.4159\n",
            "Epoch 39: val_accuracy did not improve from 0.39946\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 2.0267 - accuracy: 0.4167 - val_loss: 2.2208 - val_accuracy: 0.3875\n",
            "Epoch 40/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 2.0404 - accuracy: 0.4019\n",
            "Epoch 40: val_accuracy did not improve from 0.39946\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 2.0465 - accuracy: 0.4002 - val_loss: 2.1699 - val_accuracy: 0.3848\n",
            "Epoch 41/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 2.0007 - accuracy: 0.4158\n",
            "Epoch 41: val_accuracy did not improve from 0.39946\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 2.0084 - accuracy: 0.4149 - val_loss: 2.4119 - val_accuracy: 0.3566\n",
            "Epoch 42/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 2.0654 - accuracy: 0.3994\n",
            "Epoch 42: val_accuracy improved from 0.39946 to 0.40596, saving model to /content/asl/Adam3/cp-42-0.41.hdf5\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 2.0661 - accuracy: 0.3985 - val_loss: 2.1321 - val_accuracy: 0.4060\n",
            "Epoch 43/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 1.9074 - accuracy: 0.4431\n",
            "Epoch 43: val_accuracy improved from 0.40596 to 0.41301, saving model to /content/asl/Adam3/cp-43-0.41.hdf5\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.8982 - accuracy: 0.4453 - val_loss: 2.0883 - val_accuracy: 0.4130\n",
            "Epoch 44/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 2.0096 - accuracy: 0.4124\n",
            "Epoch 44: val_accuracy did not improve from 0.41301\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.0053 - accuracy: 0.4117 - val_loss: 2.2277 - val_accuracy: 0.4005\n",
            "Epoch 45/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 1.9613 - accuracy: 0.4219\n",
            "Epoch 45: val_accuracy improved from 0.41301 to 0.43198, saving model to /content/asl/Adam3/cp-45-0.43.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.9578 - accuracy: 0.4223 - val_loss: 2.0787 - val_accuracy: 0.4320\n",
            "Epoch 46/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 1.9668 - accuracy: 0.4113\n",
            "Epoch 46: val_accuracy did not improve from 0.43198\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.9667 - accuracy: 0.4120 - val_loss: 2.4206 - val_accuracy: 0.3301\n",
            "Epoch 47/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 1.9707 - accuracy: 0.4189\n",
            "Epoch 47: val_accuracy did not improve from 0.43198\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.9673 - accuracy: 0.4193 - val_loss: 2.1596 - val_accuracy: 0.4114\n",
            "Epoch 48/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 1.8562 - accuracy: 0.4498\n",
            "Epoch 48: val_accuracy did not improve from 0.43198\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.8653 - accuracy: 0.4477 - val_loss: 2.3594 - val_accuracy: 0.3463\n",
            "Epoch 49/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 1.9225 - accuracy: 0.4292\n",
            "Epoch 49: val_accuracy did not improve from 0.43198\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.9225 - accuracy: 0.4292 - val_loss: 2.1258 - val_accuracy: 0.4043\n",
            "Epoch 50/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 1.7865 - accuracy: 0.4685\n",
            "Epoch 50: val_accuracy did not improve from 0.43198\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.7861 - accuracy: 0.4685 - val_loss: 2.3720 - val_accuracy: 0.3436\n",
            "Epoch 51/700\n",
            "49/58 [========================>.....] - ETA: 0s - loss: 2.0518 - accuracy: 0.3965\n",
            "Epoch 51: val_accuracy did not improve from 0.43198\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.0056 - accuracy: 0.4103 - val_loss: 2.1123 - val_accuracy: 0.4163\n",
            "Epoch 52/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 1.8320 - accuracy: 0.4531\n",
            "Epoch 52: val_accuracy did not improve from 0.43198\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.8344 - accuracy: 0.4525 - val_loss: 2.0679 - val_accuracy: 0.4146\n",
            "Epoch 53/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 1.7794 - accuracy: 0.4657\n",
            "Epoch 53: val_accuracy did not improve from 0.43198\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.7808 - accuracy: 0.4651 - val_loss: 2.2375 - val_accuracy: 0.3713\n",
            "Epoch 54/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 1.8246 - accuracy: 0.4542\n",
            "Epoch 54: val_accuracy did not improve from 0.43198\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.8246 - accuracy: 0.4542 - val_loss: 2.0543 - val_accuracy: 0.4266\n",
            "Epoch 55/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 1.7464 - accuracy: 0.4797\n",
            "Epoch 55: val_accuracy improved from 0.43198 to 0.43577, saving model to /content/asl/Adam3/cp-55-0.44.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.7488 - accuracy: 0.4778 - val_loss: 1.9873 - val_accuracy: 0.4358\n",
            "Epoch 56/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 1.7534 - accuracy: 0.4788\n",
            "Epoch 56: val_accuracy did not improve from 0.43577\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.7534 - accuracy: 0.4788 - val_loss: 2.8573 - val_accuracy: 0.2352\n",
            "Epoch 57/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 1.9118 - accuracy: 0.4275\n",
            "Epoch 57: val_accuracy did not improve from 0.43577\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.8928 - accuracy: 0.4335 - val_loss: 2.0850 - val_accuracy: 0.4184\n",
            "Epoch 58/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 1.7420 - accuracy: 0.4745\n",
            "Epoch 58: val_accuracy improved from 0.43577 to 0.43902, saving model to /content/asl/Adam3/cp-58-0.44.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.7390 - accuracy: 0.4751 - val_loss: 1.9915 - val_accuracy: 0.4390\n",
            "Epoch 59/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 1.6902 - accuracy: 0.4918\n",
            "Epoch 59: val_accuracy improved from 0.43902 to 0.44553, saving model to /content/asl/Adam3/cp-59-0.45.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.6934 - accuracy: 0.4902 - val_loss: 1.9310 - val_accuracy: 0.4455\n",
            "Epoch 60/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 1.7360 - accuracy: 0.4773\n",
            "Epoch 60: val_accuracy did not improve from 0.44553\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.7371 - accuracy: 0.4769 - val_loss: 2.2049 - val_accuracy: 0.3740\n",
            "Epoch 61/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 1.6787 - accuracy: 0.4903\n",
            "Epoch 61: val_accuracy did not improve from 0.44553\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.6807 - accuracy: 0.4885 - val_loss: 1.9727 - val_accuracy: 0.4439\n",
            "Epoch 62/700\n",
            "50/58 [========================>.....] - ETA: 0s - loss: 1.7493 - accuracy: 0.4681\n",
            "Epoch 62: val_accuracy did not improve from 0.44553\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.7455 - accuracy: 0.4690 - val_loss: 2.1148 - val_accuracy: 0.3957\n",
            "Epoch 63/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 1.6656 - accuracy: 0.4910\n",
            "Epoch 63: val_accuracy did not improve from 0.44553\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.6685 - accuracy: 0.4892 - val_loss: 1.9562 - val_accuracy: 0.4444\n",
            "Epoch 64/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 1.6870 - accuracy: 0.4865\n",
            "Epoch 64: val_accuracy did not improve from 0.44553\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.6870 - accuracy: 0.4865 - val_loss: 2.1584 - val_accuracy: 0.3864\n",
            "Epoch 65/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 1.6573 - accuracy: 0.4919\n",
            "Epoch 65: val_accuracy improved from 0.44553 to 0.46721, saving model to /content/asl/Adam3/cp-65-0.47.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.6588 - accuracy: 0.4919 - val_loss: 1.8953 - val_accuracy: 0.4672\n",
            "Epoch 66/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 1.6562 - accuracy: 0.4949\n",
            "Epoch 66: val_accuracy did not improve from 0.46721\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.6527 - accuracy: 0.4961 - val_loss: 1.9867 - val_accuracy: 0.4428\n",
            "Epoch 67/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 1.6256 - accuracy: 0.5015\n",
            "Epoch 67: val_accuracy did not improve from 0.46721\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.6240 - accuracy: 0.5024 - val_loss: 1.9174 - val_accuracy: 0.4607\n",
            "Epoch 68/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 1.5287 - accuracy: 0.5306\n",
            "Epoch 68: val_accuracy improved from 0.46721 to 0.51003, saving model to /content/asl/Adam3/cp-68-0.51.hdf5\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.5369 - accuracy: 0.5298 - val_loss: 1.7795 - val_accuracy: 0.5100\n",
            "Epoch 69/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 1.7254 - accuracy: 0.4757\n",
            "Epoch 69: val_accuracy did not improve from 0.51003\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.7300 - accuracy: 0.4734 - val_loss: 2.2348 - val_accuracy: 0.3642\n",
            "Epoch 70/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 1.5918 - accuracy: 0.5092\n",
            "Epoch 70: val_accuracy did not improve from 0.51003\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.5867 - accuracy: 0.5100 - val_loss: 1.9422 - val_accuracy: 0.4477\n",
            "Epoch 71/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 1.5124 - accuracy: 0.5333\n",
            "Epoch 71: val_accuracy did not improve from 0.51003\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.5244 - accuracy: 0.5319 - val_loss: 1.8414 - val_accuracy: 0.4992\n",
            "Epoch 72/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 1.6540 - accuracy: 0.4940\n",
            "Epoch 72: val_accuracy did not improve from 0.51003\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.6540 - accuracy: 0.4940 - val_loss: 1.8971 - val_accuracy: 0.4461\n",
            "Epoch 73/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 1.5781 - accuracy: 0.5151\n",
            "Epoch 73: val_accuracy did not improve from 0.51003\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.5781 - accuracy: 0.5151 - val_loss: 1.8519 - val_accuracy: 0.4894\n",
            "Epoch 74/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 1.6220 - accuracy: 0.5012\n",
            "Epoch 74: val_accuracy did not improve from 0.51003\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.6220 - accuracy: 0.5012 - val_loss: 1.8651 - val_accuracy: 0.4883\n",
            "Epoch 75/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 1.5610 - accuracy: 0.5179\n",
            "Epoch 75: val_accuracy did not improve from 0.51003\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.5629 - accuracy: 0.5159 - val_loss: 1.8017 - val_accuracy: 0.5057\n",
            "Epoch 76/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 1.4753 - accuracy: 0.5414\n",
            "Epoch 76: val_accuracy did not improve from 0.51003\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.4728 - accuracy: 0.5436 - val_loss: 1.7910 - val_accuracy: 0.4981\n",
            "Epoch 77/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 1.4860 - accuracy: 0.5366\n",
            "Epoch 77: val_accuracy did not improve from 0.51003\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.5016 - accuracy: 0.5322 - val_loss: 1.8340 - val_accuracy: 0.4900\n",
            "Epoch 78/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 1.5229 - accuracy: 0.5265\n",
            "Epoch 78: val_accuracy improved from 0.51003 to 0.52466, saving model to /content/asl/Adam3/cp-78-0.52.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.5226 - accuracy: 0.5268 - val_loss: 1.7138 - val_accuracy: 0.5247\n",
            "Epoch 79/700\n",
            "50/58 [========================>.....] - ETA: 0s - loss: 1.4666 - accuracy: 0.5491\n",
            "Epoch 79: val_accuracy did not improve from 0.52466\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.4741 - accuracy: 0.5460 - val_loss: 1.7190 - val_accuracy: 0.5230\n",
            "Epoch 80/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 1.4481 - accuracy: 0.5512\n",
            "Epoch 80: val_accuracy improved from 0.52466 to 0.52846, saving model to /content/asl/Adam3/cp-80-0.53.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4481 - accuracy: 0.5512 - val_loss: 1.7280 - val_accuracy: 0.5285\n",
            "Epoch 81/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 1.4100 - accuracy: 0.5578\n",
            "Epoch 81: val_accuracy did not improve from 0.52846\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.4087 - accuracy: 0.5581 - val_loss: 1.7566 - val_accuracy: 0.5079\n",
            "Epoch 82/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 1.4738 - accuracy: 0.5366\n",
            "Epoch 82: val_accuracy did not improve from 0.52846\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.4785 - accuracy: 0.5354 - val_loss: 1.7545 - val_accuracy: 0.5144\n",
            "Epoch 83/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 1.5372 - accuracy: 0.5188\n",
            "Epoch 83: val_accuracy did not improve from 0.52846\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.5400 - accuracy: 0.5182 - val_loss: 1.7985 - val_accuracy: 0.4862\n",
            "Epoch 84/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 1.4715 - accuracy: 0.5407\n",
            "Epoch 84: val_accuracy did not improve from 0.52846\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.4719 - accuracy: 0.5403 - val_loss: 1.7743 - val_accuracy: 0.5051\n",
            "Epoch 85/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 1.4240 - accuracy: 0.5503\n",
            "Epoch 85: val_accuracy did not improve from 0.52846\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.4151 - accuracy: 0.5539 - val_loss: 1.8288 - val_accuracy: 0.4726\n",
            "Epoch 86/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 1.4009 - accuracy: 0.5609\n",
            "Epoch 86: val_accuracy did not improve from 0.52846\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.4047 - accuracy: 0.5597 - val_loss: 1.7675 - val_accuracy: 0.5041\n",
            "Epoch 87/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 1.5038 - accuracy: 0.5302\n",
            "Epoch 87: val_accuracy did not improve from 0.52846\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.5032 - accuracy: 0.5311 - val_loss: 1.8690 - val_accuracy: 0.4851\n",
            "Epoch 88/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 1.4655 - accuracy: 0.5412\n",
            "Epoch 88: val_accuracy did not improve from 0.52846\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.4732 - accuracy: 0.5391 - val_loss: 2.1840 - val_accuracy: 0.4049\n",
            "Epoch 89/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 1.4929 - accuracy: 0.5315\n",
            "Epoch 89: val_accuracy did not improve from 0.52846\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.4904 - accuracy: 0.5323 - val_loss: 1.7359 - val_accuracy: 0.5111\n",
            "Epoch 90/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 1.3457 - accuracy: 0.5824\n",
            "Epoch 90: val_accuracy did not improve from 0.52846\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.3561 - accuracy: 0.5802 - val_loss: 1.9473 - val_accuracy: 0.4661\n",
            "Epoch 91/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 1.4020 - accuracy: 0.5507\n",
            "Epoch 91: val_accuracy improved from 0.52846 to 0.53496, saving model to /content/asl/Adam3/cp-91-0.53.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3953 - accuracy: 0.5521 - val_loss: 1.6909 - val_accuracy: 0.5350\n",
            "Epoch 92/700\n",
            "50/58 [========================>.....] - ETA: 0s - loss: 1.3356 - accuracy: 0.5792\n",
            "Epoch 92: val_accuracy improved from 0.53496 to 0.55014, saving model to /content/asl/Adam3/cp-92-0.55.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3290 - accuracy: 0.5825 - val_loss: 1.6573 - val_accuracy: 0.5501\n",
            "Epoch 93/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 1.3739 - accuracy: 0.5641\n",
            "Epoch 93: val_accuracy did not improve from 0.55014\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.3762 - accuracy: 0.5630 - val_loss: 1.9830 - val_accuracy: 0.4444\n",
            "Epoch 94/700\n",
            "49/58 [========================>.....] - ETA: 0s - loss: 1.3804 - accuracy: 0.5533\n",
            "Epoch 94: val_accuracy did not improve from 0.55014\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.3927 - accuracy: 0.5524 - val_loss: 1.8863 - val_accuracy: 0.4737\n",
            "Epoch 95/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 1.3046 - accuracy: 0.5871\n",
            "Epoch 95: val_accuracy did not improve from 0.55014\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.3101 - accuracy: 0.5852 - val_loss: 1.7647 - val_accuracy: 0.4970\n",
            "Epoch 96/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 1.4415 - accuracy: 0.5450\n",
            "Epoch 96: val_accuracy did not improve from 0.55014\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.4413 - accuracy: 0.5447 - val_loss: 2.0018 - val_accuracy: 0.4661\n",
            "Epoch 97/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 1.3754 - accuracy: 0.5682\n",
            "Epoch 97: val_accuracy did not improve from 0.55014\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.3740 - accuracy: 0.5699 - val_loss: 1.7176 - val_accuracy: 0.5220\n",
            "Epoch 98/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 1.3084 - accuracy: 0.5881\n",
            "Epoch 98: val_accuracy did not improve from 0.55014\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.3295 - accuracy: 0.5821 - val_loss: 2.4089 - val_accuracy: 0.3556\n",
            "Epoch 99/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 1.4151 - accuracy: 0.5498\n",
            "Epoch 99: val_accuracy did not improve from 0.55014\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.4083 - accuracy: 0.5523 - val_loss: 1.7050 - val_accuracy: 0.5425\n",
            "Epoch 100/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 1.3237 - accuracy: 0.5737\n",
            "Epoch 100: val_accuracy did not improve from 0.55014\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.3186 - accuracy: 0.5746 - val_loss: 1.7546 - val_accuracy: 0.5133\n",
            "Epoch 101/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 1.3189 - accuracy: 0.5813\n",
            "Epoch 101: val_accuracy improved from 0.55014 to 0.55285, saving model to /content/asl/Adam3/cp-101-0.55.hdf5\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.3176 - accuracy: 0.5819 - val_loss: 1.6513 - val_accuracy: 0.5528\n",
            "Epoch 102/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 1.2608 - accuracy: 0.6016\n",
            "Epoch 102: val_accuracy improved from 0.55285 to 0.55989, saving model to /content/asl/Adam3/cp-102-0.56.hdf5\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.2520 - accuracy: 0.6044 - val_loss: 1.6356 - val_accuracy: 0.5599\n",
            "Epoch 103/700\n",
            "49/58 [========================>.....] - ETA: 0s - loss: 1.3047 - accuracy: 0.5879\n",
            "Epoch 103: val_accuracy improved from 0.55989 to 0.56585, saving model to /content/asl/Adam3/cp-103-0.57.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2948 - accuracy: 0.5898 - val_loss: 1.5761 - val_accuracy: 0.5659\n",
            "Epoch 104/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 1.2243 - accuracy: 0.6117\n",
            "Epoch 104: val_accuracy did not improve from 0.56585\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.2264 - accuracy: 0.6105 - val_loss: 1.8235 - val_accuracy: 0.4986\n",
            "Epoch 105/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 1.2840 - accuracy: 0.5855\n",
            "Epoch 105: val_accuracy did not improve from 0.56585\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.2843 - accuracy: 0.5853 - val_loss: 1.6900 - val_accuracy: 0.5425\n",
            "Epoch 106/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 1.2166 - accuracy: 0.6105\n",
            "Epoch 106: val_accuracy did not improve from 0.56585\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.2166 - accuracy: 0.6105 - val_loss: 1.6478 - val_accuracy: 0.5539\n",
            "Epoch 107/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 1.3181 - accuracy: 0.5774\n",
            "Epoch 107: val_accuracy did not improve from 0.56585\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.3169 - accuracy: 0.5779 - val_loss: 1.8669 - val_accuracy: 0.5062\n",
            "Epoch 108/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 1.2061 - accuracy: 0.6193\n",
            "Epoch 108: val_accuracy improved from 0.56585 to 0.59079, saving model to /content/asl/Adam3/cp-108-0.59.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2001 - accuracy: 0.6211 - val_loss: 1.5398 - val_accuracy: 0.5908\n",
            "Epoch 109/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 1.4086 - accuracy: 0.5585\n",
            "Epoch 109: val_accuracy did not improve from 0.59079\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.4095 - accuracy: 0.5580 - val_loss: 1.7253 - val_accuracy: 0.5322\n",
            "Epoch 110/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 1.3335 - accuracy: 0.5765\n",
            "Epoch 110: val_accuracy did not improve from 0.59079\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.3335 - accuracy: 0.5765 - val_loss: 1.9766 - val_accuracy: 0.4683\n",
            "Epoch 111/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 1.2768 - accuracy: 0.5828\n",
            "Epoch 111: val_accuracy improved from 0.59079 to 0.59187, saving model to /content/asl/Adam3/cp-111-0.59.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2768 - accuracy: 0.5828 - val_loss: 1.5464 - val_accuracy: 0.5919\n",
            "Epoch 112/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 1.1669 - accuracy: 0.6270\n",
            "Epoch 112: val_accuracy did not improve from 0.59187\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.1648 - accuracy: 0.6283 - val_loss: 1.7004 - val_accuracy: 0.5556\n",
            "Epoch 113/700\n",
            "50/58 [========================>.....] - ETA: 0s - loss: 1.2337 - accuracy: 0.6030\n",
            "Epoch 113: val_accuracy did not improve from 0.59187\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.2381 - accuracy: 0.6046 - val_loss: 1.7578 - val_accuracy: 0.5366\n",
            "Epoch 114/700\n",
            "50/58 [========================>.....] - ETA: 0s - loss: 1.2468 - accuracy: 0.5973\n",
            "Epoch 114: val_accuracy did not improve from 0.59187\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.2308 - accuracy: 0.5998 - val_loss: 1.6505 - val_accuracy: 0.5474\n",
            "Epoch 115/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 1.2651 - accuracy: 0.5889\n",
            "Epoch 115: val_accuracy did not improve from 0.59187\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.2598 - accuracy: 0.5906 - val_loss: 1.6661 - val_accuracy: 0.5534\n",
            "Epoch 116/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 1.1795 - accuracy: 0.6207\n",
            "Epoch 116: val_accuracy did not improve from 0.59187\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.1795 - accuracy: 0.6207 - val_loss: 1.5436 - val_accuracy: 0.5908\n",
            "Epoch 117/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 1.1673 - accuracy: 0.6304\n",
            "Epoch 117: val_accuracy did not improve from 0.59187\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.1694 - accuracy: 0.6284 - val_loss: 1.5288 - val_accuracy: 0.5897\n",
            "Epoch 118/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 1.2301 - accuracy: 0.5969\n",
            "Epoch 118: val_accuracy did not improve from 0.59187\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.2301 - accuracy: 0.5969 - val_loss: 1.5926 - val_accuracy: 0.5702\n",
            "Epoch 119/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 1.1461 - accuracy: 0.6330\n",
            "Epoch 119: val_accuracy did not improve from 0.59187\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.1461 - accuracy: 0.6330 - val_loss: 1.6788 - val_accuracy: 0.5377\n",
            "Epoch 120/700\n",
            "50/58 [========================>.....] - ETA: 0s - loss: 1.1664 - accuracy: 0.6197\n",
            "Epoch 120: val_accuracy did not improve from 0.59187\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.1561 - accuracy: 0.6223 - val_loss: 1.6752 - val_accuracy: 0.5545\n",
            "Epoch 121/700\n",
            "49/58 [========================>.....] - ETA: 0s - loss: 1.3143 - accuracy: 0.5754\n",
            "Epoch 121: val_accuracy did not improve from 0.59187\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.3203 - accuracy: 0.5735 - val_loss: 1.5963 - val_accuracy: 0.5659\n",
            "Epoch 122/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 1.1527 - accuracy: 0.6302\n",
            "Epoch 122: val_accuracy did not improve from 0.59187\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.1568 - accuracy: 0.6291 - val_loss: 1.5862 - val_accuracy: 0.5740\n",
            "Epoch 123/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 1.1293 - accuracy: 0.6369\n",
            "Epoch 123: val_accuracy did not improve from 0.59187\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.1279 - accuracy: 0.6377 - val_loss: 1.5942 - val_accuracy: 0.5789\n",
            "Epoch 124/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 1.1759 - accuracy: 0.6271\n",
            "Epoch 124: val_accuracy did not improve from 0.59187\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.1802 - accuracy: 0.6253 - val_loss: 1.9877 - val_accuracy: 0.4829\n",
            "Epoch 125/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 1.1332 - accuracy: 0.6367\n",
            "Epoch 125: val_accuracy did not improve from 0.59187\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.1351 - accuracy: 0.6355 - val_loss: 1.5855 - val_accuracy: 0.5621\n",
            "Epoch 126/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 1.1789 - accuracy: 0.6165\n",
            "Epoch 126: val_accuracy did not improve from 0.59187\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.1648 - accuracy: 0.6214 - val_loss: 1.5736 - val_accuracy: 0.5870\n",
            "Epoch 127/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 1.1097 - accuracy: 0.6359\n",
            "Epoch 127: val_accuracy did not improve from 0.59187\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 1.1029 - accuracy: 0.6390 - val_loss: 1.6672 - val_accuracy: 0.5507\n",
            "Epoch 128/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 1.0389 - accuracy: 0.6646\n",
            "Epoch 128: val_accuracy did not improve from 0.59187\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.0413 - accuracy: 0.6644 - val_loss: 1.5386 - val_accuracy: 0.5870\n",
            "Epoch 129/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 1.1786 - accuracy: 0.6179\n",
            "Epoch 129: val_accuracy did not improve from 0.59187\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.1742 - accuracy: 0.6202 - val_loss: 1.7169 - val_accuracy: 0.5550\n",
            "Epoch 130/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 1.2853 - accuracy: 0.5900\n",
            "Epoch 130: val_accuracy did not improve from 0.59187\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.2795 - accuracy: 0.5924 - val_loss: 1.5366 - val_accuracy: 0.5816\n",
            "Epoch 131/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 1.1347 - accuracy: 0.6284\n",
            "Epoch 131: val_accuracy improved from 0.59187 to 0.59946, saving model to /content/asl/Adam3/cp-131-0.60.hdf5\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 1.1355 - accuracy: 0.6280 - val_loss: 1.5123 - val_accuracy: 0.5995\n",
            "Epoch 132/700\n",
            "50/58 [========================>.....] - ETA: 0s - loss: 1.0173 - accuracy: 0.6705\n",
            "Epoch 132: val_accuracy did not improve from 0.59946\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.0112 - accuracy: 0.6714 - val_loss: 1.5238 - val_accuracy: 0.5984\n",
            "Epoch 133/700\n",
            "50/58 [========================>.....] - ETA: 0s - loss: 1.1282 - accuracy: 0.6330\n",
            "Epoch 133: val_accuracy did not improve from 0.59946\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.1242 - accuracy: 0.6340 - val_loss: 1.5299 - val_accuracy: 0.5902\n",
            "Epoch 134/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 1.1002 - accuracy: 0.6452\n",
            "Epoch 134: val_accuracy did not improve from 0.59946\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.1006 - accuracy: 0.6442 - val_loss: 1.5654 - val_accuracy: 0.5957\n",
            "Epoch 135/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 1.0502 - accuracy: 0.6593\n",
            "Epoch 135: val_accuracy did not improve from 0.59946\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.0521 - accuracy: 0.6588 - val_loss: 1.6092 - val_accuracy: 0.5897\n",
            "Epoch 136/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 1.1300 - accuracy: 0.6304\n",
            "Epoch 136: val_accuracy did not improve from 0.59946\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.1256 - accuracy: 0.6314 - val_loss: 1.5836 - val_accuracy: 0.5729\n",
            "Epoch 137/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 1.1461 - accuracy: 0.6224\n",
            "Epoch 137: val_accuracy did not improve from 0.59946\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.1514 - accuracy: 0.6210 - val_loss: 2.0295 - val_accuracy: 0.4878\n",
            "Epoch 138/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 1.1829 - accuracy: 0.6137\n",
            "Epoch 138: val_accuracy did not improve from 0.59946\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.1785 - accuracy: 0.6157 - val_loss: 1.5412 - val_accuracy: 0.5837\n",
            "Epoch 139/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 1.1019 - accuracy: 0.6362\n",
            "Epoch 139: val_accuracy did not improve from 0.59946\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.1036 - accuracy: 0.6352 - val_loss: 1.6457 - val_accuracy: 0.5621\n",
            "Epoch 140/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 1.0755 - accuracy: 0.6441\n",
            "Epoch 140: val_accuracy improved from 0.59946 to 0.61463, saving model to /content/asl/Adam3/cp-140-0.61.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0754 - accuracy: 0.6438 - val_loss: 1.4685 - val_accuracy: 0.6146\n",
            "Epoch 141/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 1.0758 - accuracy: 0.6508\n",
            "Epoch 141: val_accuracy did not improve from 0.61463\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.0758 - accuracy: 0.6508 - val_loss: 1.6095 - val_accuracy: 0.5816\n",
            "Epoch 142/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 1.1188 - accuracy: 0.6339\n",
            "Epoch 142: val_accuracy did not improve from 0.61463\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.1188 - accuracy: 0.6339 - val_loss: 1.6075 - val_accuracy: 0.5686\n",
            "Epoch 143/700\n",
            "49/58 [========================>.....] - ETA: 0s - loss: 1.2985 - accuracy: 0.5923\n",
            "Epoch 143: val_accuracy did not improve from 0.61463\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.2546 - accuracy: 0.6011 - val_loss: 1.5881 - val_accuracy: 0.5707\n",
            "Epoch 144/700\n",
            "49/58 [========================>.....] - ETA: 0s - loss: 1.0237 - accuracy: 0.6567\n",
            "Epoch 144: val_accuracy did not improve from 0.61463\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.0488 - accuracy: 0.6488 - val_loss: 1.5573 - val_accuracy: 0.5848\n",
            "Epoch 145/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 1.1925 - accuracy: 0.6113\n",
            "Epoch 145: val_accuracy did not improve from 0.61463\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.1911 - accuracy: 0.6122 - val_loss: 1.6097 - val_accuracy: 0.5610\n",
            "Epoch 146/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 1.1070 - accuracy: 0.6391\n",
            "Epoch 146: val_accuracy did not improve from 0.61463\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.1070 - accuracy: 0.6391 - val_loss: 1.5895 - val_accuracy: 0.5664\n",
            "Epoch 147/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.9789 - accuracy: 0.6821\n",
            "Epoch 147: val_accuracy improved from 0.61463 to 0.62493, saving model to /content/asl/Adam3/cp-147-0.62.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.9738 - accuracy: 0.6828 - val_loss: 1.4404 - val_accuracy: 0.6249\n",
            "Epoch 148/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.9535 - accuracy: 0.6812\n",
            "Epoch 148: val_accuracy did not improve from 0.62493\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.9544 - accuracy: 0.6806 - val_loss: 1.7124 - val_accuracy: 0.5295\n",
            "Epoch 149/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.9993 - accuracy: 0.6741\n",
            "Epoch 149: val_accuracy did not improve from 0.62493\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.9963 - accuracy: 0.6759 - val_loss: 1.6261 - val_accuracy: 0.5631\n",
            "Epoch 150/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.9876 - accuracy: 0.6719\n",
            "Epoch 150: val_accuracy did not improve from 0.62493\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.9935 - accuracy: 0.6709 - val_loss: 1.4589 - val_accuracy: 0.6130\n",
            "Epoch 151/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 1.0776 - accuracy: 0.6420\n",
            "Epoch 151: val_accuracy did not improve from 0.62493\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.0776 - accuracy: 0.6420 - val_loss: 1.5429 - val_accuracy: 0.5924\n",
            "Epoch 152/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 1.1601 - accuracy: 0.6176\n",
            "Epoch 152: val_accuracy did not improve from 0.62493\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.1602 - accuracy: 0.6177 - val_loss: 1.5113 - val_accuracy: 0.6065\n",
            "Epoch 153/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 1.1365 - accuracy: 0.6298\n",
            "Epoch 153: val_accuracy did not improve from 0.62493\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.1371 - accuracy: 0.6290 - val_loss: 1.5050 - val_accuracy: 0.5957\n",
            "Epoch 154/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 1.0060 - accuracy: 0.6717\n",
            "Epoch 154: val_accuracy did not improve from 0.62493\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.0044 - accuracy: 0.6715 - val_loss: 1.8123 - val_accuracy: 0.5431\n",
            "Epoch 155/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 1.0206 - accuracy: 0.6620\n",
            "Epoch 155: val_accuracy did not improve from 0.62493\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.0194 - accuracy: 0.6625 - val_loss: 1.5502 - val_accuracy: 0.5935\n",
            "Epoch 156/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 1.0295 - accuracy: 0.6608\n",
            "Epoch 156: val_accuracy did not improve from 0.62493\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.0287 - accuracy: 0.6610 - val_loss: 1.4542 - val_accuracy: 0.6108\n",
            "Epoch 157/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.9265 - accuracy: 0.6950\n",
            "Epoch 157: val_accuracy improved from 0.62493 to 0.62818, saving model to /content/asl/Adam3/cp-157-0.63.hdf5\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.9187 - accuracy: 0.6988 - val_loss: 1.4515 - val_accuracy: 0.6282\n",
            "Epoch 158/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.9164 - accuracy: 0.6950\n",
            "Epoch 158: val_accuracy improved from 0.62818 to 0.63252, saving model to /content/asl/Adam3/cp-158-0.63.hdf5\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.9172 - accuracy: 0.6951 - val_loss: 1.4514 - val_accuracy: 0.6325\n",
            "Epoch 159/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 1.0608 - accuracy: 0.6503\n",
            "Epoch 159: val_accuracy did not improve from 0.63252\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 1.0565 - accuracy: 0.6513 - val_loss: 1.6023 - val_accuracy: 0.5675\n",
            "Epoch 160/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.9612 - accuracy: 0.6790\n",
            "Epoch 160: val_accuracy did not improve from 0.63252\n",
            "58/58 [==============================] - 1s 20ms/step - loss: 0.9613 - accuracy: 0.6789 - val_loss: 1.6475 - val_accuracy: 0.5789\n",
            "Epoch 161/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.9743 - accuracy: 0.6826\n",
            "Epoch 161: val_accuracy did not improve from 0.63252\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.9918 - accuracy: 0.6753 - val_loss: 1.7158 - val_accuracy: 0.5442\n",
            "Epoch 162/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.9199 - accuracy: 0.6946\n",
            "Epoch 162: val_accuracy did not improve from 0.63252\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.9165 - accuracy: 0.6964 - val_loss: 1.4836 - val_accuracy: 0.6260\n",
            "Epoch 163/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.9273 - accuracy: 0.6928\n",
            "Epoch 163: val_accuracy did not improve from 0.63252\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.9284 - accuracy: 0.6908 - val_loss: 1.5607 - val_accuracy: 0.5870\n",
            "Epoch 164/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.9833 - accuracy: 0.6737\n",
            "Epoch 164: val_accuracy did not improve from 0.63252\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.9817 - accuracy: 0.6726 - val_loss: 1.4562 - val_accuracy: 0.6293\n",
            "Epoch 165/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 1.0283 - accuracy: 0.6648\n",
            "Epoch 165: val_accuracy did not improve from 0.63252\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.0149 - accuracy: 0.6673 - val_loss: 1.4665 - val_accuracy: 0.6255\n",
            "Epoch 166/700\n",
            "49/58 [========================>.....] - ETA: 0s - loss: 0.8873 - accuracy: 0.7060\n",
            "Epoch 166: val_accuracy did not improve from 0.63252\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.9086 - accuracy: 0.6989 - val_loss: 1.6270 - val_accuracy: 0.5772\n",
            "Epoch 167/700\n",
            "49/58 [========================>.....] - ETA: 0s - loss: 1.0007 - accuracy: 0.6708\n",
            "Epoch 167: val_accuracy did not improve from 0.63252\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.9990 - accuracy: 0.6721 - val_loss: 1.5371 - val_accuracy: 0.6060\n",
            "Epoch 168/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.9469 - accuracy: 0.6839\n",
            "Epoch 168: val_accuracy did not improve from 0.63252\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.9548 - accuracy: 0.6816 - val_loss: 2.0120 - val_accuracy: 0.4867\n",
            "Epoch 169/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 1.0457 - accuracy: 0.6565\n",
            "Epoch 169: val_accuracy improved from 0.63252 to 0.63740, saving model to /content/asl/Adam3/cp-169-0.64.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0395 - accuracy: 0.6587 - val_loss: 1.4927 - val_accuracy: 0.6374\n",
            "Epoch 170/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.9320 - accuracy: 0.6888\n",
            "Epoch 170: val_accuracy did not improve from 0.63740\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.9289 - accuracy: 0.6892 - val_loss: 1.4343 - val_accuracy: 0.6341\n",
            "Epoch 171/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.8896 - accuracy: 0.7001\n",
            "Epoch 171: val_accuracy did not improve from 0.63740\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.8912 - accuracy: 0.6993 - val_loss: 1.6066 - val_accuracy: 0.5762\n",
            "Epoch 172/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.9972 - accuracy: 0.6645\n",
            "Epoch 172: val_accuracy did not improve from 0.63740\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0073 - accuracy: 0.6596 - val_loss: 1.6387 - val_accuracy: 0.5707\n",
            "Epoch 173/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.9775 - accuracy: 0.6730\n",
            "Epoch 173: val_accuracy did not improve from 0.63740\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.9730 - accuracy: 0.6737 - val_loss: 1.5557 - val_accuracy: 0.5859\n",
            "Epoch 174/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.9443 - accuracy: 0.6879\n",
            "Epoch 174: val_accuracy did not improve from 0.63740\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.9468 - accuracy: 0.6867 - val_loss: 1.5222 - val_accuracy: 0.6005\n",
            "Epoch 175/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 1.0240 - accuracy: 0.6576\n",
            "Epoch 175: val_accuracy did not improve from 0.63740\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.0170 - accuracy: 0.6600 - val_loss: 1.7011 - val_accuracy: 0.5583\n",
            "Epoch 176/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.8673 - accuracy: 0.7102\n",
            "Epoch 176: val_accuracy improved from 0.63740 to 0.64228, saving model to /content/asl/Adam3/cp-176-0.64.hdf5\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.8680 - accuracy: 0.7088 - val_loss: 1.4188 - val_accuracy: 0.6423\n",
            "Epoch 177/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.9179 - accuracy: 0.6946\n",
            "Epoch 177: val_accuracy did not improve from 0.64228\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.9095 - accuracy: 0.6972 - val_loss: 1.5532 - val_accuracy: 0.6022\n",
            "Epoch 178/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 1.0180 - accuracy: 0.6629\n",
            "Epoch 178: val_accuracy improved from 0.64228 to 0.65420, saving model to /content/asl/Adam3/cp-178-0.65.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0063 - accuracy: 0.6661 - val_loss: 1.4100 - val_accuracy: 0.6542\n",
            "Epoch 179/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 1.0688 - accuracy: 0.6538\n",
            "Epoch 179: val_accuracy did not improve from 0.65420\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0782 - accuracy: 0.6512 - val_loss: 1.8066 - val_accuracy: 0.5566\n",
            "Epoch 180/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 1.0810 - accuracy: 0.6584\n",
            "Epoch 180: val_accuracy did not improve from 0.65420\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.0738 - accuracy: 0.6604 - val_loss: 1.6613 - val_accuracy: 0.5718\n",
            "Epoch 181/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.8749 - accuracy: 0.7092\n",
            "Epoch 181: val_accuracy did not improve from 0.65420\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.8750 - accuracy: 0.7094 - val_loss: 1.5070 - val_accuracy: 0.6070\n",
            "Epoch 182/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.9944 - accuracy: 0.6732\n",
            "Epoch 182: val_accuracy did not improve from 0.65420\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.9950 - accuracy: 0.6732 - val_loss: 1.6604 - val_accuracy: 0.5696\n",
            "Epoch 183/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.9477 - accuracy: 0.6811\n",
            "Epoch 183: val_accuracy did not improve from 0.65420\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.9475 - accuracy: 0.6806 - val_loss: 1.4767 - val_accuracy: 0.6336\n",
            "Epoch 184/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.9084 - accuracy: 0.6953\n",
            "Epoch 184: val_accuracy did not improve from 0.65420\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.9084 - accuracy: 0.6953 - val_loss: 1.5883 - val_accuracy: 0.5772\n",
            "Epoch 185/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.8513 - accuracy: 0.7169\n",
            "Epoch 185: val_accuracy improved from 0.65420 to 0.65691, saving model to /content/asl/Adam3/cp-185-0.66.hdf5\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.8523 - accuracy: 0.7167 - val_loss: 1.3877 - val_accuracy: 0.6569\n",
            "Epoch 186/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.8406 - accuracy: 0.7182\n",
            "Epoch 186: val_accuracy did not improve from 0.65691\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.8392 - accuracy: 0.7186 - val_loss: 1.5761 - val_accuracy: 0.6016\n",
            "Epoch 187/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.8197 - accuracy: 0.7276\n",
            "Epoch 187: val_accuracy did not improve from 0.65691\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.8195 - accuracy: 0.7256 - val_loss: 1.4648 - val_accuracy: 0.6304\n",
            "Epoch 188/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.7963 - accuracy: 0.7335\n",
            "Epoch 188: val_accuracy did not improve from 0.65691\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.8059 - accuracy: 0.7297 - val_loss: 1.4668 - val_accuracy: 0.6238\n",
            "Epoch 189/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.8322 - accuracy: 0.7235\n",
            "Epoch 189: val_accuracy did not improve from 0.65691\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.8368 - accuracy: 0.7218 - val_loss: 1.6119 - val_accuracy: 0.6108\n",
            "Epoch 190/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.9103 - accuracy: 0.6975\n",
            "Epoch 190: val_accuracy did not improve from 0.65691\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.9091 - accuracy: 0.6983 - val_loss: 1.5020 - val_accuracy: 0.6271\n",
            "Epoch 191/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.8774 - accuracy: 0.7048\n",
            "Epoch 191: val_accuracy did not improve from 0.65691\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.8774 - accuracy: 0.7048 - val_loss: 1.4862 - val_accuracy: 0.6309\n",
            "Epoch 192/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.8037 - accuracy: 0.7350\n",
            "Epoch 192: val_accuracy did not improve from 0.65691\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.8066 - accuracy: 0.7312 - val_loss: 1.7160 - val_accuracy: 0.5686\n",
            "Epoch 193/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 1.0818 - accuracy: 0.6420\n",
            "Epoch 193: val_accuracy did not improve from 0.65691\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.0867 - accuracy: 0.6410 - val_loss: 1.5960 - val_accuracy: 0.6043\n",
            "Epoch 194/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 1.0892 - accuracy: 0.6386\n",
            "Epoch 194: val_accuracy did not improve from 0.65691\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.0893 - accuracy: 0.6387 - val_loss: 1.8335 - val_accuracy: 0.5539\n",
            "Epoch 195/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.8657 - accuracy: 0.7097\n",
            "Epoch 195: val_accuracy did not improve from 0.65691\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.8605 - accuracy: 0.7088 - val_loss: 1.4152 - val_accuracy: 0.6455\n",
            "Epoch 196/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.7960 - accuracy: 0.7256\n",
            "Epoch 196: val_accuracy improved from 0.65691 to 0.66016, saving model to /content/asl/Adam3/cp-196-0.66.hdf5\n",
            "58/58 [==============================] - 1s 16ms/step - loss: 0.7938 - accuracy: 0.7264 - val_loss: 1.4076 - val_accuracy: 0.6602\n",
            "Epoch 197/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.9280 - accuracy: 0.6901\n",
            "Epoch 197: val_accuracy did not improve from 0.66016\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.9622 - accuracy: 0.6814 - val_loss: 2.1610 - val_accuracy: 0.4797\n",
            "Epoch 198/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 1.2116 - accuracy: 0.6039\n",
            "Epoch 198: val_accuracy did not improve from 0.66016\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.2030 - accuracy: 0.6076 - val_loss: 2.1817 - val_accuracy: 0.4547\n",
            "Epoch 199/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 1.1034 - accuracy: 0.6370\n",
            "Epoch 199: val_accuracy did not improve from 0.66016\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.0963 - accuracy: 0.6397 - val_loss: 1.8780 - val_accuracy: 0.5442\n",
            "Epoch 200/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 1.0516 - accuracy: 0.6481\n",
            "Epoch 200: val_accuracy did not improve from 0.66016\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.0435 - accuracy: 0.6504 - val_loss: 1.4155 - val_accuracy: 0.6423\n",
            "Epoch 201/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.7776 - accuracy: 0.7426\n",
            "Epoch 201: val_accuracy improved from 0.66016 to 0.66233, saving model to /content/asl/Adam3/cp-201-0.66.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.7781 - accuracy: 0.7420 - val_loss: 1.3887 - val_accuracy: 0.6623\n",
            "Epoch 202/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.8984 - accuracy: 0.6991\n",
            "Epoch 202: val_accuracy did not improve from 0.66233\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.8906 - accuracy: 0.7010 - val_loss: 1.5481 - val_accuracy: 0.6016\n",
            "Epoch 203/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.8365 - accuracy: 0.7174\n",
            "Epoch 203: val_accuracy did not improve from 0.66233\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.8347 - accuracy: 0.7171 - val_loss: 1.6396 - val_accuracy: 0.5919\n",
            "Epoch 204/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.9033 - accuracy: 0.6942\n",
            "Epoch 204: val_accuracy did not improve from 0.66233\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.8992 - accuracy: 0.6959 - val_loss: 1.6498 - val_accuracy: 0.6119\n",
            "Epoch 205/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.8049 - accuracy: 0.7317\n",
            "Epoch 205: val_accuracy improved from 0.66233 to 0.67046, saving model to /content/asl/Adam3/cp-205-0.67.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.8058 - accuracy: 0.7301 - val_loss: 1.4010 - val_accuracy: 0.6705\n",
            "Epoch 206/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.7939 - accuracy: 0.7257\n",
            "Epoch 206: val_accuracy did not improve from 0.67046\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.7947 - accuracy: 0.7256 - val_loss: 1.5957 - val_accuracy: 0.6098\n",
            "Epoch 207/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.8190 - accuracy: 0.7242\n",
            "Epoch 207: val_accuracy did not improve from 0.67046\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.8223 - accuracy: 0.7235 - val_loss: 1.4418 - val_accuracy: 0.6504\n",
            "Epoch 208/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.8314 - accuracy: 0.7158\n",
            "Epoch 208: val_accuracy did not improve from 0.67046\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.8263 - accuracy: 0.7174 - val_loss: 1.4831 - val_accuracy: 0.6363\n",
            "Epoch 209/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.7800 - accuracy: 0.7387\n",
            "Epoch 209: val_accuracy did not improve from 0.67046\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.8148 - accuracy: 0.7286 - val_loss: 1.6773 - val_accuracy: 0.5843\n",
            "Epoch 210/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.8381 - accuracy: 0.7127\n",
            "Epoch 210: val_accuracy did not improve from 0.67046\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.8378 - accuracy: 0.7128 - val_loss: 1.4956 - val_accuracy: 0.6336\n",
            "Epoch 211/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.7421 - accuracy: 0.7480\n",
            "Epoch 211: val_accuracy did not improve from 0.67046\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.7421 - accuracy: 0.7480 - val_loss: 1.4633 - val_accuracy: 0.6444\n",
            "Epoch 212/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.7862 - accuracy: 0.7308\n",
            "Epoch 212: val_accuracy did not improve from 0.67046\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.7865 - accuracy: 0.7316 - val_loss: 1.3972 - val_accuracy: 0.6575\n",
            "Epoch 213/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.8309 - accuracy: 0.7171\n",
            "Epoch 213: val_accuracy did not improve from 0.67046\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.8309 - accuracy: 0.7171 - val_loss: 1.4819 - val_accuracy: 0.6466\n",
            "Epoch 214/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.9904 - accuracy: 0.6733\n",
            "Epoch 214: val_accuracy did not improve from 0.67046\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.9906 - accuracy: 0.6730 - val_loss: 1.6422 - val_accuracy: 0.5897\n",
            "Epoch 215/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.7685 - accuracy: 0.7368\n",
            "Epoch 215: val_accuracy did not improve from 0.67046\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.7653 - accuracy: 0.7389 - val_loss: 1.4313 - val_accuracy: 0.6580\n",
            "Epoch 216/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.9105 - accuracy: 0.6930\n",
            "Epoch 216: val_accuracy did not improve from 0.67046\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.9054 - accuracy: 0.6942 - val_loss: 1.4943 - val_accuracy: 0.6271\n",
            "Epoch 217/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.8300 - accuracy: 0.7220\n",
            "Epoch 217: val_accuracy did not improve from 0.67046\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.8300 - accuracy: 0.7220 - val_loss: 1.5382 - val_accuracy: 0.6092\n",
            "Epoch 218/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 1.1031 - accuracy: 0.6498\n",
            "Epoch 218: val_accuracy did not improve from 0.67046\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.1043 - accuracy: 0.6488 - val_loss: 1.8387 - val_accuracy: 0.5653\n",
            "Epoch 219/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.8828 - accuracy: 0.7027\n",
            "Epoch 219: val_accuracy did not improve from 0.67046\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.8773 - accuracy: 0.7031 - val_loss: 1.4580 - val_accuracy: 0.6602\n",
            "Epoch 220/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.7649 - accuracy: 0.7444\n",
            "Epoch 220: val_accuracy did not improve from 0.67046\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.7821 - accuracy: 0.7392 - val_loss: 1.7727 - val_accuracy: 0.5707\n",
            "Epoch 221/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.8726 - accuracy: 0.7048\n",
            "Epoch 221: val_accuracy did not improve from 0.67046\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.8644 - accuracy: 0.7083 - val_loss: 1.5706 - val_accuracy: 0.6098\n",
            "Epoch 222/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.7497 - accuracy: 0.7445\n",
            "Epoch 222: val_accuracy did not improve from 0.67046\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.7550 - accuracy: 0.7424 - val_loss: 1.5885 - val_accuracy: 0.6163\n",
            "Epoch 223/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.7313 - accuracy: 0.7554\n",
            "Epoch 223: val_accuracy did not improve from 0.67046\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.7293 - accuracy: 0.7559 - val_loss: 1.5845 - val_accuracy: 0.6304\n",
            "Epoch 224/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.9025 - accuracy: 0.7016\n",
            "Epoch 224: val_accuracy did not improve from 0.67046\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.9000 - accuracy: 0.7011 - val_loss: 1.4865 - val_accuracy: 0.6580\n",
            "Epoch 225/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.9253 - accuracy: 0.6815\n",
            "Epoch 225: val_accuracy did not improve from 0.67046\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.9226 - accuracy: 0.6827 - val_loss: 1.6394 - val_accuracy: 0.5946\n",
            "Epoch 226/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.8685 - accuracy: 0.7013\n",
            "Epoch 226: val_accuracy did not improve from 0.67046\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.8671 - accuracy: 0.7018 - val_loss: 1.4023 - val_accuracy: 0.6634\n",
            "Epoch 227/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.7557 - accuracy: 0.7497\n",
            "Epoch 227: val_accuracy did not improve from 0.67046\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.7507 - accuracy: 0.7521 - val_loss: 1.5574 - val_accuracy: 0.6206\n",
            "Epoch 228/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.7417 - accuracy: 0.7456\n",
            "Epoch 228: val_accuracy improved from 0.67046 to 0.67263, saving model to /content/asl/Adam3/cp-228-0.67.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.7401 - accuracy: 0.7454 - val_loss: 1.3933 - val_accuracy: 0.6726\n",
            "Epoch 229/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.7889 - accuracy: 0.7289\n",
            "Epoch 229: val_accuracy did not improve from 0.67263\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.7933 - accuracy: 0.7275 - val_loss: 1.6051 - val_accuracy: 0.6076\n",
            "Epoch 230/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.7827 - accuracy: 0.7328\n",
            "Epoch 230: val_accuracy did not improve from 0.67263\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.7779 - accuracy: 0.7346 - val_loss: 1.4940 - val_accuracy: 0.6472\n",
            "Epoch 231/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.7499 - accuracy: 0.7451\n",
            "Epoch 231: val_accuracy did not improve from 0.67263\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.7478 - accuracy: 0.7457 - val_loss: 1.3801 - val_accuracy: 0.6715\n",
            "Epoch 232/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.7094 - accuracy: 0.7559\n",
            "Epoch 232: val_accuracy did not improve from 0.67263\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.7248 - accuracy: 0.7517 - val_loss: 1.5925 - val_accuracy: 0.6119\n",
            "Epoch 233/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.8128 - accuracy: 0.7202\n",
            "Epoch 233: val_accuracy did not improve from 0.67263\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.8169 - accuracy: 0.7167 - val_loss: 1.8354 - val_accuracy: 0.5729\n",
            "Epoch 234/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.9839 - accuracy: 0.6692\n",
            "Epoch 234: val_accuracy did not improve from 0.67263\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.9811 - accuracy: 0.6713 - val_loss: 1.5188 - val_accuracy: 0.6407\n",
            "Epoch 235/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.8465 - accuracy: 0.7095\n",
            "Epoch 235: val_accuracy did not improve from 0.67263\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.8365 - accuracy: 0.7125 - val_loss: 1.7793 - val_accuracy: 0.5691\n",
            "Epoch 236/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.8478 - accuracy: 0.7098\n",
            "Epoch 236: val_accuracy did not improve from 0.67263\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.8462 - accuracy: 0.7106 - val_loss: 1.4509 - val_accuracy: 0.6661\n",
            "Epoch 237/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.8390 - accuracy: 0.7152\n",
            "Epoch 237: val_accuracy did not improve from 0.67263\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.8429 - accuracy: 0.7128 - val_loss: 1.9147 - val_accuracy: 0.5442\n",
            "Epoch 238/700\n",
            "50/58 [========================>.....] - ETA: 0s - loss: 0.8871 - accuracy: 0.7080\n",
            "Epoch 238: val_accuracy improved from 0.67263 to 0.68022, saving model to /content/asl/Adam3/cp-238-0.68.hdf5\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.8632 - accuracy: 0.7144 - val_loss: 1.3830 - val_accuracy: 0.6802\n",
            "Epoch 239/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.7277 - accuracy: 0.7510\n",
            "Epoch 239: val_accuracy improved from 0.68022 to 0.68835, saving model to /content/asl/Adam3/cp-239-0.69.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.7240 - accuracy: 0.7532 - val_loss: 1.3608 - val_accuracy: 0.6883\n",
            "Epoch 240/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.7033 - accuracy: 0.7615\n",
            "Epoch 240: val_accuracy did not improve from 0.68835\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.7052 - accuracy: 0.7605 - val_loss: 1.4623 - val_accuracy: 0.6710\n",
            "Epoch 241/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.7631 - accuracy: 0.7393\n",
            "Epoch 241: val_accuracy did not improve from 0.68835\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.7675 - accuracy: 0.7382 - val_loss: 1.6547 - val_accuracy: 0.5848\n",
            "Epoch 242/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.8672 - accuracy: 0.7060\n",
            "Epoch 242: val_accuracy did not improve from 0.68835\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.8672 - accuracy: 0.7060 - val_loss: 1.6618 - val_accuracy: 0.6065\n",
            "Epoch 243/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 1.3054 - accuracy: 0.6078\n",
            "Epoch 243: val_accuracy did not improve from 0.68835\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.3054 - accuracy: 0.6078 - val_loss: 1.6499 - val_accuracy: 0.6070\n",
            "Epoch 244/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.7914 - accuracy: 0.7292\n",
            "Epoch 244: val_accuracy did not improve from 0.68835\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 0.7892 - accuracy: 0.7301 - val_loss: 1.5287 - val_accuracy: 0.6450\n",
            "Epoch 245/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.7372 - accuracy: 0.7422\n",
            "Epoch 245: val_accuracy did not improve from 0.68835\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.7391 - accuracy: 0.7416 - val_loss: 1.4357 - val_accuracy: 0.6623\n",
            "Epoch 246/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.7289 - accuracy: 0.7513\n",
            "Epoch 246: val_accuracy did not improve from 0.68835\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.7475 - accuracy: 0.7453 - val_loss: 1.4385 - val_accuracy: 0.6818\n",
            "Epoch 247/700\n",
            "50/58 [========================>.....] - ETA: 0s - loss: 0.7858 - accuracy: 0.7309\n",
            "Epoch 247: val_accuracy did not improve from 0.68835\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.7691 - accuracy: 0.7361 - val_loss: 1.3543 - val_accuracy: 0.6840\n",
            "Epoch 248/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.6483 - accuracy: 0.7753\n",
            "Epoch 248: val_accuracy did not improve from 0.68835\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6590 - accuracy: 0.7712 - val_loss: 1.4516 - val_accuracy: 0.6770\n",
            "Epoch 249/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.7270 - accuracy: 0.7484\n",
            "Epoch 249: val_accuracy did not improve from 0.68835\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.7185 - accuracy: 0.7521 - val_loss: 1.4465 - val_accuracy: 0.6602\n",
            "Epoch 250/700\n",
            "49/58 [========================>.....] - ETA: 0s - loss: 0.6755 - accuracy: 0.7639\n",
            "Epoch 250: val_accuracy did not improve from 0.68835\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6702 - accuracy: 0.7662 - val_loss: 1.3985 - val_accuracy: 0.6710\n",
            "Epoch 251/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.6971 - accuracy: 0.7561\n",
            "Epoch 251: val_accuracy did not improve from 0.68835\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6934 - accuracy: 0.7571 - val_loss: 1.4552 - val_accuracy: 0.6645\n",
            "Epoch 252/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.6828 - accuracy: 0.7608\n",
            "Epoch 252: val_accuracy did not improve from 0.68835\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6887 - accuracy: 0.7588 - val_loss: 1.7428 - val_accuracy: 0.5897\n",
            "Epoch 253/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.7185 - accuracy: 0.7494\n",
            "Epoch 253: val_accuracy did not improve from 0.68835\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.7180 - accuracy: 0.7491 - val_loss: 1.4045 - val_accuracy: 0.6764\n",
            "Epoch 254/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.6698 - accuracy: 0.7706\n",
            "Epoch 254: val_accuracy did not improve from 0.68835\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6887 - accuracy: 0.7651 - val_loss: 1.7516 - val_accuracy: 0.5967\n",
            "Epoch 255/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.8063 - accuracy: 0.7246\n",
            "Epoch 255: val_accuracy did not improve from 0.68835\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.8084 - accuracy: 0.7235 - val_loss: 1.5814 - val_accuracy: 0.6114\n",
            "Epoch 256/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.8083 - accuracy: 0.7263\n",
            "Epoch 256: val_accuracy did not improve from 0.68835\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.8010 - accuracy: 0.7278 - val_loss: 1.4699 - val_accuracy: 0.6748\n",
            "Epoch 257/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.6890 - accuracy: 0.7605\n",
            "Epoch 257: val_accuracy did not improve from 0.68835\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6865 - accuracy: 0.7605 - val_loss: 1.4388 - val_accuracy: 0.6656\n",
            "Epoch 258/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.7408 - accuracy: 0.7434\n",
            "Epoch 258: val_accuracy did not improve from 0.68835\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.7417 - accuracy: 0.7430 - val_loss: 1.7028 - val_accuracy: 0.5989\n",
            "Epoch 259/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.7565 - accuracy: 0.7398\n",
            "Epoch 259: val_accuracy did not improve from 0.68835\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.7876 - accuracy: 0.7315 - val_loss: 1.9513 - val_accuracy: 0.5474\n",
            "Epoch 260/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.7781 - accuracy: 0.7311\n",
            "Epoch 260: val_accuracy did not improve from 0.68835\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.7980 - accuracy: 0.7245 - val_loss: 1.9287 - val_accuracy: 0.5301\n",
            "Epoch 261/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.7484 - accuracy: 0.7356\n",
            "Epoch 261: val_accuracy did not improve from 0.68835\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.7407 - accuracy: 0.7395 - val_loss: 1.4241 - val_accuracy: 0.6542\n",
            "Epoch 262/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.6986 - accuracy: 0.7527\n",
            "Epoch 262: val_accuracy did not improve from 0.68835\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.7300 - accuracy: 0.7430 - val_loss: 1.8385 - val_accuracy: 0.5810\n",
            "Epoch 263/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.9840 - accuracy: 0.6856\n",
            "Epoch 263: val_accuracy did not improve from 0.68835\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0227 - accuracy: 0.6767 - val_loss: 2.7445 - val_accuracy: 0.4482\n",
            "Epoch 264/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.9548 - accuracy: 0.6910\n",
            "Epoch 264: val_accuracy did not improve from 0.68835\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.9360 - accuracy: 0.6974 - val_loss: 1.4214 - val_accuracy: 0.6770\n",
            "Epoch 265/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.7563 - accuracy: 0.7362\n",
            "Epoch 265: val_accuracy did not improve from 0.68835\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.7561 - accuracy: 0.7355 - val_loss: 1.6370 - val_accuracy: 0.6336\n",
            "Epoch 266/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.6597 - accuracy: 0.7739\n",
            "Epoch 266: val_accuracy did not improve from 0.68835\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.6550 - accuracy: 0.7761 - val_loss: 1.4305 - val_accuracy: 0.6818\n",
            "Epoch 267/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.6497 - accuracy: 0.7772\n",
            "Epoch 267: val_accuracy improved from 0.68835 to 0.68997, saving model to /content/asl/Adam3/cp-267-0.69.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.6497 - accuracy: 0.7774 - val_loss: 1.3762 - val_accuracy: 0.6900\n",
            "Epoch 268/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.6215 - accuracy: 0.7877\n",
            "Epoch 268: val_accuracy improved from 0.68997 to 0.69160, saving model to /content/asl/Adam3/cp-268-0.69.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.6240 - accuracy: 0.7866 - val_loss: 1.3864 - val_accuracy: 0.6916\n",
            "Epoch 269/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.7289 - accuracy: 0.7460\n",
            "Epoch 269: val_accuracy improved from 0.69160 to 0.69702, saving model to /content/asl/Adam3/cp-269-0.70.hdf5\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.7289 - accuracy: 0.7460 - val_loss: 1.3984 - val_accuracy: 0.6970\n",
            "Epoch 270/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.6941 - accuracy: 0.7584\n",
            "Epoch 270: val_accuracy did not improve from 0.69702\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.6985 - accuracy: 0.7576 - val_loss: 1.4358 - val_accuracy: 0.6699\n",
            "Epoch 271/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.6936 - accuracy: 0.7551\n",
            "Epoch 271: val_accuracy did not improve from 0.69702\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.6973 - accuracy: 0.7538 - val_loss: 1.3922 - val_accuracy: 0.6965\n",
            "Epoch 272/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 1.1025 - accuracy: 0.6462\n",
            "Epoch 272: val_accuracy did not improve from 0.69702\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.0984 - accuracy: 0.6467 - val_loss: 2.5658 - val_accuracy: 0.4580\n",
            "Epoch 273/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.9153 - accuracy: 0.6847\n",
            "Epoch 273: val_accuracy did not improve from 0.69702\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.9097 - accuracy: 0.6851 - val_loss: 1.5431 - val_accuracy: 0.6520\n",
            "Epoch 274/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.8549 - accuracy: 0.7068\n",
            "Epoch 274: val_accuracy did not improve from 0.69702\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.8490 - accuracy: 0.7096 - val_loss: 1.4652 - val_accuracy: 0.6602\n",
            "Epoch 275/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.7369 - accuracy: 0.7458\n",
            "Epoch 275: val_accuracy did not improve from 0.69702\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 0.7369 - accuracy: 0.7458 - val_loss: 1.4296 - val_accuracy: 0.6851\n",
            "Epoch 276/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.5928 - accuracy: 0.7989\n",
            "Epoch 276: val_accuracy did not improve from 0.69702\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5952 - accuracy: 0.7977 - val_loss: 1.3634 - val_accuracy: 0.6921\n",
            "Epoch 277/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.6627 - accuracy: 0.7740\n",
            "Epoch 277: val_accuracy did not improve from 0.69702\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6870 - accuracy: 0.7671 - val_loss: 1.9327 - val_accuracy: 0.5550\n",
            "Epoch 278/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.7206 - accuracy: 0.7525\n",
            "Epoch 278: val_accuracy did not improve from 0.69702\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.7352 - accuracy: 0.7475 - val_loss: 1.8083 - val_accuracy: 0.5724\n",
            "Epoch 279/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.9860 - accuracy: 0.6719\n",
            "Epoch 279: val_accuracy did not improve from 0.69702\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.9444 - accuracy: 0.6867 - val_loss: 1.4213 - val_accuracy: 0.6900\n",
            "Epoch 280/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.6427 - accuracy: 0.7811\n",
            "Epoch 280: val_accuracy did not improve from 0.69702\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.6433 - accuracy: 0.7809 - val_loss: 1.4428 - val_accuracy: 0.6607\n",
            "Epoch 281/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.6057 - accuracy: 0.7886\n",
            "Epoch 281: val_accuracy did not improve from 0.69702\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6059 - accuracy: 0.7880 - val_loss: 1.5255 - val_accuracy: 0.6412\n",
            "Epoch 282/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.6176 - accuracy: 0.7852\n",
            "Epoch 282: val_accuracy did not improve from 0.69702\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.6224 - accuracy: 0.7830 - val_loss: 1.4271 - val_accuracy: 0.6943\n",
            "Epoch 283/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.6934 - accuracy: 0.7590\n",
            "Epoch 283: val_accuracy did not improve from 0.69702\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.7139 - accuracy: 0.7541 - val_loss: 1.8417 - val_accuracy: 0.5789\n",
            "Epoch 284/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.7284 - accuracy: 0.7472\n",
            "Epoch 284: val_accuracy did not improve from 0.69702\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.7251 - accuracy: 0.7477 - val_loss: 1.4596 - val_accuracy: 0.6818\n",
            "Epoch 285/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.5946 - accuracy: 0.7925\n",
            "Epoch 285: val_accuracy did not improve from 0.69702\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5976 - accuracy: 0.7918 - val_loss: 1.4900 - val_accuracy: 0.6759\n",
            "Epoch 286/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.6868 - accuracy: 0.7585\n",
            "Epoch 286: val_accuracy did not improve from 0.69702\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6874 - accuracy: 0.7575 - val_loss: 1.4723 - val_accuracy: 0.6542\n",
            "Epoch 287/700\n",
            "50/58 [========================>.....] - ETA: 0s - loss: 0.5942 - accuracy: 0.7952\n",
            "Epoch 287: val_accuracy improved from 0.69702 to 0.70786, saving model to /content/asl/Adam3/cp-287-0.71.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5852 - accuracy: 0.7972 - val_loss: 1.3830 - val_accuracy: 0.7079\n",
            "Epoch 288/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.6480 - accuracy: 0.7701\n",
            "Epoch 288: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6693 - accuracy: 0.7624 - val_loss: 1.3929 - val_accuracy: 0.7046\n",
            "Epoch 289/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.7553 - accuracy: 0.7410\n",
            "Epoch 289: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.7583 - accuracy: 0.7389 - val_loss: 1.5068 - val_accuracy: 0.6325\n",
            "Epoch 290/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.9493 - accuracy: 0.6820\n",
            "Epoch 290: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.9607 - accuracy: 0.6795 - val_loss: 1.7945 - val_accuracy: 0.5978\n",
            "Epoch 291/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.8537 - accuracy: 0.7086\n",
            "Epoch 291: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.8517 - accuracy: 0.7094 - val_loss: 1.6572 - val_accuracy: 0.6087\n",
            "Epoch 292/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.6763 - accuracy: 0.7626\n",
            "Epoch 292: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6739 - accuracy: 0.7622 - val_loss: 1.5723 - val_accuracy: 0.6585\n",
            "Epoch 293/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.7262 - accuracy: 0.7580\n",
            "Epoch 293: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.7219 - accuracy: 0.7605 - val_loss: 1.5121 - val_accuracy: 0.6672\n",
            "Epoch 294/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.5783 - accuracy: 0.7988\n",
            "Epoch 294: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5756 - accuracy: 0.7991 - val_loss: 1.5529 - val_accuracy: 0.6547\n",
            "Epoch 295/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.6630 - accuracy: 0.7690\n",
            "Epoch 295: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6745 - accuracy: 0.7659 - val_loss: 1.9105 - val_accuracy: 0.5946\n",
            "Epoch 296/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.8932 - accuracy: 0.7015\n",
            "Epoch 296: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.8749 - accuracy: 0.7046 - val_loss: 1.7150 - val_accuracy: 0.6195\n",
            "Epoch 297/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.7657 - accuracy: 0.7361\n",
            "Epoch 297: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.7679 - accuracy: 0.7361 - val_loss: 1.5814 - val_accuracy: 0.6558\n",
            "Epoch 298/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.7296 - accuracy: 0.7483\n",
            "Epoch 298: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.7358 - accuracy: 0.7450 - val_loss: 1.8377 - val_accuracy: 0.5919\n",
            "Epoch 299/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.6602 - accuracy: 0.7671\n",
            "Epoch 299: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.6570 - accuracy: 0.7678 - val_loss: 1.5814 - val_accuracy: 0.6640\n",
            "Epoch 300/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.8091 - accuracy: 0.7235\n",
            "Epoch 300: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.8091 - accuracy: 0.7235 - val_loss: 1.7300 - val_accuracy: 0.6043\n",
            "Epoch 301/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.6325 - accuracy: 0.7771\n",
            "Epoch 301: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.6354 - accuracy: 0.7759 - val_loss: 1.6367 - val_accuracy: 0.6531\n",
            "Epoch 302/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.6322 - accuracy: 0.7839\n",
            "Epoch 302: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.6230 - accuracy: 0.7874 - val_loss: 1.4331 - val_accuracy: 0.6986\n",
            "Epoch 303/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.6883 - accuracy: 0.7647\n",
            "Epoch 303: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.6939 - accuracy: 0.7624 - val_loss: 1.9061 - val_accuracy: 0.5740\n",
            "Epoch 304/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.5982 - accuracy: 0.7877\n",
            "Epoch 304: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.6042 - accuracy: 0.7855 - val_loss: 1.4550 - val_accuracy: 0.6959\n",
            "Epoch 305/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.8308 - accuracy: 0.7236\n",
            "Epoch 305: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.8308 - accuracy: 0.7236 - val_loss: 1.6017 - val_accuracy: 0.6591\n",
            "Epoch 306/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.6204 - accuracy: 0.7821\n",
            "Epoch 306: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6235 - accuracy: 0.7805 - val_loss: 1.4648 - val_accuracy: 0.6683\n",
            "Epoch 307/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.6597 - accuracy: 0.7701\n",
            "Epoch 307: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6596 - accuracy: 0.7705 - val_loss: 1.4127 - val_accuracy: 0.6797\n",
            "Epoch 308/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.6561 - accuracy: 0.7724\n",
            "Epoch 308: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6577 - accuracy: 0.7708 - val_loss: 1.6389 - val_accuracy: 0.6287\n",
            "Epoch 309/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.7907 - accuracy: 0.7233\n",
            "Epoch 309: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.7880 - accuracy: 0.7233 - val_loss: 1.5113 - val_accuracy: 0.6710\n",
            "Epoch 310/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.7143 - accuracy: 0.7490\n",
            "Epoch 310: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.7094 - accuracy: 0.7496 - val_loss: 1.5347 - val_accuracy: 0.6667\n",
            "Epoch 311/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.6315 - accuracy: 0.7786\n",
            "Epoch 311: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.6323 - accuracy: 0.7788 - val_loss: 1.4094 - val_accuracy: 0.6970\n",
            "Epoch 312/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.5471 - accuracy: 0.8105\n",
            "Epoch 312: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5483 - accuracy: 0.8106 - val_loss: 1.4240 - val_accuracy: 0.6802\n",
            "Epoch 313/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.5725 - accuracy: 0.8013\n",
            "Epoch 313: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5961 - accuracy: 0.7918 - val_loss: 1.4356 - val_accuracy: 0.6986\n",
            "Epoch 314/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.5697 - accuracy: 0.7978\n",
            "Epoch 314: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5806 - accuracy: 0.7933 - val_loss: 1.7164 - val_accuracy: 0.6054\n",
            "Epoch 315/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.6841 - accuracy: 0.7632\n",
            "Epoch 315: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.6953 - accuracy: 0.7590 - val_loss: 1.8575 - val_accuracy: 0.5799\n",
            "Epoch 316/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.7658 - accuracy: 0.7323\n",
            "Epoch 316: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.7533 - accuracy: 0.7365 - val_loss: 1.3888 - val_accuracy: 0.6970\n",
            "Epoch 317/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.5942 - accuracy: 0.7920\n",
            "Epoch 317: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5919 - accuracy: 0.7927 - val_loss: 1.5564 - val_accuracy: 0.6439\n",
            "Epoch 318/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.7165 - accuracy: 0.7474\n",
            "Epoch 318: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.7080 - accuracy: 0.7506 - val_loss: 1.4682 - val_accuracy: 0.6824\n",
            "Epoch 319/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.6708 - accuracy: 0.7684\n",
            "Epoch 319: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6636 - accuracy: 0.7696 - val_loss: 1.5892 - val_accuracy: 0.6553\n",
            "Epoch 320/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.6694 - accuracy: 0.7616\n",
            "Epoch 320: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6672 - accuracy: 0.7632 - val_loss: 1.4749 - val_accuracy: 0.6753\n",
            "Epoch 321/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.5428 - accuracy: 0.8089\n",
            "Epoch 321: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5414 - accuracy: 0.8093 - val_loss: 1.3895 - val_accuracy: 0.7014\n",
            "Epoch 322/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.5983 - accuracy: 0.7957\n",
            "Epoch 322: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5987 - accuracy: 0.7946 - val_loss: 1.6269 - val_accuracy: 0.6412\n",
            "Epoch 323/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.5592 - accuracy: 0.8027\n",
            "Epoch 323: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5547 - accuracy: 0.8055 - val_loss: 1.5818 - val_accuracy: 0.6688\n",
            "Epoch 324/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.6656 - accuracy: 0.7673\n",
            "Epoch 324: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.6861 - accuracy: 0.7594 - val_loss: 1.5889 - val_accuracy: 0.6374\n",
            "Epoch 325/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.6381 - accuracy: 0.7765\n",
            "Epoch 325: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.6522 - accuracy: 0.7712 - val_loss: 2.0194 - val_accuracy: 0.5886\n",
            "Epoch 326/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.8775 - accuracy: 0.7089\n",
            "Epoch 326: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.8573 - accuracy: 0.7134 - val_loss: 1.4139 - val_accuracy: 0.6905\n",
            "Epoch 327/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.6369 - accuracy: 0.7759\n",
            "Epoch 327: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6617 - accuracy: 0.7689 - val_loss: 2.2160 - val_accuracy: 0.5344\n",
            "Epoch 328/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 1.3694 - accuracy: 0.6268\n",
            "Epoch 328: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.3433 - accuracy: 0.6309 - val_loss: 1.6615 - val_accuracy: 0.6184\n",
            "Epoch 329/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.5791 - accuracy: 0.7976\n",
            "Epoch 329: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.5814 - accuracy: 0.7959 - val_loss: 1.3945 - val_accuracy: 0.6981\n",
            "Epoch 330/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.5768 - accuracy: 0.8018\n",
            "Epoch 330: val_accuracy did not improve from 0.70786\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.5839 - accuracy: 0.7986 - val_loss: 1.4031 - val_accuracy: 0.7035\n",
            "Epoch 331/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.5865 - accuracy: 0.7982\n",
            "Epoch 331: val_accuracy improved from 0.70786 to 0.71220, saving model to /content/asl/Adam3/cp-331-0.71.hdf5\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.5838 - accuracy: 0.7990 - val_loss: 1.3660 - val_accuracy: 0.7122\n",
            "Epoch 332/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.5308 - accuracy: 0.8136\n",
            "Epoch 332: val_accuracy did not improve from 0.71220\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.5338 - accuracy: 0.8128 - val_loss: 1.5713 - val_accuracy: 0.6596\n",
            "Epoch 333/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.5404 - accuracy: 0.8090\n",
            "Epoch 333: val_accuracy improved from 0.71220 to 0.71274, saving model to /content/asl/Adam3/cp-333-0.71.hdf5\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 0.5426 - accuracy: 0.8089 - val_loss: 1.3792 - val_accuracy: 0.7127\n",
            "Epoch 334/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.6569 - accuracy: 0.7720\n",
            "Epoch 334: val_accuracy did not improve from 0.71274\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.6554 - accuracy: 0.7727 - val_loss: 1.5332 - val_accuracy: 0.6667\n",
            "Epoch 335/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.7377 - accuracy: 0.7483\n",
            "Epoch 335: val_accuracy did not improve from 0.71274\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.7269 - accuracy: 0.7504 - val_loss: 1.8667 - val_accuracy: 0.5995\n",
            "Epoch 336/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.5910 - accuracy: 0.7898\n",
            "Epoch 336: val_accuracy did not improve from 0.71274\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5856 - accuracy: 0.7922 - val_loss: 1.4466 - val_accuracy: 0.7117\n",
            "Epoch 337/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.5433 - accuracy: 0.8074\n",
            "Epoch 337: val_accuracy did not improve from 0.71274\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5506 - accuracy: 0.8062 - val_loss: 1.6211 - val_accuracy: 0.6417\n",
            "Epoch 338/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.6340 - accuracy: 0.7777\n",
            "Epoch 338: val_accuracy did not improve from 0.71274\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6611 - accuracy: 0.7704 - val_loss: 1.7042 - val_accuracy: 0.6282\n",
            "Epoch 339/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.6516 - accuracy: 0.7711\n",
            "Epoch 339: val_accuracy did not improve from 0.71274\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.6546 - accuracy: 0.7708 - val_loss: 1.5623 - val_accuracy: 0.6688\n",
            "Epoch 340/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.7689 - accuracy: 0.7389\n",
            "Epoch 340: val_accuracy did not improve from 0.71274\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.7617 - accuracy: 0.7416 - val_loss: 1.4969 - val_accuracy: 0.6748\n",
            "Epoch 341/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.6300 - accuracy: 0.7784\n",
            "Epoch 341: val_accuracy did not improve from 0.71274\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6247 - accuracy: 0.7816 - val_loss: 1.5701 - val_accuracy: 0.6493\n",
            "Epoch 342/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.5993 - accuracy: 0.7904\n",
            "Epoch 342: val_accuracy did not improve from 0.71274\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5981 - accuracy: 0.7899 - val_loss: 1.5120 - val_accuracy: 0.6916\n",
            "Epoch 343/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.6046 - accuracy: 0.7843\n",
            "Epoch 343: val_accuracy did not improve from 0.71274\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5993 - accuracy: 0.7862 - val_loss: 1.5934 - val_accuracy: 0.6553\n",
            "Epoch 344/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.5437 - accuracy: 0.8115\n",
            "Epoch 344: val_accuracy improved from 0.71274 to 0.71653, saving model to /content/asl/Adam3/cp-344-0.72.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5495 - accuracy: 0.8095 - val_loss: 1.3639 - val_accuracy: 0.7165\n",
            "Epoch 345/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.6196 - accuracy: 0.7821\n",
            "Epoch 345: val_accuracy did not improve from 0.71653\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6216 - accuracy: 0.7815 - val_loss: 1.8440 - val_accuracy: 0.6184\n",
            "Epoch 346/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.6535 - accuracy: 0.7703\n",
            "Epoch 346: val_accuracy did not improve from 0.71653\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6571 - accuracy: 0.7681 - val_loss: 1.6834 - val_accuracy: 0.6347\n",
            "Epoch 347/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.6706 - accuracy: 0.7632\n",
            "Epoch 347: val_accuracy did not improve from 0.71653\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6657 - accuracy: 0.7641 - val_loss: 1.7903 - val_accuracy: 0.6038\n",
            "Epoch 348/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.7577 - accuracy: 0.7344\n",
            "Epoch 348: val_accuracy did not improve from 0.71653\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.7424 - accuracy: 0.7389 - val_loss: 1.3786 - val_accuracy: 0.7035\n",
            "Epoch 349/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.6516 - accuracy: 0.7774\n",
            "Epoch 349: val_accuracy did not improve from 0.71653\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6707 - accuracy: 0.7712 - val_loss: 1.6988 - val_accuracy: 0.6509\n",
            "Epoch 350/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.5901 - accuracy: 0.7921\n",
            "Epoch 350: val_accuracy did not improve from 0.71653\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6057 - accuracy: 0.7889 - val_loss: 1.4775 - val_accuracy: 0.6835\n",
            "Epoch 351/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.5781 - accuracy: 0.7958\n",
            "Epoch 351: val_accuracy did not improve from 0.71653\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5689 - accuracy: 0.7990 - val_loss: 1.4145 - val_accuracy: 0.7068\n",
            "Epoch 352/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.5211 - accuracy: 0.8194\n",
            "Epoch 352: val_accuracy did not improve from 0.71653\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5157 - accuracy: 0.8215 - val_loss: 1.4351 - val_accuracy: 0.6916\n",
            "Epoch 353/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.5942 - accuracy: 0.7891\n",
            "Epoch 353: val_accuracy improved from 0.71653 to 0.72087, saving model to /content/asl/Adam3/cp-353-0.72.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5942 - accuracy: 0.7889 - val_loss: 1.4280 - val_accuracy: 0.7209\n",
            "Epoch 354/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.5349 - accuracy: 0.8110\n",
            "Epoch 354: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.5370 - accuracy: 0.8102 - val_loss: 1.4053 - val_accuracy: 0.7024\n",
            "Epoch 355/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.6243 - accuracy: 0.7739\n",
            "Epoch 355: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.6236 - accuracy: 0.7742 - val_loss: 1.7200 - val_accuracy: 0.6341\n",
            "Epoch 356/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.5696 - accuracy: 0.8025\n",
            "Epoch 356: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.5659 - accuracy: 0.8048 - val_loss: 1.5640 - val_accuracy: 0.6678\n",
            "Epoch 357/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.5689 - accuracy: 0.7979\n",
            "Epoch 357: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.5676 - accuracy: 0.7984 - val_loss: 1.3958 - val_accuracy: 0.7003\n",
            "Epoch 358/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.5200 - accuracy: 0.8178\n",
            "Epoch 358: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.5214 - accuracy: 0.8169 - val_loss: 1.4108 - val_accuracy: 0.7014\n",
            "Epoch 359/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.5915 - accuracy: 0.7992\n",
            "Epoch 359: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.5897 - accuracy: 0.8001 - val_loss: 1.4625 - val_accuracy: 0.7041\n",
            "Epoch 360/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.5454 - accuracy: 0.8059\n",
            "Epoch 360: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.5454 - accuracy: 0.8059 - val_loss: 1.5700 - val_accuracy: 0.6873\n",
            "Epoch 361/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.5873 - accuracy: 0.7902\n",
            "Epoch 361: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.5845 - accuracy: 0.7907 - val_loss: 1.4770 - val_accuracy: 0.6894\n",
            "Epoch 362/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.7057 - accuracy: 0.7557\n",
            "Epoch 362: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 0.7057 - accuracy: 0.7557 - val_loss: 1.8221 - val_accuracy: 0.6385\n",
            "Epoch 363/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.6246 - accuracy: 0.7768\n",
            "Epoch 363: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.6173 - accuracy: 0.7796 - val_loss: 1.5255 - val_accuracy: 0.6959\n",
            "Epoch 364/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.5186 - accuracy: 0.8152\n",
            "Epoch 364: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5187 - accuracy: 0.8147 - val_loss: 1.4837 - val_accuracy: 0.6856\n",
            "Epoch 365/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.5048 - accuracy: 0.8281\n",
            "Epoch 365: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5066 - accuracy: 0.8277 - val_loss: 1.4627 - val_accuracy: 0.6726\n",
            "Epoch 366/700\n",
            "50/58 [========================>.....] - ETA: 0s - loss: 0.5070 - accuracy: 0.8206\n",
            "Epoch 366: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5483 - accuracy: 0.8095 - val_loss: 1.6213 - val_accuracy: 0.6553\n",
            "Epoch 367/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.5362 - accuracy: 0.8119\n",
            "Epoch 367: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5322 - accuracy: 0.8144 - val_loss: 1.3994 - val_accuracy: 0.7144\n",
            "Epoch 368/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.5052 - accuracy: 0.8203\n",
            "Epoch 368: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5132 - accuracy: 0.8181 - val_loss: 1.4987 - val_accuracy: 0.6981\n",
            "Epoch 369/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.4899 - accuracy: 0.8280\n",
            "Epoch 369: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.4982 - accuracy: 0.8246 - val_loss: 1.8865 - val_accuracy: 0.6271\n",
            "Epoch 370/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.7604 - accuracy: 0.7469\n",
            "Epoch 370: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.7532 - accuracy: 0.7491 - val_loss: 1.5492 - val_accuracy: 0.6509\n",
            "Epoch 371/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.6447 - accuracy: 0.7720\n",
            "Epoch 371: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6477 - accuracy: 0.7708 - val_loss: 1.5146 - val_accuracy: 0.6802\n",
            "Epoch 372/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.9613 - accuracy: 0.7046\n",
            "Epoch 372: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.9599 - accuracy: 0.7048 - val_loss: 1.5191 - val_accuracy: 0.6770\n",
            "Epoch 373/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.8662 - accuracy: 0.7103\n",
            "Epoch 373: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.8575 - accuracy: 0.7111 - val_loss: 1.5004 - val_accuracy: 0.6954\n",
            "Epoch 374/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.9831 - accuracy: 0.6924\n",
            "Epoch 374: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.9792 - accuracy: 0.6931 - val_loss: 2.0052 - val_accuracy: 0.5745\n",
            "Epoch 375/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.6872 - accuracy: 0.7635\n",
            "Epoch 375: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6717 - accuracy: 0.7686 - val_loss: 1.4513 - val_accuracy: 0.6824\n",
            "Epoch 376/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.4710 - accuracy: 0.8388\n",
            "Epoch 376: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.4766 - accuracy: 0.8361 - val_loss: 1.4495 - val_accuracy: 0.7062\n",
            "Epoch 377/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.5112 - accuracy: 0.8224\n",
            "Epoch 377: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5114 - accuracy: 0.8209 - val_loss: 1.6176 - val_accuracy: 0.6455\n",
            "Epoch 378/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.5881 - accuracy: 0.7935\n",
            "Epoch 378: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5868 - accuracy: 0.7944 - val_loss: 1.5587 - val_accuracy: 0.6439\n",
            "Epoch 379/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.6531 - accuracy: 0.7694\n",
            "Epoch 379: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6496 - accuracy: 0.7701 - val_loss: 1.5524 - val_accuracy: 0.6715\n",
            "Epoch 380/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.5227 - accuracy: 0.8148\n",
            "Epoch 380: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5175 - accuracy: 0.8166 - val_loss: 1.5255 - val_accuracy: 0.6656\n",
            "Epoch 381/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.5667 - accuracy: 0.8038\n",
            "Epoch 381: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5629 - accuracy: 0.8053 - val_loss: 1.5988 - val_accuracy: 0.6743\n",
            "Epoch 382/700\n",
            "50/58 [========================>.....] - ETA: 0s - loss: 0.5766 - accuracy: 0.7947\n",
            "Epoch 382: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5710 - accuracy: 0.7977 - val_loss: 1.4022 - val_accuracy: 0.7057\n",
            "Epoch 383/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.5804 - accuracy: 0.7880\n",
            "Epoch 383: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5807 - accuracy: 0.7872 - val_loss: 1.6680 - val_accuracy: 0.6401\n",
            "Epoch 384/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.6270 - accuracy: 0.7775\n",
            "Epoch 384: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.6139 - accuracy: 0.7830 - val_loss: 1.7170 - val_accuracy: 0.6412\n",
            "Epoch 385/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.6706 - accuracy: 0.7703\n",
            "Epoch 385: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6799 - accuracy: 0.7675 - val_loss: 1.7131 - val_accuracy: 0.6233\n",
            "Epoch 386/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.5265 - accuracy: 0.8125\n",
            "Epoch 386: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.5222 - accuracy: 0.8146 - val_loss: 1.3995 - val_accuracy: 0.7182\n",
            "Epoch 387/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.4768 - accuracy: 0.8316\n",
            "Epoch 387: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.4762 - accuracy: 0.8314 - val_loss: 1.4763 - val_accuracy: 0.6791\n",
            "Epoch 388/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.6221 - accuracy: 0.7804\n",
            "Epoch 388: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.6192 - accuracy: 0.7813 - val_loss: 1.6744 - val_accuracy: 0.6607\n",
            "Epoch 389/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.6064 - accuracy: 0.7854\n",
            "Epoch 389: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.6064 - accuracy: 0.7854 - val_loss: 1.7575 - val_accuracy: 0.6444\n",
            "Epoch 390/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.4987 - accuracy: 0.8247\n",
            "Epoch 390: val_accuracy did not improve from 0.72087\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.5015 - accuracy: 0.8226 - val_loss: 1.4097 - val_accuracy: 0.7144\n",
            "Epoch 391/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.5541 - accuracy: 0.8030\n",
            "Epoch 391: val_accuracy improved from 0.72087 to 0.73008, saving model to /content/asl/Adam3/cp-391-0.73.hdf5\n",
            "58/58 [==============================] - 1s 13ms/step - loss: 0.5541 - accuracy: 0.8030 - val_loss: 1.3914 - val_accuracy: 0.7301\n",
            "Epoch 392/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.5171 - accuracy: 0.8163\n",
            "Epoch 392: val_accuracy did not improve from 0.73008\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.5220 - accuracy: 0.8135 - val_loss: 1.5155 - val_accuracy: 0.6824\n",
            "Epoch 393/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.4983 - accuracy: 0.8223\n",
            "Epoch 393: val_accuracy did not improve from 0.73008\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.4935 - accuracy: 0.8246 - val_loss: 1.4140 - val_accuracy: 0.7176\n",
            "Epoch 394/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.5253 - accuracy: 0.8227\n",
            "Epoch 394: val_accuracy did not improve from 0.73008\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5668 - accuracy: 0.8101 - val_loss: 2.9207 - val_accuracy: 0.4661\n",
            "Epoch 395/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 1.1356 - accuracy: 0.6706\n",
            "Epoch 395: val_accuracy did not improve from 0.73008\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.1131 - accuracy: 0.6755 - val_loss: 1.6503 - val_accuracy: 0.6439\n",
            "Epoch 396/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.5622 - accuracy: 0.8000\n",
            "Epoch 396: val_accuracy did not improve from 0.73008\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5579 - accuracy: 0.8018 - val_loss: 1.5832 - val_accuracy: 0.6818\n",
            "Epoch 397/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.4622 - accuracy: 0.8377\n",
            "Epoch 397: val_accuracy did not improve from 0.73008\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4701 - accuracy: 0.8331 - val_loss: 1.6780 - val_accuracy: 0.6623\n",
            "Epoch 398/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.5245 - accuracy: 0.8131\n",
            "Epoch 398: val_accuracy did not improve from 0.73008\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5356 - accuracy: 0.8093 - val_loss: 1.5634 - val_accuracy: 0.6797\n",
            "Epoch 399/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.4870 - accuracy: 0.8244\n",
            "Epoch 399: val_accuracy did not improve from 0.73008\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.4867 - accuracy: 0.8249 - val_loss: 1.4307 - val_accuracy: 0.7127\n",
            "Epoch 400/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.5301 - accuracy: 0.8158\n",
            "Epoch 400: val_accuracy did not improve from 0.73008\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5360 - accuracy: 0.8140 - val_loss: 1.8280 - val_accuracy: 0.6152\n",
            "Epoch 401/700\n",
            "50/58 [========================>.....] - ETA: 0s - loss: 0.4938 - accuracy: 0.8225\n",
            "Epoch 401: val_accuracy improved from 0.73008 to 0.73388, saving model to /content/asl/Adam3/cp-401-0.73.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4901 - accuracy: 0.8230 - val_loss: 1.4065 - val_accuracy: 0.7339\n",
            "Epoch 402/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.5283 - accuracy: 0.8135\n",
            "Epoch 402: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5278 - accuracy: 0.8137 - val_loss: 1.4532 - val_accuracy: 0.7171\n",
            "Epoch 403/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.5466 - accuracy: 0.8070\n",
            "Epoch 403: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5481 - accuracy: 0.8062 - val_loss: 1.4831 - val_accuracy: 0.6894\n",
            "Epoch 404/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.6262 - accuracy: 0.7878\n",
            "Epoch 404: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6152 - accuracy: 0.7903 - val_loss: 1.3940 - val_accuracy: 0.7122\n",
            "Epoch 405/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.4246 - accuracy: 0.8538\n",
            "Epoch 405: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4263 - accuracy: 0.8525 - val_loss: 1.4085 - val_accuracy: 0.7333\n",
            "Epoch 406/700\n",
            "50/58 [========================>.....] - ETA: 0s - loss: 0.5031 - accuracy: 0.8227\n",
            "Epoch 406: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5486 - accuracy: 0.8112 - val_loss: 1.8752 - val_accuracy: 0.5978\n",
            "Epoch 407/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.7459 - accuracy: 0.7485\n",
            "Epoch 407: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.7148 - accuracy: 0.7588 - val_loss: 1.4751 - val_accuracy: 0.6949\n",
            "Epoch 408/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.5405 - accuracy: 0.8110\n",
            "Epoch 408: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5492 - accuracy: 0.8066 - val_loss: 1.5519 - val_accuracy: 0.6916\n",
            "Epoch 409/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.5478 - accuracy: 0.8067\n",
            "Epoch 409: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5512 - accuracy: 0.8056 - val_loss: 1.4197 - val_accuracy: 0.7035\n",
            "Epoch 410/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.5362 - accuracy: 0.8078\n",
            "Epoch 410: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5362 - accuracy: 0.8078 - val_loss: 1.4491 - val_accuracy: 0.6992\n",
            "Epoch 411/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.4767 - accuracy: 0.8255\n",
            "Epoch 411: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4767 - accuracy: 0.8255 - val_loss: 1.4840 - val_accuracy: 0.7176\n",
            "Epoch 412/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.4877 - accuracy: 0.8262\n",
            "Epoch 412: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4875 - accuracy: 0.8245 - val_loss: 1.5259 - val_accuracy: 0.7144\n",
            "Epoch 413/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.4359 - accuracy: 0.8436\n",
            "Epoch 413: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.4395 - accuracy: 0.8421 - val_loss: 1.5474 - val_accuracy: 0.6846\n",
            "Epoch 414/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.5635 - accuracy: 0.7966\n",
            "Epoch 414: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5712 - accuracy: 0.7927 - val_loss: 1.6542 - val_accuracy: 0.6531\n",
            "Epoch 415/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.5875 - accuracy: 0.7910\n",
            "Epoch 415: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.5891 - accuracy: 0.7896 - val_loss: 1.4508 - val_accuracy: 0.7144\n",
            "Epoch 416/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.5351 - accuracy: 0.8079\n",
            "Epoch 416: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.5370 - accuracy: 0.8066 - val_loss: 1.9857 - val_accuracy: 0.5881\n",
            "Epoch 417/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.9805 - accuracy: 0.6986\n",
            "Epoch 417: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 1s 15ms/step - loss: 0.9773 - accuracy: 0.6987 - val_loss: 2.1825 - val_accuracy: 0.5729\n",
            "Epoch 418/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.7013 - accuracy: 0.7561\n",
            "Epoch 418: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 1s 22ms/step - loss: 0.7013 - accuracy: 0.7561 - val_loss: 1.4779 - val_accuracy: 0.7079\n",
            "Epoch 419/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.4561 - accuracy: 0.8411\n",
            "Epoch 419: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 1s 16ms/step - loss: 0.4537 - accuracy: 0.8428 - val_loss: 1.4356 - val_accuracy: 0.7176\n",
            "Epoch 420/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.4530 - accuracy: 0.8419\n",
            "Epoch 420: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 1s 19ms/step - loss: 0.4506 - accuracy: 0.8428 - val_loss: 1.4709 - val_accuracy: 0.7214\n",
            "Epoch 421/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.5106 - accuracy: 0.8222\n",
            "Epoch 421: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5143 - accuracy: 0.8204 - val_loss: 1.5530 - val_accuracy: 0.6721\n",
            "Epoch 422/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.6592 - accuracy: 0.7730\n",
            "Epoch 422: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.6729 - accuracy: 0.7705 - val_loss: 1.6398 - val_accuracy: 0.6780\n",
            "Epoch 423/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.6361 - accuracy: 0.7802\n",
            "Epoch 423: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6343 - accuracy: 0.7785 - val_loss: 1.8372 - val_accuracy: 0.5989\n",
            "Epoch 424/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.5078 - accuracy: 0.8200\n",
            "Epoch 424: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5028 - accuracy: 0.8219 - val_loss: 1.5789 - val_accuracy: 0.6748\n",
            "Epoch 425/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.5177 - accuracy: 0.8126\n",
            "Epoch 425: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5171 - accuracy: 0.8129 - val_loss: 1.3842 - val_accuracy: 0.7263\n",
            "Epoch 426/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.5089 - accuracy: 0.8203\n",
            "Epoch 426: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5110 - accuracy: 0.8184 - val_loss: 1.5112 - val_accuracy: 0.7106\n",
            "Epoch 427/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.4546 - accuracy: 0.8397\n",
            "Epoch 427: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.4504 - accuracy: 0.8409 - val_loss: 1.5158 - val_accuracy: 0.7019\n",
            "Epoch 428/700\n",
            "50/58 [========================>.....] - ETA: 0s - loss: 0.4946 - accuracy: 0.8217\n",
            "Epoch 428: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4990 - accuracy: 0.8207 - val_loss: 1.4014 - val_accuracy: 0.7220\n",
            "Epoch 429/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.6080 - accuracy: 0.7950\n",
            "Epoch 429: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.6277 - accuracy: 0.7881 - val_loss: 1.9444 - val_accuracy: 0.6098\n",
            "Epoch 430/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.5796 - accuracy: 0.7876\n",
            "Epoch 430: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5783 - accuracy: 0.7864 - val_loss: 1.7999 - val_accuracy: 0.6602\n",
            "Epoch 431/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.5544 - accuracy: 0.8051\n",
            "Epoch 431: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5509 - accuracy: 0.8070 - val_loss: 1.5804 - val_accuracy: 0.6883\n",
            "Epoch 432/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.4461 - accuracy: 0.8429\n",
            "Epoch 432: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.4482 - accuracy: 0.8419 - val_loss: 1.5230 - val_accuracy: 0.7100\n",
            "Epoch 433/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.5022 - accuracy: 0.8277\n",
            "Epoch 433: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5161 - accuracy: 0.8220 - val_loss: 1.5452 - val_accuracy: 0.6791\n",
            "Epoch 434/700\n",
            "50/58 [========================>.....] - ETA: 0s - loss: 0.5492 - accuracy: 0.7989\n",
            "Epoch 434: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5637 - accuracy: 0.7934 - val_loss: 2.0059 - val_accuracy: 0.6168\n",
            "Epoch 435/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.6350 - accuracy: 0.7841\n",
            "Epoch 435: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6280 - accuracy: 0.7864 - val_loss: 1.6976 - val_accuracy: 0.6596\n",
            "Epoch 436/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.5423 - accuracy: 0.8133\n",
            "Epoch 436: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5380 - accuracy: 0.8142 - val_loss: 1.4517 - val_accuracy: 0.7117\n",
            "Epoch 437/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.4677 - accuracy: 0.8307\n",
            "Epoch 437: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.4687 - accuracy: 0.8304 - val_loss: 1.4708 - val_accuracy: 0.6986\n",
            "Epoch 438/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.4075 - accuracy: 0.8560\n",
            "Epoch 438: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8544 - val_loss: 1.4723 - val_accuracy: 0.6927\n",
            "Epoch 439/700\n",
            "50/58 [========================>.....] - ETA: 0s - loss: 0.4941 - accuracy: 0.8217\n",
            "Epoch 439: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5010 - accuracy: 0.8211 - val_loss: 1.5266 - val_accuracy: 0.6981\n",
            "Epoch 440/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.5078 - accuracy: 0.8122\n",
            "Epoch 440: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5019 - accuracy: 0.8143 - val_loss: 1.5568 - val_accuracy: 0.6883\n",
            "Epoch 441/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.6291 - accuracy: 0.7883\n",
            "Epoch 441: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.6325 - accuracy: 0.7865 - val_loss: 1.5944 - val_accuracy: 0.6732\n",
            "Epoch 442/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.5226 - accuracy: 0.8143\n",
            "Epoch 442: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5199 - accuracy: 0.8152 - val_loss: 1.5038 - val_accuracy: 0.7057\n",
            "Epoch 443/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.4169 - accuracy: 0.8536\n",
            "Epoch 443: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.4224 - accuracy: 0.8521 - val_loss: 1.5813 - val_accuracy: 0.6921\n",
            "Epoch 444/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.4746 - accuracy: 0.8313\n",
            "Epoch 444: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.4729 - accuracy: 0.8329 - val_loss: 1.5692 - val_accuracy: 0.7057\n",
            "Epoch 445/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.4307 - accuracy: 0.8457\n",
            "Epoch 445: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.4405 - accuracy: 0.8418 - val_loss: 1.7188 - val_accuracy: 0.6531\n",
            "Epoch 446/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.4804 - accuracy: 0.8283\n",
            "Epoch 446: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.4844 - accuracy: 0.8257 - val_loss: 1.9470 - val_accuracy: 0.6103\n",
            "Epoch 447/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.6682 - accuracy: 0.7692\n",
            "Epoch 447: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.6708 - accuracy: 0.7667 - val_loss: 1.6950 - val_accuracy: 0.6623\n",
            "Epoch 448/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.6520 - accuracy: 0.7771\n",
            "Epoch 448: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.6520 - accuracy: 0.7771 - val_loss: 2.0478 - val_accuracy: 0.6022\n",
            "Epoch 449/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.6901 - accuracy: 0.7705\n",
            "Epoch 449: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.6901 - accuracy: 0.7705 - val_loss: 1.4496 - val_accuracy: 0.7127\n",
            "Epoch 450/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.5250 - accuracy: 0.8089\n",
            "Epoch 450: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.5277 - accuracy: 0.8076 - val_loss: 1.5031 - val_accuracy: 0.6878\n",
            "Epoch 451/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.4465 - accuracy: 0.8386\n",
            "Epoch 451: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4408 - accuracy: 0.8409 - val_loss: 1.5553 - val_accuracy: 0.7008\n",
            "Epoch 452/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.4867 - accuracy: 0.8244\n",
            "Epoch 452: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4869 - accuracy: 0.8238 - val_loss: 1.6330 - val_accuracy: 0.6770\n",
            "Epoch 453/700\n",
            "50/58 [========================>.....] - ETA: 0s - loss: 0.5254 - accuracy: 0.8131\n",
            "Epoch 453: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5143 - accuracy: 0.8165 - val_loss: 1.5532 - val_accuracy: 0.6808\n",
            "Epoch 454/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.4423 - accuracy: 0.8405\n",
            "Epoch 454: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4481 - accuracy: 0.8386 - val_loss: 1.4476 - val_accuracy: 0.7154\n",
            "Epoch 455/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.4946 - accuracy: 0.8260\n",
            "Epoch 455: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4948 - accuracy: 0.8264 - val_loss: 1.6375 - val_accuracy: 0.6678\n",
            "Epoch 456/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.5548 - accuracy: 0.8056\n",
            "Epoch 456: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5437 - accuracy: 0.8090 - val_loss: 1.7564 - val_accuracy: 0.6558\n",
            "Epoch 457/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.4864 - accuracy: 0.8242\n",
            "Epoch 457: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.4764 - accuracy: 0.8284 - val_loss: 1.4751 - val_accuracy: 0.7160\n",
            "Epoch 458/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.4838 - accuracy: 0.8308\n",
            "Epoch 458: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.4757 - accuracy: 0.8331 - val_loss: 1.4426 - val_accuracy: 0.7214\n",
            "Epoch 459/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.4451 - accuracy: 0.8370\n",
            "Epoch 459: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4463 - accuracy: 0.8360 - val_loss: 1.9818 - val_accuracy: 0.6125\n",
            "Epoch 460/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.5101 - accuracy: 0.8215\n",
            "Epoch 460: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5136 - accuracy: 0.8201 - val_loss: 1.7734 - val_accuracy: 0.6710\n",
            "Epoch 461/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.6534 - accuracy: 0.7739\n",
            "Epoch 461: val_accuracy did not improve from 0.73388\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.6317 - accuracy: 0.7804 - val_loss: 1.6388 - val_accuracy: 0.6883\n",
            "Epoch 462/700\n",
            "50/58 [========================>.....] - ETA: 0s - loss: 0.6551 - accuracy: 0.7798\n",
            "Epoch 462: val_accuracy improved from 0.73388 to 0.73713, saving model to /content/asl/Adam3/cp-462-0.74.hdf5\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.6271 - accuracy: 0.7881 - val_loss: 1.4950 - val_accuracy: 0.7371\n",
            "Epoch 463/700\n",
            "50/58 [========================>.....] - ETA: 0s - loss: 0.4433 - accuracy: 0.8419\n",
            "Epoch 463: val_accuracy did not improve from 0.73713\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.4480 - accuracy: 0.8395 - val_loss: 1.7455 - val_accuracy: 0.6547\n",
            "Epoch 464/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.4826 - accuracy: 0.8307\n",
            "Epoch 464: val_accuracy did not improve from 0.73713\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4915 - accuracy: 0.8258 - val_loss: 1.6267 - val_accuracy: 0.6797\n",
            "Epoch 465/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.4899 - accuracy: 0.8234\n",
            "Epoch 465: val_accuracy did not improve from 0.73713\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4895 - accuracy: 0.8240 - val_loss: 1.7328 - val_accuracy: 0.6656\n",
            "Epoch 466/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.5812 - accuracy: 0.7987\n",
            "Epoch 466: val_accuracy did not improve from 0.73713\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5737 - accuracy: 0.8005 - val_loss: 1.5452 - val_accuracy: 0.7030\n",
            "Epoch 467/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.7763 - accuracy: 0.7397\n",
            "Epoch 467: val_accuracy did not improve from 0.73713\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.7647 - accuracy: 0.7437 - val_loss: 1.8748 - val_accuracy: 0.6358\n",
            "Epoch 468/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.5275 - accuracy: 0.8134\n",
            "Epoch 468: val_accuracy did not improve from 0.73713\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5276 - accuracy: 0.8142 - val_loss: 1.4312 - val_accuracy: 0.7084\n",
            "Epoch 469/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.4511 - accuracy: 0.8367\n",
            "Epoch 469: val_accuracy did not improve from 0.73713\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4499 - accuracy: 0.8375 - val_loss: 1.4531 - val_accuracy: 0.7198\n",
            "Epoch 470/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.4324 - accuracy: 0.8463\n",
            "Epoch 470: val_accuracy did not improve from 0.73713\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.4360 - accuracy: 0.8441 - val_loss: 1.4648 - val_accuracy: 0.7106\n",
            "Epoch 471/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.5294 - accuracy: 0.8108\n",
            "Epoch 471: val_accuracy did not improve from 0.73713\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5268 - accuracy: 0.8101 - val_loss: 1.5739 - val_accuracy: 0.6808\n",
            "Epoch 472/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.6368 - accuracy: 0.7840\n",
            "Epoch 472: val_accuracy did not improve from 0.73713\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.6360 - accuracy: 0.7832 - val_loss: 1.7248 - val_accuracy: 0.6396\n",
            "Epoch 473/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.4489 - accuracy: 0.8409\n",
            "Epoch 473: val_accuracy did not improve from 0.73713\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.4495 - accuracy: 0.8405 - val_loss: 1.4657 - val_accuracy: 0.7079\n",
            "Epoch 474/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.4010 - accuracy: 0.8580\n",
            "Epoch 474: val_accuracy did not improve from 0.73713\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 0.3994 - accuracy: 0.8586 - val_loss: 1.6035 - val_accuracy: 0.6889\n",
            "Epoch 475/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.4210 - accuracy: 0.8512\n",
            "Epoch 475: val_accuracy did not improve from 0.73713\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 0.4199 - accuracy: 0.8513 - val_loss: 1.5263 - val_accuracy: 0.7073\n",
            "Epoch 476/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.4664 - accuracy: 0.8297\n",
            "Epoch 476: val_accuracy did not improve from 0.73713\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.4722 - accuracy: 0.8276 - val_loss: 1.4686 - val_accuracy: 0.7290\n",
            "Epoch 477/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.6912 - accuracy: 0.7642\n",
            "Epoch 477: val_accuracy did not improve from 0.73713\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.7024 - accuracy: 0.7618 - val_loss: 2.7259 - val_accuracy: 0.5024\n",
            "Epoch 478/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 1.0160 - accuracy: 0.6983\n",
            "Epoch 478: val_accuracy did not improve from 0.73713\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.0160 - accuracy: 0.6983 - val_loss: 1.7425 - val_accuracy: 0.6347\n",
            "Epoch 479/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.4321 - accuracy: 0.8489\n",
            "Epoch 479: val_accuracy did not improve from 0.73713\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.4306 - accuracy: 0.8494 - val_loss: 1.4561 - val_accuracy: 0.7328\n",
            "Epoch 480/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.4071 - accuracy: 0.8560\n",
            "Epoch 480: val_accuracy did not improve from 0.73713\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4071 - accuracy: 0.8560 - val_loss: 1.4851 - val_accuracy: 0.7024\n",
            "Epoch 481/700\n",
            "50/58 [========================>.....] - ETA: 0s - loss: 0.3926 - accuracy: 0.8627\n",
            "Epoch 481: val_accuracy did not improve from 0.73713\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.3999 - accuracy: 0.8597 - val_loss: 1.4790 - val_accuracy: 0.7171\n",
            "Epoch 482/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.4416 - accuracy: 0.8440\n",
            "Epoch 482: val_accuracy did not improve from 0.73713\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4427 - accuracy: 0.8436 - val_loss: 1.5803 - val_accuracy: 0.6786\n",
            "Epoch 483/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.4700 - accuracy: 0.8327\n",
            "Epoch 483: val_accuracy did not improve from 0.73713\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4761 - accuracy: 0.8318 - val_loss: 1.7124 - val_accuracy: 0.6911\n",
            "Epoch 484/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.3893 - accuracy: 0.8633\n",
            "Epoch 484: val_accuracy did not improve from 0.73713\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.3955 - accuracy: 0.8605 - val_loss: 1.5716 - val_accuracy: 0.6780\n",
            "Epoch 485/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.4187 - accuracy: 0.8517\n",
            "Epoch 485: val_accuracy did not improve from 0.73713\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.4148 - accuracy: 0.8520 - val_loss: 1.5447 - val_accuracy: 0.6976\n",
            "Epoch 486/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.3797 - accuracy: 0.8647\n",
            "Epoch 486: val_accuracy did not improve from 0.73713\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.3875 - accuracy: 0.8608 - val_loss: 1.7743 - val_accuracy: 0.6385\n",
            "Epoch 487/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.5285 - accuracy: 0.8121\n",
            "Epoch 487: val_accuracy did not improve from 0.73713\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5237 - accuracy: 0.8135 - val_loss: 1.6276 - val_accuracy: 0.6981\n",
            "Epoch 488/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.5480 - accuracy: 0.8093\n",
            "Epoch 488: val_accuracy did not improve from 0.73713\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5705 - accuracy: 0.8038 - val_loss: 2.1777 - val_accuracy: 0.5832\n",
            "Epoch 489/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.6693 - accuracy: 0.7758\n",
            "Epoch 489: val_accuracy did not improve from 0.73713\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.6973 - accuracy: 0.7709 - val_loss: 2.6020 - val_accuracy: 0.5388\n",
            "Epoch 490/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.8732 - accuracy: 0.7262\n",
            "Epoch 490: val_accuracy did not improve from 0.73713\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.8732 - accuracy: 0.7262 - val_loss: 1.7386 - val_accuracy: 0.6423\n",
            "Epoch 491/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.4264 - accuracy: 0.8535\n",
            "Epoch 491: val_accuracy improved from 0.73713 to 0.73930, saving model to /content/asl/Adam3/cp-491-0.74.hdf5\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.4241 - accuracy: 0.8548 - val_loss: 1.4465 - val_accuracy: 0.7393\n",
            "Epoch 492/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.3670 - accuracy: 0.8722\n",
            "Epoch 492: val_accuracy improved from 0.73930 to 0.74526, saving model to /content/asl/Adam3/cp-492-0.75.hdf5\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.3670 - accuracy: 0.8722 - val_loss: 1.3808 - val_accuracy: 0.7453\n",
            "Epoch 493/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.3990 - accuracy: 0.8547\n",
            "Epoch 493: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4004 - accuracy: 0.8545 - val_loss: 1.4094 - val_accuracy: 0.7371\n",
            "Epoch 494/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.4421 - accuracy: 0.8453\n",
            "Epoch 494: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.4387 - accuracy: 0.8456 - val_loss: 1.4555 - val_accuracy: 0.7263\n",
            "Epoch 495/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.3744 - accuracy: 0.8673\n",
            "Epoch 495: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.3775 - accuracy: 0.8667 - val_loss: 1.4289 - val_accuracy: 0.7312\n",
            "Epoch 496/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.3781 - accuracy: 0.8673\n",
            "Epoch 496: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.3827 - accuracy: 0.8649 - val_loss: 1.5344 - val_accuracy: 0.7160\n",
            "Epoch 497/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.5258 - accuracy: 0.8099\n",
            "Epoch 497: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5382 - accuracy: 0.8053 - val_loss: 1.5400 - val_accuracy: 0.7209\n",
            "Epoch 498/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.6600 - accuracy: 0.7865\n",
            "Epoch 498: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6657 - accuracy: 0.7841 - val_loss: 1.8242 - val_accuracy: 0.6341\n",
            "Epoch 499/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.5318 - accuracy: 0.8119\n",
            "Epoch 499: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5217 - accuracy: 0.8151 - val_loss: 1.4378 - val_accuracy: 0.7209\n",
            "Epoch 500/700\n",
            "50/58 [========================>.....] - ETA: 0s - loss: 0.3784 - accuracy: 0.8636\n",
            "Epoch 500: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.3793 - accuracy: 0.8639 - val_loss: 1.4562 - val_accuracy: 0.7279\n",
            "Epoch 501/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.3402 - accuracy: 0.8806\n",
            "Epoch 501: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3470 - accuracy: 0.8777 - val_loss: 1.4960 - val_accuracy: 0.7062\n",
            "Epoch 502/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.3837 - accuracy: 0.8643\n",
            "Epoch 502: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 0.3814 - accuracy: 0.8650 - val_loss: 1.4821 - val_accuracy: 0.7333\n",
            "Epoch 503/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.4840 - accuracy: 0.8324\n",
            "Epoch 503: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.4828 - accuracy: 0.8330 - val_loss: 1.8745 - val_accuracy: 0.6390\n",
            "Epoch 504/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 1.2175 - accuracy: 0.6913\n",
            "Epoch 504: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.1899 - accuracy: 0.6958 - val_loss: 1.5411 - val_accuracy: 0.6954\n",
            "Epoch 505/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.4270 - accuracy: 0.8496\n",
            "Epoch 505: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 0.4275 - accuracy: 0.8491 - val_loss: 1.4063 - val_accuracy: 0.7236\n",
            "Epoch 506/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.4059 - accuracy: 0.8566\n",
            "Epoch 506: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.4060 - accuracy: 0.8560 - val_loss: 1.8274 - val_accuracy: 0.6564\n",
            "Epoch 507/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.4403 - accuracy: 0.8428\n",
            "Epoch 507: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.4387 - accuracy: 0.8434 - val_loss: 1.4617 - val_accuracy: 0.7203\n",
            "Epoch 508/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.4002 - accuracy: 0.8574\n",
            "Epoch 508: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.4009 - accuracy: 0.8569 - val_loss: 1.4408 - val_accuracy: 0.7360\n",
            "Epoch 509/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.3684 - accuracy: 0.8736\n",
            "Epoch 509: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3723 - accuracy: 0.8722 - val_loss: 1.6621 - val_accuracy: 0.6970\n",
            "Epoch 510/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.6282 - accuracy: 0.7888\n",
            "Epoch 510: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6398 - accuracy: 0.7837 - val_loss: 2.2168 - val_accuracy: 0.5794\n",
            "Epoch 511/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.6440 - accuracy: 0.7782\n",
            "Epoch 511: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.6312 - accuracy: 0.7819 - val_loss: 1.7240 - val_accuracy: 0.6699\n",
            "Epoch 512/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.4538 - accuracy: 0.8333\n",
            "Epoch 512: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.4548 - accuracy: 0.8306 - val_loss: 1.4776 - val_accuracy: 0.7322\n",
            "Epoch 513/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.3797 - accuracy: 0.8668\n",
            "Epoch 513: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.3760 - accuracy: 0.8686 - val_loss: 1.4336 - val_accuracy: 0.7415\n",
            "Epoch 514/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.3596 - accuracy: 0.8742\n",
            "Epoch 514: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3596 - accuracy: 0.8742 - val_loss: 1.4685 - val_accuracy: 0.7290\n",
            "Epoch 515/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.5689 - accuracy: 0.8025\n",
            "Epoch 515: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5732 - accuracy: 0.8009 - val_loss: 1.5210 - val_accuracy: 0.7290\n",
            "Epoch 516/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.4472 - accuracy: 0.8389\n",
            "Epoch 516: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4521 - accuracy: 0.8365 - val_loss: 1.6436 - val_accuracy: 0.6873\n",
            "Epoch 517/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.4986 - accuracy: 0.8228\n",
            "Epoch 517: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4893 - accuracy: 0.8265 - val_loss: 1.5507 - val_accuracy: 0.7127\n",
            "Epoch 518/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.3458 - accuracy: 0.8801\n",
            "Epoch 518: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.3535 - accuracy: 0.8761 - val_loss: 1.6301 - val_accuracy: 0.6932\n",
            "Epoch 519/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.3816 - accuracy: 0.8628\n",
            "Epoch 519: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.3806 - accuracy: 0.8630 - val_loss: 1.5760 - val_accuracy: 0.7144\n",
            "Epoch 520/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.4223 - accuracy: 0.8460\n",
            "Epoch 520: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4365 - accuracy: 0.8414 - val_loss: 1.8475 - val_accuracy: 0.6645\n",
            "Epoch 521/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.4799 - accuracy: 0.8254\n",
            "Epoch 521: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.4809 - accuracy: 0.8245 - val_loss: 1.5870 - val_accuracy: 0.7046\n",
            "Epoch 522/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.4059 - accuracy: 0.8581\n",
            "Epoch 522: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.8558 - val_loss: 1.6132 - val_accuracy: 0.6959\n",
            "Epoch 523/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.5140 - accuracy: 0.8148\n",
            "Epoch 523: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5161 - accuracy: 0.8142 - val_loss: 1.5021 - val_accuracy: 0.7268\n",
            "Epoch 524/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.6054 - accuracy: 0.7858\n",
            "Epoch 524: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.6054 - accuracy: 0.7858 - val_loss: 1.6014 - val_accuracy: 0.6965\n",
            "Epoch 525/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.6019 - accuracy: 0.7858\n",
            "Epoch 525: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5992 - accuracy: 0.7872 - val_loss: 1.6449 - val_accuracy: 0.6764\n",
            "Epoch 526/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.5734 - accuracy: 0.7981\n",
            "Epoch 526: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5596 - accuracy: 0.8026 - val_loss: 1.5982 - val_accuracy: 0.6986\n",
            "Epoch 527/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.4649 - accuracy: 0.8302\n",
            "Epoch 527: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4938 - accuracy: 0.8221 - val_loss: 2.2518 - val_accuracy: 0.5902\n",
            "Epoch 528/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.4968 - accuracy: 0.8233\n",
            "Epoch 528: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5008 - accuracy: 0.8220 - val_loss: 1.8407 - val_accuracy: 0.6482\n",
            "Epoch 529/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.4178 - accuracy: 0.8525\n",
            "Epoch 529: val_accuracy did not improve from 0.74526\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.4181 - accuracy: 0.8510 - val_loss: 1.5057 - val_accuracy: 0.7225\n",
            "Epoch 530/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.3740 - accuracy: 0.8669\n",
            "Epoch 530: val_accuracy improved from 0.74526 to 0.75122, saving model to /content/asl/Adam3/cp-530-0.75.hdf5\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.3723 - accuracy: 0.8674 - val_loss: 1.4866 - val_accuracy: 0.7512\n",
            "Epoch 531/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.3560 - accuracy: 0.8736\n",
            "Epoch 531: val_accuracy did not improve from 0.75122\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.3586 - accuracy: 0.8730 - val_loss: 1.5403 - val_accuracy: 0.7393\n",
            "Epoch 532/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.4239 - accuracy: 0.8439\n",
            "Epoch 532: val_accuracy did not improve from 0.75122\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.4261 - accuracy: 0.8433 - val_loss: 1.5628 - val_accuracy: 0.7144\n",
            "Epoch 533/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.3735 - accuracy: 0.8648\n",
            "Epoch 533: val_accuracy did not improve from 0.75122\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 0.3747 - accuracy: 0.8642 - val_loss: 1.6015 - val_accuracy: 0.6986\n",
            "Epoch 534/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.4210 - accuracy: 0.8438\n",
            "Epoch 534: val_accuracy did not improve from 0.75122\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 0.4219 - accuracy: 0.8437 - val_loss: 1.6391 - val_accuracy: 0.7051\n",
            "Epoch 535/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.4618 - accuracy: 0.8365\n",
            "Epoch 535: val_accuracy did not improve from 0.75122\n",
            "58/58 [==============================] - 1s 13ms/step - loss: 0.4618 - accuracy: 0.8365 - val_loss: 1.7372 - val_accuracy: 0.6743\n",
            "Epoch 536/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.5422 - accuracy: 0.8100\n",
            "Epoch 536: val_accuracy did not improve from 0.75122\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.5411 - accuracy: 0.8108 - val_loss: 1.5858 - val_accuracy: 0.7062\n",
            "Epoch 537/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.4001 - accuracy: 0.8604\n",
            "Epoch 537: val_accuracy did not improve from 0.75122\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.4029 - accuracy: 0.8592 - val_loss: 1.7228 - val_accuracy: 0.6667\n",
            "Epoch 538/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.4121 - accuracy: 0.8506\n",
            "Epoch 538: val_accuracy did not improve from 0.75122\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4153 - accuracy: 0.8494 - val_loss: 1.5684 - val_accuracy: 0.7252\n",
            "Epoch 539/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.6236 - accuracy: 0.7910\n",
            "Epoch 539: val_accuracy did not improve from 0.75122\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.6168 - accuracy: 0.7922 - val_loss: 1.5755 - val_accuracy: 0.7225\n",
            "Epoch 540/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.4481 - accuracy: 0.8423\n",
            "Epoch 540: val_accuracy did not improve from 0.75122\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4740 - accuracy: 0.8335 - val_loss: 2.8299 - val_accuracy: 0.5469\n",
            "Epoch 541/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.7378 - accuracy: 0.7578\n",
            "Epoch 541: val_accuracy did not improve from 0.75122\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.7239 - accuracy: 0.7614 - val_loss: 1.6239 - val_accuracy: 0.6786\n",
            "Epoch 542/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.4096 - accuracy: 0.8544\n",
            "Epoch 542: val_accuracy did not improve from 0.75122\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4151 - accuracy: 0.8527 - val_loss: 1.4577 - val_accuracy: 0.7382\n",
            "Epoch 543/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.4028 - accuracy: 0.8554\n",
            "Epoch 543: val_accuracy did not improve from 0.75122\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3980 - accuracy: 0.8566 - val_loss: 1.5324 - val_accuracy: 0.7187\n",
            "Epoch 544/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.3650 - accuracy: 0.8686\n",
            "Epoch 544: val_accuracy did not improve from 0.75122\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3641 - accuracy: 0.8695 - val_loss: 1.6302 - val_accuracy: 0.6835\n",
            "Epoch 545/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.3511 - accuracy: 0.8722\n",
            "Epoch 545: val_accuracy improved from 0.75122 to 0.75230, saving model to /content/asl/Adam3/cp-545-0.75.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3424 - accuracy: 0.8766 - val_loss: 1.4393 - val_accuracy: 0.7523\n",
            "Epoch 546/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.4143 - accuracy: 0.8514\n",
            "Epoch 546: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.4152 - accuracy: 0.8502 - val_loss: 1.5042 - val_accuracy: 0.7127\n",
            "Epoch 547/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.3609 - accuracy: 0.8672\n",
            "Epoch 547: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3577 - accuracy: 0.8684 - val_loss: 1.5509 - val_accuracy: 0.7133\n",
            "Epoch 548/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.7498 - accuracy: 0.7646\n",
            "Epoch 548: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.7663 - accuracy: 0.7599 - val_loss: 1.9314 - val_accuracy: 0.6304\n",
            "Epoch 549/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.6566 - accuracy: 0.7800\n",
            "Epoch 549: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.6535 - accuracy: 0.7813 - val_loss: 1.8530 - val_accuracy: 0.6575\n",
            "Epoch 550/700\n",
            "50/58 [========================>.....] - ETA: 0s - loss: 0.4691 - accuracy: 0.8300\n",
            "Epoch 550: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4547 - accuracy: 0.8364 - val_loss: 1.5392 - val_accuracy: 0.7225\n",
            "Epoch 551/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.3493 - accuracy: 0.8805\n",
            "Epoch 551: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3553 - accuracy: 0.8756 - val_loss: 1.5810 - val_accuracy: 0.7100\n",
            "Epoch 552/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.4426 - accuracy: 0.8453\n",
            "Epoch 552: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4376 - accuracy: 0.8470 - val_loss: 1.5640 - val_accuracy: 0.6894\n",
            "Epoch 553/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.4646 - accuracy: 0.8339\n",
            "Epoch 553: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.4626 - accuracy: 0.8346 - val_loss: 1.4118 - val_accuracy: 0.7344\n",
            "Epoch 554/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.4170 - accuracy: 0.8528\n",
            "Epoch 554: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4155 - accuracy: 0.8537 - val_loss: 1.4635 - val_accuracy: 0.7339\n",
            "Epoch 555/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.3934 - accuracy: 0.8591\n",
            "Epoch 555: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.3967 - accuracy: 0.8578 - val_loss: 1.4924 - val_accuracy: 0.7312\n",
            "Epoch 556/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.5405 - accuracy: 0.8251\n",
            "Epoch 556: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5405 - accuracy: 0.8251 - val_loss: 2.2284 - val_accuracy: 0.6173\n",
            "Epoch 557/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 1.8026 - accuracy: 0.5917\n",
            "Epoch 557: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 1.7285 - accuracy: 0.5985 - val_loss: 1.7137 - val_accuracy: 0.6634\n",
            "Epoch 558/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.4487 - accuracy: 0.8396\n",
            "Epoch 558: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.4478 - accuracy: 0.8399 - val_loss: 1.4719 - val_accuracy: 0.7344\n",
            "Epoch 559/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.3584 - accuracy: 0.8760\n",
            "Epoch 559: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.3579 - accuracy: 0.8758 - val_loss: 1.6282 - val_accuracy: 0.6938\n",
            "Epoch 560/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.3595 - accuracy: 0.8717\n",
            "Epoch 560: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.3573 - accuracy: 0.8731 - val_loss: 1.4464 - val_accuracy: 0.7523\n",
            "Epoch 561/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.3455 - accuracy: 0.8771\n",
            "Epoch 561: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 1s 13ms/step - loss: 0.3455 - accuracy: 0.8771 - val_loss: 1.5270 - val_accuracy: 0.7220\n",
            "Epoch 562/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.4724 - accuracy: 0.8301\n",
            "Epoch 562: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.4775 - accuracy: 0.8288 - val_loss: 1.8169 - val_accuracy: 0.6499\n",
            "Epoch 563/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.3687 - accuracy: 0.8716\n",
            "Epoch 563: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.3653 - accuracy: 0.8720 - val_loss: 1.3904 - val_accuracy: 0.7501\n",
            "Epoch 564/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.3316 - accuracy: 0.8827\n",
            "Epoch 564: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.3325 - accuracy: 0.8826 - val_loss: 1.4856 - val_accuracy: 0.7285\n",
            "Epoch 565/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.3128 - accuracy: 0.8888\n",
            "Epoch 565: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3171 - accuracy: 0.8875 - val_loss: 1.6761 - val_accuracy: 0.6883\n",
            "Epoch 566/700\n",
            "50/58 [========================>.....] - ETA: 0s - loss: 0.3450 - accuracy: 0.8763\n",
            "Epoch 566: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3431 - accuracy: 0.8773 - val_loss: 1.4997 - val_accuracy: 0.7431\n",
            "Epoch 567/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.4472 - accuracy: 0.8433\n",
            "Epoch 567: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4472 - accuracy: 0.8433 - val_loss: 1.4296 - val_accuracy: 0.7398\n",
            "Epoch 568/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.3310 - accuracy: 0.8839\n",
            "Epoch 568: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.3361 - accuracy: 0.8827 - val_loss: 1.4904 - val_accuracy: 0.7518\n",
            "Epoch 569/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.4112 - accuracy: 0.8481\n",
            "Epoch 569: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.4127 - accuracy: 0.8476 - val_loss: 1.6335 - val_accuracy: 0.7030\n",
            "Epoch 570/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 1.0010 - accuracy: 0.7303\n",
            "Epoch 570: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 1.0515 - accuracy: 0.7206 - val_loss: 1.7154 - val_accuracy: 0.6526\n",
            "Epoch 571/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.7672 - accuracy: 0.7560\n",
            "Epoch 571: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.7672 - accuracy: 0.7560 - val_loss: 1.6831 - val_accuracy: 0.6780\n",
            "Epoch 572/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.4083 - accuracy: 0.8554\n",
            "Epoch 572: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4083 - accuracy: 0.8554 - val_loss: 1.4342 - val_accuracy: 0.7496\n",
            "Epoch 573/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.3667 - accuracy: 0.8734\n",
            "Epoch 573: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3670 - accuracy: 0.8730 - val_loss: 1.7129 - val_accuracy: 0.6840\n",
            "Epoch 574/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.3774 - accuracy: 0.8676\n",
            "Epoch 574: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.3785 - accuracy: 0.8676 - val_loss: 1.5346 - val_accuracy: 0.7160\n",
            "Epoch 575/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.4126 - accuracy: 0.8542\n",
            "Epoch 575: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.8540 - val_loss: 1.5471 - val_accuracy: 0.7127\n",
            "Epoch 576/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.7473 - accuracy: 0.7678\n",
            "Epoch 576: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.7440 - accuracy: 0.7690 - val_loss: 1.7492 - val_accuracy: 0.6645\n",
            "Epoch 577/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.3975 - accuracy: 0.8600\n",
            "Epoch 577: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3886 - accuracy: 0.8631 - val_loss: 1.4714 - val_accuracy: 0.7415\n",
            "Epoch 578/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.3353 - accuracy: 0.8819\n",
            "Epoch 578: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3366 - accuracy: 0.8813 - val_loss: 1.5373 - val_accuracy: 0.7312\n",
            "Epoch 579/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.4544 - accuracy: 0.8396\n",
            "Epoch 579: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4545 - accuracy: 0.8388 - val_loss: 1.5422 - val_accuracy: 0.7285\n",
            "Epoch 580/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.3746 - accuracy: 0.8636\n",
            "Epoch 580: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3754 - accuracy: 0.8635 - val_loss: 1.5199 - val_accuracy: 0.7149\n",
            "Epoch 581/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.3698 - accuracy: 0.8706\n",
            "Epoch 581: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.3694 - accuracy: 0.8714 - val_loss: 1.5267 - val_accuracy: 0.7290\n",
            "Epoch 582/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.3675 - accuracy: 0.8684\n",
            "Epoch 582: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3715 - accuracy: 0.8673 - val_loss: 1.5550 - val_accuracy: 0.7312\n",
            "Epoch 583/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.3785 - accuracy: 0.8638\n",
            "Epoch 583: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3785 - accuracy: 0.8635 - val_loss: 1.5984 - val_accuracy: 0.7079\n",
            "Epoch 584/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.3836 - accuracy: 0.8591\n",
            "Epoch 584: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3819 - accuracy: 0.8594 - val_loss: 1.5733 - val_accuracy: 0.7133\n",
            "Epoch 585/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.3286 - accuracy: 0.8827\n",
            "Epoch 585: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3417 - accuracy: 0.8783 - val_loss: 2.5196 - val_accuracy: 0.5713\n",
            "Epoch 586/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 1.2548 - accuracy: 0.6807\n",
            "Epoch 586: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 1.2105 - accuracy: 0.6881 - val_loss: 1.4819 - val_accuracy: 0.7322\n",
            "Epoch 587/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.3946 - accuracy: 0.8588\n",
            "Epoch 587: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.3971 - accuracy: 0.8574 - val_loss: 1.6385 - val_accuracy: 0.6921\n",
            "Epoch 588/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.3549 - accuracy: 0.8757\n",
            "Epoch 588: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.3533 - accuracy: 0.8768 - val_loss: 1.4300 - val_accuracy: 0.7469\n",
            "Epoch 589/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.3796 - accuracy: 0.8670\n",
            "Epoch 589: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.3796 - accuracy: 0.8670 - val_loss: 1.5492 - val_accuracy: 0.7257\n",
            "Epoch 590/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.3640 - accuracy: 0.8705\n",
            "Epoch 590: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.3663 - accuracy: 0.8696 - val_loss: 1.5612 - val_accuracy: 0.7187\n",
            "Epoch 591/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.3400 - accuracy: 0.8811\n",
            "Epoch 591: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.3426 - accuracy: 0.8804 - val_loss: 1.5550 - val_accuracy: 0.7220\n",
            "Epoch 592/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.3476 - accuracy: 0.8747\n",
            "Epoch 592: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.3530 - accuracy: 0.8727 - val_loss: 1.7861 - val_accuracy: 0.6629\n",
            "Epoch 593/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.5464 - accuracy: 0.8114\n",
            "Epoch 593: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 0.5453 - accuracy: 0.8121 - val_loss: 1.6807 - val_accuracy: 0.7133\n",
            "Epoch 594/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.3413 - accuracy: 0.8759\n",
            "Epoch 594: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3416 - accuracy: 0.8754 - val_loss: 1.4962 - val_accuracy: 0.7312\n",
            "Epoch 595/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.3026 - accuracy: 0.8896\n",
            "Epoch 595: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.3094 - accuracy: 0.8861 - val_loss: 1.4939 - val_accuracy: 0.7306\n",
            "Epoch 596/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 2.0415 - accuracy: 0.6313\n",
            "Epoch 596: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.0322 - accuracy: 0.6321 - val_loss: 2.6464 - val_accuracy: 0.5089\n",
            "Epoch 597/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.8244 - accuracy: 0.7323\n",
            "Epoch 597: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.8039 - accuracy: 0.7376 - val_loss: 1.6157 - val_accuracy: 0.6889\n",
            "Epoch 598/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.4821 - accuracy: 0.8338\n",
            "Epoch 598: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4749 - accuracy: 0.8357 - val_loss: 1.5140 - val_accuracy: 0.7041\n",
            "Epoch 599/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.3395 - accuracy: 0.8855\n",
            "Epoch 599: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3395 - accuracy: 0.8855 - val_loss: 1.4352 - val_accuracy: 0.7317\n",
            "Epoch 600/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.3074 - accuracy: 0.8942\n",
            "Epoch 600: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 0.3118 - accuracy: 0.8918 - val_loss: 1.6388 - val_accuracy: 0.7024\n",
            "Epoch 601/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.4366 - accuracy: 0.8436\n",
            "Epoch 601: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4366 - accuracy: 0.8436 - val_loss: 1.8717 - val_accuracy: 0.6602\n",
            "Epoch 602/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.3913 - accuracy: 0.8628\n",
            "Epoch 602: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.3929 - accuracy: 0.8620 - val_loss: 1.5408 - val_accuracy: 0.7144\n",
            "Epoch 603/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.4026 - accuracy: 0.8540\n",
            "Epoch 603: val_accuracy did not improve from 0.75230\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4004 - accuracy: 0.8543 - val_loss: 1.4888 - val_accuracy: 0.7220\n",
            "Epoch 604/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.3392 - accuracy: 0.8790\n",
            "Epoch 604: val_accuracy improved from 0.75230 to 0.75501, saving model to /content/asl/Adam3/cp-604-0.76.hdf5\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3386 - accuracy: 0.8784 - val_loss: 1.4396 - val_accuracy: 0.7550\n",
            "Epoch 605/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.5368 - accuracy: 0.8137\n",
            "Epoch 605: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5390 - accuracy: 0.8112 - val_loss: 1.8143 - val_accuracy: 0.6726\n",
            "Epoch 606/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.4188 - accuracy: 0.8487\n",
            "Epoch 606: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4083 - accuracy: 0.8527 - val_loss: 1.4622 - val_accuracy: 0.7198\n",
            "Epoch 607/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.4295 - accuracy: 0.8464\n",
            "Epoch 607: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4288 - accuracy: 0.8464 - val_loss: 1.5403 - val_accuracy: 0.7214\n",
            "Epoch 608/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.3770 - accuracy: 0.8678\n",
            "Epoch 608: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.3857 - accuracy: 0.8624 - val_loss: 1.6949 - val_accuracy: 0.6976\n",
            "Epoch 609/700\n",
            "50/58 [========================>.....] - ETA: 0s - loss: 0.3442 - accuracy: 0.8772\n",
            "Epoch 609: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3362 - accuracy: 0.8804 - val_loss: 1.4919 - val_accuracy: 0.7534\n",
            "Epoch 610/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.2788 - accuracy: 0.9072\n",
            "Epoch 610: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2786 - accuracy: 0.9078 - val_loss: 1.5275 - val_accuracy: 0.7225\n",
            "Epoch 611/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.4182 - accuracy: 0.8494\n",
            "Epoch 611: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4199 - accuracy: 0.8493 - val_loss: 1.5505 - val_accuracy: 0.7398\n",
            "Epoch 612/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.3782 - accuracy: 0.8617\n",
            "Epoch 612: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.3840 - accuracy: 0.8608 - val_loss: 2.0200 - val_accuracy: 0.6331\n",
            "Epoch 613/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.5276 - accuracy: 0.8151\n",
            "Epoch 613: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5245 - accuracy: 0.8146 - val_loss: 1.6061 - val_accuracy: 0.7084\n",
            "Epoch 614/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.3716 - accuracy: 0.8638\n",
            "Epoch 614: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3716 - accuracy: 0.8638 - val_loss: 1.8430 - val_accuracy: 0.6694\n",
            "Epoch 615/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 1.0091 - accuracy: 0.7235\n",
            "Epoch 615: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 1s 18ms/step - loss: 1.0091 - accuracy: 0.7235 - val_loss: 1.8740 - val_accuracy: 0.6379\n",
            "Epoch 616/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.3949 - accuracy: 0.8571\n",
            "Epoch 616: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 1s 19ms/step - loss: 0.3949 - accuracy: 0.8571 - val_loss: 1.5073 - val_accuracy: 0.7306\n",
            "Epoch 617/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.3184 - accuracy: 0.8932\n",
            "Epoch 617: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 1s 17ms/step - loss: 0.3188 - accuracy: 0.8932 - val_loss: 1.4387 - val_accuracy: 0.7523\n",
            "Epoch 618/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.3058 - accuracy: 0.8905\n",
            "Epoch 618: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 1s 16ms/step - loss: 0.3084 - accuracy: 0.8887 - val_loss: 1.5734 - val_accuracy: 0.7285\n",
            "Epoch 619/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.4469 - accuracy: 0.8415\n",
            "Epoch 619: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 1s 15ms/step - loss: 0.4469 - accuracy: 0.8415 - val_loss: 1.5355 - val_accuracy: 0.7203\n",
            "Epoch 620/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.3764 - accuracy: 0.8650\n",
            "Epoch 620: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 1s 16ms/step - loss: 0.3762 - accuracy: 0.8647 - val_loss: 1.7457 - val_accuracy: 0.6905\n",
            "Epoch 621/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.3531 - accuracy: 0.8723\n",
            "Epoch 621: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 1s 16ms/step - loss: 0.3479 - accuracy: 0.8747 - val_loss: 1.7632 - val_accuracy: 0.6775\n",
            "Epoch 622/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.3796 - accuracy: 0.8617\n",
            "Epoch 622: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 1s 16ms/step - loss: 0.3830 - accuracy: 0.8605 - val_loss: 1.8024 - val_accuracy: 0.6547\n",
            "Epoch 623/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.4288 - accuracy: 0.8466\n",
            "Epoch 623: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 1s 18ms/step - loss: 0.4288 - accuracy: 0.8466 - val_loss: 1.5503 - val_accuracy: 0.7274\n",
            "Epoch 624/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.4015 - accuracy: 0.8590\n",
            "Epoch 624: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 1s 14ms/step - loss: 0.4045 - accuracy: 0.8574 - val_loss: 1.6486 - val_accuracy: 0.6883\n",
            "Epoch 625/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.7085 - accuracy: 0.7891\n",
            "Epoch 625: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.7643 - accuracy: 0.7800 - val_loss: 2.9681 - val_accuracy: 0.5301\n",
            "Epoch 626/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.8097 - accuracy: 0.7407\n",
            "Epoch 626: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 1s 16ms/step - loss: 0.7870 - accuracy: 0.7471 - val_loss: 1.5596 - val_accuracy: 0.7127\n",
            "Epoch 627/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.3502 - accuracy: 0.8766\n",
            "Epoch 627: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 1s 13ms/step - loss: 0.3502 - accuracy: 0.8766 - val_loss: 1.4970 - val_accuracy: 0.7285\n",
            "Epoch 628/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.3862 - accuracy: 0.8583\n",
            "Epoch 628: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 1s 15ms/step - loss: 0.3862 - accuracy: 0.8583 - val_loss: 1.5168 - val_accuracy: 0.7312\n",
            "Epoch 629/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.2863 - accuracy: 0.8996\n",
            "Epoch 629: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 1s 14ms/step - loss: 0.2863 - accuracy: 0.8996 - val_loss: 1.4718 - val_accuracy: 0.7507\n",
            "Epoch 630/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.2996 - accuracy: 0.8967\n",
            "Epoch 630: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 1s 20ms/step - loss: 0.2996 - accuracy: 0.8967 - val_loss: 1.4885 - val_accuracy: 0.7512\n",
            "Epoch 631/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.3695 - accuracy: 0.8620\n",
            "Epoch 631: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 1s 18ms/step - loss: 0.3695 - accuracy: 0.8620 - val_loss: 1.8472 - val_accuracy: 0.6569\n",
            "Epoch 632/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.4882 - accuracy: 0.8318\n",
            "Epoch 632: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 1s 23ms/step - loss: 0.4856 - accuracy: 0.8326 - val_loss: 1.9199 - val_accuracy: 0.6385\n",
            "Epoch 633/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.3953 - accuracy: 0.8616\n",
            "Epoch 633: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 1s 22ms/step - loss: 0.3996 - accuracy: 0.8605 - val_loss: 1.5510 - val_accuracy: 0.6992\n",
            "Epoch 634/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.3955 - accuracy: 0.8584\n",
            "Epoch 634: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 1s 25ms/step - loss: 0.3924 - accuracy: 0.8585 - val_loss: 1.6077 - val_accuracy: 0.7106\n",
            "Epoch 635/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.3056 - accuracy: 0.8916\n",
            "Epoch 635: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 1s 17ms/step - loss: 0.3061 - accuracy: 0.8906 - val_loss: 1.5014 - val_accuracy: 0.7436\n",
            "Epoch 636/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.2860 - accuracy: 0.9008\n",
            "Epoch 636: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 1s 22ms/step - loss: 0.2861 - accuracy: 0.9008 - val_loss: 1.6037 - val_accuracy: 0.7144\n",
            "Epoch 637/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.3995 - accuracy: 0.8595\n",
            "Epoch 637: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 1s 16ms/step - loss: 0.3994 - accuracy: 0.8596 - val_loss: 1.4539 - val_accuracy: 0.7507\n",
            "Epoch 638/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8617\n",
            "Epoch 638: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 1s 18ms/step - loss: 0.3794 - accuracy: 0.8625 - val_loss: 1.6841 - val_accuracy: 0.6905\n",
            "Epoch 639/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.3737 - accuracy: 0.8642\n",
            "Epoch 639: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 1s 14ms/step - loss: 0.3796 - accuracy: 0.8620 - val_loss: 1.5438 - val_accuracy: 0.7382\n",
            "Epoch 640/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.4304 - accuracy: 0.8434\n",
            "Epoch 640: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 1s 18ms/step - loss: 0.4304 - accuracy: 0.8434 - val_loss: 1.5696 - val_accuracy: 0.7144\n",
            "Epoch 641/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.4031 - accuracy: 0.8574\n",
            "Epoch 641: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 1s 19ms/step - loss: 0.4230 - accuracy: 0.8531 - val_loss: 1.9894 - val_accuracy: 0.6293\n",
            "Epoch 642/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 1.1635 - accuracy: 0.6848\n",
            "Epoch 642: val_accuracy did not improve from 0.75501\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.1322 - accuracy: 0.6912 - val_loss: 1.6404 - val_accuracy: 0.6726\n",
            "Epoch 643/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.3832 - accuracy: 0.8645\n",
            "Epoch 643: val_accuracy improved from 0.75501 to 0.75556, saving model to /content/asl/Adam3/cp-643-0.76.hdf5\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.3816 - accuracy: 0.8650 - val_loss: 1.4210 - val_accuracy: 0.7556\n",
            "Epoch 644/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.3307 - accuracy: 0.8787\n",
            "Epoch 644: val_accuracy did not improve from 0.75556\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3309 - accuracy: 0.8787 - val_loss: 1.4854 - val_accuracy: 0.7550\n",
            "Epoch 645/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.2984 - accuracy: 0.8943\n",
            "Epoch 645: val_accuracy did not improve from 0.75556\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2984 - accuracy: 0.8943 - val_loss: 1.4675 - val_accuracy: 0.7463\n",
            "Epoch 646/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.2697 - accuracy: 0.9068\n",
            "Epoch 646: val_accuracy did not improve from 0.75556\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2705 - accuracy: 0.9061 - val_loss: 1.5544 - val_accuracy: 0.7295\n",
            "Epoch 647/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.3350 - accuracy: 0.8830\n",
            "Epoch 647: val_accuracy did not improve from 0.75556\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.3641 - accuracy: 0.8742 - val_loss: 1.5720 - val_accuracy: 0.7182\n",
            "Epoch 648/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.4686 - accuracy: 0.8348\n",
            "Epoch 648: val_accuracy did not improve from 0.75556\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.4877 - accuracy: 0.8278 - val_loss: 1.8850 - val_accuracy: 0.6618\n",
            "Epoch 649/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.3919 - accuracy: 0.8567\n",
            "Epoch 649: val_accuracy did not improve from 0.75556\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3919 - accuracy: 0.8567 - val_loss: 1.5337 - val_accuracy: 0.7274\n",
            "Epoch 650/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.3474 - accuracy: 0.8752\n",
            "Epoch 650: val_accuracy did not improve from 0.75556\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3397 - accuracy: 0.8780 - val_loss: 1.4984 - val_accuracy: 0.7469\n",
            "Epoch 651/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.2709 - accuracy: 0.9052\n",
            "Epoch 651: val_accuracy did not improve from 0.75556\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2709 - accuracy: 0.9052 - val_loss: 1.5404 - val_accuracy: 0.7295\n",
            "Epoch 652/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.3698 - accuracy: 0.8653\n",
            "Epoch 652: val_accuracy did not improve from 0.75556\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.3700 - accuracy: 0.8651 - val_loss: 1.5637 - val_accuracy: 0.7127\n",
            "Epoch 653/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.3127 - accuracy: 0.8858\n",
            "Epoch 653: val_accuracy did not improve from 0.75556\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 0.3144 - accuracy: 0.8853 - val_loss: 1.5048 - val_accuracy: 0.7339\n",
            "Epoch 654/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8642\n",
            "Epoch 654: val_accuracy did not improve from 0.75556\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.3815 - accuracy: 0.8644 - val_loss: 1.5350 - val_accuracy: 0.7339\n",
            "Epoch 655/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.4898 - accuracy: 0.8359\n",
            "Epoch 655: val_accuracy did not improve from 0.75556\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 0.4966 - accuracy: 0.8335 - val_loss: 1.7944 - val_accuracy: 0.6699\n",
            "Epoch 656/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.6411 - accuracy: 0.7800\n",
            "Epoch 656: val_accuracy did not improve from 0.75556\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.6411 - accuracy: 0.7800 - val_loss: 1.7997 - val_accuracy: 0.6694\n",
            "Epoch 657/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.4785 - accuracy: 0.8239\n",
            "Epoch 657: val_accuracy did not improve from 0.75556\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 0.4738 - accuracy: 0.8255 - val_loss: 1.6626 - val_accuracy: 0.7127\n",
            "Epoch 658/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.3169 - accuracy: 0.8871\n",
            "Epoch 658: val_accuracy did not improve from 0.75556\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.3174 - accuracy: 0.8874 - val_loss: 1.6764 - val_accuracy: 0.7187\n",
            "Epoch 659/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.3399 - accuracy: 0.8727\n",
            "Epoch 659: val_accuracy did not improve from 0.75556\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.3414 - accuracy: 0.8719 - val_loss: 1.6262 - val_accuracy: 0.7160\n",
            "Epoch 660/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.4516 - accuracy: 0.8320\n",
            "Epoch 660: val_accuracy did not improve from 0.75556\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4367 - accuracy: 0.8372 - val_loss: 1.6833 - val_accuracy: 0.6992\n",
            "Epoch 661/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.3331 - accuracy: 0.8824\n",
            "Epoch 661: val_accuracy did not improve from 0.75556\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3425 - accuracy: 0.8785 - val_loss: 1.5473 - val_accuracy: 0.7447\n",
            "Epoch 662/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.5113 - accuracy: 0.8277\n",
            "Epoch 662: val_accuracy did not improve from 0.75556\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5274 - accuracy: 0.8228 - val_loss: 2.3288 - val_accuracy: 0.5919\n",
            "Epoch 663/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.5877 - accuracy: 0.8044\n",
            "Epoch 663: val_accuracy did not improve from 0.75556\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5828 - accuracy: 0.8062 - val_loss: 1.6902 - val_accuracy: 0.6856\n",
            "Epoch 664/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.4101 - accuracy: 0.8469\n",
            "Epoch 664: val_accuracy did not improve from 0.75556\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4126 - accuracy: 0.8455 - val_loss: 1.7740 - val_accuracy: 0.6678\n",
            "Epoch 665/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.9652 - accuracy: 0.7253\n",
            "Epoch 665: val_accuracy did not improve from 0.75556\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.9661 - accuracy: 0.7251 - val_loss: 1.5971 - val_accuracy: 0.7079\n",
            "Epoch 666/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.4176 - accuracy: 0.8475\n",
            "Epoch 666: val_accuracy did not improve from 0.75556\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4132 - accuracy: 0.8489 - val_loss: 1.4750 - val_accuracy: 0.7366\n",
            "Epoch 667/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.3147 - accuracy: 0.8896\n",
            "Epoch 667: val_accuracy did not improve from 0.75556\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3145 - accuracy: 0.8897 - val_loss: 1.4665 - val_accuracy: 0.7491\n",
            "Epoch 668/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.2676 - accuracy: 0.9078\n",
            "Epoch 668: val_accuracy did not improve from 0.75556\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2675 - accuracy: 0.9077 - val_loss: 1.7030 - val_accuracy: 0.6862\n",
            "Epoch 669/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.2935 - accuracy: 0.8941\n",
            "Epoch 669: val_accuracy improved from 0.75556 to 0.75610, saving model to /content/asl/Adam3/cp-669-0.76.hdf5\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.2936 - accuracy: 0.8940 - val_loss: 1.4711 - val_accuracy: 0.7561\n",
            "Epoch 670/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.2779 - accuracy: 0.9029\n",
            "Epoch 670: val_accuracy did not improve from 0.75610\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2774 - accuracy: 0.9028 - val_loss: 1.5023 - val_accuracy: 0.7420\n",
            "Epoch 671/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.3462 - accuracy: 0.8730\n",
            "Epoch 671: val_accuracy did not improve from 0.75610\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3605 - accuracy: 0.8676 - val_loss: 2.0360 - val_accuracy: 0.6347\n",
            "Epoch 672/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.5956 - accuracy: 0.8040\n",
            "Epoch 672: val_accuracy did not improve from 0.75610\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.5823 - accuracy: 0.8071 - val_loss: 1.9011 - val_accuracy: 0.6396\n",
            "Epoch 673/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.4821 - accuracy: 0.8393\n",
            "Epoch 673: val_accuracy did not improve from 0.75610\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4788 - accuracy: 0.8407 - val_loss: 1.7424 - val_accuracy: 0.7057\n",
            "Epoch 674/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.3613 - accuracy: 0.8701\n",
            "Epoch 674: val_accuracy did not improve from 0.75610\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3576 - accuracy: 0.8718 - val_loss: 1.6027 - val_accuracy: 0.7339\n",
            "Epoch 675/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.2759 - accuracy: 0.9027\n",
            "Epoch 675: val_accuracy did not improve from 0.75610\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2758 - accuracy: 0.9024 - val_loss: 1.5389 - val_accuracy: 0.7447\n",
            "Epoch 676/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.3138 - accuracy: 0.8865\n",
            "Epoch 676: val_accuracy did not improve from 0.75610\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3138 - accuracy: 0.8865 - val_loss: 1.5451 - val_accuracy: 0.7241\n",
            "Epoch 677/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.2699 - accuracy: 0.9065\n",
            "Epoch 677: val_accuracy did not improve from 0.75610\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2712 - accuracy: 0.9065 - val_loss: 1.5012 - val_accuracy: 0.7491\n",
            "Epoch 678/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.2979 - accuracy: 0.8915\n",
            "Epoch 678: val_accuracy did not improve from 0.75610\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3006 - accuracy: 0.8898 - val_loss: 1.5063 - val_accuracy: 0.7518\n",
            "Epoch 679/700\n",
            "51/58 [=========================>....] - ETA: 0s - loss: 0.3736 - accuracy: 0.8604\n",
            "Epoch 679: val_accuracy did not improve from 0.75610\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3665 - accuracy: 0.8640 - val_loss: 1.5750 - val_accuracy: 0.7377\n",
            "Epoch 680/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.3988 - accuracy: 0.8647\n",
            "Epoch 680: val_accuracy did not improve from 0.75610\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.4339 - accuracy: 0.8558 - val_loss: 2.0288 - val_accuracy: 0.6417\n",
            "Epoch 681/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.6384 - accuracy: 0.7934\n",
            "Epoch 681: val_accuracy did not improve from 0.75610\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.6346 - accuracy: 0.7942 - val_loss: 1.5293 - val_accuracy: 0.7285\n",
            "Epoch 682/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.4040 - accuracy: 0.8489\n",
            "Epoch 682: val_accuracy did not improve from 0.75610\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.4040 - accuracy: 0.8489 - val_loss: 1.6867 - val_accuracy: 0.7079\n",
            "Epoch 683/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.5418 - accuracy: 0.8132\n",
            "Epoch 683: val_accuracy did not improve from 0.75610\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.5415 - accuracy: 0.8135 - val_loss: 1.5148 - val_accuracy: 0.7295\n",
            "Epoch 684/700\n",
            "53/58 [==========================>...] - ETA: 0s - loss: 0.3441 - accuracy: 0.8753\n",
            "Epoch 684: val_accuracy did not improve from 0.75610\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 0.3385 - accuracy: 0.8768 - val_loss: 1.4868 - val_accuracy: 0.7491\n",
            "Epoch 685/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.3065 - accuracy: 0.8901\n",
            "Epoch 685: val_accuracy did not improve from 0.75610\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.3122 - accuracy: 0.8874 - val_loss: 1.5072 - val_accuracy: 0.7491\n",
            "Epoch 686/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.9593 - accuracy: 0.7292\n",
            "Epoch 686: val_accuracy did not improve from 0.75610\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 0.9487 - accuracy: 0.7311 - val_loss: 2.0564 - val_accuracy: 0.6217\n",
            "Epoch 687/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.4498 - accuracy: 0.8358\n",
            "Epoch 687: val_accuracy did not improve from 0.75610\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.4511 - accuracy: 0.8356 - val_loss: 1.4804 - val_accuracy: 0.7350\n",
            "Epoch 688/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.3476 - accuracy: 0.8743\n",
            "Epoch 688: val_accuracy did not improve from 0.75610\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3476 - accuracy: 0.8743 - val_loss: 1.4984 - val_accuracy: 0.7453\n",
            "Epoch 689/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.2987 - accuracy: 0.8943\n",
            "Epoch 689: val_accuracy did not improve from 0.75610\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2981 - accuracy: 0.8945 - val_loss: 1.5419 - val_accuracy: 0.7333\n",
            "Epoch 690/700\n",
            "55/58 [===========================>..] - ETA: 0s - loss: 0.2650 - accuracy: 0.9109\n",
            "Epoch 690: val_accuracy did not improve from 0.75610\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2712 - accuracy: 0.9080 - val_loss: 1.7507 - val_accuracy: 0.6927\n",
            "Epoch 691/700\n",
            "54/58 [==========================>...] - ETA: 0s - loss: 0.3537 - accuracy: 0.8737\n",
            "Epoch 691: val_accuracy did not improve from 0.75610\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3513 - accuracy: 0.8746 - val_loss: 1.5167 - val_accuracy: 0.7415\n",
            "Epoch 692/700\n",
            "52/58 [=========================>....] - ETA: 0s - loss: 0.2955 - accuracy: 0.8918\n",
            "Epoch 692: val_accuracy did not improve from 0.75610\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3012 - accuracy: 0.8888 - val_loss: 1.5375 - val_accuracy: 0.7339\n",
            "Epoch 693/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.3008 - accuracy: 0.8936\n",
            "Epoch 693: val_accuracy did not improve from 0.75610\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3008 - accuracy: 0.8936 - val_loss: 1.5173 - val_accuracy: 0.7360\n",
            "Epoch 694/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.5708 - accuracy: 0.8013\n",
            "Epoch 694: val_accuracy did not improve from 0.75610\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5708 - accuracy: 0.8013 - val_loss: 1.5717 - val_accuracy: 0.7241\n",
            "Epoch 695/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.3675 - accuracy: 0.8654\n",
            "Epoch 695: val_accuracy did not improve from 0.75610\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3666 - accuracy: 0.8662 - val_loss: 1.5635 - val_accuracy: 0.7247\n",
            "Epoch 696/700\n",
            "57/58 [============================>.] - ETA: 0s - loss: 0.2984 - accuracy: 0.8876\n",
            "Epoch 696: val_accuracy did not improve from 0.75610\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2976 - accuracy: 0.8880 - val_loss: 1.5338 - val_accuracy: 0.7409\n",
            "Epoch 697/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.2526 - accuracy: 0.9131\n",
            "Epoch 697: val_accuracy did not improve from 0.75610\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2526 - accuracy: 0.9131 - val_loss: 1.5401 - val_accuracy: 0.7339\n",
            "Epoch 698/700\n",
            "56/58 [===========================>..] - ETA: 0s - loss: 0.3189 - accuracy: 0.8838\n",
            "Epoch 698: val_accuracy did not improve from 0.75610\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3212 - accuracy: 0.8827 - val_loss: 1.6785 - val_accuracy: 0.7160\n",
            "Epoch 699/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.6405 - accuracy: 0.7879\n",
            "Epoch 699: val_accuracy did not improve from 0.75610\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.6405 - accuracy: 0.7879 - val_loss: 1.7568 - val_accuracy: 0.6645\n",
            "Epoch 700/700\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.3807 - accuracy: 0.8639\n",
            "Epoch 700: val_accuracy did not improve from 0.75610\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3807 - accuracy: 0.8639 - val_loss: 1.4910 - val_accuracy: 0.7453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "i notice that is the downsampling method on the fututer dont improve the accuracy"
      ],
      "metadata": {
        "id": "ZivD_c1c9B30"
      }
    }
  ]
}